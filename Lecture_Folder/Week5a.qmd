---
title: "Week 5a - Statistics for Bioengineering"
author: "Bill Cresko"
format: 
  revealjs:
    transition: fade
    transition-speed: slow
editor: visual
---

```{r}
library(tidyverse)
library(gt)
library(readxl)
library(nycflights23)
theme_set(theme_minimal())
```

## This week

-   Finish Power

-   Start linear models

-   Eugenics foundations of statistics

# Statistical Power

## Power

-   Helps us to interpret the failure to reject a null hypothesis
-   What factors can affect the power of our experiment - our ability to avoid a Type 2 error?
    -   Sample size
    -   Effect size (difference between the groups)
    -   Variance (range of values for this trait/measure)

## Power

-   **Type 1 error** - $\alpha$ - incorrectly rejecting a true null hypothesis
    -   This is saying that there is an effect when there isn’t
-   **Type 2 error** - $\beta$ - incorrectly accepting a false null hypothesis
    -   This is saying that there isn’t an effect when there is
-   Power is the probability of rejecting a false null hypothesis and avoiding type II error
-   Mostly we shoot for a power of around 80%
-   Just like $\alpha$, we want to calculate our power **in advance**

## Key components of power

-   **Effect Size (ES)**: The magnitude of the difference you expect to detect.
-   **Sampling standard deviation (sd):** a measure of variability within groups
-   **Sample Size (n)**: The number of observations in the study.
-   **Significance Level (**$\alpha$**)**: The probability of committing a Type I error (rejecting the null hypothesis when it is true), typically set at 0.05.
-   **Power (1 -** $\beta$**)**: The probability of correctly rejecting the null hypothesis, commonly set at 0.80 or 80%.

## Effect size measured as Cohen's D

-   Cohen's d is a statistical measure that quantifies the effect size between two group means, expressing the difference in standard deviation units.
-   It's used to determine the magnitude of the difference between two groups in studies, like those using t-tests or ANOVA.
-   Cohen's d is calculated by dividing the difference between the two group means by the pooled standard deviation.

## Why Perform Power Analysis?

Here are the main reasons Why we Perform Power Analysis.

-   ***Determine Sample Size***: To ensure your study has enough participants to detect the expected effect.
-   ***Assess Test Feasibility***: To understand if your study can achieve meaningful results with available resources.
-   ***Optimize Resource Allocation***: To avoid over- or under-sampling, ensuring efficient use of time and resources.

## Power {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6b.002.jpeg")
```

## Power - rough calculation

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6b.003.jpeg")
```

## Parametric Power in R {.smaller}

R provides several packages for conducting power analysis, including `pwr` and `statmod`. We'll explore examples using the `pwr` package.

```{r, echo=TRUE}
library(pwr)

# Parameters
effect_size <- 0.4 # The difference between null and alternative hypotheses
sample_size <- 50 # The number of observations in each group
sd <- 4 # The standard deviation
alpha <- 0.05 # The significance level
```

```{r, echo=TRUE}
# Calculate Type II Error
pwr_result <-pwr.t.test(n = sample_size, 
                        d = effect_size / sd, 
                        sig.level = alpha,
                        type = "two.sample",
                        alternative = "two.sided")

type_II_error <- 1 - pwr_result$power
power <- pwr_result$power
```

```{r, echo=TRUE}
print(type_II_error)
print(power)
```

## Calculate sample size needed {.smaller}

```{r, echo=TRUE}

# Parameters for two-sample t-test
effect_size_t <- 2.0  
sd <- 2
d_calc <- effect_size_t/sd # Moderate effect size (Cohen's d)
alpha_t <- 0.05       # Significance level
power_t <- 0.8        # Desired power

# Calculate required sample size
sample_size_t <- pwr.t.test(d = d_calc, 
                            sig.level = alpha_t, 
                            power = power_t, 
                            type = "two.sample")$n

# Output the result
cat("Sample Size for Two-Sample t-Test:", sample_size_t, "\n")

```

## Generate Power Curve for Two-Sample t-Test {.smaller}

Now we will generate power curve for Two-Sample t-Test.

-   sample_size_curve: Specifies the sample size per group (100 in this case).

-   effect_sizes_curve: Defines a range of effect sizes (Cohen's d) from 0.2 to 0.8 with a step of 0.1.

-   Next calculates the power values for the power curve by iterating through the specified range of effect sizes and using the `pwr.t.test` function for each effect size to calculate power based on the given sample size, significance level, and type of test.

-   Finally, plots the power curve using the calculated power values against the effect sizes, with appropriate labels for the axes and title for the plot. It visualizes how power varies with different effect sizes in the two-sample t-test scenario.

## Generate Power Curve for Two-Sample t-Test {.smaller}

```{r, echo=TRUE}
# Parameters for power curve
sample_size_curve <- 100    # Sample size per group
effect_sizes_curve <- seq(0.2, 0.8, by = 0.1)  # Range of effect sizes

# Calculate power values
power_values_curve <- sapply(effect_sizes_curve, function(d) pwr.t.test(d = d, 
                                                     n = sample_size_curve, 
                                                     sig.level = alpha_t, 
                                                     type = "two.sample")$power)
```

```{r, echo=TRUE}
# Plot power curve
plot(effect_sizes_curve, power_values_curve, type = "b",
     main = "Power Curve for Two-Sample t-Test",
     xlab = "Effect Size (Cohen's d)",
     ylab = "Power",
     ylim = c(0, 1))
```

## Generate a Sample Curve for Two-Sample t-Test {.smaller}

```{r, echo=TRUE}
effect_size_t <- 2.0  
sd < - 2.0
d_calc <- effect_size_t/sd  # Moderate effect size (Cohen's d)
alpha_t <- 0.05             # Significance level
power_t <- 0.8              # Desired power

sample_sizes_curve <- seq(2, 200, by = 2)     # Sample size per group
effect_sizes_curve <- 0.4                     # Range of effect sizes

# Calculate power values
power_values_curve <- sapply(effect_sizes_curve, function(d) pwr.t.test(d = d_calc, 
                                                     n = sample_sizes_curve, 
                                                     sig.level = alpha_t, 
                                                     type = "two.sample")$power)
```

## Plot power curve

```{r, echo=TRUE}
plot(sample_sizes_curve, power_values_curve, type = "b",
     main = "Sample sizes for Two-Sample t-Test",
     xlab = "Sample size",
     ylab = "Power",
     ylim = c(0, 1))
```

## Conduct A Priori Power Analysis for One-Way ANOVA {.smaller}

Here, we set the parameters for conducting a one-way ANOVA power analysis, similar to the t-test but with different effect size and significance level.

`pwr.anova.test` function to calculate the required sample size (`sample_size_anova`) for the one-way ANOVA based on the specified effect size, number of groups (k = 3), significance level, and desired power.

```{r, echo=TRUE}
# Parameters for one-way ANOVA
effect_size_anova <- 0.25  # Small effect size (Cohen's f)
alpha_anova <- 0.05        # Significance level
power_anova <- 0.8         # Desired power

# Calculate required sample size
sample_size_anova <- pwr.anova.test(k = 3, f = effect_size_anova, 
                                    sig.level = alpha_anova, 
                                    power = power_anova)$n

# Output the result
cat("Sample Size for One-Way ANOVA:", sample_size_anova, "\n")
```

## Cohen's f {.smaller}

-   Cohen's f is an effect size statistic used in Analysis of Variance (ANOVA).

-   It measures the amount of variance in the dependent variable that is explained by the independent variable(s), or more generally, how much the group means differ from the grand mean.

-   Cohen's f, along with other effect size measures, provides a standardized way to assess the magnitude of the effect observed in an ANOVA, going beyond simply determining statistical significance.

-   Cohen's f is calculated as the square root of the variance due to the independent variable(s) divided by the total variance (or the variance within groups, depending on the specific type of ANOVA).

-   Cohen (1988) suggested the following interpretation for f:

    -   f = 0.10 is considered a small effect.
    -   f = 0.25 is considered a medium effect.
    -   f = 0.40 is considered a large effect.

## On your own - Bootstrap resampling power calculation {.smaller}

Step 1: simulating our true populations

-   What is the distribution type?

-   What is the effect size: difference in means between populations?

-   What is the variance?

## On your own - Bootstrap resampling power calculation {.smaller}

Step 1: simulating our true populations

```{r, echo=TRUE}
senior <- rpois(5000, lambda = 10)
fresh <- rpois(5000, lambda = 12)
```

```{r, echo=TRUE, out.width="40%"}
hist(senior)
hist(fresh)
```

## On your own - Bootstrap resampling power calculation {.smaller}

Step 2: drawing a sample

```{r, echo=TRUE}
sample_s <- sample(senior, size = 10, replace = FALSE)
sample_f <- sample(fresh, size = 10, replace = FALSE)
```

Step 2: drawing a sample

```{r, echo=TRUE, out.width="40%"}
hist(sample_s)
hist(sample_f)
```

## On your own - Bootstrap resampling power calculation {.smaller}

Step 3: statistical test

```{r, echo=TRUE}
t.test(sample_f, sample_s)
```

## On your own - Bootstrap resampling power calculation {.smaller}

Step 4: setting up our replicates

Take a look at the "samps_var" vectors, how are they arranged? How would we begin conducting t-tests using each replicate from the two populations?

```{r, echo=TRUE}
## sample size of 10
samps_var_s <- replicate(n = 100, sample(senior, size = 10))
samps_var_f <- replicate(n = 100, sample(fresh, size = 10))
```

## On your own - Bootstrap resampling power calculation {.smaller}

Step 4: Testing our replicates

```{r, echo=TRUE}
# setting up a "test" dataframe
tests <- data.frame(1:100)
tests$SampleSize <- rep("10", 100)

for (i in 1:ncol(samps_var_f)){
  tests$result[i] <- t.test(samps_var_s[,i], samps_var_f[,i])$p.value
}
table(tests$result < 0.05)

```

## On your own - Bootstrap resampling power calculation {.smaller}

Requires a more complex for loop

```{r, echo=TRUE, eval = FALSE}


results <- data.frame()

# using seq to set up the sample sizes

for (x in seq(10,100, by = 10)){
  samps_var_s <- replicate(n = 100, sample(senior, size = x))
  samps_var_f <- replicate(n = 100, sample(fresh, size = x))
  
  tests <- data.frame(1:100)
  tests$SampleSize <- rep(x, 100)
  for (i in 1:100){
    tests$p.value[i] <- t.test(samps_var_s[,i], samps_var_f[,i])$p.value
  }
  results <- rbind(results, tests)
}


```

------------------------------------------------------------------------

# Linear Models and Regression

# What is a linear model?

-   So far, we've been comparing a single quantitative trait between two groups

-   What if we want to compare two quantitative traits and see if there is an interaction between them?

-   We can model linear relationships

    $$ y = B_0 + B_1 x + e $$

    -   e represents the "error" (or "residual") in the model

-   Function `lm()` in R

## Covariance

-   How do we convey that 2 variables covary?
-   Covariance statistic: multiplies each y and x deviation from its respective mean, sums that product across all observations, and divides by the total number of observations to yield an average
-   Positive or negative covariance depending on the direction of the relationship, covariance of 0 if no relationship between the two

## Correlation

-   Remember when we said that the larger the mean, the greater the variance?
    -   Example: trying to compare mean body weight between elephants and mice
-   This also applies to covariance
-   We can calculate a *correlation coefficient* to standardize the covariance measure
    -   Dividing the covariance y the standard deviations of x and y variables
    -   Ranges from -1 to 1, with closer to 1 indicating a perfect linear relationship, and values close to 0 indicating no relationship

## Correlation

```{r, echo = FALSE, out.width="60%"}
knitr::include_graphics("images/week8_correlation.png")
```

## Testing for Correlation

-   We can calculate a t-statistic for our null hypothesis, and there's a function in R for this!
    -   `cor.test()`
-   What were the null and alternative hypotheses?

## Testing for Correlation - Parametric

-   R function `cor.test()`
-   Formal hypothesis tests for correlation
    -   Null hypothesis is no correlation (CC = 0)
    -   Alternative hypothesis is some correlation (CC \> 0 or \< 0)
-   Remember that parametric tests come with assumptions
    -   The relationship being tested is assumed to be linear (as opposed to strongly curvilinear)
    -   The probability distribution of the 2 variables is assumed to be normal

## Assumptions of Parametric Correlation Tests

-   Remember that parametric tests come with assumptions
-   The relationship being tested is assumed to be linear (as opposed to strongly curvilinear)
-   The probability distribution of the 2 variables is assumed to be normal

## Nonparametric Correlation tests

-   Association between variables is monotonic (consistently increasing or decreasing)

-   Spearman's rank correlation test: good for small sample sizes (\< 30)

-   Kendall's tau test: appropriate for larger sample sizes (\> 30)Testing for Correlation

-   Formal hypothesis tests for correlation

    -   Null hypothesis is no correlation (CC = 0)
    -   Alternative hypothesis is some correlation (CC \> 0 or \< 0)

-   We can calculate a t-statistic for our null hypothesis, and there's a function in R for this!

    -   `cor.test()`

## Nonparametric Correlation tests

-   Association between variables is monotonic (consistently increasing or decreasing)
-   Spearman's rank correlation test: good for small sample sizes (\< 30)
-   Kendall's tau test: appropriate for larger sample sizes (\> 30)

## Let's try it - Correlation

-   Check out the help page for `cor.test()`

## Let's try it - Correlation

-   Work with the `Drerio_development_complete.csv` data set
-   Load it into R, and refamiliarize yourself with the contents

```{r}
fish <- read.csv(file ="Drerio_development_complete.csv")
```

## Let's try it - Correlation

-   What variables might be correlated in this data set?
-   Try creating a scatterplot with the different variables. Does anything appear to be correlated?
-   Plot a histogram of the variables - do they appear to be normally distributed?

## Let's try it - Correlation

```{r}
plot(fish$Weight_mg, fish$Length_cm)
```

## Let's try it - Correlation

```{r, echo=FALSE, out.width="40%"}
hist(fish$Weight_mg)
hist(fish$Length_cm)
```

## Let's try it - Correlation

-   Run a correlation test
-   Which method should you use?

```{r, eval=FALSE}
cor.test()
```

## Let's try it - Correlation

-   Run a correlation test

```{r}
cor.test(fish$Weight_mg, fish$Length_cm, method = c("kendall"))
```

# 

## Linear Regression

-   We can model linear relationships
    -   $$ y = B_0 + B_1 x + e $$
    -   e represents the "error" (or "residual") in the model, which accounts for "noise" or random errors in y unexplained by the effect of x
-   Function `lm()` in R

## 

## Parent offspring regression

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_4b.002.jpeg")
```

## Bivariate normality

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_4b.005.jpeg")
```

## Covariance and correlation

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_4b.006.jpeg")
```

## Anscombe's Quartet

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_4b.007.jpeg")
```

## Anscombe's Quartet {.smaller}

-   *Mean* of x in each case 9 (exact)

-   *Variance* of x in each case 11 (exact)

-   Mean of y in each case 7.50 (to 2 decimal places)

-   Variance of y in each case 4.122 or 4.127 (to 3 decimal places)

-   Correlation between x and y in each case 0.816 (to 3 decimal places)

-   Linear regression line in each case $$ y = 3.00 + 0.50x$$

## A linear model to relate two variables

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_4b.008.jpeg")
```

## Many approaches are linear models

-   Is flexible: Applicable to many different study designs
-   Provides a common set of tools (lm in R for fixed effects)
-   Includes tools to estimate parameters:
    -   (e.g. sizes of effects, like the slope, or change in means)
-   Is easier to work with, especially with multiple variables

## Many approaches are linear models

-   Linear regression
-   Single factor ANOVA
-   Analysis of covariance
-   Multiple regression
-   Multi-factor ANOVA
-   Repeated-measures ANOVA

## Plethora of linear models

-   General Linear Model (**GLM**) - two or more continuous variables

-   General Linear Mixed Model (**GLMM**) - a continuous response variable with a mix of continuous and categorical predictor variables

-   Generalized Linear Model - a GLMM that doesn’t assume normality of the response (we’ll get to this later)

-   Generalized Additive Model (**GAM**) - a model that doesn’t assume linearity (we won’t get to this later)

## Linear models {.smaller}

All an be written in the form

response variable = intercept + (explanatory_variables) + random_error

in the general form:

$$ Y=\beta_0 +\beta_1*X_1 + \beta_2*X_2 +... + error$$

where $\beta_0, \beta_1, \beta_2, ....$ are the parameters of the linear model

## linear model parameters

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_4b.010.jpeg")
```

## linear model parameters

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_4b.009.jpeg")
```

## linear models in R

All of these will *include* the intercept

```{r, echo=TRUE, eval=FALSE}
Y~X
Y~1+X
Y~X+1
```

All of these will *exclude* the intercept

```{r, echo=TRUE, eval=FALSE}
Y~-1+X
Y~X-1
```

Need to fit the model and then 'read' the output

```{r, echo=TRUE, eval=FALSE}
trial_lm <- lm(Y~X)
summary (trial_lm)
```

## R INTERLUDE {.smaller}

Write a script to read in the perchlorate data set. Now, add the code to perform a linear model of two continuous variables. Notice how the output of the linear model is specified to a new variable. Also note that the variables and dataset are placeholders

```{r, echo=TRUE, eval=FALSE}
my_lm <- lm(dataset$variable1 ~ dataset$variable2)
```

Now look at a summary of the linear model

```{r, echo=TRUE, eval=FALSE}
summary(my_lm)
print(my_lm)
```

Now let's produce a nice regression plot

```{r, echo=TRUE, eval=FALSE}
plot(dataset$variable1 ~ dataset$variable2, col = “blue”)
abline(my_lm, col = “red”)
```

Notice that you are adding the fitted line from your linear model Finally, remake this plot in GGPlot2

## R INTERLUDE {.smaller}

```{r, echo=TRUE, eval=TRUE}
Perchlorate_Data <- read.table("perchlorate_data.tsv", header=T)
head(Perchlorate_Data)

x <- Perchlorate_Data$T4_Hormone_Level
y <- Perchlorate_Data$Testes_Area

perc_lm <- lm(y ~ x)
summary (perc_lm)

plot(y ~ x, col = "blue")
abline(perc_lm, col = "red")
```

## R INTERLUDE - Checking the output

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/lmtable.jpeg")
```

## 
