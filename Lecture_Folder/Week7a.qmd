---
title: "Week 7a - Statistics for Bioengineering"
author: "Bill Cresko"
format: 
  revealjs:
    transition: fade
    transition-speed: slow
editor: visual
---

```{r}
library(tidyverse)
library(gt)
library(readxl)
library(ggplot2)
```

## This week {.smaller}

-   Finish One Factor Analysis of Variance (ANOVA)

    -   post-hoc means comparisons

    -   *a priori* means tests

    -   fixed vs. random effects in ANOVA

-   How to report statistics in papers

-   Multifactor ANOVA

    -   Factorial
    -   Nested
    
-   Key principles of experimental design

-   Generalized Linear Mixed Models (GLMMs)

# Analysis of Variance

## An Example - Irises

```{r, echo=TRUE, out.width="80%"}
stripchart(iris$Sepal.Length ~ iris$Species, vertical=T, method="jitter",
           ylab="sepal length", xlab="species", pch=19, cex=0.5)
```

## ANOVAs and Hypotheses {.smaller}

$$ H_0: \mu(\text{versicolor_length"}) = \mu(\text{setosa_length}) = \mu(\text{virginica_length})  $$\

$$ H_a: \mu(\text{versicolor_length"}) \neq \mu(\text{setosa_length}) \neq \mu(\text{virginica_length}) $$

## ANOVA \| similar to regression {.vcenter .flexbox}

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.016.jpeg")
```

## ANOVA {.vcenter .flexbox}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.015.jpeg")
```

## Assumptions of ANOVA

1.  The response variable (y) is approximately normal in all groups (factor levels)

    -   Deviation from normality O.K. if sample sizes and variances across groups are approximately equal
    -   Most statisticians think that this is within a factor of 2 or 3

2.  Variances equal across groups

3.  Observations within a group are independent

    -   randomly sampled

    -   no structuring of the sampling (but we'll handle this later)

## Differences in Iris sepal length

```{r, echo=TRUE, eval=TRUE}
iris_aov <- aov(Sepal.Length ~ Species, iris)
anova(iris_aov)
```

-   Would report this as

$$F_{2, 147} = 119.26; p <2.2*10^{-16}$$

## Means estimates using `lm` {.smaller}

```{r, echo=TRUE, eval=TRUE}
summary(lm(iris$Sepal.Length ~ iris$Species))
```

# Testing what levels of a factor variable differ from one another

## Means for greater than two factor levels? {.smaller}

-   The F-ratio test for a single-factor ANOVA tests for any difference among groups.
-   If we want to understand specific differences, we need further “contrasts”.
-   Unplanned comparisons (post hoc):
    -   Multiple comparisons carried out after the results are obtained.
    -   Used to find which means differ from which other means
    -   Comparisons require protection for inflated Type 1 error rates:
-   Planned comparisons (*a priori*):
    -   Comparisons between group means that were decided when the experiment was designed (not after the data were in)
    -   Must be few in number to avoid inflating Type 1 error rates

## *Post Hoc* Comparisons {.smaller}

-   Say you start your experiment with no idea of how groups would differ.
-   So now you've got a significant result that says your groups are different from one another!
-   But **how** are they different?
    -   2 groups could be the same and 1 is different,
    -   or all 3 could be different from each other!
-   There are several ways to compare groups after an ANOVA
-   One of the most common ways is by Tukey's tests
    -   Tukey's honestly significant difference (HSD) test (all pairs)
    -   Scheffé contrasts (all combinations of means)
-   The function `TukeyHSD()` in R

## Irises

```{r, echo=TRUE, eval=TRUE}
iris_aov <- aov(Sepal.Length ~ Species, iris)
TukeyHSD(iris_aov)
```

## Irises

```{r, echo=F, eval=TRUE}
library(ggplot2)
ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  geom_jitter(width = 0.2, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "red") +
  labs(
    title = "Box Plot by Category",
    x = "Species",
    y = "Sepal Length"
  ) +
  theme_minimal()
```

## Irises

```{r, echo=T, eval=F}
library(ggplot2)
ggplot(iris, aes(x = Species, y = Sepal.Length)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  geom_jitter(width = 0.2, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "red") +
  labs(
    title = "Box Plot by Category",
    x = "Species",
    y = "Sepal Length"
  ) +
  theme_minimal()
```

## Biomarker Data {.smaller}

```{r, echo=TRUE, eval=TRUE}

biomarker_data <-read.table("biomarkers.tsv", header=T, sep="\t")
biomarker_anova <- aov(marker5 ~ diagnosis, biomarker_data)
anova(biomarker_anova)
```

## Biomarker Data {.smaller}

```{r, echo=TRUE, eval=TRUE}
biomarker_data <-read.table("biomarkers.tsv", header=T, sep="\t")
biomarker_anova <- aov(marker5 ~ diagnosis, biomarker_data)
TukeyHSD(biomarker_anova)
```

## Biomarker Data

```{r, echo=F, eval=TRUE}
library(ggplot2)
ggplot(biomarker_data, aes(x = diagnosis, y = marker5)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  geom_jitter(width = 0.2, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "red") +
  labs(
    title = "Box Plot by Category",
    x = "Category",
    y = "Value"
  ) +
  theme_minimal()

```

## Biomarker Data {.smaller}

```{r, echo=TRUE, eval=TRUE}
biomarker_data <-read.table("biomarkers.tsv", header=T, sep="\t")
biomarker_anova <- aov(marker5 ~ diagnosis, biomarker_data)
summary(lm(marker5 ~ diagnosis, biomarker_data))
```

## Let's practice - using the categorical predictor variables in the stickleback data set

-   Read in the data as before
-   Pick one categorical predictor variable to include
-   Make sure that R sees them as type `factor`
-   Set up the model and evaluate the overall fit
-   Do a post-hoc means test with Tukey's HSD

## Fitting the model

```{r, echo=TRUE, eval=TRUE}

stickle_micro <-read.table("Stickle_RNAseq.tsv", header=T, sep="\t")
  
stickle_micro_anova <- aov(Gene42 ~ Geno.Micro, stickle_micro)
anova(stickle_micro_anova)
```

## Tukey's posthoc

```{r, echo=TRUE, eval=TRUE}
TukeyHSD(stickle_micro_anova)
```

## Plot of the different levels

```{r, echo=F, eval=TRUE}
library(ggplot2)
ggplot(stickle_micro, aes(x = Geno.Micro, y = Gene42)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  geom_jitter(width = 0.2, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "red") +
  labs(
    title = "Box Plot by Category",
    x = "treatment category",
    y = "Value"
  ) +
  theme_minimal()

```

# Planned (*a priori*) contrasts

## Planned (*a priori*) contrasts {.smaller}

-   A well planned experiment often dictates which comparison of means are of most interest, whereas other comparisons are of no interest.
-   By restricting the comparisons to just those of interest, researchers can mitigate the multiple testing problem associated with *post-hoc* tests.
-   Some statisticians argue that, in fact, planned comparisons allow researchers to avoid adjusting p-values all together because each test is therefore unique.
-   Contrasts can also allow more complicated tests of the relationships among means.
-   Coding *a priori* contrasts in `R` is quite easy and just depends upon writing the right series of coefficient contrasts.


## Planned (a priori) contrasts {.flexbox .vcenter}

|          Null Hypothesis          | Group_1 | Group_2 | Group_3 | Group_4 |
|:---------------------------------:|:-------:|:-------:|:-------:|:-------:|
|          $\mu_1 =\mu_2$           |    1    |   -1    |    0    |    0    |
|          $\mu_1 =\mu_3$           |    1    |    0    |   -1    |    0    |
|          $\mu_3 =\mu_4$           |    0    |    0    |   -1    |    1    |
| $\frac{(\mu_1+\mu_2)}{2} = \mu_3$ |   0.5   |   0.5   |   -1    |    0    |

## R INTERLUDE \| Planned contrasts {.smaller}

```{r, eval=F, echo=TRUE}
RNAseq_Data <- read.table("Stickle_RNAseq.tsv", header=T, sep='')

RNAseq_Data$Geno.Micro <- factor(RNAseq_Data$Geno.Micro)

contrast_matrix <- matrix(c(
  -1, 1, 0, 0,
  -1, 0, 1, 0
), ncol = 2)

colnames(contrast_matrix) <- c("level1_vs_level2", "level1_vs_level3")
rownames(contrast_matrix) <- levels(RNAseq_Data$Geno.Micro)

contrasts(RNAseq_Data$Geno.Micro) <- contrast_matrix

RNA_model <- aov(Gene10 ~ Geno.Micro, data = RNAseq_Data)
summary.lm(RNA_model)
```

## R INTERLUDE \| Planned contrasts {.smaller}

```{r, eval=T, echo=F}
RNAseq_Data <- read.table("Stickle_RNAseq.tsv", header=T, sep='')

RNAseq_Data$Geno.Micro <- factor(RNAseq_Data$Geno.Micro)

contrast_matrix <- matrix(c(
  -1, 1, 0, 0,
  -1, 0, 1, 0
), ncol = 2)

colnames(contrast_matrix) <- c("level1_vs_level2", "level1_vs_level3")
rownames(contrast_matrix) <- levels(RNAseq_Data$Geno.Micro)

contrasts(RNAseq_Data$Geno.Micro) <- contrast_matrix

RNA_model <- aov(Gene10 ~ Geno.Micro, data = RNAseq_Data)
summary.lm(RNA_model)
```

------------------------------------------------------------------------

# Fixed vs. Random Effects in ANOVA

## ANOVA \| Fixed effects of factors  {.smaller}

-   Groups are predetermined, of direct interest, repeatable.
-   For example:
    -   medical treatments in a clinical trial
    -   predetermined doses of a toxin
    -   age groups in a population
    -   habitat, season, etc.
-   Any conclusions reached in the study about differences among groups can be applied only to the groups included in the study.
-   The results cannot be generalized to other treatments, habitats, etc. not included in the study.

## ANOVA \| Random effects of factors   {.smaller}

-   Measurements that come in groups. A group can be:
    -   a family made up of siblings
    -   a subject measured repeatedly
    -   a transect of quadrats in a sampling survey
    -   a block of an experiment done at a given time
-   Groups are assumed to be randomly sampled from a population of groups.
-   Therefore, conclusions reached about groups can be generalized to the population of groups.
-   With random effects, the variance among groups is the main quantity of interest, not the specific group attributes.

## ANOVA \| Random effects of factors {.smaller}

-   Whenever your sampling design is nested
-   Whenever you divide up plots and apply separate treatments to subplots
-   Whenever your replicates are grouped spatially or temporally
    -   in blocks
    -   in batches
-   Whenever you take measurements on related individuals
-   Whenever you measure subjects or other sampling units repeatedly

## ANOVA \| Random effects of factors 

$$ H_0: \sigma^2_\alpha=0$$
$$ H_A: \sigma^2_\alpha \neq 0$$

## ANOVA \| Caution about fixed vs. random effects

-   Using fixed vs. random effects changes the way that statistical tests are performed in ANOVA
-   Most statistical packages assume that all factors are fixed unless you instruct it otherwise
-   Designating factors as random takes extra work and probably a read of the manual
-   In `R`, `lm` assumes that all effects are fixed
-   For random effects, use `lme` instead (part of the nlme package)

## ANOVA \| R interlude

- Set up an analysis of the stickleback data but with the factor as a random effect

```{r, echo=TRUE, eval=TRUE}
library(nlme)
RNAseq_Data <- read.table("Stickle_RNAseq.tsv", header=T, sep='')

RNAseq_Data$Geno.Micro <- factor(RNAseq_Data$Geno.Micro)

micro_model_random_effect <- lme(fixed = Gene202 ~ 1,
                                 random = ~1 | Geno.Micro,
                                 data = stickle_micro)

summary(micro_model_random_effect)

```


-------------------------------------------

# How to present your statistical results

## Style of a results section {.smaller}

-   Write the text of the `Result`s section concisely and objectively.
-   The passive voice will likely dominate here, but use the active voice as much as possible.
-   Use the past tense.
-   Avoid repetitive paragraph structures. 
-   Do not interpret the data here.

## Function of a results section {.smaller}

-   The function is to objectively present your key results, without interpretation, in an orderly and logical sequence using both text and illustrative materials (Tables and Figures).

-   The results section always begins with text, reporting the key results and referring to figures and tables as you proceed.

-   The text of the Results section should be crafted to follow this sequence and highlight the evidence needed to answer the questions/hypotheses you investigated.

-   Important negative results should be reported, too. 
-   Authors usually write the text of the results section based upon the sequence of Tables and Figures.

## Summaries of the statistical analyses {.smaller}

- May appear either in the text (usually parenthetically) or in the relevant Tables or Figures (in the legend or as footnotes to the Table or Figure). 
- Each Table and Figure must be referenced in the text portion of the results, and you must tell the reader what the key result(s) is that each Table or Figure conveys.

-   Tables and Figures are assigned numbers separately and in the sequence that you will refer to them from the text.
    -   The first Table you refer to is Table 1, the next Table 2 and so forth.
    -   Similarly, the first Figure is Figure 1, the next Figure 2, etc.
-   Each Table or Figure must include a brief description of the results being presented and other necessary information in a legend.
    -   Table legends go above the Table; tables are read from top to bottom.
    -   Figure legends go below the figure; figures are usually viewed from bottom to top.
-   When referring to a Figure from the text, "Figure" is abbreviated as Fig.,e.g., (Fig. 1. Table is never abbreviated, e.g., Table 1.

## Example {.smaller}

- For example, suppose you asked the question, "Is the average height of male students the same as female students in a pool of randomly selected Biology majors?" 
- You would first collect height data from large random samples of male and female students. 
- You would then calculate the descriptive statistics for those samples (mean, SD, n, range, etc) and plot these numbers. 
- Suppose you found that male Biology majors are, on average, 12.5 cm taller than female majors; this is the answer to the question. 
- Notice that the outcome of a statistical analysis itself is not a key result, but rather an analytical tool that helps us understand what is our key result.

## Differences, directionality, and magnitude {.smaller}

-   Report your results so as to provide as much information as possible to the reader about the nature of differences or relationships.

-   For example, if you are testing for differences among groups, and you find a significant difference, it is not sufficient to simply report that "groups A and B were significantly different". How are they different? How much are they different?

-   It is much more informative to say something like, "Group A individuals were 23% larger than those in Group B", or, "Group B pups gained weight at twice the rate of Group A pups."

-   Report the direction of differences (greater, larger, smaller, etc) and the magnitude of differences (% difference, how many times, etc.) whenever possible.

## Statistical results in text  {.smaller}

-   Statistical test summaries (test name, p-value) are usually reported parenthetically in conjunction with the biological results they support. This parenthetical reference should include the statistical test used, the value, degrees of freedom and the level of significance.

-   For example, if you found that the mean height of male Biology majors was significantly larger than that of female Biology majors, you might report this result (in blue) and your statistical conclusion (shown in red) as follows:

    -   "Males (180.5 ± 5.1 cm; n=34) averaged 12.5 cm taller than females (168 ± 7.6 cm; n=34) in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p \< 0.001).”

-   If the summary statistics are shown in a figure, the sentence above need not report them specifically, but must include a reference to the figure where they may be seen:

    -   "Males averaged 12.5 cm taller than females in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p \< 0.001; Fig. 1)."

## Statistical results in text  {.smaller}

-   Always enter the appropriate units when reporting data or summary statistics.
    -   for an individual value you would write, "the mean length was 10 cm", or, "the maximum time was 140 min."
    -   When including a measure of variability, place the unit after the error value, e.g., "...was 10 ± 2.3 m".
    -   Likewise place the unit after the last in a series of numbers all having the same unit. For example: "lengths of 5, 10, 15, and 20 m", or "no differences were observed after 2, 4, 6, or 8 min. of incubation".
    

--------------------------------------


# Multifactor ANOVA

## Multifactor ANOVA {.smaller}

-   **Nested ANOVA** or nested design
    -   factors might be hierarchical - in other words nested - within one another
    -   The sources of variance are therefore hierarchical too
-   The **factorial ANOVA** design is the most common experimental design used to investigate more than one treatment variable
    -   In a factorial design every combination of treatments from two (or more) treatment variables is investigated.
    -   The main purpose of a factorial design is to evaluate possible interactions between variables.
    -   An **interaction** between two explanatory variables means that the effect of one variable on the response depends on the state of a second variable.

## Multifactor ANOVA \| Key difference between nested and factorial designs {.smaller}

-   Nested designs are hierarchical
    -   often contain sub-replicates that are random, uncontrolled, nuisance effects
    -   but the nested factors can be of interest too
-   Factorial designs are
    -   all pairwise combinations,
    -   and often involve all combinations of factor levels
    -   when each factor is fixed interactions can be assessed
-   Completely nested designs therefore have no interaction terms, whereas factorial designs do
-   **Mixed models** can have a combination of fixed and random factors that are more complicated

# Factorial Designs

## Multifactor ANOVA {.smaller}

-   For example, Relyae (2003) looked at how a moderate dose (1.6mg/L) of a commonly used pesticide, carbaryl (Sevin), affected bullfrog tadpole survival.
-   In particular, the experiment asked how the effect of carbaryl depended on whether a native predator, the red-spotted newt, was also present.
-   The newt was caged and could cause no direct harm, but it emitted visual and chemical cues to other tadpoles
-   The experiment was carried out in 10-L tubs (experimental units), each containing 10 tadpoles.
-   The four combinations of pesticide treatment (carbaryl vs. water only) and predator treatment (present or absent) were randomly assigned to tubs.
-   The results showed that survival was high except when pesticide was applied together with the predator.
-   Thus, the two treatments, predation and pesticide, seem to have interacted.

```{r, echo=FALSE, out.width='30%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.011.jpeg")
```

## Multifactor ANOVA

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.012.jpeg")
```

## Two Factor Factorial Designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.013.jpeg")
```

## Three Factor Factorial Designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.014.jpeg")
```

## Factorial Designs \| Number of Replicates {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.015.jpeg")
```

## Model 1 factorial ANOVA \| both main effects fixed {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.016.jpeg")
```

## Model 2 factorial ANOVA \| both main effects fixed {.flexbox .vcenter}

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.017.jpeg")
```

## Model 2 factorial ANOVA \| both main effects random {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.018.jpeg")
```

## The mean squares for a factorial model {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.019.jpeg")
```

## The F-ratios for a factorial model {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.020.jpeg")
```

## Interpretation \| significant main and interaction effects {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.021.jpeg")
```

## Interaction plots {.flexbox .vcenter}

```{r, echo=FALSE, out.width='75%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.022.jpeg")
```

## R INTERLUDE \| 2-by-2 fixed effect factorial ANOVA

```{r, echo=TRUE, eval=FALSE}
rnadata <- read.table('RNAseq.tsv', header=T, sep='')
head(rnadata)
```

-   continuous response variable and two main effect categorical variables

```{r, echo=TRUE, eval=FALSE}
gene <- rnadata$Gene80
microbiota <- rnadata$Microbiota
genotype <- rnadata$Genotype
boxplot(gene ~ microbiota)
boxplot(gene ~ genotype)
boxplot(gene ~ microbiota*genotype)
```

## Fit the factorial linear model \| two different ways to do the same thing

```{r, echo=TRUE, eval=FALSE}
rna_aov <- aov(gene ~ microbiota + genotype + microbiota:genotype)
rna_aov <- aov(gene ~ microbiota*genotype)
```

-   Examine the fitted model diagnostics and the ANOVA results table

```{r, echo=TRUE, eval=FALSE}
plot(rna_aov)
summary(rna_aov)
anova(rna_aov)
```

-   What are the general results of our hypothesis tests?
-   If there is an interaction, can we understand it by looking at the boxplots?

## R INTERLUDE \| 2-by-3 fixed effect factorial ANOVA {.flexbox .vcenter}

-   Try the following code to produce an interaction plot for the response variable cell count.
-   In this case there are 2 genotypes and 3 treatment levels.
-   Download the `IntPlot_data` file and `IntPlot_Example.R`
-   Go through the R script, get a feel for what it’s doing, and try to produce and interpret the interaction plot.

# Means tests for multifactorial ANOVAs

## Means tests \| factor level combinations in multi-factor ANOVA

-   The F-ratio test for a single-factor ANOVA tests for any difference among groups.
-   If we want to understand specific differences, we need further “contrasts”.
-   Unplanned comparisons (post hoc)
-   Planned comparisons (a priori)
-   Now we need to make 'pseudo-factors' that combine our levels of interest

## Planned (a priori) contrasts {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.002.jpeg")
```

## R INTERLUDE \| 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction {.smaller}

continuous response and two main effect variables

```{r, eval=FALSE, echo=TRUE}
rnadata <- read.table('RNAseq.tsv', header=T, sep='')
gene <- rnadata$Gene80
microbiota <- rnadata$Microbiota
genotype <- rnadata$Genotype
```

make new “pseudo factor,” combining genotype and microbiota

```{r, eval=FALSE, echo=TRUE}
gxm <- interaction(genotype,microbiota)
levels(gxm)
boxplot(gene ~ gxm)
```

specify the following 2 contrasts

```{r, eval=FALSE, echo=TRUE}
contrasts(gxm) <- cbind(c(2, -1, 0, -1), c(-1, -1, 3, -1))
```

## R INTERLUDE \| 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction {.smaller}

Fit the factorial linear model

```{r, eval=FALSE, echo=TRUE}
rna_aov <- aov(gene ~ gxm)
```

Examine the ANOVA table, using supplied contrasts. Figure out the appropriate titles to give them.

```{r, eval=FALSE, echo=TRUE}
summary(rna_aov, split = list(gxm = list('xxx'=1,'xxx'=2)))
```

What does the contrast summary tell you about the nature of the interaction?

# Nested ANOVA

## Nested ANOVA \| Walking stick example {.smaller}

-   Example 1: Study of “repeatability” (simple nested design)
-   The walking stick, *Timema cristinae*, is a wingless herbivorous insect on plants in chaparral habitats of California.
-   Nosil and Crespi (2006) measured individuals using digital photographs.
-   To evaluate measurement repeatability they took two separate photographs of each specimen.
-   After measuring traits on one set of photographs, they repeated the measurements on the second set.

```{r, echo=FALSE, out.width='50%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.001.jpeg")
```

## Nested ANOVA \| Walking stick example {.flexbox .vcenter}

Each pair of dots represents the two measurements

```{r, echo=FALSE, out.width='70%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.002.jpeg")
```

## Nested ANOVA \| Walking stick example {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.003.jpeg")
```

## Nested ANOVA \| ANOVA Table of Results {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.004.jpeg")
```

## Nesting Logic {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.005.jpeg")
```

## Nesting equations {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.006.jpeg")
```

## Nesting hypothesis tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.007.jpeg")
```

## Nesting MS calculations {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.008.jpeg")
```

## Nested ANOVA table of results {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.009.jpeg")
```

## R INTERLUDE \| Nested ANOVA

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.010.jpeg")
```

## R INTERLUDE \| Nested ANOVA {.smaller}

```{r, echo=TRUE, eval=FALSE}
andrew_data <- read.table('andrew.tsv', header=T, sep=‘\t')
head(andrew_data)
```

-   There are four variables: ‘TREAT’, ‘PATCH’, ‘QUAD’ and ‘ALGAE’
-   The main effect factor is TREAT
-   Make a simplified factor called TREAT2, in which 0% and 33% are a level called “low” and 66% and 100% are “high”

```{r, echo=TRUE, eval=FALSE}
andrew_data$TREAT2 <- factor(c(rep(“low”,40),rep(“high”,40))
```

-   The nested factor is PATCH - also need to turn this into a factor

```{r, echo=TRUE, eval=FALSE}
andrew_data$PATCH <- factor(andrew_data$PATCH)
```

## R INTERLUDE \| Nested ANOVA {.smaller}

-   In this case, our response variable is ALGAE
-   Look at the distribution of ALGAE for the two levels of TREAT2 using boxplots based on the patch means, which are the replicates in this case.

```{r, echo=TRUE, eval=FALSE}
andrew.agg <- with(andrew_data, aggregate(data.frame(ALGAE), 
                  by = list(TREAT2=TREAT2, PATCH=PATCH), mean)

library(nlme)
andrew.agg <- gsummary(andrew_data, groups=andrew_data$PATCH)

boxplot(ALGAE ~ TREAT2, andrew.agg)
```

-   Evaluate assumptions based on the boxplots
-   Is the design balanced (equal numbers of sub-replicates per PATCH)?

## R INTERLUDE \| Nested ANOVA {.smaller}

-   Run the nested ANOVA:

```{r, echo=TRUE, eval=FALSE}
nested.aov <- aov(ALGAE ~ TREAT2 + Error(PATCH), data=andrew_data)
summary(nested.aov)
```

-   Do we detect an effect of TREAT2 (high vs low sea urchin density)?
-   Estimate variance components to assess relative contributions of the random factors

```{r, echo=TRUE, eval=FALSE}
library(nlme)
VarCorr(lme(ALGAE ~ 1, random = ~1 | TREAT2/PATCH, andrew_data))
```

-   Calculate the % of variation due to between-treatment differences vs. due to among patches within treatment differences.
-   See pg. 302 in Logan if you need help.
-   What do these variance component estimates tell us???


# Design principles for planning a good experiment

## What is an experimental study?  {.smaller}

-   In an experimental study the researcher assigns treatments to units
-   In an observational study nature does the assigning of treatments to units
-   The crucial advantage of experiments derives from the random assignment of treatments to units
-   Random assignment, or randomization, minimizes the influence of confounding variables
-   Can infer cause and effect more easily

## Key components of a good experiment {.smaller}

- An experiment is when two or more treatment groups are assigned to research units 
- randomization - research units are assigne at random to tratment groups in one of several ways. In particular neither the researcher or the unit should decide who gets the treatment 
- control - different treatemnt groups are as identical as posible, ecept for the specfic treatment they receive. A lack of controls can lead to confounding variables. Note the placebo effect. 
- replication - repeated to be able to estimate sampling variation. Different types of random sampling depending upon the nature of the experiment 
- blinding - single or better yet double blind - neither the subject nor the

## Mount Everest example {.vcenter .flexbox}

Survival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.

**Why?**

## Mount Everest example  {.smaller}

-   One possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).
-   The other is that the two variables are associated because other variables affect both supplemental oxygen and survival.
-   Use of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.
-   Variables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called **confounding variables**
-   They are correlated with the variable of interest, and therefore preventing a decision about cause and effect.
-   With random assignment, no confounding variables will be associated with treatment except by chance.

## Clinical Trials  {.smaller}

-   The gold standard of experimental designs is the **clinical trial**
-   Experimental design in all areas of biology have been informed by procedures used in clinical trials
-   A clinical trial is an experimental study in which two or more treatments are assigned to human subjects
-   The design of clinical trials has been refined because the cost of making a mistake with human subjects is so high
-   Experiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”

## Example of a clinical trial {.smaller}

-   Transmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa
-   The spermicide nonoxynol-9 had shown *in vitro* activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).
-   They tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.
-   Data were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.
-   Two gel treatments were assigned randomly to women at each clinic.
-   One gel contained nonoxynol-9 and the other a placebo.
-   Neither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo.

## Example of a clinical trial {.flexbox .vcenter}

<br>

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.005.jpeg")
```

## Design components of a clinical trial {.smaller}

The goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.

-   To reduce bias, the experiment included:
    -   **Simultaneous control group**: study included both the treatment of interest and a control group (the women receiving the placebo).
    -   **Randomization**: treatments were randomly assigned to women at each clinic.
    -   **Blinding**: neither the subjects nor the clinicians knew which women were assigned which treatment.

## Design components of a clinical trial {.smaller}

-   To reduce the effects of sampling error, the experiment included:
    -   **Replication**: study was carried out on multiple independent subjects.
    -   **Balance**: number of women was nearly equal in the two groups at every clinic.
    -   **Blocking**: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”).

## Simultaneous control group {.smaller}

-   In clinical trials either a placebo or the currently accepted treatment should be provided.
-   In experiments requiring intrusive methods to administer treatment, such as
    -   injections
    -   surgery
    -   restraint
    -   confinement
-   the control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit.

## Simultaneous control group {.smaller}

-   The “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.
-   In field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.
-   Ideally, the same disturbance should be applied to the control plots.

## Randomization  {.smaller}

-   The researcher should randomize assignment of treatments to units or subjects
-   Chance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control
-   A completely randomized design is one in which treatments are assigned to all units by randomization

## Randomization  {.smaller}

-   Randomization breaks the association between possible confounding variables and the explanatory variable
-   Randomization doesn't eliminate the variation contributed by confounding variables, only their correlation with treatment
-   Randomization ensures that variation from confounding variables is similar between the different treatment groups.

## Randomization  {.smaller}

-   Randomization should be carried out using a random process:
    -   List all n subjects, one per row, in a computer spreadsheet.
    -   Use the computer to give each individual a random number.
    -   Assign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.
-   Other ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.
-   “Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias.

## Randomization Types  {.smaller}

-   Completely randomized design - all subjects are placed to treatment or control with equal probability

-   Randomized block - first broken into gropus (e.g. age or gender) then assigend to tratment groups at random

-   Mathced pair design - sujects are paired by similarity before being randoly assigned to treatment groups

## Sampling approaches  {.smaller}

-   simple random sample - every sample has equal probability of being chosen
-   stratified sample - divvided into groups then a simple random sample are taken from each
-   cluster sample - divided into similar gropu, usually naturally occure, a simple random samples of clusters is then taken and very member of the cluster is included in the sample
-   multistage sampling - combines the above. First clusters are random sampled. Second random samples are take from each. Then process is repeated
-   systematic sample - members of a sample are chosen in a pre-determiend ways. e.g Choose everyth 20th person coming into a store

## Bias in experiments  {.smaller}

-   lack of control
-   lac of blinidng
-   lack of reandomiztaion

## Bias in surveys  {.smaller}

-   samplign bias - not all members of the ppulation or cluster are equally likely
-   non-response bias - xxx
-   asymmetric questions - xxx
-   social desirability bias - xxx

## Statistical sampling  {.smaller}

-   censuse - collect ifnormation from a completel population of interest
-   sampling bad ways
    -   anecdotal evidence
    -   conveience sample - easily acessible (say students in a class
    -   Random sample - a random process is used, and the point is to avoid bias

)

## Blinding  {.smaller}

-   Blinding is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.
-   Blinding prevents subjects and researchers from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.
-   For example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding (Ernst and White 1998).

## Blinding {.smaller}

-   In a single-blind experiment, the subjects are unaware of the treatment that they have been assigned.
-   Treatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.
-   Blinding can also be a concern in non-human studies where animals respond to stimuli

## Blinding {.smaller}

-   In a double-blind experiment the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments
    -   Researchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome
    -   Many response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias
    -   Researchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response

## Blinding  {.smaller}

-   Reviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).
-   Experiments on non–human subjects are also prone to bias from lack of blinding.

## Blinding  {.smaller}

-   Bebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.
-   Blinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order).

## Replication  {.smaller}

-   The goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables
-   One way to reduce noise is to make the experimental conditions constant
-   In field experiments, however, highly constant experimental conditions might not be feasible nor desirable
-   By limiting the conditions of an experiment, we also limit the generality of the results
-   Another way to make treatment effects stand out is to include extreme treatments and to replicate the data.

## Replication {.smaller}

-   Replication is the assignment of each treatment to multiple, independent experimental units.
-   Without replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.
-   Studies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.
-   Larger samples mean more information, and more information means better estimates and more powerful tests.

## Replication {.smaller}

-   Replication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.
-   The figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated.

## Pseudoreplication {.smaller}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.006.jpeg")
```

## Balance  {.smaller}

-   A study design is balanced if all treatments have the same sample size.
-   Conversely, a design is unbalanced if there are unequal sample sizes between treatments.
-   Balance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.
-   To appreciate this, look again at the equation for the standard error of the difference between two treatment means.

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.007.jpeg")
```

## Balance  {.smaller}

-   For a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.
-   Balance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so.

## Blocking  {.smaller}

-   Blocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.
-   Blocking essentially repeats the same, completely randomized experiment multiple times, once for each block.
-   Differences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks is discarded.

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.008.jpeg")
```

## Blocking \| Paired designs  {.smaller}

-   For example, consider the design choices for a two-treatment experiment to investigate the effect of clear cutting on salamander density.
-   In the completely randomized (“two-sample”) design we take a random sample of forest plots from the population and then randomly assign each plot to either the clear-cut treatment or the no clear-cut treatment.
-   In the paired design we take a random sample of forest plots and clear-cut a randomly chosen half of each plot, leaving the other half untouched.

## Blocking \| Paired designs  {.smaller}

-   In the paired design, measurements on adjacent plot-halves are not independent. This is because they are likely to be similar in soil, water, sunlight, and other conditions that affect the number of salamanders.
-   As a result, we must analyze paired data differently than when every plot is independent of all the others, as in the case of the two-sample design.
-   Paired design is usually more powerful than completely randomized design because it controls for a lot of the extraneous variation between plots or sampling units that sometimes obscures the effects we are looking for.

## Blocking \| Paired designs {.smaller}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.009.jpeg")
```

## Blocking \| Randomized complete block design  {.smaller}

-   RCB design is analogous to the paired design, but may have more than two treatments. Each treatment is applied once to every block.
-   As in the paired design, treatment effects in a randomized block design are measured by differences between treatments exclusively within blocks.
-   By accounting for some sources of sampling variation blocking can make differences between treatments stand out.
-   Blocking is worthwhile if units within blocks are relatively homogeneous, apart from treatment effects, and units belonging to different blocks vary because of environmental or other differences.

## What if you can't do experiments?  {.smaller}

-   Experimental studies are not always feasible, in which case we must fall back upon observational studies.
-   The best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.
-   Randomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.
-   Two strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates).




-----------------------------------------


# General Linear Mixed Models

## What is a GLMM?

-   General Linear Mixed Model (**GLMM**) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects

## How do we factor in categorical variables?

-   For a single categorical predictor, we can include effects of each factor level:

$$ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e $$

-   Each factor level (ex: for Wolbachia: Yes or No) becomes it's own "effector" that will change the value of y
-   Instead of x being a continuous numerical value, for categorical data it will be either a 0 or 1

## A Generalized Linear Model

-   Check out the help page in RStudio for `glm()`

```{r, echo=TRUE, eval=FALSE}
glm(formula = y ~ x1 + x2, family = gaussian(link = "identity"))
```

## First steps: use a glm to test Wolbachia infection

-   Set up a `glm()` to test for the effect of Wolbachia infection on Recombinant Fraction

## First steps: use a glm to test Wolbachia infection

-   What do these components mean?

```{r, echo=TRUE, eval=TRUE}
fly <- read.table("Mostoufi2022_Recombination_Edit.csv", header=T, sep=',')
model <- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link="identity"))
summary(model)
```

## Interpreting the GLM

-   Why is our intercept significant?
    -   Remember that the null hypothesis is a model with an intercept and slope of 0
-   How would you interpret the "WolbachiaYes" coefficient, especially the estimate and the p value?

## Second steps - adding more variables

-   Now let's add Food to our model - how does this change our model results?

## Second steps - adding more variables

```{r, echo=TRUE, eval=TRUE}
model2 <- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = "identity"))
summary(model2)
```

## Interpreting the GLM

-   How would you interpret the Intercept and Food coefficients, especially the estimate and the p value?

## Interaction effects in GLMs

-   You can also model interactions between two categorical variables in glms
    -   What if variable x and variable z interact in non-additive ways?
-   Use the notation x\*z in the formula

## Third steps - adding interaction effects

-   Let's finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model
-   Run the model - what are the results?

## Third steps - adding interaction effects

-   How do we interpret these findings?

```{r, echo=TRUE, eval=TRUE}
model3 <- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = "identity"))
summary(model3)
```

## How do we know which model to use?

-   Want to be careful not to *overfit* your linear model (give too many variables)
-   The Akaike information criterion (AIC) is a metric for comparing different models to find the best fit
    -   Notice the AIC score in your output?
    -   For more on this, take Advanced Bio Stats! Or do some reading on the internet.

------------------------------------------------------------------------

# Mixed effect models with unequal sample sizes {.flexbox .vcenter}

## Attributes of mixed effects models {.flexbox .vcenter}

-   Linear models that include both fixed and random effects.
-   The model is split into fixed and random parts:
    -   Fixed effects influence mean of the response variable Y.
    -   Random effects influence the variance of Y.
-   There is a different error variance for each level of grouping.
-   Estimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.
-   P-values for fixed effects are conservative when design unbalanced.
-   Implemented in the `nlme` & `lme4` packages in `R`.

## Assumptions of mixed-effects models {.flexbox .vcenter}

-   Variation within groups follows a normal distribution with equal variance among groups.
-   Groups are randomly sampled from “population” of groups.
-   Group means follow a normal distribution.
-   Measurements within groups are independent.

## Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.003.jpeg")
```

## General R syntax for two factor factorial designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.004.jpeg")
```

## R INTERLUDE \| Variance components with 2 random factors using LME4 {.smaller}

```{r, echo=TRUE, eval=FALSE}
rnadata <- read.table('RNAseq.tsv', header=T, sep='')
head(rnadata)
```

variables excluding first 5 and last 5 observations

```{r, echo=TRUE, eval=FALSE}
gene <- rnadata$Gene80[6:75] 
microbiota <- rnadata$Microbiota[6:75]
genotype <- rnadata$Genotype[6:75]
boxplot(gene ~ microbiota)
boxplot(gene ~ genotype)
boxplot(gene ~ microbiota*genotype)
```

Estimate the variance components using Restricted Maximum Likelihood (REML)

```{r, echo=TRUE, eval=FALSE}
library(lme4)
lmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))
```

Based on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?

# Analysis of Covariance (ANCOVA)

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.005.jpeg")
```

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.006.jpeg")
```

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.007.jpeg")
```

## ANCOVA {.flexbox .vcenter}

-   Analysis of covariance - mixture of regression and ANOVA
-   Response is still a normally distributed continuous variable
-   One or more continuous predictor variables (covariates)
-   Sometimes the covariates are of biological interest
-   Most often we want to remove unexplained variance
-   In this way they are similar to a blocking variable in ANOVA
-   Operationally, ANCOVA is regular ANOVA in which the group and overall means are replaced by group and overall relationships

## ANCOVA \| Adjusting for the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.008.jpeg")
```

## ANCOVA \| Adjusting for the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.009.jpeg")
```

## ANCOVA \| Linear model with two covariates {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.010.jpeg")
```

## ANCOVA \| Factor and covariate hypothesis tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.011.jpeg")
```

## ANCOVA \| F ratio tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.012.jpeg")
```

## ANCOVA \| Assumptions {.flexbox .vcenter}

-   The residuals are normally distributed
-   The residuals show homoscedasticity of variance
-   The residuals are independent of one another
-   The relationship between the response variable and each covariate is linear
-   Homogeneity of slopes among the groups
-   Similar covariate ranges among the groups

## ANCOVA \| Heterogeneous slopes {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.013.jpeg")
```

## ANCOVA \| Heterogeneous slopes {.flexbox .vcenter}

-   Problem - adjusting to a mean is difficult or impossible if the slopes are different
-   In essence, the samples for the groups come from two different populations
-   A test for homogeneity of slopes can be performed
-   The assumption is tested by looking for a significant interaction term between the categorical response variables and the covariate(s)

## ANCOVA \| Non-overlapping range of the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.014.jpeg")
```

## R INTERLUDE \| ANCOVA

-   Impacts of sexual activity on male fruitfly longevity
-   Data from Partridge and Faraquhar (1981)
-   Longevity of male measured in response to access to
    -   no females
    -   one virgin
    -   eight virgins
    -   one mated
    -   eight mated
-   The male fruit flies also varied in size
-   The males were assigned randomly to each of the treatment levels, and then measured thorax length as a covariate

## R INTERLUDE \| ANCOVA {.smaller}

```{r, echo=TRUE, eval=FALSE}
longevity_data <- read.table('longevity.csv', header=T, sep=',')
head(longevity_data)
```

Variables

```{r, echo=TRUE, eval=FALSE}
long <- longevity_data$LONGEVITY
treat <- longevity_data$TREATMENT
thorax <- longevity_data$THORAX
```

-   check to see if the covariate should be included

```{r, echo=TRUE, eval=FALSE}
boxplot(long ~ treat)
plot(long ~ thorax)
```

## R INTERLUDE \| ANCOVA {.smaller}

-   assess assumptions of normality and homogeneity of variance

```{r, echo=TRUE, eval=FALSE}
plot(aov(long ~ thorax + treat ), which = 1)
```

-   †ry it again with a transformed response variable

```{r, echo=TRUE, eval=FALSE}
plot(aov(log10(long) ~ thorax + treat ), which = 1)
```

-   visually assess linearity, homogenetiy of slopes and covariate range equality

```{r, echo=TRUE, eval=FALSE}
library(lattice)
print(xyplot(log10(long) ~ thorax | treat, type = c("r", "p")))
```

## R INTERLUDE \| ANCOVA {.smaller}

-   formally test homogenetiy of slopes by testing the interaction term

```{r, echo=TRUE, eval=FALSE}
anova(aov(log10(long) ~ thorax*treat))
```

-   formally test covariate range disparity by modeling the effect of the treatments on the covariate

```{r, echo=TRUE, eval=FALSE}
anova(aov(thorax ~ treat))
```

-   FINALLY, set up contrasts, fit the additive model and visualize the results (pg. 459 and 460 of your Logan book)
-   Summarize the trends in a nice plot (pg. 461 of your Logan book)
