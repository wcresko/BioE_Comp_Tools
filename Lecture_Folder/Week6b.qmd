---
title: "Week 6b - Statistics for Bioengineering"
author: "Bill Cresko"
format: 
  revealjs:
    transition: fade
    transition-speed: slow
editor: visual
---

```{r}
library(tidyverse)
library(gt)
library(readxl)
library(ggplot2)
```

## This week

-   Model 1 and 2 regression

-   Multiple linear regression

-   Analysis of Variance (ANOVA)

-   Key principles of experimental design

-   How to report statistics in papers

# Multiple Linear regression

## Multiple Linear Regression \| Additive and multiplicative models of 2 or more predictors

Additive model $$y_i = \beta_0 + \beta_1x_{1} + \beta_2x_{2} + ... + \beta_jx_{j} + \epsilon_i$$

\

Multiplicative model (with two predictors) $$y_i = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_1x_2 + \epsilon_i$$

## Multiple Linear Regression \| Additive and multiplicative models

<br>

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5a.006.jpeg")
```

# Model selection when you have many predictor variables

## Model selection

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.004.jpeg")
```

## Model selection \| the problems

-   How to decide the complexity of polynomial: straight line regression, quadratic, cubic, ....

-   Which variables to keep/ discard when building a multiple regression model?

-   Selecting from candidate models representing different biological processes.

## Model selection \| a beetle example

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.005.jpeg")
```

## Start with linear regression

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.006.jpeg")
```

## Quadratic (2nd degree) polynomial?

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.007.jpeg")
```

## A polynomial of degree 10?

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.010.jpeg")
```

## The problem with this approach

-   The log likelihood of the model increases with the number of parameters
-   So does $r^2$
-   Isn't this good - the best fit to the data?

```{r, echo=FALSE, out.width='70%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.011.jpeg")
```

## The problem with this approach

> "models should be pared down until they are minimal and adequate”

Crawley 2007, p325

\
\

-   Parsimony - fit no more parameters than is necessary.
-   If two or more models fit the data almost equally well, prefer the simpler model.



## Let's consider our goals

-   Model should predicts well

-   Approximates true relationship between the variables

-   Be able to evaluate a wider array of models.

-   An overfitted model may not predict well in the future!

## How do we accomplish these goals? {.flexbox .vcenter}

How to accomplish these goals To answer this, we need

1. A criterion to compare models:
    -   Adjusted $R^2$
    -   Mallow’s Cp
    -   AIC (Akaike’s Information Criterion)
    -   BIC (Bayesian Information Criterion)
2. A strategy for searching the candidate models
    - Forwards
    - Backwards
    - All combinations


## How do we accomplish these goals? {.smaller}

-   **Adjusted** $R^2$ 
      - the proportion of mean amount of variation in response variable explained by the model
      - is adjusted for both sample size and the number of terms. 
      - Larger values indicate better fit.

-   **Mallow’s Cp** - 
    - is an index resulting from the comparison of the specific model to a model that contain all the possible terms. 
    - Models with the lowest value and/or values closest to their respective p (the number of model terms, including the y-intercept) indicate best fit.
    -   Frequently used in multiple regression
    -   Strategy: Test all possible models and selection the one with the smallest Cp
    -   Cp ~ P - the model is considered to be a good fit
    -   Cp > P - the model might be missing important factors
    -   Cp < P - the model might be overfitting too many parameters
    -   `leaps` package in R does a smart search among models

## How do we accomplish these goals? {.smaller}

-   **Akaike Information Criteria (AIC)** 
    - There are several different versions of AIC
    - Each version adds a different constant designed to penalize according to the number of parameters and sample size to a likelihood function to produce a relative measure of the information content of a model. 
    - ***Significantly*** smaller values indicate more parsimonious models. 
    - As a rule of thumb, if the difference between two AIC values (delta AIC) is greater than 2, the lower AIC is a significant improvement in parsimony.

-   **Bayesian or Schwarz Information Criteria (BIC or SIC)** 
    - BIC is outwardly similar to AIC. 
    - Like AIC, the model with the lowest BIC is typically selected
    - The constant added to the likelihood function penalizes models with more predictor terms more heavily (and thus select more simple models) than AIC. 
    - It is for this reason that BIC is favored by many researchers.



## R INTERLUDE - model fitting {.smaller}

- The `MASS` library is used for `stepAIC` and `stepBIC`
- The `leaps` library is used for `Mallow's Cp`

```{r, echo=TRUE, eval=TRUE}
library(MASS)       # for stepAIC
library(leaps)      # for regsubsets (Mallow's Cp)
library(car)        # for vif (optional: multicollinearity)

biomarker_data <- read.table("biomarkers.tsv", header=T, sep="\t")

full_model <- lm(biomarker_data$marker1 ~ marker2 + marker3 + marker4 + marker5 + marker6, data = biomarker_data)
summary(full_model)
```

## AIC-based stepwise selection {.smaller}

```{r, echo=TRUE, eval=TRUE}
### AIC-based stepwise selection ###
# Stepwise selection using AIC (both directions)
step_aic <- stepAIC(full_model, direction = "both", trace = FALSE)
summary(step_aic)
```


## BIC-based stepwise selection  {.smaller}

```{r, echo=TRUE, eval=TRUE}
### BIC-based stepwise selection ###
# BIC is calculated as: -2*logLik + log(n)*k
n <- nrow(df)
step_bic <- stepAIC(full_model, direction = "both", trace = FALSE)
# step_bic <- stepAIC(full_model, direction = "both", k = log(n), trace = FALSE)
summary(step_bic)
```

## Mallow's Cp using all subsets regression  {.smaller}
```{r, echo=TRUE, eval=TRUE}

### Mallow's Cp using all subsets regression ###
# Use leaps to compute Mallow's Cp
leaps_result <- regsubsets(biomarker_data$marker1 ~ ., data = biomarker_data, nvmax = ncol(df) - 1)
leaps_summary <- summary(leaps_result)

# Extract Mallow's Cp values
cp_values <- leaps_summary$cp

# Find model with minimum Cp
min_cp_index <- which.min(cp_values)
best_model_vars <- names(coef(leaps_result, min_cp_index))[-1]  # exclude intercept

# Fit model using variables from best Cp
cp_formula <- as.formula(paste("biomarker_data$marker1 ~", paste(best_model_vars, collapse = " + ")))
cp_model <- lm(cp_formula, data = biomarker_data)
summary(cp_model)
```


## Comparing the models  {.smaller}

```{r, echo=FALSE, eval=TRUE}
# OPTIONAL: Compare models
cat("\n--- AIC Model ---\n")
print(formula(step_aic))
cat("AIC:", AIC(step_aic), "\n\n")

cat("--- BIC Model ---\n")
print(formula(step_bic))
cat("BIC:", BIC(step_bic), "\n\n")

cat("--- Mallow's Cp Model ---\n")
print(cp_formula)
cat("Cp:", cp_values[min_cp_index], "\n")

```


------------------------------------------------------------------------

# Analysis of Variance

## ANOVA {.flexbox .vcenter}

-   Stands for **AN**alysis **o**f **VA**riance
-   Core statistical procedure in biology
-   Developed by R.A. Fisher in the early 20th Century
-   The core idea is to ask how much variation exists within vs. among groups
-   ANOVAs are linear models that have **categorical predictor** and **continuous response** variables
-   The categorical predictors are often called **factors**, and can have two or more **levels** (important to specify in R)
-   Each factor will have a **hypothesis test**
-   The levels of each factor may also need to be tested (means tests)

# An Example - Irises

-   Let's use an example to think about how ANOVA works under the hood
-   Our system: Iris flowers have sepals and petals of differing lengths
-   The question: do different species have different sepal lengths?

```{r, echo=FALSE, out.width = "60%", fig.align='center'}
knitr::include_graphics("images/week9_irises.png")
```

## An Example - Irises

-   We have data built into base R
-   3 Different species: *Iris versicolor*, *Iris setosa*, and *Iris virginica*
-   Length of sepal as a continuous variable
-   Question - do the species differ in the length of sepals?

## An Example - Irises

```{r, echo=TRUE, out.width="80%"}
stripchart(iris$Sepal.Length ~ iris$Species, vertical=T, method="jitter",
           ylab="sepal length", xlab="species", pch=19, cex=0.5)
```

## ANOVAs and Hypotheses {.smaller}

-   As with any statistical test, we will be testing the probability of accepting or rejecting our null hypothesis, compared to an alternative hypothesis

-   What are the null and alternative hypotheses for our example?

$$ H_0: \mu(\text{versicolor_length"}) = \mu(\text{setosa_length}) = \mu(\text{virginica_length})  $$\

$$ H_a: \mu(\text{versicolor_length"}) \neq \mu(\text{setosa_length}) \neq \mu(\text{virginica_length}) $$

-   NOTE: the alternative hypothesis is that at least one group is different


## ANOVA \| similar to regression {.vcenter .flexbox}

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.016.jpeg")
```

## ANOVA {.vcenter .flexbox}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.015.jpeg")
```


## ANOVA \| Statistical results table {.vcenter .flexbox}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.017.jpeg")
```

## ANOVA \| F-ratio calculation {.vcenter .flexbox}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.018.jpeg")
```

## ANOVA \| F-ratio calculation {.vcenter .flexbox}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_5b.019.jpeg")
```

## Assumptions of ANOVA

1.  The response variable (y) is approximately normal in all groups (factor levels)

    -   Deviation from normality O.K. if sample sizes and variances across groups are equal

2.  Variances equal across groups

3.  Observations within a group are independent

    -   randomly sampled

    -   no structuring

## Let's practice with irises {.smaller}

-   First steps, what are the null and alternative hypotheses for our test? (Already done!)
-   Next, do our data meet or violate the assumptions of ANOVA tests?
-   Then, we can set up our ANOVA
-   What tests should you run (functions, graphing, etc.) in RStudio to evaluate if the data is O.K. to use in an ANOVA test?
    -   Plot the data for each group as a histogram - is it normally distributed?
    -   Run variance tests between the groups - do they have equal variance?
    -   Is our data randomly sampled? Assume yes.

## Let's practice with irises

```{r, out.width="33%", echo=TRUE}
set <- subset(iris, Species =="setosa")
vers <- subset(iris, Species =="versicolor")
vir <- subset(iris, Species=="virginica")
hist(set$Sepal.Length, main = "I. setosa")
hist(vers$Sepal.Length, main = "I. versicolor")
hist(vir$Sepal.Length, main="I. virginica")
```

## Let's practice with irises


```{r, echo=TRUE, eval=TRUE}
iris_aov <- aov(Sepal.Length ~ Species, iris)
anova(iris_aov)
```

-   How do we interpret these findings?

## ANOVA results

-   Species is significantly associated with differences in sepal length!
-   The Mean Square (MS) of our factor (species) explains more of the variance in the response variable (sepal length) than the residuals (random or unmeasured variables)

## Nonparametric tests similar to ANOVA

-   The Kruskal-Wallis test is robust to non-normality and group variance differences
-   Check out the help page for `kruskal.test()` and run a model on iris sepal length

## Nonparametric tests similar to ANOVA

-   Also a significant difference between species

```{r, echo=TRUE, eval=TRUE}
kruskal.test(Sepal.Length ~ Species, iris)
```

# ANOVA and linear models

-   We can use the function `lm()` to also run an analysis of variance
-   Try it out! Set up a linear model to find the relationship between species and sepal length
-   Can you identify where in the results you can find information about ANOVA?

## ANOVA and linear models {.smaller}

```{r, echo=TRUE, eval=TRUE}
summary(lm(iris$Sepal.Length ~ iris$Species))
```

## On your own 

- set up an analysis using the biomarker data
- Use the `diagnosis` categorical variable as the predictor for one of the markers
- Note that you'll likely need to coerce the varible to be `as.factor`

# Testing what levels of factor variable differ from one another

## Post Hoc Comparisons {.smaller}

-   So now you've got a significant result that says your groups are different from one another!
-   But **how** are they different? 2 groups could be the same and 1 is different, or all 3 could be different from each other!
-   There are several ways to compare groups after an ANOVA
-   One of the most common ways is by Tukey's tests (Tukey's range test, Tukey's honestly significant difference (HSD) test)
-   The function `TukeyHSD()` in R


## Let's practice - using the categorical predictor variables in the stickleback data set

-   Read in the data as before
-   Pick one or two categorical predictor variables to include
-   Make sure that R sees them as type `factor`
-   Set up the model and evaluate the overall fit
-   Do a post-hoc means test with Tukey's HSD


## Fitting the model

```{r, echo=TRUE, eval=TRUE}

stickle_micro <-read.table("Stickle_RNAseq.tsv", header=T, sep="\t")
  
stickle_micro_anova <- aov(Gene42 ~ Geno.Micro, stickle_micro)
anova(stickle_micro_anova)
```

## Tukey's posthoc

```{r, echo=TRUE, eval=TRUE}
TukeyHSD(stickle_micro_anova)
```


## Plot of the different levels

```{r, echo=TRUE, eval=TRUE}
library(ggplot2)
ggplot(stickle_micro, aes(x = Geno.Micro, y = Gene42)) +
  geom_boxplot(fill = "lightblue", color = "black") +
  geom_jitter(width = 0.2, alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "red") +
  labs(
    title = "Box Plot by Category",
    x = "Category",
    y = "Value"
  ) +
  theme_minimal()

```

## On your own - Irises and Biomarker Data

-   The function `TukeyHSD()` in R
-   Run post-hoc analyses on your anova model using TukeyHSD function
    -   Check out the help page to figure out how to run
-   How do you interpret the results?

## Let's practice - Irises and Biomarker Data

```{r, echo=TRUE, eval=TRUE}
iris_aov <- aov(Sepal.Length ~ Species, iris)
TukeyHSD(iris_aov)
```

------------------------------------------------------------------------

# General Linear Mixed Models

## What is a GLMM?

-   General Linear Mixed Model (**GLMM**) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects (for more on this, see Peter Ralph's Advanced Bio Stats class)

## How do we factor in categorical variables?

-   For a single categorical predictor, we can include effects of each factor level:

$$ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e $$

-   Each factor level (ex: for Wolbachia: Yes or No) becomes it's own "effector" that will change the value of y
-   Instead of x being a continuous numerical value, for categorical data it will be either a 0 or 1

## A Generalized Linear Model

-   Check out the help page in RStudio for `glm()`

```{r, eval=F}
glm(formula = y ~ x1 + x2, family = gaussian(link = "identity"))
```

## First steps: use a glm to test Wolbachia infection

-   Set up a `glm()` to test for the effect of Wolbachia infection on Recombinant Fraction

## First steps: use a glm to test Wolbachia infection

-   What do these components mean?

```{r, eval=FALSE}
model <- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link="identity"))
summary(model)
```

## Interpreting the GLM

-   Why is our intercept significant?
    -   Remember that the null hypothesis is a model with an intercept and slope of 0
-   How would you interpret the "WolbachiaYes" coefficient, especially the estimate and the p value?

## Second steps - adding more variables

-   Now let's add Food to our model - how does this change our model results?

## Second steps - adding more variables

```{r, eval=FALSE}
model2 <- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = "identity"))
summary(model2)
```

## Interpreting the GLM

-   How would you interpret the Intercept and Food coefficients, especially the estimate and the p value?

## Interaction effects in GLMs

-   You can also model interactions between two categorical variables in glms
    -   What if variable x and variable z interact in non-additive ways?
-   Use the notation x\*z in the formula

## Third steps - adding interaction effects

-   Let's finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model
-   Run the model - what are the results?

## Third steps - adding interaction effects

-   How do we interpret these findings?

```{r, eval=FALSE}
model3 <- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = "identity"))
summary(model3)
```

## How do we know which model to use?

-   Want to be careful not to *overfit* your linear model (give too many variables)
-   The Akaike information criterion (AIC) is a metric for comparing different models to find the best fit
    -   Notice the AIC score in your output?
    -   For more on this, take Advanced Bio Stats! Or do some reading on the internet.

## Multiple Linear Regression - Goals

-   To develop a better predictive model than is possible from models based on single independent variables.
-   To investigate the relative individual effects of each of the multiple independent variables above and beyond the effects of the other variables.
-   The individual effects of each of the predictor variables on the response variable can be depicted by single partial regression lines.
-   The slope of any single partial regression line (partial regression slope) thereby represents the rate of change or effect of that specific predictor variable (holding all the other predictor variables constant to their respective mean values) on the response variable.

## R INTERLUDE \| One way ANOVA {.smaller}

-   Again, use the RNAseq_lip.tsv data again.
-   Let’s test for an effect of Population on Gene01 expression levels
-   First, let’s look at how the data are distributed

```{r, echo=TRUE, eval=FALSE}
RNAseq_Data <- read.table('RNAseq_lip.tsv', header=T, sep='\t')
g1 <- RNAseq_Data$Gene01
Pop <- RNAseq_Data$Population
boxplot(g1~Pop, col=c("blue","green"))
```

Or, to plot all points:

```{r, echo=TRUE, eval=FALSE}
stripchart(g1~Pop, vertical=T, pch=19, col=c("blue","green"), 
           at=c(1.25,1.75), method="jitter", jitter=0.05)
Pop_Anova <- aov(g1 ~ Pop)
summary(Pop_Anova)
```

## R INTERLUDE \| One way ANOVA {.smaller .vcenter .flexbox}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.001.jpeg")
```

## ANOVA \| One or more predictor variables

-   One-way ANOVAs just have a single factor
-   Multi-factor ANOVAs
    -   Factorial - two or more factors and their interactions
    -   Nested - the levels of one factor are contained within another level
    -   The models can be quite complex
-   ANOVAs use an F-statistic to test factors in a model
    -   Ratio of two variances (numerator and denominator)
    -   The numerator and denominator d.f. need to be included (e.g. $F_{1, 34} = 29.43$)
-   Determining the appropriate test ratios for complex ANOVAs takes some work

## ANOVA \| Assumptions

-   Normally distributed groups
    -   robust to non-normality if equal variances and sample sizes
-   Equal variances across groups
    -   okay if largest-to-smallest variance ratio \< 3:1
    -   problematic if there is a mean-variance relationship among groups
-   Observations in a group are independent
    -   randomly selected
    -   don’t confound group with another factor

# Different ways to include factors in models

## ANOVA \| Fixed effects of factors

-   Groups are predetermined, of direct interest, repeatable.
-   For example:
    -   medical treatments in a clinical trial
    -   predetermined doses of a toxin
    -   age groups in a population
    -   habitat, season, etc.
-   Any conclusions reached in the study about differences among groups can be applied only to the groups included in the study.
-   The results cannot be generalized to other treatments, habitats, etc. not included in the study.

## ANOVA \| Random effects of factors

-   Measurements that come in groups. A group can be:
    -   a family made up of siblings
    -   a subject measured repeatedly
    -   a transect of quadrats in a sampling survey
    -   a block of an experiment done at a given time
-   Groups are assumed to be randomly sampled from a population of groups.
-   Therefore, conclusions reached about groups can be generalized to the population of groups.
-   With random effects, the variance among groups is the main quantity of interest, not the specific group attributes.

## ANOVA \| Random effects of factors {.smaller}

-   Below are cases where you are likely to treat factors as random effects
-   Whenever your sampling design is nested
    -   quadrats within transects
    -   transects within woodlots
    -   woodlots within districts
-   Whenever you divide up plots and apply separate treatments to subplots
-   Whenever your replicates are grouped spatially or temporally
    -   in blocks
    -   in batches
-   Whenever you take measurements on related individuals
-   Whenever you measure subjects or other sampling units repeatedly

## ANOVA \| Random effects of factors {.smaller .vcenter .flexbox}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.002.jpeg")
```

## ANOVA \| Random effects - test your understanding

-   Factor is sex (Male vs. Female)
-   Factor is fish tank (10 tanks in an experiment)
-   Factor is family (measure multiple sibs per family)
-   Factor is temperature (10 arbitrary temps over natural range)

## ANOVA \| Caution about fixed vs. random effects

-   Using fixed vs. random effects changes the way that statistical tests are performed in ANOVA
-   Most statistical packages assume that all factors are fixed unless you instruct it otherwise
-   Designating factors as random takes extra work and probably a read of the manual
-   In `R`, `lm` assumes that all effects are fixed
-   For random effects, use `lme` instead (part of the nlme package)

# Means test to compare levels of a factor

## Means for greater than two factor levels? {.smaller}

-   The F-ratio test for a single-factor ANOVA tests for any difference among groups.
-   If we want to understand specific differences, we need further “contrasts”.
-   Unplanned comparisons (post hoc):
    -   Multiple comparisons carried out after the results are obtained.
    -   Used to find where the differences lie (which means differ from which other means)
    -   Comparisons require protection for inflated Type 1 error rates:
        -   Tukey tests: compare all pairs of means and control for multiple comparisons
        -   Scheffé contrasts: compare all combinations of means
-   Planned comparisons (a priori):
    -   Comparisons between group means that were decided when the experiment was designed (not after the data were in)
    -   Must be few in number to avoid inflating Type 1 error rates

## Planned (a priori) contrasts

-   A well planned experiment often dictates which comparison of means are of most interest, whereas other comparisons are of no interest.
-   By restricting the comparisons to just the ones of interest, researchers can mitigate the multiple testing problem associated with post-hoc tests.
-   Some statisticians argue that, in fact, planned comparisons allow researchers to avoid adjusting p-values all together because each test is therefore unique.
-   Contrasts can also allow more complicated tests of the relationships among means.
-   Coding a priori contrasts in R is quite easy and just depends upon writing the right series of coefficient contrasts.

## Planned (a priori) contrasts {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.003.jpeg")
```

## Understand the coefficients table {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.004.jpeg")
```

## R INTERLUDE \| Planned contrasts {.smaller}

-   Take the RNAseq data you've examined before and create a new four level genotype by combining genotype and microbiota treatment into a single variable
-   Think about how to do this using `dplyr` functions.

```{r, eval=FALSE, echo=TRUE}
RNAseq_Data <- read.table("RNAseq.tsv", header=T, sep='')

x <- RNAseq_Data$categorical_var
y <- RNAseq_Data$continuous_var1
z <- RNAseq_Data$continuous_var2
```

-   Set up the a priori contrasts specifically testing one group mean against another
-   These are just examples - you should figure out the logic of the contrasts

```{r, eval=FALSE, echo=TRUE}
contrasts(x) <- cbind(c(0, 1, 0, -1), c(2, -1, 0, -1), c(-1, -1, 3, -1))
```

-   Confirm that the contrasts are orthogonal

```{r, eval=FALSE, echo=TRUE}
round(crossprod(contrasts(x)), 2)
```

## R INTERLUDE \| Planned contrasts {.smaller}

-   Define the contrast labels

```{r, eval=FALSE, echo=TRUE}
rnaseq_data_list <- list(x = list(‘xxx vs. xxx’ = 1, ‘xxx vs. xxx’ = 2, ‘xxx vs. xxx’ = 3))
```

-   Then fit the fixed effect model

```{r, eval=FALSE, echo=TRUE}
RNAseq_aov_fixed <- aov(y ~ x)
plot(RNAseq_aov_fixed)
boxplot(y ~ x)
summary(RNAseq_aov_fixed, split = rnaseq_data_list)
```

## R INTERLUDE \| Unplanned contrasts {.smaller}

-   Remember that this is when you had no hypotheses of differences in means in advance
-   Read in the perchlorate data from Week 3
-   Let’s assess the effects of the 4 perchlorate levels on T4
-   Which perchlorate levels differ in their effect on T4?

```{r, eval=FALSE, echo=TRUE}
perc <- read.table('perchlorate_data.tsv', header=T, sep='\t')

x <- perc$Perchlorate_Level
y <- log10(perc$T4_Hormone_Level)

MyANOVA <- aov(y ~ x)
summary (MyANOVA)
boxplot(y ~ x)

install.packages("multcomp")
library(multcomp)

summary(glht(MyANOVA, linfct = mcp(x = "Tukey")))
```

# Multifactor ANOVA

## Multifactor ANOVA {.smaller}

-   **Nested ANOVA** or nested design
    -   factors might be hierarchical - in other words nested - within one another
    -   The sources of variance are therefore hierarchical too
-   The **factorial ANOVA** design is the most common experimental design used to investigate more than one treatment variable
    -   In a factorial design every combination of treatments from two (or more) treatment variables is investigated.
    -   The main purpose of a factorial design is to evaluate possible interactions between variables.
    -   An **interaction** between two explanatory variables means that the effect of one variable on the response depends on the state of a second variable.

## Multifactor ANOVA \| Key difference between nested and factorial designs {.smaller}

-   Nested designs are hierarchical
    -   often contain sub-replicates that are random, uncontrolled, nuisance effects
    -   but the nested factors can be of interest too
-   Factorial designs are
    -   all pairwise combinations,
    -   and often involve all combinations of factor levels
    -   when each factor is fixed interactions can be assessed
-   Completely nested designs therefore have no interaction terms, whereas factorial designs do
-   **Mixed models** can have a combination of fixed and random factors that are more complicated

# Nested ANOVA

## Nested ANOVA \| Walking stick example {.smaller}

-   Example 1: Study of “repeatability” (simple nested design)
-   The walking stick, *Timema cristinae*, is a wingless herbivorous insect on plants in chaparral habitats of California.
-   Nosil and Crespi (2006) measured individuals using digital photographs.
-   To evaluate measurement repeatability they took two separate photographs of each specimen.
-   After measuring traits on one set of photographs, they repeated the measurements on the second set.

```{r, echo=FALSE, out.width='50%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.001.jpeg")
```

## Nested ANOVA \| Walking stick example {.flexbox .vcenter}

Each pair of dots represents the two measurements

```{r, echo=FALSE, out.width='70%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.002.jpeg")
```

## Nested ANOVA \| Walking stick example {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.003.jpeg")
```

## Nested ANOVA \| ANOVA Table of Results {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.004.jpeg")
```

## Nesting Logic {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.005.jpeg")
```

## Nesting equations {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.006.jpeg")
```

## Nesting hypothesis tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.007.jpeg")
```

## Nesting MS calculations {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.008.jpeg")
```

## Nested ANOVA table of results {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.009.jpeg")
```

## R INTERLUDE \| Nested ANOVA

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.010.jpeg")
```

## R INTERLUDE \| Nested ANOVA {.smaller}

```{r, echo=TRUE, eval=FALSE}
andrew_data <- read.table('andrew.tsv', header=T, sep=‘\t')
head(andrew_data)
```

-   There are four variables: ‘TREAT’, ‘PATCH’, ‘QUAD’ and ‘ALGAE’
-   The main effect factor is TREAT
-   Make a simplified factor called TREAT2, in which 0% and 33% are a level called “low” and 66% and 100% are “high”

```{r, echo=TRUE, eval=FALSE}
andrew_data$TREAT2 <- factor(c(rep(“low”,40),rep(“high”,40))
```

-   The nested factor is PATCH - also need to turn this into a factor

```{r, echo=TRUE, eval=FALSE}
andrew_data$PATCH <- factor(andrew_data$PATCH)
```

## R INTERLUDE \| Nested ANOVA {.smaller}

-   In this case, our response variable is ALGAE
-   Look at the distribution of ALGAE for the two levels of TREAT2 using boxplots based on the patch means, which are the replicates in this case.

```{r, echo=TRUE, eval=FALSE}
andrew.agg <- with(andrew_data, aggregate(data.frame(ALGAE), 
                  by = list(TREAT2=TREAT2, PATCH=PATCH), mean)

library(nlme)
andrew.agg <- gsummary(andrew_data, groups=andrew_data$PATCH)

boxplot(ALGAE ~ TREAT2, andrew.agg)
```

-   Evaluate assumptions based on the boxplots
-   Is the design balanced (equal numbers of sub-replicates per PATCH)?

## R INTERLUDE \| Nested ANOVA {.smaller}

-   Run the nested ANOVA:

```{r, echo=TRUE, eval=FALSE}
nested.aov <- aov(ALGAE ~ TREAT2 + Error(PATCH), data=andrew_data)
summary(nested.aov)
```

-   Do we detect an effect of TREAT2 (high vs low sea urchin density)?
-   Estimate variance components to assess relative contributions of the random factors

```{r, echo=TRUE, eval=FALSE}
library(nlme)
VarCorr(lme(ALGAE ~ 1, random = ~1 | TREAT2/PATCH, andrew_data))
```

-   Calculate the % of variation due to between-treatment differences vs. due to among patches within treatment differences.
-   See pg. 302 in Logan if you need help.
-   What do these variance component estimates tell us???

# Factorial Designs

## Multifactor ANOVA {.smaller}

-   For example, Relyae (2003) looked at how a moderate dose (1.6mg/L) of a commonly used pesticide, carbaryl (Sevin), affected bullfrog tadpole survival.
-   In particular, the experiment asked how the effect of carbaryl depended on whether a native predator, the red-spotted newt, was also present.
-   The newt was caged and could cause no direct harm, but it emitted visual and chemical cues to other tadpoles
-   The experiment was carried out in 10-L tubs (experimental units), each containing 10 tadpoles.
-   The four combinations of pesticide treatment (carbaryl vs. water only) and predator treatment (present or absent) were randomly assigned to tubs.
-   The results showed that survival was high except when pesticide was applied together with the predator.
-   Thus, the two treatments, predation and pesticide, seem to have interacted.

```{r, echo=FALSE, out.width='30%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.011.jpeg")
```

## Multifactor ANOVA

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.012.jpeg")
```

## Two Factor Factorial Designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.013.jpeg")
```

## Three Factor Factorial Designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.014.jpeg")
```

## Factorial Designs \| Number of Replicates {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.015.jpeg")
```

## Model 1 factorial ANOVA \| both main effects fixed {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.016.jpeg")
```

## Model 2 factorial ANOVA \| both main effects fixed {.flexbox .vcenter}

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.017.jpeg")
```

## Model 2 factorial ANOVA \| both main effects random {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.018.jpeg")
```

## The mean squares for a factorial model {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.019.jpeg")
```

## The F-ratios for a factorial model {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.020.jpeg")
```

## Interpretation \| significant main and interaction effects {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.021.jpeg")
```

## Interaction plots {.flexbox .vcenter}

```{r, echo=FALSE, out.width='75%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.022.jpeg")
```

## R INTERLUDE \| 2-by-2 fixed effect factorial ANOVA

```{r, echo=TRUE, eval=FALSE}
rnadata <- read.table('RNAseq.tsv', header=T, sep='')
head(rnadata)
```

-   continuous response variable and two main effect categorical variables

```{r, echo=TRUE, eval=FALSE}
gene <- rnadata$Gene80
microbiota <- rnadata$Microbiota
genotype <- rnadata$Genotype
boxplot(gene ~ microbiota)
boxplot(gene ~ genotype)
boxplot(gene ~ microbiota*genotype)
```

## Fit the factorial linear model \| two different ways to do the same thing

```{r, echo=TRUE, eval=FALSE}
rna_aov <- aov(gene ~ microbiota + genotype + microbiota:genotype)
rna_aov <- aov(gene ~ microbiota*genotype)
```

-   Examine the fitted model diagnostics and the ANOVA results table

```{r, echo=TRUE, eval=FALSE}
plot(rna_aov)
summary(rna_aov)
anova(rna_aov)
```

-   What are the general results of our hypothesis tests?
-   If there is an interaction, can we understand it by looking at the boxplots?

## R INTERLUDE \| 2-by-3 fixed effect factorial ANOVA {.flexbox .vcenter}

-   Try the following code to produce an interaction plot for the response variable cell count.
-   In this case there are 2 genotypes and 3 treatment levels.
-   Download the `IntPlot_data` file and `IntPlot_Example.R`
-   Go through the R script, get a feel for what it’s doing, and try to produce and interpret the interaction plot.

# Means tests for multifactorial ANOVAs

## Means tests \| factor level combinations in multi-factor ANOVA

-   The F-ratio test for a single-factor ANOVA tests for any difference among groups.
-   If we want to understand specific differences, we need further “contrasts”.
-   Unplanned comparisons (post hoc)
-   Planned comparisons (a priori)
-   Now we need to make 'pseudo-factors' that combine our levels of interest

## Planned (a priori) contrasts {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.002.jpeg")
```

## R INTERLUDE \| 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction {.smaller}

continuous response and two main effect variables

```{r, eval=FALSE, echo=TRUE}
rnadata <- read.table('RNAseq.tsv', header=T, sep='')
gene <- rnadata$Gene80
microbiota <- rnadata$Microbiota
genotype <- rnadata$Genotype
```

make new “pseudo factor,” combining genotype and microbiota

```{r, eval=FALSE, echo=TRUE}
gxm <- interaction(genotype,microbiota)
levels(gxm)
boxplot(gene ~ gxm)
```

specify the following 2 contrasts

```{r, eval=FALSE, echo=TRUE}
contrasts(gxm) <- cbind(c(2, -1, 0, -1), c(-1, -1, 3, -1))
```

## R INTERLUDE \| 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction {.smaller}

Fit the factorial linear model

```{r, eval=FALSE, echo=TRUE}
rna_aov <- aov(gene ~ gxm)
```

Examine the ANOVA table, using supplied contrasts. Figure out the appropriate titles to give them.

```{r, eval=FALSE, echo=TRUE}
summary(rna_aov, split = list(gxm = list('xxx'=1,'xxx'=2)))
```

What does the contrast summary tell you about the nature of the interaction?

# Mixed effect models with unequal sample sizes {.flexbox .vcenter}

## Attributes of mixed effects models {.flexbox .vcenter}

-   Linear models that include both fixed and random effects.
-   The model is split into fixed and random parts:
    -   Fixed effects influence mean of the response variable Y.
    -   Random effects influence the variance of Y.
-   There is a different error variance for each level of grouping.
-   Estimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.
-   P-values for fixed effects are conservative when design unbalanced.
-   Implemented in the `nlme` & `lme4` packages in `R`.

## Assumptions of mixed-effects models {.flexbox .vcenter}

-   Variation within groups follows a normal distribution with equal variance among groups.
-   Groups are randomly sampled from “population” of groups.
-   Group means follow a normal distribution.
-   Measurements within groups are independent.

## Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.003.jpeg")
```

## General R syntax for two factor factorial designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.004.jpeg")
```

## R INTERLUDE \| Variance components with 2 random factors using LME4 {.smaller}

```{r, echo=TRUE, eval=FALSE}
rnadata <- read.table('RNAseq.tsv', header=T, sep='')
head(rnadata)
```

variables excluding first 5 and last 5 observations

```{r, echo=TRUE, eval=FALSE}
gene <- rnadata$Gene80[6:75] 
microbiota <- rnadata$Microbiota[6:75]
genotype <- rnadata$Genotype[6:75]
boxplot(gene ~ microbiota)
boxplot(gene ~ genotype)
boxplot(gene ~ microbiota*genotype)
```

Estimate the variance components using Restricted Maximum Likelihood (REML)

```{r, echo=TRUE, eval=FALSE}
library(lme4)
lmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))
```

Based on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?

# Analysis of Covariance (ANCOVA)

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.005.jpeg")
```

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.006.jpeg")
```

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.007.jpeg")
```

## ANCOVA {.flexbox .vcenter}

-   Analysis of covariance - mixture of regression and ANOVA
-   Response is still a normally distributed continuous variable
-   One or more continuous predictor variables (covariates)
-   Sometimes the covariates are of biological interest
-   Most often we want to remove unexplained variance
-   In this way they are similar to a blocking variable in ANOVA
-   Operationally, ANCOVA is regular ANOVA in which the group and overall means are replaced by group and overall relationships

## ANCOVA \| Adjusting for the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.008.jpeg")
```

## ANCOVA \| Adjusting for the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.009.jpeg")
```

## ANCOVA \| Linear model with two covariates {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.010.jpeg")
```

## ANCOVA \| Factor and covariate hypothesis tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.011.jpeg")
```

## ANCOVA \| F ratio tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.012.jpeg")
```

## ANCOVA \| Assumptions {.flexbox .vcenter}

-   The residuals are normally distributed
-   The residuals show homoscedasticity of variance
-   The residuals are independent of one another
-   The relationship between the response variable and each covariate is linear
-   Homogeneity of slopes among the groups
-   Similar covariate ranges among the groups

## ANCOVA \| Heterogeneous slopes {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.013.jpeg")
```

## ANCOVA \| Heterogeneous slopes {.flexbox .vcenter}

-   Problem - adjusting to a mean is difficult or impossible if the slopes are different
-   In essence, the samples for the groups come from two different populations
-   A test for homogeneity of slopes can be performed
-   The assumption is tested by looking for a significant interaction term between the categorical response variables and the covariate(s)

## ANCOVA \| Non-overlapping range of the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.014.jpeg")
```

## R INTERLUDE \| ANCOVA

-   Impacts of sexual activity on male fruitfly longevity
-   Data from Partridge and Faraquhar (1981)
-   Longevity of male measured in response to access to
    -   no females
    -   one virgin
    -   eight virgins
    -   one mated
    -   eight mated
-   The male fruit flies also varied in size
-   The males were assigned randomly to each of the treatment levels, and then measured thorax length as a covariate

## R INTERLUDE \| ANCOVA {.smaller}

```{r, echo=TRUE, eval=FALSE}
longevity_data <- read.table('longevity.csv', header=T, sep=',')
head(longevity_data)
```

Variables

```{r, echo=TRUE, eval=FALSE}
long <- longevity_data$LONGEVITY
treat <- longevity_data$TREATMENT
thorax <- longevity_data$THORAX
```

-   check to see if the covariate should be included

```{r, echo=TRUE, eval=FALSE}
boxplot(long ~ treat)
plot(long ~ thorax)
```

## R INTERLUDE \| ANCOVA {.smaller}

-   assess assumptions of normality and homogeneity of variance

```{r, echo=TRUE, eval=FALSE}
plot(aov(long ~ thorax + treat ), which = 1)
```

-   †ry it again with a transformed response variable

```{r, echo=TRUE, eval=FALSE}
plot(aov(log10(long) ~ thorax + treat ), which = 1)
```

-   visually assess linearity, homogenetiy of slopes and covariate range equality

```{r, echo=TRUE, eval=FALSE}
library(lattice)
print(xyplot(log10(long) ~ thorax | treat, type = c("r", "p")))
```

## R INTERLUDE \| ANCOVA {.smaller}

-   formally test homogenetiy of slopes by testing the interaction term

```{r, echo=TRUE, eval=FALSE}
anova(aov(log10(long) ~ thorax*treat))
```

-   formally test covariate range disparity by modeling the effect of the treatments on the covariate

```{r, echo=TRUE, eval=FALSE}
anova(aov(thorax ~ treat))
```

-   FINALLY, set up contrasts, fit the additive model and visualize the results (pg. 459 and 460 of your Logan book)
-   Summarize the trends in a nice plot (pg. 461 of your Logan book)



# Design principles for planning a good experiment

## What is an experimental study?

-   In an experimental study the researcher assigns treatments to units
-   In an observational study nature does the assigning of treatments to units
-   The crucial advantage of experiments derives from the random assignment of treatments to units
-   Random assignment, or randomization, minimizes the influence of confounding variables
-   Can infer cause and effect more easily

## Key components of a good experiment

An experiment is when two or more treatment groups are assigned to research units
- randomization - research units are assigne at random to tratment groups in one of several ways. In particular neither the researcher or the unit should decide who gets the treatment
- control - different treatemnt groups are as identical as posible, ecept for the specfic treatment they receive. A lack of controls can lead to confounding variables. Note the placebo effect.
- replication - repeated to be able to estimate sampling variation. Different types of random sampling depending upon the nature of the experiment
- blinding - single or better yet double blind - neither the subject nor the 

## Mount Everest example {.vcenter .flexbox}

Survival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.

**Why?**

## Mount Everest example

-   One possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).
-   The other is that the two variables are associated because other variables affect both supplemental oxygen and survival.
-   Use of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.
-   Variables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called **confounding variables**
-   They are correlated with the variable of interest, and therefore preventing a decision about cause and effect.
-   With random assignment, no confounding variables will be associated with treatment except by chance.

## Clinical Trials

-   The gold standard of experimental designs is the **clinical trial**
-   Experimental design in all areas of biology have been informed by procedures used in clinical trials
-   A clinical trial is an experimental study in which two or more treatments are assigned to human subjects
-   The design of clinical trials has been refined because the cost of making a mistake with human subjects is so high
-   Experiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”

## Example of a clinical trial {.smaller}

-   Transmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa
-   The spermicide nonoxynol-9 had shown *in vitro* activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).
-   They tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.
-   Data were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.
-   Two gel treatments were assigned randomly to women at each clinic.
-   One gel contained nonoxynol-9 and the other a placebo.
-   Neither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo.

## Example of a clinical trial {.flexbox .vcenter}

<br>

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.005.jpeg")
```

## Design components of a clinical trial {.smaller}

The goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.

-   To reduce bias, the experiment included:
    -   **Simultaneous control group**: study included both the treatment of interest and a control group (the women receiving the placebo).
    -   **Randomization**: treatments were randomly assigned to women at each clinic.
    -   **Blinding**: neither the subjects nor the clinicians knew which women were assigned which treatment.

## Design components of a clinical trial {.smaller}

-   To reduce the effects of sampling error, the experiment included:
    -   **Replication**: study was carried out on multiple independent subjects.
    -   **Balance**: number of women was nearly equal in the two groups at every clinic.
    -   **Blocking**: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”).

## Simultaneous control group {.smaller}

-   In clinical trials either a placebo or the currently accepted treatment should be provided.
-   In experiments requiring intrusive methods to administer treatment, such as
    -   injections
    -   surgery
    -   restraint
    -   confinement
-   the control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit.

## Simultaneous control group {.smaller}

-   The “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.
-   In field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.
-   Ideally, the same disturbance should be applied to the control plots.

## Randomization

-   The researcher should randomize assignment of treatments to units or subjects
-   Chance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control
-   A completely randomized design is one in which treatments are assigned to all units by randomization

## Randomization

-   Randomization breaks the association between possible confounding variables and the explanatory variable
-   Randomization doesn't eliminate the variation contributed by confounding variables, only their correlation with treatment
-   Randomization ensures that variation from confounding variables is similar between the different treatment groups.

## Randomization

-   Randomization should be carried out using a random process:
    -   List all n subjects, one per row, in a computer spreadsheet.
    -   Use the computer to give each individual a random number.
    -   Assign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.
-   Other ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.
-   “Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias.

## Randomization Types

- Completely randomized design - all subjects are placed to treatment or control with equal probability
- Randomized block - first broken into gropus (e.g. age or gender) then assigend to tratment groups at random

- Mathced pair design - sujects are paired by similarity before being randoly assigned to treatment groups

## Sampling approaches 
- simple random sample - every sample has equal probability of being chosen
- stratified sample - divvided into groups then a simple random sample are taken from each
- cluster sample - divided into similar gropu, usually naturally occure, a simple random samples of clusters is then taken and very member of the cluster is included in the sample
- multistage sampling - combines the above. First clusters are random sampled. Second random samples are take from each.
Then process is repeated
- systematic sample - members of a sample are chosen in a pre-determiend ways. e.g Choose everyth 20th person coming into a store

## Bias in experiments
- lack of control
- lac of blinidng
- lack of reandomiztaion

## Bias in surveys
- samplign bias - not all members of the ppulation or cluster are equally likely
- non-response bias - xxx
- asymmetric questions - xxx
- social desirability bias - xxx

## Statistical sampling

- censuse - collect ifnormation from a completel population of interest
- sampling bad ways
    - anecdotal evidence
    - conveience sample - easily acessible (say students in a class
    - Random sample - a random process is used, and the point is to avoid bias
    
)

## Blinding

-   Blinding is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.
-   Blinding prevents subjects and researchers from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.
-   For example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding (Ernst and White 1998).

## Blinding {.smaller}

-   In a single-blind experiment, the subjects are unaware of the treatment that they have been assigned.
-   Treatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.
-   Blinding can also be a concern in non-human studies where animals respond to stimuli

## Blinding {.smaller}

-   In a double-blind experiment the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments
    -   Researchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome
    -   Many response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias
    -   Researchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response

## Blinding

-   Reviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).
-   Experiments on non–human subjects are also prone to bias from lack of blinding.

## Blinding

-   Bebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.
-   Blinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order).

## Replication

-   The goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables
-   One way to reduce noise is to make the experimental conditions constant
-   In field experiments, however, highly constant experimental conditions might not be feasible nor desirable
-   By limiting the conditions of an experiment, we also limit the generality of the results
-   Another way to make treatment effects stand out is to include extreme treatments and to replicate the data.

## Replication {.smaller}

-   Replication is the assignment of each treatment to multiple, independent experimental units.
-   Without replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.
-   Studies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.
-   Larger samples mean more information, and more information means better estimates and more powerful tests.

## Replication {.smaller}

-   Replication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.
-   The figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated.

## Pseudoreplication {.smaller}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.006.jpeg")
```

## Balance

-   A study design is balanced if all treatments have the same sample size.
-   Conversely, a design is unbalanced if there are unequal sample sizes between treatments.
-   Balance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.
-   To appreciate this, look again at the equation for the standard error of the difference between two treatment means.

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.007.jpeg")
```

## Balance

-   For a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.
-   Balance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so.

## Blocking

-   Blocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.
-   Blocking essentially repeats the same, completely randomized experiment multiple times, once for each block.
-   Differences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks is discarded.

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.008.jpeg")
```

## Blocking \| Paired designs

-   For example, consider the design choices for a two-treatment experiment to investigate the effect of clear cutting on salamander density.
-   In the completely randomized (“two-sample”) design we take a random sample of forest plots from the population and then randomly assign each plot to either the clear-cut treatment or the no clear-cut treatment.
-   In the paired design we take a random sample of forest plots and clear-cut a randomly chosen half of each plot, leaving the other half untouched.

## Blocking \| Paired designs

-   In the paired design, measurements on adjacent plot-halves are not independent. This is because they are likely to be similar in soil, water, sunlight, and other conditions that affect the number of salamanders.
-   As a result, we must analyze paired data differently than when every plot is independent of all the others, as in the case of the two-sample design.
-   Paired design is usually more powerful than completely randomized design because it controls for a lot of the extraneous variation between plots or sampling units that sometimes obscures the effects we are looking for.

## Blocking \| Paired designs {.smaller}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.009.jpeg")
```

## Blocking \| Randomized complete block design

-   RCB design is analogous to the paired design, but may have more than two treatments. Each treatment is applied once to every block.
-   As in the paired design, treatment effects in a randomized block design are measured by differences between treatments exclusively within blocks.
-   By accounting for some sources of sampling variation blocking can make differences between treatments stand out.
-   Blocking is worthwhile if units within blocks are relatively homogeneous, apart from treatment effects, and units belonging to different blocks vary because of environmental or other differences.

## What if you can't do experiments?

-   Experimental studies are not always feasible, in which case we must fall back upon observational studies.
-   The best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.
-   Randomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.
-   Two strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates).

# How to present your statistical results

## Style of a results section {.flexbox .vcenter}

-   Write the text of the Results section concisely and objectively.
-   The passive voice will likely dominate here, but use the active voice as much as possible.
-   Use the past tense.
-   Avoid repetitive paragraph structures. Do not interpret the data here.

## Function of a results section {.flexbox .vcenter}

-   The function is to objectively present your key results, without interpretation, in an orderly and logical sequence using both text and illustrative materials (Tables and Figures).

-   The results section always begins with text, reporting the key results and referring to figures and tables as you proceed.

-   The text of the Results section should be crafted to follow this sequence and highlight the evidence needed to answer the questions/hypotheses you investigated.

-   Important negative results should be reported, too. Authors usually write the text of the results section based upon the sequence of Tables and Figures.

## Summaries of the statistical analyses {.smaller .flexbox .vcenter}

May appear either in the text (usually parenthetically) or in the relevant Tables or Figures (in the legend or as footnotes to the Table or Figure). Each Table and Figure must be referenced in the text portion of the results, and you must tell the reader what the key result(s) is that each Table or Figure conveys.

-   Tables and Figures are assigned numbers separately and in the sequence that you will refer to them from the text.
    -   The first Table you refer to is Table 1, the next Table 2 and so forth.
    -   Similarly, the first Figure is Figure 1, the next Figure 2, etc.
-   Each Table or Figure must include a brief description of the results being presented and other necessary information in a legend.
    -   Table legends go above the Table; tables are read from top to bottom.
    -   Figure legends go below the figure; figures are usually viewed from bottom to top.
-   When referring to a Figure from the text, "Figure" is abbreviated as Fig.,e.g., (Fig. 1. Table is never abbreviated, e.g., Table 1.

## Example {.flexbox .vcenter}

For example, suppose you asked the question, "Is the average height of male students the same as female students in a pool of randomly selected Biology majors?" You would first collect height data from large random samples of male and female students. You would then calculate the descriptive statistics for those samples (mean, SD, n, range, etc) and plot these numbers. Suppose you found that male Biology majors are, on average, 12.5 cm taller than female majors; this is the answer to the question. Notice that the outcome of a statistical analysis is not a key result, but rather an analytical tool that helps us understand what is our key result.

## Differences, directionality, and magnitude {.smaller .flexbox .vcenter}

-   Report your results so as to provide as much information as possible to the reader about the nature of differences or relationships.

-   For example, if you are testing for differences among groups, and you find a significant difference, it is not sufficient to simply report that "groups A and B were significantly different". How are they different? How much are they different?

-   It is much more informative to say something like, "Group A individuals were 23% larger than those in Group B", or, "Group B pups gained weight at twice the rate of Group A pups."

-   Report the direction of differences (greater, larger, smaller, etc) and the magnitude of differences (% difference, how many times, etc.) whenever possible.

## Statistical results in text {.smaller .flexbox .vcenter}

-   Statistical test summaries (test name, p-value) are usually reported parenthetically in conjunction with the biological results they support. This parenthetical reference should include the statistical test used, the value, degrees of freedom and the level of significance.

-   For example, if you found that the mean height of male Biology majors was significantly larger than that of female Biology majors, you might report this result (in blue) and your statistical conclusion (shown in red) as follows:

    -   "Males (180.5 ± 5.1 cm; n=34) averaged 12.5 cm taller than females (168 ± 7.6 cm; n=34) in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p \< 0.001).”

-   If the summary statistics are shown in a figure, the sentence above need not report them specifically, but must include a reference to the figure where they may be seen:

    -   "Males averaged 12.5 cm taller than females in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p \< 0.001; Fig. 1)."

## Statistical results in text {.flexbox .vcenter}

-   Always enter the appropriate units when reporting data or summary statistics.
    -   for an individual value you would write, "the mean length was 10 cm", or, "the maximum time was 140 min."
    -   When including a measure of variability, place the unit after the error value, e.g., "...was 10 ± 2.3 m".
    -   Likewise place the unit after the last in a series of numbers all having the same unit. For example: "lengths of 5, 10, 15, and 20 m", or "no differences were observed after 2, 4, 6, or 8 min. of incubation".
