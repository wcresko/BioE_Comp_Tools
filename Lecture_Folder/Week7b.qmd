---
title: "Week 7b - Statistics for Bioengineering"
author: "Bill Cresko"
format: 
  revealjs:
    transition: fade
    transition-speed: slow
editor: visual
---

```{r}
library(tidyverse)
library(gt)
library(readxl)
library(ggplot2)
```

## This week {.smaller}

-   Multifactor ANOVA

    -   Factorial
    -   Nested

-   Key principles of experimental design

-   Generalized Linear Mixed Models (GLMMs)

# Multifactor ANOVA

## Multifactor ANOVA {.smaller}

-   The **factorial ANOVA** design is the most common experimental design used to investigate more than one treatment variable
    -   In a factorial design every combination of treatments from two (or more) treatment variables is investigated.
    -   The main purpose of a factorial design is to evaluate possible interactions between variables.
    -   An **interaction** between two explanatory variables means that the effect of one variable on the response depends on the state of a second variable.
-   **Nested ANOVA** or nested design
    -   factors might be hierarchical - in other words nested - within one another
    -   The sources of variance are therefore hierarchical too
    -   A common situation is where sampling of observations occurs within groups

## Multifactor ANOVA \| Key difference between nested and factorial designs {.smaller}

-   **Factorial** designs are
    -   all pairwise combinations,
    -   and often involve all combinations of factor levels
    -   when each factor is fixed interactions can be assessed
-   **Nested** designs are hierarchical
    -   often contain sub-replicates that are random, uncontrolled, nuisance effects
    -   but the nested factors can be of interest too
-   Completely nested designs therefore **have no interaction terms**, whereas factorial designs do
-   **Mixed models** can have a combination of fixed and random factors that are more complicated

# Factorial Designs

## Multifactor ANOVA {.smaller}

-   Relyae (2003) looked at how a moderate dose (1.6mg/L) of a commonly used pesticide, carbaryl (Sevin), affected bullfrog tadpole survival.
-   In particular, the experiment asked how the effect of carbaryl depended on whether a native predator, the red-spotted newt, was also present.
-   The experiment was carried out in 10-L tubs (experimental units), each containing 10 tadpoles.
-   The four combinations of pesticide treatment (carbaryl vs. water only) and predator treatment (present or absent) were randomly assigned to tubs.
-   The results showed that survival was high except when pesticide was applied together with the predator.
-   Thus, the two treatments, predation and pesticide, seem to have **interacted**.

## Multifactor ANOVA

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.012.jpeg")
```

## Two Factor Factorial Designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.013.jpeg")
```

## Three Factor Factorial Designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.014.jpeg")
```

## Factorial ANOVA \| both main effects fixed {.flexbox .vcenter}

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.017.jpeg")
```

## Factorial Designs \| Number of Replicates {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.015.jpeg")
```

## Factorial ANOVA \| both main effects random {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.018.jpeg")
```

## The mean squares for a factorial model {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.019.jpeg")
```

## The F-ratios for a factorial model {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.020.jpeg")
```

## Interpretation \| significant main and interaction effects {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.021.jpeg")
```

## Interaction plots {.flexbox .vcenter}

```{r, echo=FALSE, out.width='75%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.022.jpeg")
```

## R INTERLUDE \| 2-by-2 fixed effect factorial ANOVA

```{r, echo=TRUE, eval=TRUE}
rna_data <-read.table("Stickle_RNAseq.tsv", header=T, sep="\t")
head(rna_data)
```

## R INTERLUDE \| 2-by-2 fixed effect factorial ANOVA

-   continuous response variable and two main effect categorical variables

```{r, echo=TRUE, eval=FALSE}
gene <- rna_data$Gene80
microbiota <- rna_data$Microbiota
genotype <- rna_data$Genotype
boxplot(gene ~ microbiota)
boxplot(gene ~ genotype)
boxplot(gene ~ microbiota*genotype)
```

## 2-by-2 fixed effect boxplots

```{r, echo=FALSE, eval=TRUE}
gene <- rna_data$Gene80
microbiota <- rna_data$Microbiota
genotype <- rna_data$Genotype
boxplot(gene ~ microbiota)
```

## 2-by-2 fixed effect boxplots

```{r, echo=FALSE, eval=TRUE}
gene <- rna_data$Gene80
microbiota <- rna_data$Microbiota
genotype <- rna_data$Genotype
boxplot(gene ~ genotype)
```

## 2-by-2 fixed effect boxplots

```{r, echo=FALSE, eval=TRUE}
gene <- rna_data$Gene80
microbiota <- rna_data$Microbiota
genotype <- rna_data$Genotype
boxplot(gene ~ microbiota*genotype)
```

## Fit the factorial linear model \| different ways to do the same thing

```{r, echo=TRUE, eval=TRUE}
rna_aov <- aov(gene ~ microbiota + genotype + microbiota:genotype)
rna_aov <- aov(gene ~ microbiota*genotype)
rna_lm <- lm(gene ~ microbiota + genotype + microbiota:genotype)
rna_lm <- lm(gene ~ microbiota*genotype)
```

-   Examine the fitted model diagnostics and the ANOVA results table

## Fit the factorial linear model \| different ways to do the same thing

```{r, echo=TRUE, eval=FALSE}
plot(rna_aov)
summary(rna_aov)
anova(rna_aov)

plot(rna_lm)
summary(rna_alm)
anova(rna_alm)
```

## Fit the factorial linear model \| different ways to do the same thing

```{r, echo=TRUE, eval=TRUE}
anova(rna_aov)
anova(rna_lm)
```

## Fit the factorial linear model \| different ways to do the same thing

```{r, echo=TRUE, eval=TRUE}
summary(rna_aov)
summary(rna_lm)
```

## Interaction Plots {.flexbox .vcenter}

```{R}
#| echo: TRUE
#| eval: FALSE

library(ggplot2)
library(dplyr)

summary_df <- rna_data |>
  group_by(Genotype, Microbiota) |>
  summarise(mean_response = mean(Gene80), .groups = "drop")

summary_df <- rna_data |>
  group_by(Genotype, Microbiota) |>
  summarise(mean_response = mean(Gene80),
            se = sd(Gene80) / sqrt(n()), .groups = "drop")

# ggplot interaction plot
ggplot(summary_df, aes(x = Genotype, y = mean_response, group = Microbiota, color = Microbiota)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_response - se, ymax = mean_response + se), width = 0.2) +
  labs(title = "Interaction Plot with SE",
       x = "Genotype",
       y = "Mean Expression of Gene80",
       color = "Microbiota") +
  theme_minimal()

```

## Interaction Plots

```{R}
#| echo: FALSE
#| eval: TRUE

library(ggplot2)
library(dplyr)

summary_df <- rna_data |>
  group_by(Genotype, Microbiota) |>
  summarise(mean_response = mean(Gene80), .groups = "drop")

summary_df <- rna_data |>
  group_by(Genotype, Microbiota) |>
  summarise(mean_response = mean(Gene80),
            se = sd(Gene80) / sqrt(n()), .groups = "drop")

# ggplot interaction plot
ggplot(summary_df, aes(x = Genotype, y = mean_response, group = Microbiota, color = Microbiota)) +
  geom_line(size = 1.2) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = mean_response - se, ymax = mean_response + se), width = 0.2) +
  labs(title = "Interaction Plot with SE",
       x = "Genotype",
       y = "Mean Expression of Gene80",
       color = "Microbiota") +
  theme_minimal()

```

# Means tests for multifactorial ANOVAs

## Means tests \| factor level combinations in multi-factor ANOVA

-   The F-ratio test for a single-factor ANOVA tests for any difference among groups.
-   If we want to understand specific differences, we need further “contrasts”.
-   Unplanned comparisons (post hoc)
-   Planned comparisons (a priori)
-   Now we need to make 'pseudo-factors' that combine our levels of interest

## Planned (a priori) contrasts {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.002.jpeg")
```

## R INTERLUDE \| 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction {.smaller}

continuous response and two main effect variables

```{r, eval=TRUE, echo=TRUE}
rna_data <-read.table("Stickle_RNAseq.tsv", header=T, sep="\t")
gene <- rna_data$Gene80
microbiota <- rna_data$Microbiota
genotype <- rna_data$Genotype
```

make new “pseudo factor,” combining genotype and microbiota

```{r, eval=TRUE, echo=TRUE}
gxm <- interaction(genotype,microbiota)
levels(gxm)
boxplot(gene ~ gxm)
```

specify the following 2 contrasts

```{r, eval=FALSE, echo=TRUE}
contrasts(gxm) <- cbind(c(2, -1, 0, -1), c(-1, -1, 3, -1))
```

## R INTERLUDE \| 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction {.smaller}

Fit the factorial linear model

```{r, eval=FALSE, echo=TRUE}
rna_aov <- aov(gene ~ gxm)
```

Examine the ANOVA table, using supplied contrasts. Figure out the appropriate titles to give them.

```{r, eval=FALSE, echo=TRUE}
summary(rna_aov, split = list(gxm = list('xxx'=1,'xxx'=2)))
```

What does the contrast summary tell you about the nature of the interaction?

# Nested ANOVA

## Nested ANOVA \| Walking stick example {.smaller}

-   Example 1: Study of “repeatability” (simple nested design)
-   The walking stick, *Timema cristinae*, is a wingless herbivorous insect on plants in chaparral habitats of California.
-   Nosil and Crespi (2006) measured individuals using digital photographs.
-   To evaluate measurement repeatability they took two separate photographs of each specimen.
-   After measuring traits on one set of photographs, they repeated the measurements on the second set.

```{r, echo=FALSE, out.width='50%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.001.jpeg")
```

## Nested ANOVA \| Walking stick example {.flexbox .vcenter}

Each pair of dots represents the two measurements

```{r, echo=FALSE, out.width='70%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.002.jpeg")
```

## Nested ANOVA \| Walking stick example {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.003.jpeg")
```

## Nested ANOVA \| ANOVA Table of Results {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.004.jpeg")
```

## Nesting Logic {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.005.jpeg")
```

## Nesting equations {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.006.jpeg")
```

## Nesting hypothesis tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.007.jpeg")
```

## Nesting MS calculations {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.008.jpeg")
```

## Nested ANOVA table of results {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.009.jpeg")
```

## R INTERLUDE \| Nested ANOVA

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7a.010.jpeg")
```

## R INTERLUDE \| Nested ANOVA {.smaller}

```{r, echo=TRUE, eval=FALSE}
andrew_data <- read.table('andrew.tsv', header=T, sep=‘\t')
head(andrew_data)
```

-   There are four variables: ‘TREAT’, ‘PATCH’, ‘QUAD’ and ‘ALGAE’
-   The main effect factor is TREAT
-   Make a simplified factor called TREAT2, in which 0% and 33% are a level called “low” and 66% and 100% are “high”

```{r, echo=TRUE, eval=FALSE}
andrew_data$TREAT2 <- factor(c(rep(“low”,40),rep(“high”,40))
```

-   The nested factor is PATCH - also need to turn this into a factor

```{r, echo=TRUE, eval=FALSE}
andrew_data$PATCH <- factor(andrew_data$PATCH)
```

## R INTERLUDE \| Nested ANOVA {.smaller}

-   In this case, our response variable is ALGAE
-   Look at the distribution of ALGAE for the two levels of TREAT2 using boxplots based on the patch means, which are the replicates in this case.

```{r, echo=TRUE, eval=FALSE}
andrew.agg <- with(andrew_data, aggregate(data.frame(ALGAE), 
                  by = list(TREAT2=TREAT2, PATCH=PATCH), mean)

library(nlme)
andrew.agg <- gsummary(andrew_data, groups=andrew_data$PATCH)

boxplot(ALGAE ~ TREAT2, andrew.agg)
```

-   Evaluate assumptions based on the boxplots
-   Is the design balanced (equal numbers of sub-replicates per PATCH)?

## R INTERLUDE \| Nested ANOVA {.smaller}

-   Run the nested ANOVA:

```{r, echo=TRUE, eval=FALSE}
nested.aov <- aov(ALGAE ~ TREAT2 + Error(PATCH), data=andrew_data)
summary(nested.aov)
```

-   Do we detect an effect of TREAT2 (high vs low sea urchin density)?
-   Estimate variance components to assess relative contributions of the random factors

```{r, echo=TRUE, eval=FALSE}
library(nlme)
VarCorr(lme(ALGAE ~ 1, random = ~1 | TREAT2/PATCH, andrew_data))
```

-   Calculate the % of variation due to between-treatment differences vs. due to among patches within treatment differences.
-   What do these variance component estimates tell us???

# Design principles for planning a good experiment

## What is an experimental study? {.smaller}

-   In an **experimental study** the researcher assigns treatments to units
-   In an **observational study** nature does the assigning of treatments to units
-   The crucial advantage of experiments derives from **the random assignment of treatments to units**
-   Randomization **minimizes the influence of confounding variables**
-   Can infer cause and effect more easily

## Mount Everest example {.vcenter .flexbox}

Survival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.

**Why?**

## Mount Everest example {.smaller}

-   One possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).
-   The other is that the two variables are associated because other variables affect both supplemental oxygen and survival.
-   Use of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.
-   Variables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called **confounding variables**
-   They are correlated with the variable of interest, and therefore preventing a decision about cause and effect.
-   With random assignment, no confounding variables will be associated with treatment except by chance.

## Clinical Trials {.smaller}

-   The gold standard of experimental designs is the **clinical trial**
-   Experimental design in all areas of biology have been informed by procedures used in clinical trials
-   A clinical trial is an experimental study in which two or more treatments are assigned to human subjects
-   The design of clinical trials has been refined because the cost of making a mistake with human subjects is so high
-   Experiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”

## Example of a clinical trial {.smaller}

-   Transmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa
-   The spermicide nonoxynol-9 had shown *in vitro* activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).
-   They tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.
-   Data were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.
-   Two gel treatments were assigned randomly to women at each clinic.
-   One gel contained nonoxynol-9 and the other a placebo.
-   Neither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo.

## Example of a clinical trial {.flexbox .vcenter}

<br>

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.005.jpeg")
```

## Design components of a clinical trial {.smaller}

The goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.

-   To reduce bias, the experiment included:
    -   **Simultaneous control group**: study included both the treatment of interest and a control group (the women receiving the placebo).
    -   **Randomization**: treatments were randomly assigned to women at each clinic.
    -   **Blinding**: neither the subjects nor the clinicians knew which women were assigned which treatment.

## Design components of a clinical trial {.smaller}

-   To reduce the effects of sampling error, the experiment included:
    -   **Replication**: study was carried out on multiple independent subjects.
    -   **Balance**: number of women was nearly equal in the two groups at every clinic.
    -   **Blocking**: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”).

## 1. Simultaneous control group {.smaller}

-   In clinical trials either a placebo or the currently accepted treatment should be provided.
-   In experiments requiring intrusive methods to administer treatment, such as
    -   injections
    -   surgery
    -   restraint
    -   confinement
-   the control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit.

## 1. Simultaneous control group {.smaller}

-   The “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.
-   In field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.
-   Ideally, the same disturbance should be applied to the control plots.

## 2. Randomization {.smaller}

-   The researcher should randomize assignment of treatments to units or subjects
-   Chance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control
-   A completely randomized design is one in which treatments are assigned to all units by randomization

## 2. Randomization {.smaller}

-   Randomization breaks the association between possible confounding variables and the explanatory variable
-   Randomization doesn't eliminate the variation contributed by confounding variables, only their correlation with treatment
-   Randomization ensures that variation from confounding variables is similar between the different treatment groups.

## 2. Randomization {.smaller}

-   Randomization should be carried out using a random process:
    -   List all n subjects, one per row, in a computer spreadsheet.
    -   Use the computer to give each individual a random number.
    -   Assign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.
-   Other ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.
-   “Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias.

## 2. Randomization Types {.smaller}

-   **Completely randomized design** - all subjects are placed to treatment or control with equal probability

-   **Randomized block** - first broken into groups (e.g. age or gender) then assigned to treatment groups at random

-   **Matched pair design** - subjects are paired by similarity before being randomly assigned to treatment groups

## 2. Random sampling approaches {.smaller}

-   **simple random sample** - every sample has equal probability of being chosen
-   **stratified sample** - divided into groups then a simple random sample are taken from each
-   **cluster sample** - divided into similar group, usually naturally occured, a simple random samples of clusters is then taken and very member of the cluster is included in the sample
-   **multistage sampling** - combines the above. First clusters are random sampled. Second random samples are take from each. Then process is repeated
-   **systematic sample** - members of a sample are chosen in a pre-determined ways. e.g Choose every 20th person coming into a store

## 3. Blinding {.smaller}

-   **Blinding** is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.
-   Blinding prevents **subjects** and **researchers** from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.
-   For example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding (Ernst and White 1998).

## 3. Blinding {.smaller}

-   In a **single-blind experiment**, the subjects are unaware of the treatment that they have been assigned.
-   Treatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.
-   Blinding can also be a concern in non-human studies where animals respond to stimuli

## 3. Blinding {.smaller}

-   In a **double-blind experiment** the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments
    -   Researchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome
    -   Many response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias
    -   Researchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response

## 3. Blinding {.smaller}

-   Reviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).
-   Experiments on non–human subjects are also prone to bias from lack of blinding.

## 3. Blinding {.smaller}

-   Bebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.
-   Blinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order).

## 4. Replication {.smaller}

-   The goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables
-   One way to reduce noise is to make the experimental conditions constant
-   In field experiments, however, highly constant experimental conditions might not be feasible nor desirable
-   By limiting the conditions of an experiment, we also limit the generality of the results
-   Another way to make treatment effects stand out is to include extreme treatments and to replicate the data.

## 4. Replication {.smaller}

-   Replication is the assignment of each treatment to multiple, independent experimental units.
-   Without replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.
-   Studies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.
-   Larger samples mean more information, and more information means better estimates and more powerful tests.

## 4. Replication {.smaller}

-   Replication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.
-   The figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated.

## 4. Pseudoreplication {.smaller}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.006.jpeg")
```

## 5. Balance {.smaller}

-   A study design is balanced if all treatments have the same sample size.
-   Conversely, a design is unbalanced if there are unequal sample sizes between treatments.
-   Balance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.
-   To appreciate this, look again at the equation for the standard error of the difference between two treatment means.

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.007.jpeg")
```

## 5. Balance {.smaller}

-   For a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.
-   Balance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so.

## 6. Blocking {.smaller}

-   Blocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.
-   Blocking essentially repeats the same, completely randomized experiment multiple times, once for each block.
-   Differences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks is discarded.

```{r, echo=FALSE, out.width='80%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.008.jpeg")
```

## 6. Blocking \| Paired designs {.smaller}

-   For example, consider the design choices for a two-treatment experiment to investigate the effect of clear cutting on salamander density.
-   In the completely randomized (“two-sample”) design we take a random sample of forest plots from the population and then randomly assign each plot to either the clear-cut treatment or the no clear-cut treatment.
-   In the paired design we take a random sample of forest plots and clear-cut a randomly chosen half of each plot, leaving the other half untouched.

## 6. Blocking \| Paired designs {.smaller}

-   In the paired design, measurements on adjacent plot-halves are not independent. This is because they are likely to be similar in soil, water, sunlight, and other conditions that affect the number of salamanders.
-   As a result, we must analyze paired data differently than when every plot is independent of all the others, as in the case of the two-sample design.
-   Paired design is usually more powerful than completely randomized design because it controls for a lot of the extraneous variation between plots or sampling units that sometimes obscures the effects we are looking for.

## 6. Blocking \| Paired designs {.smaller}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_6a.009.jpeg")
```

## 6. Blocking \| Randomized complete block design {.smaller}

-   RCB design is analogous to the paired design, but may have more than two treatments. Each treatment is applied once to every block.
-   As in the paired design, treatment effects in a randomized block design are measured by differences between treatments exclusively within blocks.
-   By accounting for some sources of sampling variation blocking can make differences between treatments stand out.
-   Blocking is worthwhile if units within blocks are relatively homogeneous, apart from treatment effects, and units belonging to different blocks vary because of environmental or other differences.

## What if you can't do experiments? {.smaller}

-   Experimental studies are not always feasible, in which case we must fall back upon observational studies.
-   The best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.
-   Randomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.
-   Two strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates).

------------------------------------------------------------------------

# General Linear Mixed Models

## What is a GLMM?

-   General Linear Mixed Model (**GLMM**) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects

## How do we factor in categorical variables?

-   For a single categorical predictor, we can include effects of each factor level:

$$ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e $$

-   Each factor level (ex: for Wolbachia: Yes or No) becomes it's own "effector" that will change the value of y
-   Instead of x being a continuous numerical value, for categorical data it will be either a 0 or 1

## A Generalized Linear Model

-   Check out the help page in RStudio for `glm()`

```{r, echo=TRUE, eval=FALSE}
glm(formula = y ~ x1 + x2, family = gaussian(link = "identity"))
```

## First steps: use a glm to test Wolbachia infection

-   Set up a `glm()` to test for the effect of Wolbachia infection on Recombinant Fraction

## First steps: use a glm to test Wolbachia infection

-   What do these components mean?

```{r, echo=TRUE, eval=TRUE}
fly <- read.table("Mostoufi2022_Recombination_Edit.csv", header=T, sep=',')
model <- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link="identity"))
summary(model)
```

## Interpreting the GLM

-   Why is our intercept significant?
    -   Remember that the null hypothesis is a model with an intercept and slope of 0
-   How would you interpret the "WolbachiaYes" coefficient, especially the estimate and the p value?

## Second steps - adding more variables

-   Now let's add Food to our model - how does this change our model results?

## Second steps - adding more variables

```{r, echo=TRUE, eval=TRUE}
model2 <- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = "identity"))
summary(model2)
```

## Interpreting the GLM

-   How would you interpret the Intercept and Food coefficients, especially the estimate and the p value?

## Interaction effects in GLMs

-   You can also model interactions between two categorical variables in glms
    -   What if variable x and variable z interact in non-additive ways?
-   Use the notation x\*z in the formula

## Third steps - adding interaction effects

-   Let's finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model
-   Run the model - what are the results?

## Third steps - adding interaction effects

-   How do we interpret these findings?

```{r, echo=TRUE, eval=TRUE}
model3 <- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = "identity"))
summary(model3)
```

## How do we know which model to use?

-   Want to be careful not to *overfit* your linear model (give too many variables)
-   The Akaike information criterion (AIC) is a metric for comparing different models to find the best fit
    -   Notice the AIC score in your output?
    -   For more on this, take Advanced Bio Stats! Or do some reading on the internet.

------------------------------------------------------------------------

# Mixed effect models with unequal sample sizes {.flexbox .vcenter}

## Attributes of mixed effects models {.flexbox .vcenter}

-   Linear models that include both fixed and random effects.
-   The model is split into fixed and random parts:
    -   Fixed effects influence mean of the response variable Y.
    -   Random effects influence the variance of Y.
-   There is a different error variance for each level of grouping.
-   Estimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.
-   P-values for fixed effects are conservative when design unbalanced.
-   Implemented in the `nlme` & `lme4` packages in `R`.

## Assumptions of mixed-effects models {.flexbox .vcenter}

-   Variation within groups follows a normal distribution with equal variance among groups.
-   Groups are randomly sampled from “population” of groups.
-   Group means follow a normal distribution.
-   Measurements within groups are independent.

## Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.003.jpeg")
```

## General R syntax for two factor factorial designs {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.004.jpeg")
```

## R INTERLUDE \| Variance components with 2 random factors using LME4 {.smaller}

```{r, echo=TRUE, eval=FALSE}
rnadata <- read.table('RNAseq.tsv', header=T, sep='')
head(rnadata)
```

variables excluding first 5 and last 5 observations

```{r, echo=TRUE, eval=FALSE}
gene <- rnadata$Gene80[6:75] 
microbiota <- rnadata$Microbiota[6:75]
genotype <- rnadata$Genotype[6:75]
boxplot(gene ~ microbiota)
boxplot(gene ~ genotype)
boxplot(gene ~ microbiota*genotype)
```

Estimate the variance components using Restricted Maximum Likelihood (REML)

```{r, echo=TRUE, eval=FALSE}
library(lme4)
lmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))
```

Based on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?

# Analysis of Covariance (ANCOVA)

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.005.jpeg")
```

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.006.jpeg")
```

## Brain & body size \| neaderthals as compared to humans {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.007.jpeg")
```

## ANCOVA {.flexbox .vcenter}

-   Analysis of covariance - mixture of regression and ANOVA
-   Response is still a normally distributed continuous variable
-   One or more continuous predictor variables (covariates)
-   Sometimes the covariates are of biological interest
-   Most often we want to remove unexplained variance
-   In this way they are similar to a blocking variable in ANOVA
-   Operationally, ANCOVA is regular ANOVA in which the group and overall means are replaced by group and overall relationships

## ANCOVA \| Adjusting for the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.008.jpeg")
```

## ANCOVA \| Adjusting for the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.009.jpeg")
```

## ANCOVA \| Linear model with two covariates {.flexbox .vcenter}

```{r, echo=FALSE, out.width='90%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.010.jpeg")
```

## ANCOVA \| Factor and covariate hypothesis tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.011.jpeg")
```

## ANCOVA \| F ratio tests {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.012.jpeg")
```

## ANCOVA \| Assumptions {.flexbox .vcenter}

-   The residuals are normally distributed
-   The residuals show homoscedasticity of variance
-   The residuals are independent of one another
-   The relationship between the response variable and each covariate is linear
-   Homogeneity of slopes among the groups
-   Similar covariate ranges among the groups

## ANCOVA \| Heterogeneous slopes {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.013.jpeg")
```

## ANCOVA \| Heterogeneous slopes {.flexbox .vcenter}

-   Problem - adjusting to a mean is difficult or impossible if the slopes are different
-   In essence, the samples for the groups come from two different populations
-   A test for homogeneity of slopes can be performed
-   The assumption is tested by looking for a significant interaction term between the categorical response variables and the covariate(s)

## ANCOVA \| Non-overlapping range of the covariate {.flexbox .vcenter}

```{r, echo=FALSE, out.width='100%', fig.asp=.75, fig.align='center'}
knitr::include_graphics("images/images_7b.014.jpeg")
```

## R INTERLUDE \| ANCOVA

-   Impacts of sexual activity on male fruitfly longevity
-   Data from Partridge and Faraquhar (1981)
-   Longevity of male measured in response to access to
    -   no females
    -   one virgin
    -   eight virgins
    -   one mated
    -   eight mated
-   The male fruit flies also varied in size
-   The males were assigned randomly to each of the treatment levels, and then measured thorax length as a covariate

## R INTERLUDE \| ANCOVA {.smaller}

```{r, echo=TRUE, eval=FALSE}
longevity_data <- read.table('longevity.csv', header=T, sep=',')
head(longevity_data)
```

Variables

```{r, echo=TRUE, eval=FALSE}
long <- longevity_data$LONGEVITY
treat <- longevity_data$TREATMENT
thorax <- longevity_data$THORAX
```

-   check to see if the covariate should be included

```{r, echo=TRUE, eval=FALSE}
boxplot(long ~ treat)
plot(long ~ thorax)
```

## R INTERLUDE \| ANCOVA {.smaller}

-   assess assumptions of normality and homogeneity of variance

```{r, echo=TRUE, eval=FALSE}
plot(aov(long ~ thorax + treat ), which = 1)
```

-   †ry it again with a transformed response variable

```{r, echo=TRUE, eval=FALSE}
plot(aov(log10(long) ~ thorax + treat ), which = 1)
```

-   visually assess linearity, homogenetiy of slopes and covariate range equality

```{r, echo=TRUE, eval=FALSE}
library(lattice)
print(xyplot(log10(long) ~ thorax | treat, type = c("r", "p")))
```

## R INTERLUDE \| ANCOVA {.smaller}

-   formally test homogenetiy of slopes by testing the interaction term

```{r, echo=TRUE, eval=FALSE}
anova(aov(log10(long) ~ thorax*treat))
```

-   formally test covariate range disparity by modeling the effect of the treatments on the covariate

```{r, echo=TRUE, eval=FALSE}
anova(aov(thorax ~ treat))
```

-   FINALLY, set up contrasts, fit the additive model and visualize the results (pg. 459 and 460 of your Logan book)
-   Summarize the trends in a nice plot (pg. 461 of your Logan book)
