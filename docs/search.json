[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BioEngineering Statistics 2025",
    "section": "",
    "text": "I created this course website using Quarto. To learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to the website for BioE610 - Statistics for Bioengineers.\nBelow you will find the core information for the course.\nMore detailed information can be found under the ‘Syllabus’ and ‘Policies’ links.\nThe course schedule can be found under the ‘Schedule’ header.\nI will be posting the lectures after each class under the ‘Lectures’ header.\nAdditional resources for the class will gradually accrue under the ‘Resources’ Header."
  },
  {
    "objectID": "Syllabus.html",
    "href": "Syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course in an introduction to data management, data visualization and statistical inference that is intended for early-stage bioengineering and bioscience graduate students with no background in statistics. This is a practical course with a foundation of conceptual intuition matched with hands-on coding each week. The primary objective of the course is to provide foundational training in the organization, manipulation, visualization, and analysis of data, using the R statistical language in a reproducible manner. After this course students will be able to analyze their own data sets with confidence using reasonable approaches, and to provide a foundation for more advanced courses in statistics, data science and machine learning. The course is designed to primarily for the analysis of univariate (single response variable) data. For students interested in multivariate analysis, other courses in Department of Data Science are available. Examples and assignments in class will largely be drawn from bioengineering and the life sciences."
  },
  {
    "objectID": "Lecture_1.html",
    "href": "Lecture_1.html",
    "title": "lecture_1",
    "section": "",
    "text": "x\nxx\nblue"
  },
  {
    "objectID": "Lecture_1.html#slide-1",
    "href": "Lecture_1.html#slide-1",
    "title": "lecture_1",
    "section": "slide 1",
    "text": "slide 1\n\nx\nxx\nblue"
  },
  {
    "objectID": "Lecture_1.html#slide-2",
    "href": "Lecture_1.html#slide-2",
    "title": "lecture_1",
    "section": "slide 2",
    "text": "slide 2\n\nyy\ny\ngray"
  },
  {
    "objectID": "Lectures.html",
    "href": "Lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "Lecture_1a\nLecture_1b\nLecture_2a\nLecture_2b\nLecture_3a\nLecture_3b\nLecture_4a"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html",
    "href": "Lecture_Folder/Lecture_1.html",
    "title": "lecture_1 - placeholder",
    "section": "",
    "text": "x\nxx\nblue"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#slide-1",
    "href": "Lecture_Folder/Lecture_1.html#slide-1",
    "title": "lecture_1",
    "section": "slide 1",
    "text": "slide 1\n\nx\nxx\nblue"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#slide-2",
    "href": "Lecture_Folder/Lecture_1.html#slide-2",
    "title": "lecture_1",
    "section": "slide 2",
    "text": "slide 2\n\nyy\ny\ngray"
  },
  {
    "objectID": "Syllabus.html#course-schedule",
    "href": "Syllabus.html#course-schedule",
    "title": "BioE 610 - Bioengineering Statistics - Syllabus 2025",
    "section": "",
    "text": "Date\nTopics\nReadings\n\n\n\n\n01 April\nxxxxssssssssssssssssssssssssssssssssssss\nxxxx\n\n\n03 April\n\n\n\n\n\n08 April\n\n\n\n\n10 April\n\n\n\n\n\n15 April\n\n\n\n\n17 April\n\n\n\n\n\n22 April\n\n\n\n\n24 April\n\n\n\n\n\n29 April\n\n\n\n\n01 May\n\n\n\n\n\n06 May\n\n\n\n\n08 May\n\n\n\n\n\n13 May\n\n\n\n\n15 May\n\n\n\n\n\n20 May\n\n\n\n\n22 May\n\n\n\n\n\n27 May\n\n\n\n\n29 May\n\n\n\n\n\n3 June\n\n\n\n\n5 June\n\n\n\n\n\n10 June\nFINALS WEEK"
  },
  {
    "objectID": "about.html#instructor-and-class-information",
    "href": "about.html#instructor-and-class-information",
    "title": "About the Course",
    "section": "Instructor and class information",
    "text": "Instructor and class information\n\n\n\n\nInstructor\nBill Cresko\n\n\nClass times\nTuesday/Thursday 4:00 to 5:50\n\n\nClass room\nKC158\n\n\nOffice Hours\nMonday 3:30 to 4:30\n\n\ne-mail\nwcresko@uoregon.edu"
  },
  {
    "objectID": "about.html#course-description",
    "href": "about.html#course-description",
    "title": "About the Course",
    "section": "Course Description",
    "text": "Course Description\nThis course in an introduction to data management, data visualization and statistical inference that is intended for early-stage graduate students with no background in statistics. The primary objective of the course is to get students up to speed with respect to organization, manipulation, visualization, and analysis of data, using the R statistical language. Students will learn to organize and analyze data sets in the form of RStudio projects, using R Markdown files to reproducibly capture and render code, visualizations and analyses. This is a practical course with a foundation of conceptual intuition with the goal of enabling students to analyze their own data sets with confidence using reasonable approaches, and to provide a foundation for more advanced courses in statistics, data science and machine learning. The course is designed to primarily on univariate (single response variable) analysis. For students interested in multivariate analysis, other courses in Department of Data Science will be available. Examples and assignments in class will largely be drawn from the life sciences in general, and bioengineering in particular. For learning outcomes, and specific topics covered in class, please see the course goals below and the schedule on the ‘Syllabus’ page of this website."
  },
  {
    "objectID": "about.html#course-objectives",
    "href": "about.html#course-objectives",
    "title": "About the Course",
    "section": "Course Objectives",
    "text": "Course Objectives\n\nScientific Computing Fundamentals\n\nDescribe fundamental aspects of computer systems, including file types, storage structure, and the logic of programming languages.\nRead and write code in Unix.\nRead and write code in R using RStudio.\nProperly organize and format primary data and metadata files for analysis\nLearn programming fundamentals of the R statistical language, including objects, functions, iteration, and simulation.\nArticulate the importance of and requirements for reproducible science in bioinformatics.\nUtilize the UO’s supercomputer cluster, Talapas, for computationally intensive tasks.\n\nProbability and Exploratory Data Analysis\n\nDescribe the history of data analysis and statistics, particularly its eugenics origins.\nExplain probability in the context of distributions and sampling.\nDescribe the meaning of p-values, test statistics, and types of errors.\n\nStatistical Visualization\n\nProduce well-designed and informative figures in RStudio.\nMake publication-quality data visualizations, including scatterplots, boxplots, frequency distributions, mosaic plots, etc.\n\nPoint Estimation\n\nParameters and statistics\nConfidence intervals\nStatistical distributions\nT-statistics\n\nExperimental Design and Linear Models\n\nDesign experiments and clinical trials to produce the necessary types of data required to answer a given scientific question.\nUnderstand Type I and Type II statistical error, including p-values and power analysis.\nUnderstand ordinary least-squares regression and linear models in general\nLearn to apply general linear models to basic univariate analysis problems,including Analysis of Variance (ANOVA)\n\nApplication of Linear Models to Machine Learning\n\nxxx\nxxx\nxxx\n\nNonparameteric Statistics\n\nLearn nonparametric approaches to parameter estimate and statistical inference,\nincluding resampling (bootstrapping), permutation, and rank-based analysis.\nUnderstand how to analyze binary response variables and frequency-based (e.g. contingency table) data sets.\n\n\n/"
  },
  {
    "objectID": "about.html#instructor-information",
    "href": "about.html#instructor-information",
    "title": "About",
    "section": "Instructor information",
    "text": "Instructor information\n\n\n\nInstructor\nBill Cresko\n\n\nOffices\nM306 KC East Tower & Pacific 312\n\n\ne-mail\nwcresko@uoregon.edu"
  },
  {
    "objectID": "about.html#class-information",
    "href": "about.html#class-information",
    "title": "About",
    "section": "Class information",
    "text": "Class information\n\n\n\nClass times\nTuesday/Thursday 4:00 to 5:50\n\n\nClass room\nKC158\n\n\nOffice Hours\nMonday 3:30 to 4:30\n\n\nOffice hour location\nTBD"
  },
  {
    "objectID": "about.html#course-structure",
    "href": "about.html#course-structure",
    "title": "About the Course",
    "section": "Course Structure",
    "text": "Course Structure\nWe will hold on Tuesdays and Thursdays from 4:00PM to 5:50PM. These meetings will be relatively informal, and will usually begin with a 20-30 min. review of the most salient topics from the course book, possibly including some R coding demonstrations. I will post all lecture slides as Markdown and HTML after class to the course website under the ‘Lectures’ tab. The remaining meeting time will be reserved for questions, answers, and discussion (similar to a “recitation”, or additional “office hours”). I encourage students to work on exercises and assignments during these periods so that questions can be directly addressed as they emerge."
  },
  {
    "objectID": "Syllabus.html#course-description",
    "href": "Syllabus.html#course-description",
    "title": "Syllabus",
    "section": "",
    "text": "This course in an introduction to data management, data visualization and statistical inference that is intended for early-stage bioengineering and bioscience graduate students with no background in statistics. This is a practical course with a foundation of conceptual intuition matched with hands-on coding each week. The primary objective of the course is to provide foundational training in the organization, manipulation, visualization, and analysis of data, using the R statistical language in a reproducible manner. After this course students will be able to analyze their own data sets with confidence using reasonable approaches, and to provide a foundation for more advanced courses in statistics, data science and machine learning. The course is designed to primarily for the analysis of univariate (single response variable) data. For students interested in multivariate analysis, other courses in Department of Data Science are available. Examples and assignments in class will largely be drawn from bioengineering and the life sciences."
  },
  {
    "objectID": "Syllabus.html#course-structure",
    "href": "Syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nWe will hold on Tuesdays and Thursdays from 4:00PM to 5:50PM. These meetings will be relatively informal, and will usually begin with a 30-45 min. conceptual overview of topics with R coding demonstrations. I will post all lecture slides as Markdown and HTML after class to the course website under the ‘Lectures’ tab. The remaining meeting time will be reserved for group work, questions, answers, and discussion (similar to a “recitation”, or additional “office hours”). I encourage students to work on exercises and assignments during these periods so that questions can be directly addressed as they emerge."
  },
  {
    "objectID": "Syllabus.html#course-objectives",
    "href": "Syllabus.html#course-objectives",
    "title": "Syllabus",
    "section": "Course Objectives",
    "text": "Course Objectives\n\nScientific Computing Fundamentals\n\nDescribe fundamental aspects of computer systems, including file types, storage structure, and the logic of programming languages.\nRead and write code in Unix.\nRead and write code in R using RStudio.\nProperly organize and format primary data and metadata files for analysis\nLearn programming fundamentals of the R statistical language, including objects, functions, iteration, and simulation.\nArticulate the importance of and requirements for reproducible science in bioinformatics.\nUtilize the UO’s supercomputer cluster, Talapas, for computationally intensive tasks.\n\nProbability and Exploratory Data Analysis\n\nDescribe the history of data analysis and statistics, particularly its eugenics origins.\nExplain probability in the context of distributions and sampling.\nDescribe the meaning of p-values, test statistics, and types of errors.\n\nStatistical Visualization\n\nProduce well-designed and informative figures in RStudio.\nMake publication-quality data visualizations, including scatterplots, boxplots, frequency distributions, mosaic plots, etc.\n\nPoint Estimation\n\nParameters and statistics\nConfidence intervals\nStatistical distributions\nT-statistics\n\nExperimental Design and Linear Models\n\nDesign experiments and clinical trials to produce the necessary types of data required to answer a given scientific question.\nUnderstand Type I and Type II statistical error, including p-values and power analysis.\nUnderstand ordinary least-squares regression and linear models in general\nLearn to apply general linear models to basic univariate analysis problems,including Analysis of Variance (ANOVA)\n\nApplication of Linear Models to Machine Learning\n\nExamining linear models as classical machine learning\nPrediction and estimation\nShrinkage and regularization\nCross-validation\n\nNonparameteric Statistics\n\nLearn nonparametric approaches to parameter estimate and statistical inference,\nincluding resampling (bootstrapping), permutation, and rank-based analysis.\nUnderstand how to analyze binary response variables and frequency-based (e.g. contingency table) data sets."
  },
  {
    "objectID": "Policies.html",
    "href": "Policies.html",
    "title": "Policies",
    "section": "",
    "text": "This is a 4-credit hour course, so you should expect to complete ~ 120 hours of work for the course—an average, or about 12 hours each week (this includes time in-class).\nMy estimate for time usage for activities and assignments in an average week is below – some weeks may have shorter or longer time commitments either by design or due to course scheduling.\n\n\n\nActivity\nHours per Week\n\n\n\n\nIn-class meetings\n3-4\n\n\nPre-class reading\n4\n\n\nInformal exercises\n1\n\n\nHomework assignments\n2\n\n\nResearch, drafting, editing for final project\n1\n\n\nTOTAL\n12"
  },
  {
    "objectID": "Schedule.html",
    "href": "Schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "I’ve started putting together out online textbook\nHere’s a link\n\n\n\n\n\nR for Data Science (RDS). 2025. Wickham, Çetinkaya-Rundel, and Grolemund. O’Reilly Press.\nModern Statistics with R (MSR). 2025. Måns Thulin, CRC Press.\nAn Introduction to Statistical Learning (ISLR). 2023. James, Witten, Hastie, Tibshirani. Springer\n\n\n\n\n\nModern Statistics for Modern Biology. 2019. Holmes and Huber. Cambridge University Press.\nggPlot2: Elegant Graphics for Data Analysis, 3rd Edition. Wickham, Navarro, Pedersen. Springer.\nThe Visual Display of Quantitative Information. Tufte, E.R. Graphics Press, Cheshire CT\n\n\n\n\n\nYou will be working on your own laptop computeri\nIf you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account\nLaTeX installed on your computer"
  },
  {
    "objectID": "Resources.html",
    "href": "Resources.html",
    "title": "Resources",
    "section": "",
    "text": "Base R Cheat Sheet\nRStudio Collection of Cheat Sheets\nGit Cheat Sheet\nMarkdown Cheat Sheet\nLaTeX Cheat Sheet"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#xxx",
    "href": "Lecture_Folder/Lecture_1.html#xxx",
    "title": "lecture_1 - placeholder",
    "section": "",
    "text": "x\nxx\nblue"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#xxx-1",
    "href": "Lecture_Folder/Lecture_1.html#xxx-1",
    "title": "lecture_1 - placeholder",
    "section": "xxx",
    "text": "xxx\n\nyy\ny\ngray"
  },
  {
    "objectID": "Syllabus.html#online-course-resources",
    "href": "Syllabus.html#online-course-resources",
    "title": "Syllabus",
    "section": "Online Course Resources",
    "text": "Online Course Resources\n\nWe will be using Canvas as well as this GitHub Pages website for the course.\nTo access our course Canvas site, log into canvas.uoregon.edu using your DuckID.\nIf you have questions about using Canvas, visit the Canvas support page.\nCanvas and Technology Support also is available by phone (541-346-4357) or by live chat."
  },
  {
    "objectID": "Syllabus.html#technical-requirements",
    "href": "Syllabus.html#technical-requirements",
    "title": "Syllabus",
    "section": "Technical Requirements",
    "text": "Technical Requirements\n\nYou will be working on your own laptop computer, but if you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)"
  },
  {
    "objectID": "Syllabus.html#graded-assignments",
    "href": "Syllabus.html#graded-assignments",
    "title": "Syllabus",
    "section": "Graded Assignments",
    "text": "Graded Assignments\nProblem sets: Students will be assigned four problem sets (roughly one every 2 weeks) to complete independently. These will mostly focus on one or a few data sets each, and the goal will be for the students to organize, visualize, analyze, and interpret the data sets in light of specific scientific motivations. - 80% of grade.\nTerm project: Students will choose to analyze a dataset of their choice from their own research. The goal of this project is allow students agency in applying what they are learning in class to their own data, and to format the results in an appropriate Rmarkdown or Quarto document that can form the nucleus of a subsequent publication - 20% of grade.\nPreparing and submitting assignments: The information required to complete all in-class assignments and problem sets will be given in instructions on Canvas. Students should carefully follow the detailed instructions associated with each assignment. Students are encouraged to work together and share information. In particular, some students will have a higher skill level than others, and we encourage those students with more experience to help their peers. However, no direct sharing of code is allowed.\nPreparing and submitting assignments: Assignments will be submitted on Canvas in the form of Quarto files, with the rendered html output. Be sure to include your name on the document. Be professional – appropriately name your files, make sure they are organized, and submit only the information requested. Late assignments will not be accepted.\n\nGrading\n\n\n\nAssignment\nPercentage of Total Grade\n\n\n\n\nProblem Sets - 4 in total, 20% each\n80%\n\n\nTerm-long Projects\n20%\n\n\n\n\n\n\nGrade Percentage\nLetter Grade\nPass/No Pass Grade\n\n\n\n\n100% - 90%\nA\nPass\n\n\n89% - 80%\nB\nPass\n\n\n79% - 80%\nC\nNo Pass\n\n\n69% - 60%\nD\nNo Pass\n\n\n60% - 0%\nF\nNo Pass"
  },
  {
    "objectID": "Syllabus.html#grading",
    "href": "Syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\n\n\n\nAssignment\nPercentage of Total Grade\n\n\n\n\nProblem Sets - 4 in total, 20% each\n80%\n\n\nTerm-long Projects\n20%\n\n\n\n\n\n\nGrade Percentage\nLetter Grade\nPass/No Pass Grade\n\n\n\n\n100% - 90%\nA\nPass\n\n\n89% - 80%\nB\nPass\n\n\n79% - 80%\nC\nNo Pass\n\n\n69% - 60%\nD\nNo Pass\n\n\n60% - 0%\nF\nNo Pass"
  },
  {
    "objectID": "Schedule.html#books-reading-materials-and-tools",
    "href": "Schedule.html#books-reading-materials-and-tools",
    "title": "Schedule",
    "section": "",
    "text": "R for Data Science (RDS). 2025. Wickham, Çetinkaya-Rundel, and Grolemund. O’Reilly Press.\nModern Statistics with R (MSR). 2025. Måns Thulin, CRC Press.\nAn Introduction to Statistical Learning (ISLR). 2023. James, Witten, Hastie, Tibshirani. Springer\n\n\n\n\n\nModern Statistics for Modern Biology. 2019. Holmes and Huber. Cambridge University Press.\nggPlot2: Elegant Graphics for Data Analysis, 3rd Edition. Wickham, Navarro, Pedersen. Springer.\nThe Visual Display of Quantitative Information. Tufte, E.R. Graphics Press, Cheshire CT\n\n\n\n\n\nYou will be working on your own laptop computer, but if you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)"
  },
  {
    "objectID": "Schedule.html#course-schedule",
    "href": "Schedule.html#course-schedule",
    "title": "Schedule",
    "section": "Course schedule",
    "text": "Course schedule\n\n\n\nWeek\nDates\nTopics\nReadings\nAssignments\n\n\n\n\n1\nApril1/3\n\nUnix & shell commands\nR scripts & reproducible analysis\nUse of GenAI\nTidy data and data wrangling\nGit, GitHub & Markdown\nSundry history of statistics\n\n\nRDS: 1-8; 27-29\nMSR: 1-2\nHappy Git\n\n\n\n\n2\nApril8/10\n\nExploratory data analysis\nData visualization\nParameters & statistics\nProbability distributions\nEstimates & confidence intervals\nClinical trials & experimental design\n\n\nRDS: 9-11\nMSR: 3-5\n\n\n\n\n3\nApril15/17\n\nHypothesis testing & significance\nType I & II errors\nT-tests\n\n\nMSR: 6-7\n\nHW1 Due\n\n\n4\nApril22/24\n\nFrequency analyses\nContingency tests\nNon-parametric tests\n\n\n\n\n\n5\nApril29/May1\n\nCorrelation & covariance\nOrdinary Linear Models (OLMs)\nSimple linear regression\n\n\nMSR: 8\n\nHW2 Due\n\n\n6\nMay 6/8\n\nAnalysis of Variance (ANOVA)\nSingle factor ANOVA\nPlanned & post hoc comparisons\n\n\nMSR: 8\n\n\n\n\n7\nMay 13/15\n\nMultiple factor ANOVA\nFactorial & Nested ANOVA\nRandom effects\n\n\nMSR: 8\n\nHW3 Due\n\n\n8\nMay 20/22\n\nHierarchical & mixed models\nGeneralized Linear Models (GLMs)\nLogistic & Poisson regression\n\n\nISLR: 1-3\n\n\n\n\n9\nMay 27/29\n\nIntro to statistical learning\nClassification & prediction\nValidation\nSimulation in statistics\n\n\nMSR: 11\nISLR: 4-6\n\nHW4 Due\n\n\n10\nJune 3/5\n\nRemote super computing\nTalapas and SLURM\nAWS Azure\n\n\n\n\n\n11\n10 June\nFINALS WEEK\n\nProject Due"
  },
  {
    "objectID": "Schedule.html#reading-materials-and-tools",
    "href": "Schedule.html#reading-materials-and-tools",
    "title": "Schedule",
    "section": "",
    "text": "I’ve started putting together out online textbook\nHere’s a link\n\n\n\n\n\nR for Data Science (RDS). 2025. Wickham, Çetinkaya-Rundel, and Grolemund. O’Reilly Press.\nModern Statistics with R (MSR). 2025. Måns Thulin, CRC Press.\nAn Introduction to Statistical Learning (ISLR). 2023. James, Witten, Hastie, Tibshirani. Springer\n\n\n\n\n\nModern Statistics for Modern Biology. 2019. Holmes and Huber. Cambridge University Press.\nggPlot2: Elegant Graphics for Data Analysis, 3rd Edition. Wickham, Navarro, Pedersen. Springer.\nThe Visual Display of Quantitative Information. Tufte, E.R. Graphics Press, Cheshire CT\n\n\n\n\n\nYou will be working on your own laptop computeri\nIf you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account\nLaTeX installed on your computer"
  },
  {
    "objectID": "about.html#online-course-resources",
    "href": "about.html#online-course-resources",
    "title": "About",
    "section": "Online Course Resources",
    "text": "Online Course Resources\n\nWe will be using Canvas as well as this GitHub Pages website (https://wcresko.github.io/BioE_Stats/).\nTo access our course Canvas site, log into canvas.uoregon.edu using your DuckID.\nIf you have questions about using Canvas, visit the Canvas support page.\nCanvas and Technology Support also is available by phone (541-346-4357) or by live chat."
  },
  {
    "objectID": "about.html#technical-requirements",
    "href": "about.html#technical-requirements",
    "title": "About",
    "section": "Technical Requirements",
    "text": "Technical Requirements\n\nYou will be working on your own laptop computer.\nIf you would like to borrow a laptop let me know.\nLatest version of R (install here).\nLatest version of RStudio (install here).\nA terminal that allows ssh connection to the UO computing cluster (Talapas)."
  },
  {
    "objectID": "Policies.html#workload-expectations",
    "href": "Policies.html#workload-expectations",
    "title": "Policies",
    "section": "",
    "text": "This is a 4-credit hour course, so you should expect to complete ~ 120 hours of work for the course—an average, or about 12 hours each week (this includes time in-class).\nMy estimate for time usage for activities and assignments in an average week is below – some weeks may have shorter or longer time commitments either by design or due to course scheduling.\n\n\n\nActivity\nHours per Week\n\n\n\n\nIn-class meetings\n3-4\n\n\nPre-class reading\n4\n\n\nInformal exercises\n1\n\n\nHomework assignments\n2\n\n\nResearch, drafting, editing for final project\n1\n\n\nTOTAL\n12"
  },
  {
    "objectID": "Policies.html#communication",
    "href": "Policies.html#communication",
    "title": "Policies",
    "section": "Communication",
    "text": "Communication\n\nElectronic\n\nOur class will communicate through our Canvas site. Announcements and emails are archived there, automatically forwarded to your UO email, and can even reach you by text. Check and adjust your settings under Account &gt; Notifications.\nWe will also be using this GitHub Pages website (https://wcresko.github.io/BioE_Stats/) for the course as the repository for lecture schedule, syllabus, lecture slides and other materials.\nEvery Monday I will post an Announcement that previews critical concepts we’ll work on that week and a checklist of the week’s due dates.\nI will contact individual students when needed through email, and I try to respond to questions within one business day.\nWhen giving feedback on assignments, I do so in Canvas, and turnaround time for feedback is generally one week.\n\n\n\nOffice hours\n\nI will host office hours each week on Monday and from 3:30 to 4:30. The end of many class periods will also function as a form of office hour.\nI welcome meetings outside my regular office hours as well - please email me to set a time.\nDuring office hours, students bring in a wide range of concerns, questions, and successes. We might\n\ntalk through a specific concept or problem to clarify it\nthink together about an issue a student is curious about that relates to the class\ndiscuss a student’s post-graduation goals\nidentify more supportive methods to study for a future exam or to begin a project\nor any number of other topics"
  },
  {
    "objectID": "Policies.html#classroom-community-expectations",
    "href": "Policies.html#classroom-community-expectations",
    "title": "Policies",
    "section": "Classroom Community Expectations",
    "text": "Classroom Community Expectations\n\nParticipate and Contribute:\nAll students are expected to participate by sharing ideas and contributing to the learning environment. This entails preparing, following instructions, and engaging respectfully and thoughtfully with others. While all students should participate, participation is not just talking, and a range of participation activities support learning. Participation might look like speaking aloud in the full class and in small groups, and working collaboratively on coding projects. We will establish more specific participation guidelines and criteria for contributions in our first weeks of the term.\n\n\nExpect and Respect Diversity\nAll classes at the University of Oregon welcome and respect diverse experiences, perspectives, and approaches. What is not welcome are behaviors or contributions that undermine, demean, or marginalize others based on race, ethnicity, gender, sex, age, sexual orientation, religion, ability, or socioeconomic status. We will value differences and communicate disagreements with respect. We may establish more specific guidelines and protocols to ensure inclusion and equity for all members of our learning community.\n\n\nHelp Everyone Learn\nPart of how we learn together is by learning from one another. To do this effectively, we need to be patient with each other, identify ways we can assist others, and be open-minded to receiving help and feedback from others. Don’t hesitate to contact me to ask for assistance or offer suggestions that might help us learn better."
  },
  {
    "objectID": "Policies.html#generative-artificial-intelligence-genai-use",
    "href": "Policies.html#generative-artificial-intelligence-genai-use",
    "title": "Policies",
    "section": "Generative Artificial Intelligence (GenAI) Use",
    "text": "Generative Artificial Intelligence (GenAI) Use\nStudents can use GenAI tools in this class to help with certain aspects of coding. We will discuss during the first week how GenAI can be a tool to help you, but it cannot replace your statistical intuition and knowledge. However, you cannot use content such as text, graphics and code created by GenAI tools in your work. You must be the author/creator of your work submissions. For example, you can use a GenAI tool to suggest a paper outline based on a draft you provide it, or suggest some code, but you cannot submit a paper with text or code generated by GenAI as if the text or code is your own writing. If you are in doubt or have questions about a particular GenAI tool and if its use is okay, check in with me and let’s discuss!"
  },
  {
    "objectID": "Policies.html#university-course-policies",
    "href": "Policies.html#university-course-policies",
    "title": "Policies",
    "section": "University Course Policies",
    "text": "University Course Policies\nPlease read and make sure you are familiar with the important policies that apply to all UO courses, which can be found here."
  },
  {
    "objectID": "Software.html",
    "href": "Software.html",
    "title": "Software",
    "section": "",
    "text": "Latest version of R\nLatest version of RStudio\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account for version control and collaboration\nLaTeX installed on your computer for mathematical typesetting"
  },
  {
    "objectID": "Software.html#software-tools-to-install",
    "href": "Software.html#software-tools-to-install",
    "title": "Software",
    "section": "",
    "text": "Latest version of R\nLatest version of RStudio\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account for version control and collaboration\nLaTeX installed on your computer for mathematical typesetting"
  },
  {
    "objectID": "Software.html#r-and-rstudio",
    "href": "Software.html#r-and-rstudio",
    "title": "Software",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nLatest version of R (install here)\nLatest version of RStudio (install here)"
  },
  {
    "objectID": "Software.html#accessing-the-shell-via-a-terminal-application",
    "href": "Software.html#accessing-the-shell-via-a-terminal-application",
    "title": "Software",
    "section": "Accessing the shell via a terminal application",
    "text": "Accessing the shell via a terminal application\n\nMac or Linux users\n\nopen the native “Terminal” app on Mac or Linux\ninstall another terminal like “iTerm2”\n\n\n\nWindows users\n\nGuide: https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10#1-overview\nRun Windows PowerShell as administrator\nInstall WSL2 by typing wsl --install\nRestart your computer\nSearch for and install Ubuntu from Microsoft store app\nOR type wsl --install -d ubuntu on PowerShell to do both at once\n\n\n\nAccessing the shell on Windows\n\nOpen Ubuntu and set up a username and password\nDoes not have to match your login info for Windows\nRun sudo apt update then sudo apt upgrade to ensure everything is up to date\nWill need to create folders and files within your Ubuntu folder on your computer"
  },
  {
    "objectID": "Software.html#git-and-github",
    "href": "Software.html#git-and-github",
    "title": "Software",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\nLastest version of Git (install here)\nA GitHub account (information here)"
  },
  {
    "objectID": "Software.html#latex",
    "href": "Software.html#latex",
    "title": "Software",
    "section": "LaTeX",
    "text": "LaTeX\n\nLastest version of LaTeX (install here)"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html",
    "href": "Lecture_Folder/Week1a.html",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#statistics-for-bioengineers",
    "href": "Lecture_Folder/Week1a.html#statistics-for-bioengineers",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Statistics for Bioengineers",
    "text": "Statistics for Bioengineers\n{height = “50”}"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#goals-of-the-course",
    "href": "Lecture_Folder/Week1a.html#goals-of-the-course",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Goals of the course",
    "text": "Goals of the course\n\n\n\n\n\n\n\nThis is a practical course and we will learn by doing\n\n\n\nTeach fundamental skills for your scientific careers\nProvide a broad coverage of the core components of modern statistics\nProvide you with the computational tools necessary to carry out your work\nTo prepare you for more advanced statistics and programming education"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#class-introductions",
    "href": "Lecture_Folder/Week1a.html#class-introductions",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Class Introductions",
    "text": "Class Introductions\n\n\n\n\n\n\n\nWho are you?\n\n\n\nYour name\nYear in grad school\nHome lab or rotation lab\nWhat is your good news this week?\nWhat has your experience with programming/statistics been like?"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#what-will-you-learn",
    "href": "Lecture_Folder/Week1a.html#what-will-you-learn",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "What will you learn?",
    "text": "What will you learn?\n\n\nRead and write code in Unix and R\nImplement reproducible research practices through\n\nMarkdown\nGitHub\nTalapas and Amazon Web Services (AWS)"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#what-will-you-learn-1",
    "href": "Lecture_Folder/Week1a.html#what-will-you-learn-1",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "What will you learn?",
    "text": "What will you learn?\n\n\nExploratory data analysis and visualization\nProbability in the context of distributions and sampling\nExperimental design\np-values, test statistics, and types of errors\nStatistical analyses such as t-tests and contigency tests\nLinear and non-linear modeling\nClassical machine learning"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#class-logistics",
    "href": "Lecture_Folder/Week1a.html#class-logistics",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Class Logistics",
    "text": "Class Logistics\n\n\nMeet Tuesdays and Thursdays from 4:00pm - 5:50pm in KC158\n\nMost of class time will be hands-on coding practice, less time lecturing\n\nCoding and statistics practice via homework in Weeks 2-9\n\nAvailable Tuesday of that week, due before class on Tuesday in two weeks\n\nWeeks 10-11 you will complete a final coding project\n\nDesign script(s) that works with your research and interests using the skills you’ve learned this term"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#required-materials",
    "href": "Lecture_Folder/Week1a.html#required-materials",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Required Materials",
    "text": "Required Materials\n\nNo textbooks or purchases required\nAccess to a laptop or computer running Windows, MacOS, or Linux operating systems\nAn account on Talapas (through your lab, or through CBDS)\nAnnouncements and assignments posted on Canvas\nThe majority of course material on our class website https://wcresko.github.io/BioE_Stats/"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#section-5",
    "href": "Lecture_Folder/Week1a.html#section-5",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "",
    "text": "Note\n\n\n\nMac and Linux systems run using the same language, but previous versions of Windows lacks some of the basic features found on other systems\nTo help you practice and learn how to code in Unix, we will help you install some programs on your computer for running Unix\nR and RStudio should work on any computer"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#running-r",
    "href": "Lecture_Folder/Week1a.html#running-r",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Running R",
    "text": "Running R\n\nNeed to make sure that you have R installed\n\nlocally or on a server\nhttps://www.r-project.org\n\nCan run R from the command line\n\njust type R\ncan run it locally as well as on clusters"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#running-r-1",
    "href": "Lecture_Folder/Week1a.html#running-r-1",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Running R",
    "text": "Running R\n\nInstall an R Integrated Development Environment (IDE)\n\nRStudio: http://www.rstudio.com\nMakes working with R much easier, particularly for a new R user\nRun on Windows, Mac or Linux OS\nUse the RStudio Desktop Open Source (Free)"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#rstudio",
    "href": "Lecture_Folder/Week1a.html#rstudio",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#accessing-the-shell",
    "href": "Lecture_Folder/Week1a.html#accessing-the-shell",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Accessing the shell",
    "text": "Accessing the shell\n\nMac users: open the “Terminal” app, or use another app like ‘iTerm2’\nLinux users: open one of several “Terminal” apps\n\n\n\n\n\n\nWindows users have a little more work to do\n\n\nSee the next slides"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#accessing-the-shell-1",
    "href": "Lecture_Folder/Week1a.html#accessing-the-shell-1",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Accessing the shell",
    "text": "Accessing the shell\nWindows users\n\nGuide: https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10#1-overview\nRun Windows PowerShell as administrator\nInstall WSL2 by typing wsl --install\nRestart your computer\nSearch for and install Ubuntu from Microsoft store app\nOR type wsl --install -d ubuntu on PowerShell to do both at once"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#accessing-the-shell-on-windows",
    "href": "Lecture_Folder/Week1a.html#accessing-the-shell-on-windows",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Accessing the shell on Windows",
    "text": "Accessing the shell on Windows\n\nOpen Ubuntu and set up a username and password\nDoes not have to match your login info for Windows\nRun sudo apt update then sudo apt upgrade to ensure everything is up to date\nWill need to create folders and files within your Ubuntu folder on your computer"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#terminal-in-rstudio",
    "href": "Lecture_Folder/Week1a.html#terminal-in-rstudio",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Terminal in RStudio",
    "text": "Terminal in RStudio\n\n\n\n\n\n\nImportant\n\n\nRStudio has a terminal pane all it's own that you can use"
  },
  {
    "objectID": "Resources.html#week-1",
    "href": "Resources.html#week-1",
    "title": "Resources",
    "section": "",
    "text": "Data_Set_1"
  },
  {
    "objectID": "Resources.html#cheat-sheets",
    "href": "Resources.html#cheat-sheets",
    "title": "Resources",
    "section": "",
    "text": "Base R Cheat Sheet\nRStudio Collection of Cheat Sheets\nGit Cheat Sheet\nMarkdown Cheat Sheet\nLaTeX Cheat Sheet"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-do-we-need-coding-and-scripting",
    "href": "Lecture_Folder/Week1b.html#why-do-we-need-coding-and-scripting",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why do we need coding and scripting?",
    "text": "Why do we need coding and scripting?\n\n\nIt is incredibly fast and powerful, particularly for repeated actions\nIt allows you to do thousands of ‘clicks’ with single commands\nAbility to analyze large datasets that Excel and other GUIs can’t handle well\nAccess to thousands of free programs made for and by scientists\nThe commands work almost identically across platforms\nAbility to use computer clusters like Talapas"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#what-is-the-difference-between-coding-and-scripting",
    "href": "Lecture_Folder/Week1b.html#what-is-the-difference-between-coding-and-scripting",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "What is the difference between coding and scripting?",
    "text": "What is the difference between coding and scripting?\n\n\ncoding generally involves computer languages that use compilers\n\nC^{++}, Fortran, etc\n\nscripting generally involves computer languages that are interpreted on the fly\n\nPython, R, Julia, etc.\n\ncoding - faster but less flexible; scripting - flexible but slower\nThe distinction between the two has become somewhat fuzzy and most modern analytical pipelines contain a combination of both"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-do-we-need-statistics",
    "href": "Lecture_Folder/Week1b.html#why-do-we-need-statistics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why do we need statistics?",
    "text": "Why do we need statistics?\n\n\nWe almost never know the world perfectly, but still want to draw conclusions or make decisions\nWe need to estimate underlying parameters from samples of data\nSometimes we need to test hypotheses using data\nOther times we need to more succinctly summarize and/or visualize large amounts of data\nThere are well known mathematical rules that help us\nStatistics can be done by hand, but computers let us do most of the mathematics quickly"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-do-we-need-statistics-1",
    "href": "Lecture_Folder/Week1b.html#why-do-we-need-statistics-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why do we need statistics?",
    "text": "Why do we need statistics?\n\n\nWe want to turn data into conclusions about the world\n\npoint estimates and confidence intervals\nexperimental design\nhypothesis testing\ndata reduction of highly dimensional data\n\nWe need a firm understanding of probability, sampling and distributions"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#what-is-unix",
    "href": "Lecture_Folder/Week1b.html#what-is-unix",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "What is Unix?",
    "text": "What is Unix?\n\n\nA scripting language developed in 1969, released in 1973\nServes as the base language for many programs and computers\nIs the operating system for computers\nLinux is an open-source version of the same language"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#what-is-a-shell",
    "href": "Lecture_Folder/Week1b.html#what-is-a-shell",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "What is a shell?",
    "text": "What is a shell?\n\nThe ‘shell’ is a program that runs UNIX and takes in commands and gives them to the operating system\nBash acts as the shell in macs, linux, and now windows\nYou can access the shell via a terminal window"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#recipes-for-a-shell-command",
    "href": "Lecture_Folder/Week1b.html#recipes-for-a-shell-command",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Recipes for a shell command",
    "text": "Recipes for a shell command\n\nPrompt: notation used to indicate your computer is ready to accept a new command\nCommand: the building blocks of programming, tell computer to do a specific task\nOptions: change the behavior of a command\nArgument: what the command should operate on"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-use-the-shell",
    "href": "Lecture_Folder/Week1b.html#why-use-the-shell",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why use the shell?",
    "text": "Why use the shell?\n\n\nSpeed\nExamine large and/or unique files\nAccess super computers\nUse programs only available via shell\nThe commands work almost identically across platforms\nYou can even use them on a large computer cluster like Talapas\nIt is incredibly powerful particularly for repeated actions\nIt allows you to do thousands of ‘clicks’ with single commands"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#where-do-you-get-help",
    "href": "Lecture_Folder/Week1b.html#where-do-you-get-help",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Where do you get help?",
    "text": "Where do you get help?\n\nManual pages!\n\nThe shell has manuals for all basic commands\nType man [command_name] to access the manual for a specific command\nType q to exit\n\nAlso…the internet!"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#common-navigation-commands-1",
    "href": "Lecture_Folder/Week1b.html#common-navigation-commands-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Common navigation commands",
    "text": "Common navigation commands"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#the-way-you-normally-navigate",
    "href": "Lecture_Folder/Week1b.html#the-way-you-normally-navigate",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "The way you normally navigate",
    "text": "The way you normally navigate"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#how-is-a-computer-organized",
    "href": "Lecture_Folder/Week1b.html#how-is-a-computer-organized",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "How is a computer organized?",
    "text": "How is a computer organized?\n\nSystem of directories (folders) and files\n/ = the root directory, which holds all other directories\nMost of your files will be located under /Users in a directory of your username\nthe ~ is shorthand for your home folder\nNavigation in the shell consists of jumping up and down between directories and seeing what’s in them\nThe “path” refers to the location a file is in\n\nex: “/Users/wcresko/Documents”"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#common-navigation-commands-2",
    "href": "Lecture_Folder/Week1b.html#common-navigation-commands-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Common navigation commands",
    "text": "Common navigation commands\n\n\npwd = “print working directory”, which will print where you currently are in the system\n\nIn Windows, cd will print your working directory\n\nls = “list”, list all directories and files in your current position\n\nls –F = denote which results are directories, files, etc.\nls –l = ”long format”, lists total file sizes\nls –r = “reverse”, lists the results in reverse order\nls –S = “size”, sort results by size\nls –t = “time”, sort results by time created, from most recent to last"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#common-navigation-commands-3",
    "href": "Lecture_Folder/Week1b.html#common-navigation-commands-3",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Common Navigation Commands",
    "text": "Common Navigation Commands\n\ncd = “change directory”, will place you in a new position based on your path argument\n\ncd .. = go up one directory\ncd – = go to the directory you were at last (like the back arrow on an internet browser)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#lets-practice",
    "href": "Lecture_Folder/Week1b.html#lets-practice",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Let’s practice!",
    "text": "Let’s practice!\n\nTry navigating around your computer using cd and ls\nIf you are on Ubuntu, you may need to create some empty directories in your Ubuntu folder before navigating in the terminal"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#making-new-files",
    "href": "Lecture_Folder/Week1b.html#making-new-files",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Making new files",
    "text": "Making new files\n\n\nMake new folders: mkdir\nMake new files: nano, touch\nRename files: mv\nMove files: mv\nCopy files: cp\nDelete files: rm\nExamining file length: wc\nReading files: cat\nLooking at beginning or end: head or tail"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#things-to-keep-in-mind",
    "href": "Lecture_Folder/Week1b.html#things-to-keep-in-mind",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Things to keep in mind",
    "text": "Things to keep in mind\n\nThe shell trusts you\n\nIt will delete files you say to delete\nIt will override files if you name 2 things the same\n\nNaming conventions\n\nAvoid spaces\nDon’t start with a –\nStick to letters, numbers, . , -, and _\n\nUse appropriate file extensions in file names\n\nSome software expect files with certain extensions (.fasta, .txt, etc.)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#lets-try-it-out",
    "href": "Lecture_Folder/Week1b.html#lets-try-it-out",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nMake a new directory called whatever you’d like.\nAdd a file named “Practice.txt” to the directory and add some text to it\nRead the contents of the file and get its length\nRename the file to “Super_practice.txt”\nMove the file to a new folder named “Testing”\nMake a copy of the file named “Super_practice_copy.txt”\nRead the contents of the file and get its length to make sure it’s the same as Super_practice.txt\nDelete the original “Super_practice.txt”"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#break",
    "href": "Lecture_Folder/Week1b.html#break",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Break",
    "text": "Break"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#an-example-to-get-us-started",
    "href": "Lecture_Folder/Week1b.html#an-example-to-get-us-started",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "An example to get us started",
    "text": "An example to get us started"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#data-set-rules-of-thumb-aka-tidy-data",
    "href": "Lecture_Folder/Week1b.html#data-set-rules-of-thumb-aka-tidy-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Data set rules of thumb (aka Tidy Data)",
    "text": "Data set rules of thumb (aka Tidy Data)\n\nStore a copy of data in nonproprietary software and hardware formats, such as plain ASCII text (aka a flat file)\nLeave an uncorrected file when doing analyses\nUse descriptive names for your data files and variables\nInclude a header line with descriptive variable names\nMaintain effective metadata about the data\nWhen you add observations to a database, add rows\nWhen you add variables to a database, add columns, not rows\nA column of data should contain only one data type"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#computational-tools---r-and-rstudio",
    "href": "Lecture_Folder/Week1b.html#computational-tools---r-and-rstudio",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Computational Tools - R and RStudio",
    "text": "Computational Tools - R and RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-use-r",
    "href": "Lecture_Folder/Week1b.html#why-use-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nGood general scripting tool for statistics and mathematics\nPowerful and flexible and free\nRuns on all computer platforms\nNew enhancements coming out all the time\nSuperb data management & graphics capabilities"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-use-r-1",
    "href": "Lecture_Folder/Week1b.html#why-use-r-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nReproducibility - can keep your scripts to see exactly what was done\nYou can write your own functions\nLots of online help available\nCan use a nice GUI front end such as Rstudio\nCan embed your R analyses in dynamic, polished files using Markdown\nMarkdown can be reused for websites, papers, books, presentations…"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#r-scripts-and-markdown-files",
    "href": "Lecture_Folder/Week1b.html#r-scripts-and-markdown-files",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "R scripts and Markdown files",
    "text": "R scripts and Markdown files\n\nOften we want to write scripts that can just be run\nWe can also embed code in Markdown files that provide more annotations\nhttps://quarto.org/docs/authoring/markdown-basics.html\nYou can insert Rchunks into Quarto markdown documents"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#rscript-basics",
    "href": "Lecture_Folder/Week1b.html#rscript-basics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Rscript basics",
    "text": "Rscript basics\n\nA series of R commands that will be executed\nCan add comments using hashtags #\nCan have pipes (|&gt;) to connect one step to the next"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#markdown-basics",
    "href": "Lecture_Folder/Week1b.html#markdown-basics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Markdown basics",
    "text": "Markdown basics\n\na very simplified way for standard typesetting\nsimple markdown can be rendered in numerous different ways\nLists, codeblocks, images and more can all be inserted"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#inserting-equations-in-markdown",
    "href": "Lecture_Folder/Week1b.html#inserting-equations-in-markdown",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Inserting equations in markdown",
    "text": "Inserting equations in markdown\n$$e=mc^2$$\n\\[e=mc^2\\]\n$$\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy$$\n\\[\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy\\]"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#basics-of-r",
    "href": "Lecture_Folder/Week1b.html#basics-of-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "BASICS of R",
    "text": "BASICS of R\n\nCommands can be submitted through the terminal, console or scripts\nIn your scripts, anything that follows ‘#’ symbol (aka hash) is just for humans\nNotice on these slides I’m evaluating the code chunks and showing output\nThe output is shown here after the two # symbols and the number of output items is in []\nAlso notice that R follows the normal priority of mathematical evaluation\n\n\n4*4\n\n[1] 16\n\n\n\n(4+3*2^2)\n\n[1] 16"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#assigning-variables",
    "href": "Lecture_Folder/Week1b.html#assigning-variables",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nA better way to do this is to assign variables\nVariables are assigned values using the &lt;- operator.\nVariable names must begin with a letter, but other than that, just about anything goes.\nDo keep in mind that R is case sensitive."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#assigning-variables-1",
    "href": "Lecture_Folder/Week1b.html#assigning-variables-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nx &lt;- 2\nx*3\n\n[1] 6\n\ny &lt;- x * 3\ny-2\n\n[1] 4\n\n\nThese do not work\n\n3y &lt;- 3\n3*y &lt;- 3"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions",
    "href": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\nArithmetic operations can be performed easily on functions as well as numbers.\nTry the following, and then your own.\n\n\nx+2\nx^2\nlog(x)\n\n\nNote that the last of these - log - is a built in function of R, and therefore the object of the function needs to be put in parentheses\nThese parentheses will be important, and we’ll come back to them later when we add arguments after the object in the parentheses\n\nThe outcome of calculations can be assigned to new variables as well, and the results can be checked using the ‘print’ command"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions-1",
    "href": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\ny &lt;- 67\nprint(y)\n\n[1] 67\n\nx &lt;- 124\nz &lt;- (x*y)^2\nprint(z)\n\n[1] 69022864"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#strings",
    "href": "Lecture_Folder/Week1b.html#strings",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nVariables and operations can be performed on characters as well\nNote that characters need to be set off by quotation marks to differentiate them from numbers\nThe c stands for concatenate\nNote that we are using the same variable names as we did previously, which means that we’re overwriting our previous assignment\nA good rule of thumb is to use new names for each variable, and make them short but still descriptive"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#strings-1",
    "href": "Lecture_Folder/Week1b.html#strings-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nx &lt;- \"I Love\"\nprint (x)\n\n[1] \"I Love\"\n\ny &lt;- \"Biostatistics\"\nprint (y)\n\n[1] \"Biostatistics\"\n\nz &lt;- c(x,y)\nprint (z)\n\n[1] \"I Love\"        \"Biostatistics\""
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#factors",
    "href": "Lecture_Folder/Week1b.html#factors",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nThe variable z is now what is called a list of character values.\nSometimes we would like to treat the characters as if they were units for subsequent calculations.\nThese are called factors, and we can redefine our character variables as factors.\nThis might seem a bit strange, but it’s important for statistical analyses where we might want to see the mean or variance for two different treatments."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#factors-1",
    "href": "Lecture_Folder/Week1b.html#factors-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nz_factor &lt;- as.factor(z)\nprint (z_factor)\n\n\nNote that factor levels are reported alphabetically"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#vectors",
    "href": "Lecture_Folder/Week1b.html#vectors",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nIn general R thinks in terms of vectors (a list of characters, factors or numerical values) and it will benefit any R user to try to write programs with that in mind, as it will simplify most things.\nVectors can be assigned directly using the ‘c()’ function and then entering the exact values."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#vectors-1",
    "href": "Lecture_Folder/Week1b.html#vectors-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nx &lt;- c(2,3,4,2,1,2,4,5,10,8,9)\nprint(x)\n\n [1]  2  3  4  2  1  2  4  5 10  8  9"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#basic-statistics",
    "href": "Lecture_Folder/Week1b.html#basic-statistics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nMany functions exist to operate on vectors.\nCombine these with your previous variable to see what happens.\nAlso, try to find other functions (e.g. standard deviation)."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#basic-statistics-1",
    "href": "Lecture_Folder/Week1b.html#basic-statistics-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nmean(x)\nmedian(x)\nvar(x)\nlog(x)\nln(x)\nsqrt(x)\nsum(x)\nlength(x)\nsample(x, replace = T)\n\n\nNotice that the last function (sample) has an argument (replace=T)\nArguments simply modify or direct the function in some way\nThere are many arguments for each function, some of which are defaults"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#getting-help",
    "href": "Lecture_Folder/Week1b.html#getting-help",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\nGetting Help on any function is very easy - just type a question mark and the name of the function.\nThere are functions for just about anything within R and it is easy enough to write your own functions if none already exist to do what you want to do.\nIn general, function calls have a simple structure: a function name, a set of parentheses and an optional set of parameters to send to the function.\nHelp pages exist for all functions that, at a minimum, explain what parameters exist for the function.\n\nHelp can be accessed a few ways - try them :"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#getting-help-1",
    "href": "Lecture_Folder/Week1b.html#getting-help-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\n- help(mean)\n- ?mean\n- example(mean)\n- help.search(\"mean\")\n- apropos(\"mean\")\n- args(mean)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors",
    "href": "Lecture_Folder/Week1b.html#creating-vectors",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nCreating vector of new data by entering it by hand can be a drag\nHowever, it is also very easy to use functions such as seq and sample\nTry the examples below Can you figure out what the three arguments in the parentheses mean?\nTry varying the arguments to see what happens.\nDon’t go too crazy with the last one or your computer might slow way down"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors-1",
    "href": "Lecture_Folder/Week1b.html#creating-vectors-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nprint(seq_1)\n\n  [1]  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.0  1.1  1.2  1.3  1.4\n [16]  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9\n [31]  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.0  4.1  4.2  4.3  4.4\n [46]  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9\n [61]  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.0  7.1  7.2  7.3  7.4\n [76]  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4  8.5  8.6  8.7  8.8  8.9\n [91]  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9 10.0\n\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)\nprint(seq_2)\n\n  [1] 10.0  9.9  9.8  9.7  9.6  9.5  9.4  9.3  9.2  9.1  9.0  8.9  8.8  8.7  8.6\n [16]  8.5  8.4  8.3  8.2  8.1  8.0  7.9  7.8  7.7  7.6  7.5  7.4  7.3  7.2  7.1\n [31]  7.0  6.9  6.8  6.7  6.6  6.5  6.4  6.3  6.2  6.1  6.0  5.9  5.8  5.7  5.6\n [46]  5.5  5.4  5.3  5.2  5.1  5.0  4.9  4.8  4.7  4.6  4.5  4.4  4.3  4.2  4.1\n [61]  4.0  3.9  3.8  3.7  3.6  3.5  3.4  3.3  3.2  3.1  3.0  2.9  2.8  2.7  2.6\n [76]  2.5  2.4  2.3  2.2  2.1  2.0  1.9  1.8  1.7  1.6  1.5  1.4  1.3  1.2  1.1\n [91]  1.0  0.9  0.8  0.7  0.6  0.5  0.4  0.3  0.2  0.1  0.0"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors-2",
    "href": "Lecture_Folder/Week1b.html#creating-vectors-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square &lt;- (seq_2)*(seq_2)\nprint(seq_square)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors-3",
    "href": "Lecture_Folder/Week1b.html#creating-vectors-3",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square_new &lt;- (seq_2)^2\nprint(seq_square_new)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nHere is a way to create your own data sets that are random samples.\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-1",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(x,y)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-2",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(xy)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-3",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-3",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nhist(x)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-4",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-4",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nYou’ve probably figured out that y from the last example is drawing numbers with equal probability.\nWhat if you want to draw from a distribution?\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-5",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-5",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;-rnorm(1000, 0, 100)\nhist(x, xlim = c(-500,500))\ncurve(50000*dnorm(x, 0, 100), xlim = c(-500,500), add=TRUE, col='Red')\n\n\n\ndnorm() generates the probability density, which can be plotted using the curve() function.\nNote that is curve is added to the plot using add=TRUE"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#visualizing-data",
    "href": "Lecture_Folder/Week1b.html#visualizing-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nSo far you’ve been visualizing just the list of output numbers\nExcept for the last example where I snuck in a hist function.\nYou can also visualize all of the variables that you’ve created using the plot function (as well as a number of more sophisticated plotting functions).\nEach of these is called a high level plotting function, which sets the stage\nLow level plotting functions will tweak the plots and make them beautiful"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#visualizing-data-1",
    "href": "Lecture_Folder/Week1b.html#visualizing-data-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nWhat do you think that each of the arguments means for the plot function?\nA cool thing about R is that the options for the arguments make sense.\nTry adjusting an argument and see if it works\nNote next week we will be exploring the plotting in GGPlot2"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#visualizing-data-2",
    "href": "Lecture_Folder/Week1b.html#visualizing-data-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1) \nplot (seq_1, xlab=\"space\", ylab =\"function of space\", type = \"p\", col = \"red\")"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure",
    "href": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\nOn the next slide\nThe first line of the lower script tells R that you are going to create a composite figure that has two rows and two columns. Can you tell how?\nNow, modify the code to add two more variables and add one more row of two panels.\n\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure-1",
    "href": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\npar(mfrow=c(2,2))\nplot (seq_1, xlab=\"time\", ylab =\"p in population 1\", type = \"p\", col = 'red')\nplot (seq_2, xlab=\"time\", ylab =\"p in population 2\", type = \"p\", col = 'green')\nplot (seq_square, xlab=\"time\", ylab =\"p2 in population 2\", type = \"p\", col = 'blue')\nplot (seq_square_new, xlab=\"time\", ylab =\"p in population 1\", type = \"l\", col = 'yellow')"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#example-using-binomial-distribution",
    "href": "Lecture_Folder/Week1b.html#example-using-binomial-distribution",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nAs above for the normal distribution, data can be generated by being sampled from nearly any distribution and then visualized.\nBelow I’m having you use the ‘histogram’ function. What does it do?"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-1",
    "href": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\n10 successes (out of 20 trials) is the most frequent outcome\n\n\nheads &lt;- rbinom(n=1000, size=20, prob=0.5)\nhist(heads)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-2",
    "href": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nThis kind of statement can be run in one line as well, which is sometimes easier.\n\n\nhist(rbinom(n=1000, size=20, prob=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-data-frames-in-r",
    "href": "Lecture_Folder/Week1b.html#creating-data-frames-in-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating Data Frames in R",
    "text": "Creating Data Frames in R\n\nAs you have seen, in R you can generate your own random data set drawn from nearly any distribution very easily.\nOften we will want to use collected data.\nNow, let’s make a dummy dataset to get used to dealing with data frames\nSet up three variables (hydrogel_concentration, compression and conductivity) as vectors\n\n\nhydrogel_concentration &lt;- factor(c(\"low\", \"high\", \"high\", \"high\", \"medium\", \"medium\", \"medium\",\"low\"))\ncompression &lt;- c(3.4, 3.4, 8.4, 3, 5.6, 8.1, 8.3, 4.5)\nconductivity &lt;- c(0, 9.2, 3.8, 5, 5.6, 4.1, 7.1, 5.3)\n\n\nCreate a data frame where vectors become columns\n\n\nmydata &lt;- data.frame(hydrogel_concentration, compression, conductivity)\nrow.names(mydata) &lt;- c(\"Sample_1\", \"Sample_2\", \"Sample_3\", \"Sample_4\", \n                       \"Sample_5\", \"Sample_6\", \"Sample_7\", \"Sample_8\")\n\n\nNow you have a hand-made data frame with row names\nTake a look at it in the data section of RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r",
    "href": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nA strength of R is being able to import data from an external source\nCreate the same table that you did above in a spreadsheet like Excel\nExport it to comma separated and tab separated text files for importing into R.\nThe first will read in a comma-delimited file, whereas the second is a tab-delimited\nIn both cases the header and row.names arguments indicate that there is a header row and row label column\nNote that the name of the file by itself will have R look in the CWD, whereas a full path can also be used"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r-1",
    "href": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nYourFile &lt;- read.table('yourfile.csv', header=T, row.names=1, sep=',')\nYourFile &lt;- read.table('yourfile.txt', header=T, row.names=1, sep='\\t')"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#exporting-data-frames-in-r",
    "href": "Lecture_Folder/Week1b.html#exporting-data-frames-in-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Exporting Data Frames in R",
    "text": "Exporting Data Frames in R\n\nwrite.table(YourFile, \"yourfile.csv\", quote=F, row.names=T, sep=\",\")\nwrite.table(YourFile, \"yourfile.txt\", quote=F, row.names=T, sep=\"\\t\")"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#indexing-in-data-frames",
    "href": "Lecture_Folder/Week1b.html#indexing-in-data-frames",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nNext up - indexing just a subset of the data\nThis is a very important idea in R, that you can analyze just a subset of the data.\nThis is analyzing only the data in the file you made that has the factor value ‘mixed’.\n\n\nprint (YourFile[,2])\nprint (YourFile$temp)\nprint (YourFile[2,])\nplot (YourFile$temp, YourFile$elevation)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#indexing-in-data-frames-1",
    "href": "Lecture_Folder/Week1b.html#indexing-in-data-frames-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nYou can perform operations on particular levels of a factor\nCalculating the mean of the ‘mixed’ and ‘gipps’ levels of habitat.\nNote that the first argument is the numerical column vector, and the second is the factor column vector.\nThe third is the operation. Reversing the first two does not work (the one below).\n\n\ntapply(YourFile$temp, YourFile$habitat, mean)\ntapply(YourFile$temp, YourFile$habitat, var)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#r-interlude-some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week1b.html#r-interlude-some-real-transcriptomic-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Some real transcriptomic data",
    "text": "R INTERLUDE | Some real transcriptomic data\n\nExamine the data file\nHow many many rows and columns are there?\nHow many different variables are there?\nWhat are the general types of variables?\nNow let’s read the data file into R and analyze it\nThis exercise will help you get used to reading in and manipulating genomic data files\nFirst off, remember to set your working directory to find your file correctly"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week1b.html#some-real-transcriptomic-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Some real transcriptomic data",
    "text": "Some real transcriptomic data\n\nRNAseq_Data &lt;- read.table('&lt;name_of_file&gt;', header=TRUE, sep=',')\n\nprint (RNAseq_Data)\nhead (RNAseq_Data)\ntail (RNAseq_Data)\n\nprint (RNAseq_Data[,2])\nprint (RNAseq_Data[1,])\nprint (RNAseq_Data[1,2])\nprint (RNAseq_Data$ENSGACG00000000010)\nprint (RNAseq_Data$ENSGACG00000000010&gt;45.0)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#summary-stats-and-figures",
    "href": "Lecture_Folder/Week1b.html#summary-stats-and-figures",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Summary stats and figures",
    "text": "Summary stats and figures\n\nsummary1 &lt;- summary(RNAseq_Data $ENSGACG00000000003)\nprint (summary1)\n\nhist(RNAseq_Data $ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003~RNAseq_Data$Population)\nplot(RNAseq_Data $ENSGACG00000000003, RNAseq_Data$ENSGACG00000000003)\n\nboxplot(RNAseq_Data $ENSGACG00000000003~RNAseq_Data$Treatment, \n        col = \"red\", ylab = \"Expression Level\", xlab = \"Treatment level\", \n        border =\"orange\", \n        main = \"Boxplot of variation in gene expression across microbiota treatments\")\n\n\n\n\nBioE_Stats_2025 - Knight Campus"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html",
    "href": "Lecture_Folder/Week2b.html",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#today-we-will",
    "href": "Lecture_Folder/Week2b.html#today-we-will",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Today we will",
    "text": "Today we will\n\nFinish Markdown, Latex\nExploratory data analysis with ggplot2\nProbability and distributions\n\n\n\n\n\n\n\nNote\n\n\nHomeworks will be assigned this evening and be due in 2 weeks"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-markdown",
    "href": "Lecture_Folder/Week2b.html#what-is-markdown",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is markdown?",
    "text": "What is markdown?\n\nLightweight formal markup languages are used to add formatting to plaintext documents\n\nAdding basic syntax to the text will make elements look different once rendered/knit\nAvailable in many base editors\n\nYou then need a markdown application with a markdown processor/parser to render your text files into something more exciting\n\nStatic and dynamic outputs!\npdf, HTML, presentations, websites, scientific articles, books etc"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-text",
    "href": "Lecture_Folder/Week2b.html#formatting-text",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting text",
    "text": "Formatting text\n\n*Italic* or _Italic_\n**Bold** or __Bold__\n\n\nItalic or Italic\nBold or Bold"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-text-1",
    "href": "Lecture_Folder/Week2b.html#formatting-text-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting text",
    "text": "Formatting text\n\n&gt; \"You know the greatest danger facing us is ourselves, an irrational fear of the unknown. \nBut there’s no such thing as the unknown — only things temporarily hidden, temporarily not understood.\"\n&gt;\n&gt; --- Captain James T. Kirk\n\n\n“You know the greatest danger facing us is ourselves, an irrational fear of the unknown. But there’s no such thing as the unknown — only things temporarily hidden, temporarily not understood.”\n— Captain James T. Kirk"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-lists",
    "href": "Lecture_Folder/Week2b.html#formatting-lists",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting lists",
    "text": "Formatting lists\n\n- list_element\n    - sub_list_element #double tab to indent\n    - sub_list_element #double tab to indent\n    - sub_list_element #double tab to indent\n- list_element\n    - sub_list_element #double tab to indent\n#note the space after each dash- this is important!\n\n\nlist_element\n\nsub_list_element\nsub_list_element\nsub_list_element\n\nlist_element\n\nsub_list_element"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-lists-1",
    "href": "Lecture_Folder/Week2b.html#formatting-lists-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting lists",
    "text": "Formatting lists\n\n1. One\n2. Two\n3. Three\n4. Four\n\n\nOne\nTwo\nThree\nFour"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#inserting-images-or-urls",
    "href": "Lecture_Folder/Week2b.html#inserting-images-or-urls",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Inserting images or URLs",
    "text": "Inserting images or URLs\n\n[Link](https://commonmark.org/help/)\n![Image](https://i1.wp.com/evomics.org/wp-content/uploads/2012/07/20120115-IMG_0297.jpg)\n\nLink"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#including-code-chunks",
    "href": "Lecture_Folder/Week2b.html#including-code-chunks",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Including code chunks",
    "text": "Including code chunks\n\nx &lt;- 2\nx^2\n\n[1] 4"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-latex",
    "href": "Lecture_Folder/Week2b.html#what-is-latex",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is LaTeX?",
    "text": "What is LaTeX?\n\nPronounced «Lah-tech» or «Lay-tech» (to rhyme with «Bertolt Brecht»)\nA document preparation system for high-quality typesetting\nIt is most often used for medium-to-large technical or scientific documents\nCan be used for almost any form of publishing.\nTypesetting journal articles, technical reports, books, and slide presentations\nAllows for precise mathematical statements\nhttps://www.latex-project.org\nImportantly, LaTeX can be included right into Markdown documents"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#operators-and-symbols",
    "href": "Lecture_Folder/Week2b.html#operators-and-symbols",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Operators and Symbols",
    "text": "Operators and Symbols\n\n$$ \\large a^x, \\sqrt[n]{x}, \\vec{\\jmath}, \\tilde{\\imath}$$\n\n\\[ \\large a^x, \\sqrt[n]{x}, \\vec{\\jmath}, \\tilde{\\imath}\\]\n\n$$ \\large \\alpha, \\beta, \\gamma$$\n\n\\[ \\large \\alpha, \\beta, \\gamma\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#operators-and-symbols-1",
    "href": "Lecture_Folder/Week2b.html#operators-and-symbols-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Operators and Symbols",
    "text": "Operators and Symbols\n\n$$ \\large\\approx, \\neq, \\nsim $$\n\n\\[ \\large\\approx, \\neq, \\nsim \\]\n\n$$\\large \\partial, \\mathbb{R}, \\flat$$\n\n\\[\\large \\partial, \\mathbb{R}, \\flat\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#equations",
    "href": "Lecture_Folder/Week2b.html#equations",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Equations",
    "text": "Equations\nBinomial sampling equation\n\n$$\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}$$\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\nPoisson Sampling Equation\n\n$$\\large Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}$$\n\n\\[\\large Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#differential-equations",
    "href": "Lecture_Folder/Week2b.html#differential-equations",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Differential Equations",
    "text": "Differential Equations\n\n$$\\iint xy^2\\,dx\\,dy =\\frac{1}{6}x^2y^3$$\n\n\\[\\iint xy^2\\,dx\\,dy =\\frac{1}{6}x^2y^3\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#matrix-formulations",
    "href": "Lecture_Folder/Week2b.html#matrix-formulations",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Matrix formulations",
    "text": "Matrix formulations\n\n$$  \\begin{matrix}\n        -2 & 1 & 0 & 0 & \\cdots & 0  \\\\\n        1 & -2 & 1 & 0 & \\cdots & 0  \\\\\n        0 & 1 & -2 & 1 & \\cdots & 0  \\\\\n        0 & 0 & 1 & -2 & \\ddots & \\vdots \\\\\n        \\vdots & \\vdots & \\vdots & \\ddots & \\ddots & 1  \\\\\n        0 & 0 & 0 & \\cdots & 1 & -2\n    \\end{matrix} $$\n\n\\[  \\begin{matrix}\n        -2 & 1 & 0 & 0 & \\cdots & 0  \\\\\n        1 & -2 & 1 & 0 & \\cdots & 0  \\\\\n        0 & 1 & -2 & 1 & \\cdots & 0  \\\\\n        0 & 0 & 1 & -2 & \\ddots & \\vdots \\\\\n        \\vdots & \\vdots & \\vdots & \\ddots & \\ddots & 1  \\\\\n        0 & 0 & 0 & \\cdots & 1 & -2\n    \\end{matrix} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#in-line-versus-fenced",
    "href": "Lecture_Folder/Week2b.html#in-line-versus-fenced",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "In-line versus fenced",
    "text": "In-line versus fenced\n\nThis equation, $y=\\frac{1}{2}$, is included inline\n\nThis equation, \\(y=\\frac{1}{2}\\), is included inline\n\nWhereas this equation, $$y=\\frac{1}{2}$$, is put on a separate line\n\nWhereas this equation \\[y=\\frac{1}{2}\\] is put on a separate line"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#markdown-is-very-flexible",
    "href": "Lecture_Folder/Week2b.html#markdown-is-very-flexible",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Markdown is very flexible",
    "text": "Markdown is very flexible\n\nYou can import RMarkdown templates into RStudio and open as a new Rmarkdown file\nBetter yet there are packages that add functionality\n\nbooks\njournal articles\nslide shows (these slides!)\ninteractive exercises"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#reading-in-and-exporting-data-frames",
    "href": "Lecture_Folder/Week2b.html#reading-in-and-exporting-data-frames",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Reading in and Exporting Data Frames",
    "text": "Reading in and Exporting Data Frames\n\n\n\n\nYourFile &lt;- read.table('yourfile.csv', header=T, row.names=1, sep=',')\nYourFile &lt;- read.table('yourfile.txt', header=T, row.names=1, sep='\\t')\n\n\n\n\n\nwrite.table(YourFile, \"yourfile.csv\", quote=F, row.names=T, sep=\",\")\nwrite.table(YourFile, \"yourfile.txt\", quote=F, row.names=T, sep=\"\\t\")"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#indexing-in-data-frames",
    "href": "Lecture_Folder/Week2b.html#indexing-in-data-frames",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nNext up - indexing just a subset of the data\nThis is a very important idea in R, that you can analyze just a subset of the data.\nThis is analyzing only the data in the file you made that has the factor value ‘mixed’.\n\n\nprint (YourFile[,2])\nprint (YourFile$variable)\nprint (YourFile[2,])\nplot (YourFile$variable1, YourFile$variable2)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#types-of-vectors-of-data",
    "href": "Lecture_Folder/Week2b.html#types-of-vectors-of-data",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\n\nint stands for integers\ndbl stands for doubles, or real numbers\nchr stands for character vectors, or strings\ndttm stands for date-times (a date + a time)\nlgl stands for logical, vectors that contain only TRUE or FALSE\nfctr stands for factors, which R uses to represent categorical variables with fixed possible values\ndate stands for dates\n\n\n\n\n\n\n\nNote\n\n\n\nInteger and double vectors are known collectively as numeric vectors.\nIn R numbers are doubles by default."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#types-of-vectors-of-data-1",
    "href": "Lecture_Folder/Week2b.html#types-of-vectors-of-data-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\n\nLogical vectors can take only three possible values:\n\nFALSE\nTRUE\nNA which is ‘not available’.\n\nIntegers have one special value: NA, while doubles have four:\n\nNA\nNaN which is ‘not a number’\nInf\n-Inf"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#plotting-using-ggplot2",
    "href": "Lecture_Folder/Week2b.html#plotting-using-ggplot2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Plotting using ggplot2()",
    "text": "Plotting using ggplot2()\n\nPart of the tidyverse suite of packages\nIn most cases, you start with ggplot2()\nSupply a dataset and aesthetic mapping with aes()\nDetermine the type of plot using geom_point() or geom_histogram() or others\nMany more options and controls available!\nMore info: https://ggplot2.tidyverse.org/"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics",
    "href": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "GGPlot2 and the Grammar of Graphics",
    "text": "GGPlot2 and the Grammar of Graphics\n\nGG stands for ‘Grammar of Graphics’\nA good paragraph uses good grammar to convey information\nA good figure uses good grammar in the same way\nSeven general components can be used to create most figures"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics-1",
    "href": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "GGPlot2 and the Grammar of Graphics",
    "text": "GGPlot2 and the Grammar of Graphics"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#plotting-using-ggplot",
    "href": "Lecture_Folder/Week2b.html#plotting-using-ggplot",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Plotting using ggplot()",
    "text": "Plotting using ggplot()\n\nInstall and load ggplot2\n\n\n# install.packages(\"ggplot2\")\nlibrary(\"ggplot2\")"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#scatterplots-with-ggplot",
    "href": "Lecture_Folder/Week2b.html#scatterplots-with-ggplot",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Scatterplots with ggplot",
    "text": "Scatterplots with ggplot\n\nUse the preloaded mpg dataset available in RStudio\n\n\nggplot(mpg, aes(displ, hwy, color = class)) + \n  geom_point(size = 6,\n             shape = \"square\",\n             alpha = 0.4)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#boxplots-in-ggplot",
    "href": "Lecture_Folder/Week2b.html#boxplots-in-ggplot",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Boxplots in ggplot",
    "text": "Boxplots in ggplot\n\nggplot(mpg, aes(manufacturer, hwy, colour = class)) + \n  geom_boxplot() + \n  theme_classic() + \n  theme(axis.text.x = element_text(angle = 45, hjust=1))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_bar-function",
    "href": "Lecture_Folder/Week2b.html#the-geom_bar-function",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_bar function",
    "text": "The geom_bar function\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut))\n\nNow try this…\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut, color=cut))\n\nand this…\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut, fill=cut))\n\nand finally this…\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut, fill=clarity), position=\"dodge\")"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_histogram-and-geom_freqpolyfunction",
    "href": "Lecture_Folder/Week2b.html#the-geom_histogram-and-geom_freqpolyfunction",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_histogram and geom_freqpolyfunction",
    "text": "The geom_histogram and geom_freqpolyfunction\nWith this function you can make a histogram\n\nggplot(data=diamonds) +\n  geom_histogram(mapping=aes(x=carat), binwidth=0.5)\n\nThis allows you to make a frequency polygram\n\nggplot(data=diamonds) +\n  geom_histogram(mapping=aes(x=carat), binwidth=0.5)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_boxplot-function",
    "href": "Lecture_Folder/Week2b.html#the-geom_boxplot-function",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_boxplot function",
    "text": "The geom_boxplot function\nBoxplots are very useful for visualizing data\n\nggplot(data=diamonds, mapping=aes(x=cut, y=price)) +\n  geom_boxplot()\n\n\n\n\nggplot(data=mpg, mapping=aes(x=reorder(class, hwy, FUN=median), y=hwy)) +\n  coordflip()\n\n\n\n\nggplot(data=mpg, mapping=aes(x=class, y=hwy)) +\n  geom_boxplot() +\n  coordflip"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_point-geom_smooth-functions",
    "href": "Lecture_Folder/Week2b.html#the-geom_point-geom_smooth-functions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_point & geom_smooth functions",
    "text": "The geom_point & geom_smooth functions\n\nggplot(data=diamonds2, mapping=aes(x=x, y=y)) +\n  geompoint()\n\n\n\n\nggplot(data=mpg) +\n  geompoint(mapping=aes(x=displ, y=hwy)) +\n  facet_wrap(~class, nrow=2)\n\n\n\n\nggplot(data=mpg) +\n  geompoint(mapping=aes(x=displ, y=hwy)) +\n  facet_grid(drv~cyl)\n\n\n\n\nggplot(data=mpg) +\n  geomsmooth(mapping=aes(x=displ, y=hwy))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#combining-geoms",
    "href": "Lecture_Folder/Week2b.html#combining-geoms",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Combining geoms",
    "text": "Combining geoms\n\nggplot(data=mpg) +\n  geom_point(mapping=aes(x=displ, y=hwy)) +\n  geom_smooth(mapping=aes(x=displ, y=hwy))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#adding-labels",
    "href": "Lecture_Folder/Week2b.html#adding-labels",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Adding labels",
    "text": "Adding labels\n\nggplot(data=mpg, aes(displ, hwy)) +\n  geom_point(aes(color=class)) +\n  geom_smooth(se=FALSE) +\n  labs(\n    title = \"Fuel efficiency generally decreases with engine size\",\n    caption = \"Data from fueleconomy.gov\"\n  )"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-type-of-plot-do-i-use-for-each-data-type",
    "href": "Lecture_Folder/Week2b.html#what-type-of-plot-do-i-use-for-each-data-type",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What type of plot do I use for each data type?",
    "text": "What type of plot do I use for each data type?\n\n\nFlow chart to determine what type of data visualization and which ggplot geom to use\n\nBioE_Stats_2025 - Knight Campus"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#different-flavors-of-inferential-statistics",
    "href": "Lecture_Folder/Week2b.html#different-flavors-of-inferential-statistics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Different flavors of inferential statistics",
    "text": "Different flavors of inferential statistics\n\nFrequentist Statistics\n\nClassical or standard approaches\nNull hypothesis testing\n\n\n\nHierarchical Probabilistic Modeling\n\nMaximum Likelihood\nBayesian Analyses\nMachine Learning"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-probability",
    "href": "Lecture_Folder/Week2b.html#what-is-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is probability",
    "text": "What is probability\n\nFrequency interpretation\n\n“Probabilities are understood as mathematically convenient approximations to long run relative frequencies.”\n\nSubjective (Bayesian) interpretation\n\n“A probability statement expresses the opinion of some individual regarding how certain an event is to occur.”"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#random-variables-probability",
    "href": "Lecture_Folder/Week2b.html#random-variables-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nProbability is the expression of belief in some future outcome\nA random variable can take on different values with different probabilities\nThe sample space of a random variable is the universe of all possible values"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#random-variables-probability-1",
    "href": "Lecture_Folder/Week2b.html#random-variables-probability-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nThe sample space can be represented by a\n\nprobability distribution (discrete)\nprobability density function (PDF) (continuous)\nalgebra and calculus are used for each respectively\nprobabilities of a sample space always sum to 1.0\n\nHow does it make sense that a sample space will always sum to 1?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#bernoulli-distribution",
    "href": "Lecture_Folder/Week2b.html#bernoulli-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nDescribes the expected outcome of a single event with probability p\nExample of flipping of a fair coin once\n\n\\[Pr(X=\\text{Head}) = \\frac{1}{2} = 0.5 = p \\]\n\\[Pr(X=\\text{Tails}) = \\frac{1}{2} = 0.5 = 1 - p = q \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#bernoulli-distribution-1",
    "href": "Lecture_Folder/Week2b.html#bernoulli-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nIf the coin isn’t fair then \\(p \\neq 0.5\\)\nHowever, the probabilities still sum to 1\n\n\\[ p + (1-p) = 1 \\] \\[ p + q = 1 \\]\n\nSame is true for other binary possibilities\n\nsuccess or failure\nyes or no answers\nchoosing an allele from a population based upon allele frequencies (Hardy-Weinberg ring any bells??)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#probability-rules",
    "href": "Lecture_Folder/Week2b.html#probability-rules",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nFlip a coin twice\nRepresent the first flip as ‘X’ and the second flip as ‘Y’\n\n\\[ Pr(\\text{X=H and Y=H}) = p*p = p^2 \\] \\[ Pr(\\text{X=H and Y=T}) = p*q = pq = p^2 \\] \\[ Pr(\\text{X=T and Y=H}) = q*p = pq \\] \\[ Pr(\\text{X=T and Y=T}) = q*q = q^2 \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#probability-rules-1",
    "href": "Lecture_Folder/Week2b.html#probability-rules-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nProbability that the H and T can occur in any order\n\n\\[ \\text{Pr(X=H) or Pr(X=T)} = p+q=1\\]\n\\[ \\text{Pr(X=H and Y=T) or Pr(X=T and Y=H)} = \\] \\[ (p*q) + (p*q) = 2pq \\]\n\nThese are the ‘and’ and ‘or’ rules of probability\n\n‘and’ means multiply the probabilities\n‘or’ means sum the probabilities\nmost probability distributions can be built up from these simple rules"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips",
    "href": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\n# tossing a fair coin\ncoin &lt;- c(\"heads\", \"tails\")\n\nsample(coin)\n\n[1] \"tails\" \"heads\""
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips-1",
    "href": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\nWhat happens when we change the probabilities or the sample size? How confident are we that our coin is fair?\n\n\nflips &lt;- sample(coin, prob = c(0.5, 0.5), size=10, replace=TRUE)\nbarplot(table(flips))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#expectation-and-moments-of-distributions",
    "href": "Lecture_Folder/Week2b.html#expectation-and-moments-of-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Expectation and Moments of Distributions",
    "text": "Expectation and Moments of Distributions\n\nDistributions have moments that can be estimated\n1st, 2nd, 3rd and 4th moments of a distribution?\nThe expectation or mean of a random variable X is:\n\n\\[E[X] = \\sum_{\\text{all x}}^{}xP(X=x) = \\mu\\]\n\nOften we want to know how dispersed the random variable is around its mean.\nOne measure of dispersion is the variance\n\n\\[Var(X) = E[X^2] = \\sigma^2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#joint-probability",
    "href": "Lecture_Folder/Week2b.html#joint-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Joint probability",
    "text": "Joint probability\n\\[Pr(X,Y) = Pr(X) * Pr(Y)\\]\n\nNote that this is true for two independent events\nHowever, for two non-independent events we also have to take into account their covariance\nTo do this we need conditional probabilities"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#conditional-probability",
    "href": "Lecture_Folder/Week2b.html#conditional-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nFor two independent variables: Probability of Y, given X, or the probability of X, given Y.\n\n\\[Pr(Y|X) = Pr(Y)\\text{ and }Pr(X|Y) = Pr(X)\\]\n\nFor two non-independent variables\n\n\\[Pr(Y|X) \\neq Pr(Y)\\text{ and }Pr(X|Y) \\neq Pr(X)\\]\n\nVariables that are non-independent have a shared variance, which is also known as the covariance\nCovariance standardized to a mean of zero and a unit standard deviation is correlation"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-likelihood-vs.-probability",
    "href": "Lecture_Folder/Week2b.html#what-is-likelihood-vs.-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is Likelihood vs. Probability?",
    "text": "What is Likelihood vs. Probability?\n\nThe probability of an event is the proportion of times that the event would occur if we repeated a random trial over and over again under the same conditions.\nThe likelihood is a conditional probability of a parameter value given a set of data\nThe likelihood of a population parameter equaling a specific value, given the data\n\nL[parameter|data] = Pr[data|parameter]\n\nLikelihood function which can have a maximum"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#extra-bayesian-material",
    "href": "Lecture_Folder/Week2b.html#extra-bayesian-material",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Extra Bayesian material",
    "text": "Extra Bayesian material"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#who-wants-to-win-a-car",
    "href": "Lecture_Folder/Week2b.html#who-wants-to-win-a-car",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Who wants to win a car?",
    "text": "Who wants to win a car?\n\nPretend that there are three doors, and behind one is a car. Behind the other doors are cats.\nYou choose one of the doors, and then Monte Hall opens one of the two remaining doors to reveal a cat.\nAt this point you have the choice of changing doors or staying with your original choice.\nWhat should you do?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#geometric-distribution",
    "href": "Lecture_Folder/Week2b.html#geometric-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week2b.html#geometric-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#geometric-distribution-2",
    "href": "Lecture_Folder/Week2b.html#geometric-distribution-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week2b.html#testing-geometric-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\n#dgeom(x=20, p=0.1)\n# 0.01215767\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week2b.html#testing-geometric-distributions-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-distribution",
    "href": "Lecture_Folder/Week2b.html#binomial-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-distribution-1",
    "href": "Lecture_Folder/Week2b.html#binomial-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-probability-distribution",
    "href": "Lecture_Folder/Week2b.html#binomial-probability-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-binomial-distributions",
    "href": "Lecture_Folder/Week2b.html#testing-binomial-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\ndbinom gives the density (probability) of number successes (x) in number trials (size), with (prob) probability between 0-1\n\n\n# dbinom(x=5, size=10, p=0.5)\n# 0.246\nplot(dbinom(x=1:10, size=10, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-binomial-distributions-1",
    "href": "Lecture_Folder/Week2b.html#testing-binomial-distributions-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\npbinom gives the cumulative probability of reaching at least (q) number of successes after (size) number of trials\n\n\nplot(pbinom(q=1:100, size=100, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week2b.html#negative-binomial-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “successes” have happened.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “success” appearing on the \\(k^{th}\\) trial\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week2b.html#negative-binomial-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 AA\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week2b.html#testing-poisson-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#uniform-distribution",
    "href": "Lecture_Folder/Week2b.html#uniform-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week2b.html#uniform-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#exponential-distribution",
    "href": "Lecture_Folder/Week2b.html#exponential-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week2b.html#exponential-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gamma-distribution",
    "href": "Lecture_Folder/Week2b.html#gamma-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week2b.html#gamma-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-gaussian-or-normal-distribution",
    "href": "Lecture_Folder/Week2b.html#the-gaussian-or-normal-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The Gaussian or Normal Distribution",
    "text": "The Gaussian or Normal Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "href": "Lecture_Folder/Week2b.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Log-normal PDF | Continuous version of Poisson (-ish)",
    "text": "Log-normal PDF | Continuous version of Poisson (-ish)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#transformations-to-normalize-data",
    "href": "Lecture_Folder/Week2b.html#transformations-to-normalize-data",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#transformations-to-normalize-data-1",
    "href": "Lecture_Folder/Week2b.html#transformations-to-normalize-data-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-to-normal-categorical-to-continuous",
    "href": "Lecture_Folder/Week2b.html#binomial-to-normal-categorical-to-continuous",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial to Normal | Categorical to continuous",
    "text": "Binomial to Normal | Categorical to continuous"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "href": "Lecture_Folder/Week2b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The Normal (aka Gaussian) | Probability Density Function (PDF)",
    "text": "The Normal (aka Gaussian) | Probability Density Function (PDF)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf",
    "href": "Lecture_Folder/Week2b.html#normal-pdf",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf-a-function-of-two-parameters",
    "href": "Lecture_Folder/Week2b.html#normal-pdf-a-function-of-two-parameters",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF | A function of two parameters",
    "text": "Normal PDF | A function of two parameters\n\n(\\(\\mu\\) and \\(\\sigma\\))\n\n\n\n\n\n\n\n\n\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\epsilon \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf-estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week2b.html#normal-pdf-estimates-of-mean-and-variance",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF | estimates of mean and variance",
    "text": "Normal PDF | estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf-1",
    "href": "Lecture_Folder/Week2b.html#normal-pdf-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology",
    "href": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-1",
    "href": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-2",
    "href": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week2b.html#parent-offspring-resemblance",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week2b.html#genetic-model-of-complex-traits",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week2b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week2b.html#why-else-is-the-normal-special",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nThe normal distribution is immensely useful because of the central limit theorem, which says that the mean of many random variables independently drawn from the same distribution is distributed approximately normally\nOne can think of numerous situations, such as\n\nwhen multiple genes contribute to a phenotype\nor that many factors contribute to a biological process\n\nIn addition, whenever there is variance introduced by stochastic factors the central limit theorem holds\nThus, normal distributions occur throughout genomics\nIt’s also the basis of the majority of classical statistics"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have a mean of 0 and a standard deviation of 1\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#resources",
    "href": "Lecture_Folder/Week2b.html#resources",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Resources:",
    "text": "Resources:\n\nVignette (from the tidyr package)\nOriginal paper (Hadley Wickham, 2014 JSS)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#r-packages-youll-need-today",
    "href": "Lecture_Folder/Week2b.html#r-packages-youll-need-today",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "R packages you’ll need today",
    "text": "R packages you’ll need today\ntidyverse\nnycflights13"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-vs.-base-r-cont.",
    "href": "Lecture_Folder/Week2b.html#tidyverse-vs.-base-r-cont.",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse vs. base R (cont.)",
    "text": "Tidyverse vs. base R (cont.)\nOne point of convenience is that there is often a direct correspondence between a tidyverse command and its base R equivalent.\nThese generally follow a tidyverse::snake_case vs base::period.case rule. E.g. Compare:\n\n\n\ntidyverse\nbase\n\n\n\n\n?readr::read_csv\n?utils::read.csv\n\n\n?dplyr::if_else\n?base::ifelse\n\n\n?tibble::tibble\n?base::data.frame\n\n\n\nEtcetera.\nIf you call up the above examples, you’ll see that the tidyverse alternative typically offers some enhancements or other useful options (and sometimes restrictions) over its base counterpart.\n–\nRemember: There are (almost) always multiple ways to achieve a single goal in R."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-packages",
    "href": "Lecture_Folder/Week2b.html#tidyverse-packages",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse packages",
    "text": "Tidyverse packages\nLet’s load the tidyverse meta-package and check the output.\n\nlibrary(tidyverse)\n\n–\nWe see that we have actually loaded a number of packages (which could also be loaded individually): ggplot2, tibble, dplyr, etc. - We can also see information about the package versions and some namespace conflicts."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.",
    "href": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse packages (cont.)",
    "text": "Tidyverse packages (cont.)\nThe tidyverse actually comes with a lot more packages than those that are just loaded automatically.1\n\ntidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nWe’ll use several of these additional packages during the remainder of this course.\n\nE.g. The lubridate package for working with dates and the rvest package for webscraping.\nHowever, bear in mind that these packages will have to be loaded separately.\n\n.footnote[ 1 It also includes a lot of dependencies upon installation. This is a matter of some controversy.]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.-1",
    "href": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse packages (cont.)",
    "text": "Tidyverse packages (cont.)\nI hope to cover most of the tidyverse packages over the length of this course.\nToday, however, I’m only really going to focus on two packages: 1. dplyr 2. tidyr\nThese are the workhorse packages for cleaning and wrangling data. They are thus the ones that you will likely make the most use of (alongside ggplot2, which we already met back in Lecture 1). - Data cleaning and wrangling occupies an inordinate amount of time, no matter where you are in your research career."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#an-aside-on-pipes",
    "href": "Lecture_Folder/Week2b.html#an-aside-on-pipes",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "An aside on pipes: %>%",
    "text": "An aside on pipes: %&gt;%\nThe tidyverse loads its own pipe operator, denoted %&gt;%.\n\n## These next two lines of code do exactly the same thing.\nmpg %&gt;% filter(manufacturer==\"audi\") %&gt;% group_by(model) %&gt;% summarise(hwy_mean = mean(hwy))\nsummarise(group_by(filter(mpg, manufacturer==\"audi\"), model), hwy_mean = mean(hwy))\n\n–\nThe first line reads from left to right, exactly how I thought of the operations in my head. - Take this object (mpg), do this (filter), then do this (group_by), etc.\nThe second line totally inverts this logical order (the final operation comes first!) - Who wants to read things inside out?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#an-aside-on-pipes-cont.",
    "href": "Lecture_Folder/Week2b.html#an-aside-on-pipes-cont.",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "An aside on pipes: %>% (cont.)",
    "text": "An aside on pipes: %&gt;% (cont.)\nThe piped version of the code is even more readable if we write it over several lines. Here it is again and, this time, I’ll run it for good measure so you can see the output:\n\nmpg %&gt;% \n  filter(manufacturer==\"audi\") %&gt;% \n  group_by(model) %&gt;% \n  summarise(hwy_mean = mean(hwy))\n\n# A tibble: 3 × 2\n  model      hwy_mean\n  &lt;chr&gt;         &lt;dbl&gt;\n1 a4             28.3\n2 a4 quattro     25.8\n3 a6 quattro     24  \n\n\nRemember: Using vertical space costs nothing and makes for much more readable/writeable code than cramming things horizontally."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#dplyr",
    "href": "Lecture_Folder/Week2b.html#dplyr",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "dplyr",
    "text": "dplyr"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#key-dplyr-verbs",
    "href": "Lecture_Folder/Week2b.html#key-dplyr-verbs",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Key dplyr verbs",
    "text": "Key dplyr verbs\nThere are five key dplyr verbs that you need to learn.\n\nfilter: Filter (i.e. subset) rows based on their values.\narrange: Arrange (i.e. reorder) rows based on their values.\nselect: Select (i.e. subset) columns by their names:\nmutate: Create new columns.\nsummarise: Collapse multiple rows into a single summary value.1"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#other-dplyr-goodies",
    "href": "Lecture_Folder/Week2b.html#other-dplyr-goodies",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Other dplyr goodies",
    "text": "Other dplyr goodies\ngroup_by and ungroup: For (un)grouping. - Particularly useful with the summarise and mutate commands, as we’ve already seen.\n\n\nslice: Subset rows by position rather than filtering by values. - E.g. starwars %&gt;% slice(c(1, 5))\n\n\npull: Extract a column from as a data frame as a vector or scalar. - E.g. starwars %&gt;% filter(gender==\"female\") %&gt;% pull(height)\n\n\ncount and distinct: Number and isolate unique observations. - E.g. starwars %&gt;% count(species), or starwars %&gt;% distinct(species) - You could also use a combination of mutate, group_by, and n(), e.g. starwars %&gt;% group_by(species) %&gt;% mutate(num = n())."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#data-cleaning-and-manipulation",
    "href": "Lecture_Folder/Week2b.html#data-cleaning-and-manipulation",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Data cleaning and manipulation",
    "text": "Data cleaning and manipulation\n\nHere, we differentiate “data cleaning” from “data manipulation”, which is perhaps an arbitrary distinction.\n“Data cleaning” typically refers to altering variable class information, fixing mistakes that could have arisen in the data (e.g., an extra ‘.’ symbol in a numeric value), and things of this nature.\n“Data manipulation”, in my mind, refers to altering the structure of the data in a way that changes the functional structure the data (e.g., an addition of a column, deletion of rows, long/wide formatting change)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data",
    "href": "Lecture_Folder/Week2b.html#gapminder-data",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nThe gapminder data are commonly used to explore concepts of data exploration and manipulation, maybe because of the combination of character and numeric variables, nested structure in terms of country and year, or maybe it is just out of ease in copying notes from other people.\n\ndat &lt;- read.delim(file = \"http://www.stat.ubc.ca/~jenny/notOcto/STAT545A/examples/gapminder/data/gapminderDataFiveYear.txt\")\n\n\nhead(dat)\n\n      country year      pop continent lifeExp gdpPercap\n1 Afghanistan 1952  8425333      Asia  28.801  779.4453\n2 Afghanistan 1957  9240934      Asia  30.332  820.8530\n3 Afghanistan 1962 10267083      Asia  31.997  853.1007\n4 Afghanistan 1967 11537966      Asia  34.020  836.1971\n5 Afghanistan 1972 13079460      Asia  36.088  739.9811\n6 Afghanistan 1977 14880372      Asia  38.438  786.1134\n\nstr(dat)\n\n'data.frame':   1704 obs. of  6 variables:\n $ country  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...\n $ continent: chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n $ lifeExp  : num  28.8 30.3 32 34 36.1 ...\n $ gdpPercap: num  779 821 853 836 740 ..."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-1",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nWe can use what we learned before in terms of base R functions to calculate summary statistics.\n\n# mean life expectancy\nmean(dat$lifeExp)\n\n[1] 59.47444\n\n\nBut what does mean life expectancy really tell us, when we also have information on space (country) and time (year)? So we may wish to subset the data to a specific country or time period. We can do this using which statements.\n\ndat[which(dat$country == 'Afghanistan'), ]\ndat[which(dat$year &lt; 1960), ]\n\nRecall that which evaluates a condition, and then determines the index of each TRUE value. So for the first example, the which tells us the indices where the vector dat$country is equal to “Afghanistan”. Putting this result vector of indices within the square brackets allows us to subset the data.frame based on these indices (specifically, we are subsetting specific rows of data).\nIn the second example, we want to see all data that was recorded prior to 1960. As you will quickly realize, there are always multiple ways to do the same thing when programming. For instance, this second statement could be done in base R using the subset function.\n\nsubset(dat, dat$year &lt; 1960)\n\nThe subset function also allows you to ‘select’ specific columns in the output.\n\nsubset(dat, dat$year &lt; 1955, select=c(lifeExp,gdpPercap))\n\nHowever, this is the same as\n\ndat[which(dat$year &lt; 1960), c(\"lifeExp\",\"gdpPercap\")]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-2",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nTo refresh your memory and clarify the use of conditionals, the list below provides a bit more information.\n\n==: equals exactly\n&lt;, &lt;=: is smaller than, is smaller than or equal to\n&gt;, &gt;=: is bigger than, is bigger than or equal to\n!=: not equal to"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-3",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-3",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nAnd some that we did not go into before, but will go into a bit more detail on now:\n\n!: NOT operator, to specify things that should be omitted\n&: AND operator, allows you to chain two conditions which must both be met\n|: OR operator, to chains two conditions when at least one should be met\n%in%: belongs to one of the following (usually followed by a vector of possible values)\n\nThe AND (&) and the OR (|) operators are also super useful when you want to separate data based on multiple conditions."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-4",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-4",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\n\ndat[which(dat$country=='Afghanistan' & dat$year==1977),]\ndat[which(dat$lifeExp &lt; 40 | dat$gdpPercap &lt; 500), ]\n\nFinally, the %in% operator is super useful when you want to subset data based on multiple conditions\n\n#fails\ndat[which(dat$country == c('Afghanistan', 'Turkey')), ]\n\n         country year      pop continent lifeExp gdpPercap\n1    Afghanistan 1952  8425333      Asia  28.801  779.4453\n3    Afghanistan 1962 10267083      Asia  31.997  853.1007\n5    Afghanistan 1972 13079460      Asia  36.088  739.9811\n7    Afghanistan 1982 12881816      Asia  39.854  978.0114\n9    Afghanistan 1992 16317921      Asia  41.674  649.3414\n11   Afghanistan 2002 25268405      Asia  42.129  726.7341\n1574      Turkey 1957 25670939    Europe  48.079 2218.7543\n1576      Turkey 1967 33411317    Europe  54.336 2826.3564\n1578      Turkey 1977 42404033    Europe  59.507 4269.1223\n1580      Turkey 1987 52881328    Europe  63.108 5089.0437\n1582      Turkey 1997 63047647    Europe  68.835 6601.4299\n1584      Turkey 2007 71158647    Europe  71.777 8458.2764\n\n#does not fail\ndat[which(dat$country %in% c('Afghanistan', 'Turkey')), ]\n\n         country year      pop continent lifeExp gdpPercap\n1    Afghanistan 1952  8425333      Asia  28.801  779.4453\n2    Afghanistan 1957  9240934      Asia  30.332  820.8530\n3    Afghanistan 1962 10267083      Asia  31.997  853.1007\n4    Afghanistan 1967 11537966      Asia  34.020  836.1971\n5    Afghanistan 1972 13079460      Asia  36.088  739.9811\n6    Afghanistan 1977 14880372      Asia  38.438  786.1134\n7    Afghanistan 1982 12881816      Asia  39.854  978.0114\n8    Afghanistan 1987 13867957      Asia  40.822  852.3959\n9    Afghanistan 1992 16317921      Asia  41.674  649.3414\n10   Afghanistan 1997 22227415      Asia  41.763  635.3414\n11   Afghanistan 2002 25268405      Asia  42.129  726.7341\n12   Afghanistan 2007 31889923      Asia  43.828  974.5803\n1573      Turkey 1952 22235677    Europe  43.585 1969.1010\n1574      Turkey 1957 25670939    Europe  48.079 2218.7543\n1575      Turkey 1962 29788695    Europe  52.098 2322.8699\n1576      Turkey 1967 33411317    Europe  54.336 2826.3564\n1577      Turkey 1972 37492953    Europe  57.005 3450.6964\n1578      Turkey 1977 42404033    Europe  59.507 4269.1223\n1579      Turkey 1982 47328791    Europe  61.036 4241.3563\n1580      Turkey 1987 52881328    Europe  63.108 5089.0437\n1581      Turkey 1992 58179144    Europe  66.146 5678.3483\n1582      Turkey 1997 63047647    Europe  68.835 6601.4299\n1583      Turkey 2002 67308928    Europe  70.845 6508.0857\n1584      Turkey 2007 71158647    Europe  71.777 8458.2764"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-5",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-5",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nRelated to %in%, is match. match is best for identifying the index of single types in a vector of unique values. For instance,\n\ndat[match(c('Afghanistan', 'Turkey'), dat$country),]\n\n         country year      pop continent lifeExp gdpPercap\n1    Afghanistan 1952  8425333      Asia  28.801  779.4453\n1573      Turkey 1952 22235677    Europe  43.585 1969.1010"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-6",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-6",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nonly returns two rows, because it only matches the first instance of both countries in the data. We can use match to get the index associated with a single value (useful when writing functions).\n\nmatch('dog', c('dog', 'cat', 'snake'))\n\n[1] 1\n\n#not ideal behavior\nmatch('dog', c('dog', 'cat', 'snake', 'dog'))\n\n[1] 1\n\n\nor it can be used to identify multiple instances of a single value across a vector of values.\n\nmatch(c('dog', 'cat', 'snake', 'dog'), 'dog')\n\n[1]  1 NA NA  1\n\nmatch(c('dog', 'cat', 'snake', 'dog'), c('dog', 'cat'))\n\n[1]  1  2 NA  1"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-7",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-7",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nWhile a bit opaque, these functions are pretty useful in a variety of situations. Speaking of data manipulation functions that are useful but a bit conceptually difficult, do.call and Reduce are solid base R functions.\ndo.call is a way of calling the same function recursively on multiple objects, and may have similar output to Reduce, which is also a way to recursively apply a function.\n\nlst &lt;- list(1:10, 1:10, 1:10, 1:10, 1:10)\nlst\n\n[[1]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[2]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[3]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[4]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[5]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n#this makes a single rbind call with each element of the list as an argument\nstr(do.call(rbind, lst))\n\n int [1:5, 1:10] 1 1 1 1 1 2 2 2 2 2 ...\n\n#this does it iteratively (so makes n-1 rbind calls)\nReduce(rbind, lst)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\ninit    1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-tidyverse",
    "href": "Lecture_Folder/Week2b.html#the-tidyverse",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The tidyverse",
    "text": "The tidyverse\n\nThere are many R libraries designed to manipulate data and work with specific data structures (e.g., purrr for list objects, lubridate for dates, etc.).\nFor the sake of brevity and generality, we will examine one main useful packages for data manipulation: dplyr."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#rename",
    "href": "Lecture_Folder/Week2b.html#rename",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "rename",
    "text": "rename\n\ndf &lt;- data.frame(A=runif(100), B=runif(100), D=rnorm(100,1,1))\ndf2 &lt;- dplyr::rename(df, a=A, b=B, d=D)\n\nThis is the same functionality as the base R function colnames (or names for a data.frame)\nnames(df2) &lt;- c('a', 'b', 'd')\n#or \nnames(df2) &lt;- tolower(names(df))\nThe nice part about dplyr::rename() is that we specify the old and new column names, meaning that there is little risk of an indexing error as with using the colnames() or names() functions."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#select",
    "href": "Lecture_Folder/Week2b.html#select",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "select",
    "text": "select\nMany of the next functions are directly analogs of functions from another programming language used to query databases (SQL). This makes it really nice to learn, as you can essentially learn two languages while learning one. SQL is pretty powerful when working with relational data. I will not go into what I mean by this, unless there is time during lecture and interest among you all.\nWe use dplyr::select when we want to…select…columns.\n\ndplyr::select(df2, a)\ndplyr::select(df2, obs = starts_with('a'))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#filter",
    "href": "Lecture_Folder/Week2b.html#filter",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "filter",
    "text": "filter\ndplyr::filter is another one of those useful functions that we already know how to use in base R. Previously, we have used which statements or the subset function. dplyr::filter is used to filter down a data.frame by some condition applied to rows.\n\ndplyr::filter(df2, a &lt; 0.5)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#mutate",
    "href": "Lecture_Folder/Week2b.html#mutate",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "mutate",
    "text": "mutate\ndplyr::mutate is used when we wish to create a new covariate based on our existing covariates. For instance, if we wanted to create a column e on df2 that was the sum of a+b divided by d…\n\ndf2 &lt;- dplyr::mutate(df2, e=(a+b)/d)\nhead(df2,5)\n\n          a          b          d           e\n1 0.3243548 0.79117276  1.5810743  0.70555041\n2 0.2800363 0.28220355 -0.4963027 -1.13285681\n3 0.9318768 0.75790762  0.9595241  1.76106510\n4 0.7583689 0.04228768  1.2519443  0.63953053\n5 0.1081216 0.07187200  2.8208981  0.06380719\n\n\nNotice that the function creates a new column and appends it to the existing data.frame, but does not “write in place”. That is, the df2 object is not modified unless it is stored (which we do above)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#group_by",
    "href": "Lecture_Folder/Week2b.html#group_by",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "group_by",
    "text": "group_by\ndplyr::group_by is really useful as an intermediate step to getting at summary statistics which take into account grouping by a character or factor variable. For instance, if we wanted to calculate the mean life expectancy (lifeExp) for every country in the gapminder data (dat), we would first have to group by country.\n\ndatG &lt;- dplyr::group_by(dat, country)\n\nThis is a bit like a non-function, since dat and datG are essentially the same….but they are not for the purposes of computing group-wise statistics. This is done using the dplyr::summarise function."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#summarise",
    "href": "Lecture_Folder/Week2b.html#summarise",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "summarise",
    "text": "summarise\nSo if we wanted to calculate mean life expectancy (lifeExp) per country, we could use the grouped data.frame datG and the dplyr::summarise function to do so.\n\ndplyr::summarise(datG, mnLife=mean(lifeExp))\n\n# A tibble: 142 × 2\n   country     mnLife\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Afghanistan   37.5\n 2 Albania       68.4\n 3 Algeria       59.0\n 4 Angola        37.9\n 5 Argentina     69.1\n 6 Australia     74.7\n 7 Austria       73.1\n 8 Bahrain       65.6\n 9 Bangladesh    49.8\n10 Belgium       73.6\n# ℹ 132 more rows"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#joins",
    "href": "Lecture_Folder/Week2b.html#joins",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "joins",
    "text": "joins\njoins are something taken directly from SQL. Table joins are ways of combining relational data by some index variable. That is, we often have situations where our data are inherently multi-dimensional. If we have a data.frame containing rows corresponding to observations of a species at a given location, we could have another data.frame containing species-level morphometric or trait data. While we could mash this into a single data.frame, it would repeat many values, which is not ideal for data clarity or memory management.\n\ndf$species &lt;- sample(c('dog', 'cat', 'bird'),100, replace=TRUE)\n\ninfo &lt;- data.frame(species=c('dog', 'cat', 'bird', 'snake'),\n    annoying=c(10, 2, 100, 1), \n    meanBodySize=c(20, 5, 1, 2))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#joins-1",
    "href": "Lecture_Folder/Week2b.html#joins-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "joins",
    "text": "joins\nNow we can join some stuff together, combining data on mean species-level characteristics with individual-level observations.\n\n# maintains the structure of df (the \"left\" data structure)\nleft_join(df, info, by='species')\n\n# maintains the structure of info (the \"right\" data structure)\nright_join(df,info, by='species')\n\n# return things that are in info but not in df\nanti_join(info, df, by='species')\n\nThere are other forms of joins (full_join, inner_join, etc.), but I find that I mostly use the left or right variations of the joins, as it specifically allows me to control the output (i.e., using dplyr::left_join, I know that the resulting data.frame will have the same number of rows as the left hand data.frame)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#piping",
    "href": "Lecture_Folder/Week2b.html#piping",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "piping",
    "text": "piping\nAlright. So before we discussed joins, we were describing the different main verbs of dplyr. We discussed rename, select, mutate, group_by, and summarise. A final point, and something tidyverse folks really love, is the use of these functions in nested statements through the use of piping.\nPipes in bash scripting look like |, pipes in R syntax look like %&gt;%. It does not matter what it looks like though, it matter what it does. Here is a simple example of the use of piping. We can go back to the example of calculating the mean life expectancy per country from the gapminder data.\nThe usual way\n\ntmp &lt;- dplyr::group_by(dat, country)\ntmp2 &lt;- dplyr::summarise(tmp, mnLifeExp=mean(lifeExp))\n\nThe piped way\n\ntmp3 &lt;- dat %&gt;%\n    dplyr::group_by(country) %&gt;%\n    dplyr::summarise(mnLifeExp=mean(lifeExp))\n\nThe results of these two are identical (all(tmp3==tmp2) returns TRUE).\nThis is useful, as commands can be chained together, including the creation of new variables, subsetting and summarising of existing variables, etc. One thing to keep in mind is to check intermediate results – instead of just piping all the way through – as data manipulation errors can be introduced mid-statement and go unnoticed. That is, in some situations, piping does not help reproducibility. Many proponents argue that it helps with code readability, while many others say that actively makes code less human readable. It definitely does require adopting a certain syntax and the assumption that every end user is on the tidyverse train, which is not ideal when reproducibility involves everyone, not just the cool tidy/Hadley/RStudio crowd."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#midterm-feedback",
    "href": "Lecture_Folder/Week2b.html#midterm-feedback",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Midterm Feedback",
    "text": "Midterm Feedback\n\nThank you all for providing thoughtful feedback on the last Problem Set!\nYou all really enjoy in-class exercises - we’ll do more of that!\nThe homework difficulty doesn’t always align well with the lectures - will try to remedy this"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#understanding-populations-and-their-parameters",
    "href": "Lecture_Folder/Week2b.html#understanding-populations-and-their-parameters",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Understanding Populations and their Parameters",
    "text": "Understanding Populations and their Parameters\n\nWe often think about the samples we are collecting as a part of a larger population\nSince we can’t measure every member of that population, we instead use sampling to estimate the parameters of the population as a whole\n\nSome common parameters: mean, range, median\nIf we performed random sampling, we assume that the parameter estimates of our sample are equitable to the true population parameters"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#simulations-to-compare-parameter-estimates-2",
    "href": "Lecture_Folder/Week2b.html#simulations-to-compare-parameter-estimates-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Simulations to compare parameter estimates",
    "text": "Simulations to compare parameter estimates\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nhist(true_pop, xlim = c(0,16))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-parameters",
    "href": "Lecture_Folder/Week2b.html#calculating-parameters",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-parameters-1",
    "href": "Lecture_Folder/Week2b.html#calculating-parameters-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?\n\n\nmean(true_pop)\n\n[1] 4.927\n\nrange(true_pop)\n\n[1]  0 13\n\nmedian(true_pop)\n\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-exercise",
    "href": "Lecture_Folder/Week2b.html#sampling-exercise",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-exercise-1",
    "href": "Lecture_Folder/Week2b.html#sampling-exercise-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\n\n\n\n\n\n\n\n\n[1] \"Mean: \" \"4.95\"  \n\n\n[1] \"Range: \" \"1\"       \"10\""
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week2b.html#randomness-in-sampling",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week2b.html#surveying-your-sampling",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week2b.html#surveying-your-sampling-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\ntable(samps_var_means &gt; 4.5 & samps_var_means &lt; 5.5)\n\n\nFALSE  TRUE \n   19    31"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#surveying-your-sampling-2",
    "href": "Lecture_Folder/Week2b.html#surveying-your-sampling-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-sampling-distributions",
    "href": "Lecture_Folder/Week2b.html#normal-sampling-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal Sampling Distributions",
    "text": "Normal Sampling Distributions"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-sampling-distributions-1",
    "href": "Lecture_Folder/Week2b.html#normal-sampling-distributions-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal Sampling Distributions",
    "text": "Normal Sampling Distributions"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-distributions---its-been-normal-this-whole-time",
    "href": "Lecture_Folder/Week2b.html#sampling-distributions---its-been-normal-this-whole-time",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Distributions - It’s been Normal this whole time?!",
    "text": "Sampling Distributions - It’s been Normal this whole time?!"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-distributions---exercise",
    "href": "Lecture_Folder/Week2b.html#sampling-distributions---exercise",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Distributions - Exercise",
    "text": "Sampling Distributions - Exercise\n\nTry creating some data using one of the other distributions we discussed last time (Exponential Distribution) and then create a sampling distribution. Is it normal?\n\n\ntrue_pop &lt;- rexp(n, rate)\nsamps_var &lt;- replicate(n = , sample(true_pop, size = ))\nsamps_var_means &lt;- apply(samps_var, 2, mean)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-central-limit-theorem",
    "href": "Lecture_Folder/Week2b.html#the-central-limit-theorem",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#standard-error",
    "href": "Lecture_Folder/Week2b.html#standard-error",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Standard Error",
    "text": "Standard Error\n\nThe sample size and the spread of the distribution (range) - contribute to what is known as the standard error of a random variable.\nThe standard error for any given sample attribute (such as a sample mean), can be calculated either based on distributional assumptions, or by a process called “resampling.”"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#standard-error-1",
    "href": "Lecture_Folder/Week2b.html#standard-error-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Standard error",
    "text": "Standard error"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-the-standard-error",
    "href": "Lecture_Folder/Week2b.html#calculating-the-standard-error",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nStandard Error of the Mean (SEM)\nSEM = SD / sqrt(sample size)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-the-standard-error-1",
    "href": "Lecture_Folder/Week2b.html#calculating-the-standard-error-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week2b.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#bootstrapping-1",
    "href": "Lecture_Folder/Week2b.html#bootstrapping-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned. - - It works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#confidence-intervals",
    "href": "Lecture_Folder/Week2b.html#confidence-intervals",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#relationship-between-mean-and-variance-1",
    "href": "Lecture_Folder/Week2b.html#relationship-between-mean-and-variance-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Relationship between mean and variance",
    "text": "Relationship between mean and variance\n\nThis means it is inappropriate to compare variations of different populations with largely different means\n\nFor instance, comparing the standard deviation for a body measurement in a population of mice, with the same body measurement in a population of elephants is not meaningful."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#test-it-out",
    "href": "Lecture_Folder/Week2b.html#test-it-out",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nprint(sd(true_pop))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week2b.html#coefficient-of-variation",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#today-well-be-talking-about",
    "href": "Lecture_Folder/Week2b.html#today-well-be-talking-about",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Today we’ll be talking about",
    "text": "Today we’ll be talking about\n\nA roadmap for the rest of the term\nThe unethical history of statistics and data science\nLast week’s homework"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#thinking-about-your-final-project",
    "href": "Lecture_Folder/Week2b.html#thinking-about-your-final-project",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Thinking about your final project",
    "text": "Thinking about your final project\n\nAs we’re going through these statistical techniques, think about which one(s) might be most appropriate for your data analysis.\nThe project ideally will take in some sort of raw data, analyze it (summary statistics, significance tests), and plot your findings.\nCan incorporate Unix and/or R, can be presented via a script and/or RMarkdown document."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics",
    "href": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\nFrancis Galton: Darwin’s half cousin\nStudied human variation and genetic inheritance\n\nHuman height, fingerprints, intelligence\nCorrelation, regression toward the mean, and “nature versus nurture”\nPioneered twin studies\n\n\n\n\n\nGalton"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics-1",
    "href": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\nBelieved that intelligence was hereditary based on surveying prominent academics in Europe\nUsed the ideas of correlation and regression towards the mean to argue that the upper class should breed amongst themselves to keep those “good genes” pure\nWanted to provide monetary incentives for “good” couples to marry and reproduce as a way to avoid the upper class being genetically muddied by the lower class"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "href": "Lecture_Folder/Week2b.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "A common sight at state fairs around the U.S. in the 1930s",
    "text": "A common sight at state fairs around the U.S. in the 1930s\n\nCompetitions for the “perfect family” to encourage public consciousness and support for eugenics"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#galton-with-charles-davenport-and-g.-stanley-hall",
    "href": "Lecture_Folder/Week2b.html#galton-with-charles-davenport-and-g.-stanley-hall",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Galton with Charles Davenport and G. Stanley Hall",
    "text": "Galton with Charles Davenport and G. Stanley Hall\n\nAmerican Eugenics Record Office (ERO) founded in Cold Springs Harbor"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#logo-of-the-us-eugenics-society",
    "href": "Lecture_Folder/Week2b.html#logo-of-the-us-eugenics-society",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Logo of the US eugenics society",
    "text": "Logo of the US eugenics society"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#eugenics-societies-in-america",
    "href": "Lecture_Folder/Week2b.html#eugenics-societies-in-america",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Eugenics societies in America",
    "text": "Eugenics societies in America\n\nAdvocated for state laws to ban interracial marriages and promote sterilization of “unfit” individuals (negative eugenics) - especially black, Latinx, and Native American women\n30 states passed laws to force mental institution patients to be sterilized\nBetween 1907 and 1963, over 64,000 individuals were forcibly sterilized under eugenic legislation in the United States"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics-in-london",
    "href": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics-in-london",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics in London",
    "text": "RA Fisher and Eugenics in London\n\nDeveloper of Fishers exact test, analysis of variance (ANOVA), null hypothesis, p values, maximum likelihood, probability density functions\nFounding Chairman of the University of Cambridge Eugenics Society"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics",
    "href": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics",
    "text": "RA Fisher and Eugenics\n\n1/3rd of his work “The Genetical Theory of Natural Selection” discussed eugenics and his theory that the fall of civilizations was due to the fertility of their upper classes being diminished\nUsed these statistical methods to test data on human variation to prove biological differences between human races\nEugenics and racism were the primary motivators for many of these statistical tests that we use today"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#eugenics-has-a-direct-line-to-hitler-and-nazism",
    "href": "Lecture_Folder/Week2b.html#eugenics-has-a-direct-line-to-hitler-and-nazism",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Eugenics has a direct line to Hitler and Nazism",
    "text": "Eugenics has a direct line to Hitler and Nazism\n\nEugenics existed in America (and England) before it became popular in Germany.\nBy 1933, California had subjected more people to forceful sterilization than all other U.S. states combined.\nThe forced sterilization program engineered by the Nazis was partly inspired by California’s."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sterilizations-continue-in-america",
    "href": "Lecture_Folder/Week2b.html#sterilizations-continue-in-america",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sterilizations continue in America",
    "text": "Sterilizations continue in America\n\nOur history books paint Nazi Germany as the primary evil of that time, while we try to cover up our significant role in eugenics\nIt wasn’t until 1978 that the US passed regulations on sterilization procedures\nCalifornia only passed a bill to outlaw sterilization of inmates in 2014\nCertain members of the genetic engineering community threaten to bring back eugenics ideas"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#so-what-do-we-do-from-here",
    "href": "Lecture_Folder/Week2b.html#so-what-do-we-do-from-here",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "So, what do we do from here?",
    "text": "So, what do we do from here?\n\nThe statistical methods that Galton, Fisher, and others developed are useful science tools\nImportant to use these tools for good - improving our planet, human health, and technology\nImportant to acknowledge and not forget the history of science - educate others to avoid repeating history"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#interested-in-learning-more",
    "href": "Lecture_Folder/Week2b.html#interested-in-learning-more",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Interested in learning more?",
    "text": "Interested in learning more?\n\n\n\n\n\n\n\n\n\n\nSee also “The Gene” by Siddhartha Mukherjee"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html",
    "href": "Lecture_Folder/Week2a.html",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#an-example-to-get-us-started",
    "href": "Lecture_Folder/Week2a.html#an-example-to-get-us-started",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "An example to get us started",
    "text": "An example to get us started"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#data-set-rules-of-thumb-aka-tidy-data",
    "href": "Lecture_Folder/Week2a.html#data-set-rules-of-thumb-aka-tidy-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Data set rules of thumb (aka Tidy Data)",
    "text": "Data set rules of thumb (aka Tidy Data)\n\nStore a copy of data in nonproprietary software and hardware formats, such as plain ASCII text (aka a flat file)\nLeave an uncorrected file when doing analyses\nUse descriptive names for your data files and variables\nInclude a header line with descriptive variable names\nMaintain effective metadata about the data (data dictionary)\nWhen you add observations to a database, add rows\nWhen you add variables to a database, add columns, not rows\nA column of data should contain only one data type"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#not-all-data-are-tidy-to-begin-with",
    "href": "Lecture_Folder/Week2a.html#not-all-data-are-tidy-to-begin-with",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Not all data are tidy to begin with",
    "text": "Not all data are tidy to begin with\n\nSometimes need to do some data wrangling\nBut also contingency tables"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#types-of-data",
    "href": "Lecture_Folder/Week2a.html#types-of-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Types of data",
    "text": "Types of data\n\n\n\n\n\n\n\n\n\nCategorical\n\nQuantitative\n\n\n\nOrdinal\nNominal\nRatio\nInterval\n\n\nsmall, medium, large\napples, oranges, bananas\nkilograms, dollars, years\ntemperature, calendar year\n\n\nordered character\ncharacter\nnumeric\ninteger\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n‘Factor’ is a special type of character variable that we will explore more later"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#computational-tools---r-and-rstudio",
    "href": "Lecture_Folder/Week2a.html#computational-tools---r-and-rstudio",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Computational Tools - R and RStudio",
    "text": "Computational Tools - R and RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#why-use-r",
    "href": "Lecture_Folder/Week2a.html#why-use-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nGood general scripting tool for statistics and mathematics\nPowerful and flexible and free\nRuns on all computer platforms\nNew enhancements coming out all the time\nSuperb data management & graphics capabilities"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#why-use-r-1",
    "href": "Lecture_Folder/Week2a.html#why-use-r-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nReproducibility - can keep your scripts to see exactly what was done\nYou can write your own functions\nLots of online help available\nCan use a nice GUI front end such as Rstudio\nCan embed your R analyses in dynamic, polished files using Markdown\nMarkdown can be reused for websites, papers, books, presentations…"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#r-scripts-and-markdown-files",
    "href": "Lecture_Folder/Week2a.html#r-scripts-and-markdown-files",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "R scripts and Markdown files",
    "text": "R scripts and Markdown files\n\nOften we want to write scripts that can just be run\nWe can also embed code in Markdown files that provide more annotations\nhttps://quarto.org/docs/authoring/markdown-basics.html\nYou can insert Rchunks into Quarto markdown documents"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#rscript-basics",
    "href": "Lecture_Folder/Week2a.html#rscript-basics",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Rscript basics",
    "text": "Rscript basics\n\nA series of R commands that will be executed\nCan add comments using hashtags #\nCan have pipes (|&gt;) to connect one step to the next"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#markdown-basics",
    "href": "Lecture_Folder/Week2a.html#markdown-basics",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Markdown basics",
    "text": "Markdown basics\n\na very simplified way for standard typesetting\nsimple markdown can be rendered in numerous different ways\nLists, codeblocks, images and more can all be inserted"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#inserting-equations-in-markdown",
    "href": "Lecture_Folder/Week2a.html#inserting-equations-in-markdown",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Inserting equations in markdown",
    "text": "Inserting equations in markdown\n$$e=mc^2$$\n\\[e=mc^2\\]\n$$\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy$$\n\\[\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#basics-of-r",
    "href": "Lecture_Folder/Week2a.html#basics-of-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "BASICS of R",
    "text": "BASICS of R\n\nCommands can be submitted through the terminal, console or scripts\nIn your scripts, anything that follows ‘#’ symbol (aka hash) is just for humans\nNotice on these slides I’m evaluating the code chunks and showing output\nThe output is shown here after the two # symbols and the number of output items is in []\nAlso notice that R follows the normal priority of mathematical evaluation\n\n\n4*4\n\n[1] 16\n\n\n\n(4+3*2^2)\n\n[1] 16"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#assigning-variables",
    "href": "Lecture_Folder/Week2a.html#assigning-variables",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nA better way to do this is to assign variables\nVariables are assigned values using the &lt;- operator.\nVariable names must begin with a letter, but other than that, just about anything goes.\nDo keep in mind that R is case sensitive."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#assigning-variables-1",
    "href": "Lecture_Folder/Week2a.html#assigning-variables-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nx &lt;- 2\nx*3\n\n[1] 6\n\ny &lt;- x * 3\ny-2\n\n[1] 4\n\n\nThese do not work\n\n3y &lt;- 3\n3*y &lt;- 3"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions",
    "href": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\nArithmetic operations can be performed easily on functions as well as numbers.\nTry the following, and then your own.\n\n\nx+2\nx^2\nlog(x)\n\n\nNote that the last of these - log - is a built in function of R, and therefore the object of the function needs to be put in parentheses\nThese parentheses will be important, and we’ll come back to them later when we add arguments after the object in the parentheses\n\nThe outcome of calculations can be assigned to new variables as well, and the results can be checked using the ‘print’ command"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions-1",
    "href": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\ny &lt;- 67\nprint(y)\n\n[1] 67\n\nx &lt;- 124\nz &lt;- (x*y)^2\nprint(z)\n\n[1] 69022864"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#strings",
    "href": "Lecture_Folder/Week2a.html#strings",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nVariables and operations can be performed on characters as well\nNote that characters need to be set off by quotation marks to differentiate them from numbers\nThe c stands for concatenate\nNote that we are using the same variable names as we did previously, which means that we’re overwriting our previous assignment\nA good rule of thumb is to use new names for each variable, and make them short but still descriptive"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#strings-1",
    "href": "Lecture_Folder/Week2a.html#strings-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nx &lt;- \"I Love\"\nprint (x)\n\n[1] \"I Love\"\n\ny &lt;- \"Biostatistics\"\nprint (y)\n\n[1] \"Biostatistics\"\n\nz &lt;- c(x,y)\nprint (z)\n\n[1] \"I Love\"        \"Biostatistics\""
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#factors",
    "href": "Lecture_Folder/Week2a.html#factors",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nThe variable z is now what is called a list of character values.\nSometimes we would like to treat the characters as if they were units for subsequent calculations.\nThese are called factors, and we can redefine our character variables as factors.\nThis might seem a bit strange, but it’s important for statistical analyses where we might want to see the mean or variance for two different treatments."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#factors-1",
    "href": "Lecture_Folder/Week2a.html#factors-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nz_factor &lt;- as.factor(z)\nprint (z_factor)\n\n\nNote that factor levels are reported alphabetically"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#vectors",
    "href": "Lecture_Folder/Week2a.html#vectors",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nIn general R thinks in terms of vectors (a list of characters, factors or numerical values)\nit will benefit any R user to try to write programs with that in mind, as it will simplify most things.\nVectors can be assigned directly using the ‘c()’ function and then entering the exact values."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#vectors-1",
    "href": "Lecture_Folder/Week2a.html#vectors-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nx &lt;- c(2,3,4,2,1,2,4,5,10,8,9)\nprint(x)\n\n [1]  2  3  4  2  1  2  4  5 10  8  9"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#basic-statistics",
    "href": "Lecture_Folder/Week2a.html#basic-statistics",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nMany functions exist to operate on vectors.\nCombine these with your previous variable to see what happens.\nAlso, try to find other functions (e.g. standard deviation)."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#basic-statistics-1",
    "href": "Lecture_Folder/Week2a.html#basic-statistics-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nmean(x)\nmedian(x)\nvar(x)\nlog(x)\nln(x)\nsqrt(x)\nsum(x)\nlength(x)\nsample(x, replace = T)\n\n\nNotice that the last function (sample) has an argument (replace=T)\nArguments simply modify or direct the function in some way\nThere are many arguments for each function, some of which are defaults"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#getting-help",
    "href": "Lecture_Folder/Week2a.html#getting-help",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\nGetting Help on any function is very easy - just type a question mark and the name of the function.\nThere are functions for just about anything within R and it is easy enough to write your own functions if none already exist to do what you want to do.\nIn general, function calls have a simple structure: a function name, a set of parentheses and an optional set of parameters to send to the function.\nHelp pages exist for all functions that, at a minimum, explain what parameters exist for the function.\n\nHelp can be accessed a few ways - try them :"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#getting-help-1",
    "href": "Lecture_Folder/Week2a.html#getting-help-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\n- help(mean)\n- ?mean\n- example(mean)\n- help.search(\"mean\")\n- apropos(\"mean\")\n- args(mean)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors",
    "href": "Lecture_Folder/Week2a.html#creating-vectors",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nCreating vector of new data by entering it by hand can be a drag\nHowever, it is also very easy to use functions such as seq and sample\nTry the examples below Can you figure out what the three arguments in the parentheses mean?\nTry varying the arguments to see what happens.\nDon’t go too crazy with the last one or your computer might slow way down"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors-1",
    "href": "Lecture_Folder/Week2a.html#creating-vectors-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nprint(seq_1)\n\n  [1]  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.0  1.1  1.2  1.3  1.4\n [16]  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9\n [31]  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.0  4.1  4.2  4.3  4.4\n [46]  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9\n [61]  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.0  7.1  7.2  7.3  7.4\n [76]  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4  8.5  8.6  8.7  8.8  8.9\n [91]  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9 10.0\n\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)\nprint(seq_2)\n\n  [1] 10.0  9.9  9.8  9.7  9.6  9.5  9.4  9.3  9.2  9.1  9.0  8.9  8.8  8.7  8.6\n [16]  8.5  8.4  8.3  8.2  8.1  8.0  7.9  7.8  7.7  7.6  7.5  7.4  7.3  7.2  7.1\n [31]  7.0  6.9  6.8  6.7  6.6  6.5  6.4  6.3  6.2  6.1  6.0  5.9  5.8  5.7  5.6\n [46]  5.5  5.4  5.3  5.2  5.1  5.0  4.9  4.8  4.7  4.6  4.5  4.4  4.3  4.2  4.1\n [61]  4.0  3.9  3.8  3.7  3.6  3.5  3.4  3.3  3.2  3.1  3.0  2.9  2.8  2.7  2.6\n [76]  2.5  2.4  2.3  2.2  2.1  2.0  1.9  1.8  1.7  1.6  1.5  1.4  1.3  1.2  1.1\n [91]  1.0  0.9  0.8  0.7  0.6  0.5  0.4  0.3  0.2  0.1  0.0"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors-2",
    "href": "Lecture_Folder/Week2a.html#creating-vectors-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square &lt;- (seq_2)*(seq_2)\nprint(seq_square)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors-3",
    "href": "Lecture_Folder/Week2a.html#creating-vectors-3",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square_new &lt;- (seq_2)^2\nprint(seq_square_new)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nHere is a way to create your own data sets that are random samples.\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-1",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(x,y)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-2",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(xy)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-3",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-3",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nhist(x)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-4",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-4",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nYou’ve probably figured out that y from the last example is drawing numbers with equal probability.\nWhat if you want to draw from a distribution?\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-5",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-5",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;-rnorm(1000, 0, 100)\nhist(x, xlim = c(-500,500))\ncurve(50000*dnorm(x, 0, 100), xlim = c(-500,500), add=TRUE, col='Red')\n\n\n\n\n\n\n\n\n\ndnorm() generates the probability density, which can be plotted using the curve() function.\nNote that is curve is added to the plot using add=TRUE"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#visualizing-data",
    "href": "Lecture_Folder/Week2a.html#visualizing-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nSo far you’ve been visualizing just the list of output numbers\nExcept for the last example where I snuck in a hist function.\nYou can also visualize all of the variables that you’ve created using the plot function (as well as a number of more sophisticated plotting functions).\nEach of these is called a high level plotting function, which sets the stage\nLow level plotting functions will tweak the plots and make them beautiful"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#visualizing-data-1",
    "href": "Lecture_Folder/Week2a.html#visualizing-data-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nWhat do you think that each of the arguments means for the plot function?\nA cool thing about R is that the options for the arguments make sense.\nTry adjusting an argument and see if it works\nNote soon we will be exploring the plotting in ggplot2"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#visualizing-data-2",
    "href": "Lecture_Folder/Week2a.html#visualizing-data-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1) \nplot (seq_1, xlab=\"space\", ylab =\"function of space\", type = \"p\", col = \"red\")"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure",
    "href": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\nOn the next slide\nThe first line of the lower script tells R that you are going to create a composite figure that has two rows and two columns. Can you tell how?\nNow, modify the code to add two more variables and add one more row of two panels.\n\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure-1",
    "href": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\npar(mfrow=c(2,2))\nplot (seq_1, xlab=\"time\", ylab =\"p in population 1\", type = \"p\", col = 'red')\nplot (seq_2, xlab=\"time\", ylab =\"p in population 2\", type = \"p\", col = 'green')\nplot (seq_square, xlab=\"time\", ylab =\"p2 in population 2\", type = \"p\", col = 'blue')\nplot (seq_square_new, xlab=\"time\", ylab =\"p in population 1\", type = \"l\", col = 'yellow')"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#example-using-binomial-distribution",
    "href": "Lecture_Folder/Week2a.html#example-using-binomial-distribution",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nAs above for the normal distribution, data can be generated by being sampled from nearly any distribution and then visualized.\nBelow I’m having you use the ‘histogram’ function. What does it do?"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-1",
    "href": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\n10 successes (out of 20 trials) is the most frequent outcome\n\n\nheads &lt;- rbinom(n=1000, size=20, prob=0.5)\nhist(heads)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-2",
    "href": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nThis kind of statement can be run in one line as well, which is sometimes easier.\n\n\nhist(rbinom(n=1000, size=20, prob=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-data-frames-in-r",
    "href": "Lecture_Folder/Week2a.html#creating-data-frames-in-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating Data Frames in R",
    "text": "Creating Data Frames in R\n\nAs you have seen, in R you can generate your own random data set drawn from nearly any distribution very easily.\nOften we will want to use collected data.\nNow, let’s make a dummy dataset to get used to dealing with data frames\nSet up three variables (hydrogel_concentration, compression and conductivity) as vectors\n\n\nhydrogel_concentration &lt;- factor(c(\"low\", \"high\", \"high\", \"high\", \"medium\", \"medium\", \"medium\",\"low\"))\ncompression &lt;- c(3.4, 3.4, 8.4, 3, 5.6, 8.1, 8.3, 4.5)\nconductivity &lt;- c(0, 9.2, 3.8, 5, 5.6, 4.1, 7.1, 5.3)\n\n\nCreate a data frame where vectors become columns\n\n\nmydata &lt;- data.frame(hydrogel_concentration, compression, conductivity)\nrow.names(mydata) &lt;- c(\"Sample_1\", \"Sample_2\", \"Sample_3\", \"Sample_4\", \n                       \"Sample_5\", \"Sample_6\", \"Sample_7\", \"Sample_8\")\n\n\nNow you have a hand-made data frame with row names\nTake a look at it in the data section of RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r",
    "href": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nA strength of R is being able to import data from an external source\nCreate the same table that you did above in a spreadsheet like Excel\nExport it to comma separated and tab separated text files for importing into R.\nThe first will read in a comma-delimited file, whereas the second is a tab-delimited\nIn both cases the header and row.names arguments indicate that there is a header row and row label column\nNote that the name of the file by itself will have R look in the CWD, whereas a full path can also be used"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r-1",
    "href": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nYourFile &lt;- read.table('yourfile.csv', header=T, row.names=1, sep=',')\nYourFile &lt;- read.table('yourfile.txt', header=T, row.names=1, sep='\\t')"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#exporting-data-frames-in-r",
    "href": "Lecture_Folder/Week2a.html#exporting-data-frames-in-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Exporting Data Frames in R",
    "text": "Exporting Data Frames in R\n\nwrite.table(YourFile, \"yourfile.csv\", quote=F, row.names=T, sep=\",\")\nwrite.table(YourFile, \"yourfile.txt\", quote=F, row.names=T, sep=\"\\t\")"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#indexing-in-data-frames",
    "href": "Lecture_Folder/Week2a.html#indexing-in-data-frames",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nNext up - indexing just a subset of the data\nThis is a very important idea in R, that you can analyze just a subset of the data.\nThis is analyzing only the data in the file you made that has the factor value ‘mixed’.\n\n\nprint (YourFile[,2])\nprint (YourFile$variable)\nprint (YourFile[2,])\nplot (YourFile$variable1, YourFile$variable2)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#r-interlude-some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week2a.html#r-interlude-some-real-transcriptomic-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Some real transcriptomic data",
    "text": "R INTERLUDE | Some real transcriptomic data\n\nExamine the data file\nHow many many rows and columns are there?\nHow many different variables are there?\nWhat are the general types of variables?\nNow let’s read the data file into R and analyze it\nThis exercise will help you get used to reading in and manipulating genomic data files\nFirst off, remember to set your working directory to find your file correctly"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week2a.html#some-real-transcriptomic-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Some real transcriptomic data",
    "text": "Some real transcriptomic data\n\nRNAseq_Data &lt;- read.table('&lt;name_of_file&gt;', header=TRUE, sep=',')\n\nprint (RNAseq_Data)\nhead (RNAseq_Data)\ntail (RNAseq_Data)\n\nprint (RNAseq_Data[,2])\nprint (RNAseq_Data[1,])\nprint (RNAseq_Data[1,2])\nprint (RNAseq_Data$ENSGACG00000000010)\nprint (RNAseq_Data$ENSGACG00000000010&gt;45.0)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#summary-stats-and-figures",
    "href": "Lecture_Folder/Week2a.html#summary-stats-and-figures",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Summary stats and figures",
    "text": "Summary stats and figures\n\nsummary1 &lt;- summary(RNAseq_Data $ENSGACG00000000003)\nprint (summary1)\n\nhist(RNAseq_Data $ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003~RNAseq_Data$Population)\nplot(RNAseq_Data $ENSGACG00000000003, RNAseq_Data$ENSGACG00000000003)\n\nboxplot(RNAseq_Data $ENSGACG00000000003~RNAseq_Data$Treatment, \n        col = \"red\", ylab = \"Expression Level\", xlab = \"Treatment level\", \n        border =\"orange\", \n        main = \"Boxplot of variation in gene expression across microbiota treatments\")"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#what-type-of-plot-do-i-use-for-each-data-type",
    "href": "Lecture_Folder/Week3a.html#what-type-of-plot-do-i-use-for-each-data-type",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "What type of plot do I use for each data type?",
    "text": "What type of plot do I use for each data type?\n\nFlow chart to determine what type of data visualization and which ggplot geom to use"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#three-dimensional-data",
    "href": "Lecture_Folder/Week3a.html#three-dimensional-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Three dimensional data",
    "text": "Three dimensional data\n\nset.seed(345) # make the example reproducible\na &lt;- rnorm(100,10,10)\nb &lt;- rnorm(100,5,5)\nc &lt;- rnorm(100,1,1)\nd &lt;- data.frame(a,b,c)\n\nlibrary(MASS)\nDENS &lt;- kde2d(d$a,d$b)\ncontour(DENS)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#three-dimensional-data-1",
    "href": "Lecture_Folder/Week3a.html#three-dimensional-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Three dimensional data",
    "text": "Three dimensional data\n\nset.seed(345) # make the example reproducible\na &lt;- rnorm(100,10,10)\nb &lt;- rnorm(100,5,5)\nc &lt;- rnorm(100,1,1)\nd &lt;- data.frame(a,b,c)\n\nlibrary(MASS)\nDENS &lt;- kde2d(d$a,d$b)\nfilled.contour(DENS,plot.axes = {\n  axis(1)\n  axis(2)\ncontour(DENS,add = TRUE)})"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#three-dimensional-data-2",
    "href": "Lecture_Folder/Week3a.html#three-dimensional-data-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Three dimensional data",
    "text": "Three dimensional data\n\nset.seed(345) # make the example reproducible\na &lt;- rnorm(100,10,10)\nb &lt;- rnorm(100,5,5)\nc &lt;- rnorm(100,1,1)\nd &lt;- data.frame(a,b,c)\n\nlibrary(ggplot2)\nggplot(d,aes(x=a,y=b)) +\n  geom_density2d()"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#section",
    "href": "Lecture_Folder/Week3a.html#section",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "",
    "text": "Examples of bad graphs and how to improve them.\nCourtesy of K.W. Broman\n\nwww.biostat.wisc.edu/~kbroman/topten_worstgraphs/"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#ticker-tape-parade",
    "href": "Lecture_Folder/Week3a.html#ticker-tape-parade",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Ticker tape parade",
    "text": "Ticker tape parade\n\nRoeder K 1994 DNA fingerprinting: A review of the controversy with discussion . Statistical Science 9:222T278, Figure 4"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-line-to-no-understanding",
    "href": "Lecture_Folder/Week3a.html#a-line-to-no-understanding",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "A line to no understanding",
    "text": "A line to no understanding\n\nEpstein MP, Satten GA 2003 Inference on haplotype effects in caseTcontrol studies using unphased genotype data. American Journal of Human Genetics 73:1316T1329, Figure 1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-hot-cup-o-mixed-messages",
    "href": "Lecture_Folder/Week3a.html#a-hot-cup-o-mixed-messages",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "A hot cup o’ mixed messages",
    "text": "A hot cup o’ mixed messages"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#i-want-the-biggest-slice-of-the-tfbs-pie",
    "href": "Lecture_Folder/Week3a.html#i-want-the-biggest-slice-of-the-tfbs-pie",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "I want the biggest slice of the TFBS pie",
    "text": "I want the biggest slice of the TFBS pie\n\nCawley S, et al. 2004 Unbiased mapping of transcription factor binding sites along human chromosomes 21 and 22 points to widespread regulation of noncoding RNAs. Cell 116:499T509, Figure 1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-bake-sale-of-pie-charts",
    "href": "Lecture_Folder/Week3a.html#a-bake-sale-of-pie-charts",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "A bake sale of pie charts",
    "text": "A bake sale of pie charts\n\nBell ML, et al. 2007 Spatial and temporal variation in PM2.5 chemical composition in the United States for health effects studies. Environmental Health Perspectives 115:989T995, Figure 3"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#wack-a-mole",
    "href": "Lecture_Folder/Week3a.html#wack-a-mole",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Wack a mole",
    "text": "Wack a mole\n\nCotter DJ, et al. 2004 Hematocrit was not validated as a surrogate endpoint for survival amoung epoetinTtreated hemodialysis patients. Journal of Clinical Epidemiology 57:1086T1095, Figure 2"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#principles-of-effective-display",
    "href": "Lecture_Folder/Week3a.html#principles-of-effective-display",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Principles of effective display",
    "text": "Principles of effective display\n\n“Graphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space”\n— Edward Tufte"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-best-statistical-graphic-ever-drawn-according-to-edward-tufte",
    "href": "Lecture_Folder/Week3a.html#the-best-statistical-graphic-ever-drawn-according-to-edward-tufte",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The best statistical graphic ever drawn according to Edward Tufte",
    "text": "The best statistical graphic ever drawn according to Edward Tufte\n\nThis map by Charles Joseph Minard portrays the losses suffered by Napoleon’s army in the Russian campaign of 1812"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#principles-of-effective-display-1",
    "href": "Lecture_Folder/Week3a.html#principles-of-effective-display-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Principles of effective display",
    "text": "Principles of effective display\n\nShow the data\n\nEncourage the eye to compare differences\nRepresent magnitudes honestly and accurately\n\nDraw graphical elements clearly, minimizing clutter\n\nMake displays easy to interpret"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#above-all-else-show-the-data-tufte-1983",
    "href": "Lecture_Folder/Week3a.html#above-all-else-show-the-data-tufte-1983",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "“Above all else show the data” | Tufte 1983",
    "text": "“Above all else show the data” | Tufte 1983\n\nThe relationship between the numbers of native tropical stingless bees and Africanized honey bees onflowering shrubs in French Guiana. The data have been erased in the left panel. Redrawn from Roubik 1978."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#maximize-the-data-to-ink-ratio-within-reason-tufte-1983",
    "href": "Lecture_Folder/Week3a.html#maximize-the-data-to-ink-ratio-within-reason-tufte-1983",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "“Maximize the data to ink ratio, within reason” | Tufte 1983",
    "text": "“Maximize the data to ink ratio, within reason” | Tufte 1983\nDraw graphical elements clearly, minimizing clutter\n\nThe percentage of adults over 18 with a “body mass index” greater than 25 in different years The Economist 2006 . Body mass index is a measure of weight relative to height."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-graphic-does-not-distort-if-the-visual-representation-of-the-data-is-consistent-with-the-numerical-representation-tufte-1983",
    "href": "Lecture_Folder/Week3a.html#a-graphic-does-not-distort-if-the-visual-representation-of-the-data-is-consistent-with-the-numerical-representation-tufte-1983",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "“A graphic does not distort if the visual representation of the data is consistent with the numerical representation” – Tufte 1983",
    "text": "“A graphic does not distort if the visual representation of the data is consistent with the numerical representation” – Tufte 1983\nRepresent magnitudes honestly and accurately\n\nSlow wave sleep in the brain hemispheres of mallard ducks sleeping with one eye open. From Rattenborg et al. 1999 Nature"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.",
    "href": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "How Fox News makes a figure ….",
    "text": "How Fox News makes a figure …."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.-1",
    "href": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "How Fox News makes a figure ….",
    "text": "How Fox News makes a figure ….\n\n“Graphical excellence begins with telling the truth about the data” – Tufte 1983"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude",
    "href": "Lecture_Folder/Week3a.html#r-interlude",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R Interlude",
    "text": "R Interlude\n\nread in the data set Week1b_Stickle_RNAseq.tsv and assign it to a data object\ntry out the command View for the whole data set\ntry out the command summary for one of the variables\nload the package tidyverse and try the command glimpse\ntry making some nice plots of the different types of data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#stochastic-processes-in-statistics",
    "href": "Lecture_Folder/Week3a.html#stochastic-processes-in-statistics",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Stochastic Processes in Statistics",
    "text": "Stochastic Processes in Statistics\n\nWe often want to know truths about the world, but the best we can do is estimate them\nUncertainty in those estimates is a given.\nThe process of statistics is largely about quantifying and managing uncertainty.\nRandom variables are the product of stochastic processes\nExpectations can be based on theoretical probability distributions\nWe are going to start with probability rules and then slowly experience different distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#different-flavors-of-inferential-statistics",
    "href": "Lecture_Folder/Week3a.html#different-flavors-of-inferential-statistics",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Different flavors of inferential statistics",
    "text": "Different flavors of inferential statistics\n\nFrequentist Statistics\n\nClassical or standard approaches\nNull hypothesis testing\n\n\n\nHierarchical Probabilistic Modeling\n\nMaximum Likelihood\nBayesian Analyses\nMachine Learning"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#what-is-probability",
    "href": "Lecture_Folder/Week3a.html#what-is-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "What is probability",
    "text": "What is probability\n\nFrequency interpretation\n\n“Probabilities are understood as mathematically convenient approximations to long run relative frequencies.”\n\nSubjective (Bayesian) interpretation\n\n“A probability statement expresses the opinion of some individual regarding how certain an event is to occur.”"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#random-variables-probability",
    "href": "Lecture_Folder/Week3a.html#random-variables-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nProbability is the expression of belief in some future outcome\nA random variable can take on different values with different probabilities\nThe sample space of a random variable is the universe of all possible values"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#random-variables-probability-1",
    "href": "Lecture_Folder/Week3a.html#random-variables-probability-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nThe sample space can be represented by a\n\nprobability mass distribution (discrete)\nprobability density function (PDF) (continuous)\nalgebra and calculus are used for each respectively\nprobabilities of a sample space always sum to 1.0\n\nHow does it make sense that a sample space will always sum to 1?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#bernoulli-distribution",
    "href": "Lecture_Folder/Week3a.html#bernoulli-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nDescribes the expected outcome of a single event with probability p\nExample of flipping of a fair coin once\n\n\\[Pr(X=\\text{Head}) = \\frac{1}{2} = 0.5 = p \\]\n\\[Pr(X=\\text{Tails}) = \\frac{1}{2} = 0.5 = 1 - p = q \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#bernoulli-distribution-1",
    "href": "Lecture_Folder/Week3a.html#bernoulli-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nIf the coin isn’t fair then \\(p \\neq 0.5\\)\nHowever, the probabilities still sum to 1\n\n\\[ p + (1-p) = 1 \\] \\[ p + q = 1 \\]\n\nSame is true for other binary possibilities\n\nsuccess or failure\nyes or no answers\nchoosing an allele from a population based upon allele frequencies (Hardy-Weinberg ring any bells??)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#probability-rules",
    "href": "Lecture_Folder/Week3a.html#probability-rules",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nFlip a coin twice\nRepresent the first flip as ‘X’ and the second flip as ‘Y’\n\n\\[ Pr(\\text{X=H and Y=H}) = p*p = p^2 \\] \\[ Pr(\\text{X=H and Y=T}) = p*q = pq = p^2 \\] \\[ Pr(\\text{X=T and Y=H}) = q*p = pq \\] \\[ Pr(\\text{X=T and Y=T}) = q*q = q^2 \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#probability-rules-1",
    "href": "Lecture_Folder/Week3a.html#probability-rules-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nProbability that the H and T can occur in any order\n\n\\[ \\text{Pr(X=H) or Pr(X=T)} = p+q=1\\]\n\\[ \\text{Pr(X=H and Y=T) or Pr(X=T and Y=H)} = \\] \\[ (p*q) + (p*q) = 2pq \\]\n\nThese are the ‘and’ and ‘or’ rules of probability\n\n‘and’ means multiply the probabilities\n‘or’ means sum the probabilities\nmost probability distributions can be built up from these simple rules"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips",
    "href": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\n# tossing a fair coin\ncoin &lt;- c(\"heads\", \"tails\")\n\nsample(coin)\n\n[1] \"tails\" \"heads\""
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips-1",
    "href": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\nWhat happens when we change the probabilities or the sample size? How confident are we that our coin is fair?\n\n\nflips &lt;- sample(coin, prob = c(0.5, 0.5), size=13, replace=TRUE)\nbarplot(table(flips))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#expectation-and-moments-of-distributions",
    "href": "Lecture_Folder/Week3a.html#expectation-and-moments-of-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Expectation and Moments of Distributions",
    "text": "Expectation and Moments of Distributions\n\nDistributions have moments that can be estimated\n1st, 2nd, 3rd and 4th moments of a distribution?\nThe expectation or mean of a random variable X is:\n\n\\[E[X] = \\sum_{\\text{all x}}^{}xP(X=x) = \\mu\\]\n\nOften we want to know how dispersed the random variable is around its mean.\nOne measure of dispersion is the variance\nThere are higher moments of distributions (e.g. skew and kurtosis)\n\n\\[Var(X) = E[X^2] = \\sigma^2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#joint-probability",
    "href": "Lecture_Folder/Week3a.html#joint-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Joint probability",
    "text": "Joint probability\n\\[Pr(X,Y) = Pr(X) * Pr(Y)\\]\n\nNote that this is true for two independent events\nHowever, for two non-independent events we also have to take into account their covariance\nTo do this we need conditional probabilities"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#conditional-probability",
    "href": "Lecture_Folder/Week3a.html#conditional-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nFor two independent variables: Probability of Y, given X, or the probability of X, given Y.\n\n\\[Pr(Y|X) = Pr(Y)\\text{ and }Pr(X|Y) = Pr(X)\\]\n\nFor two non-independent variables\n\n\\[Pr(Y|X) \\neq Pr(Y)\\text{ and }Pr(X|Y) \\neq Pr(X)\\]\n\nVariables that are non-independent have a shared variance, which is also known as the covariance\nCovariance standardized to a mean of zero and a unit standard deviation is correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#what-is-likelihood-vs.-probability",
    "href": "Lecture_Folder/Week3a.html#what-is-likelihood-vs.-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "What is Likelihood vs. Probability?",
    "text": "What is Likelihood vs. Probability?\n\nThe probability of an event is the proportion of times that the event would occur if we repeated a random trial over and over again under the same conditions.\nThe likelihood is a conditional probability of a parameter value given a set of data\nThe likelihood of a population parameter equaling a specific value, given the data\n\nL[parameter|data] = Pr[data|parameter]\n\nLikelihood function which can have a maximum\nWhat is a Bayesian estimate? - the use of prior distribution to update a posterior distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#data-cleaning-and-manipulation",
    "href": "Lecture_Folder/Week3a.html#data-cleaning-and-manipulation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Data cleaning and manipulation",
    "text": "Data cleaning and manipulation\n\nHere, we differentiate “data cleaning” from “data manipulation”, which is perhaps an arbitrary distinction.\n“Data cleaning” typically refers to altering variable class information, fixing mistakes that could have arisen in the data (e.g., an extra ‘.’ symbol in a numeric value), and things of this nature.\n“Data manipulation”, in my mind, refers to altering the structure of the data in a way that changes the functional structure the data (e.g., an addition of a column, deletion of rows, long/wide formatting change)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages",
    "href": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Tidyverse family of packages",
    "text": "Tidyverse family of packages\n\nLet’s load the tidyverse meta-package and check the output.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages-1",
    "href": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Tidyverse family of packages",
    "text": "Tidyverse family of packages\n\nHadley Wickham and others have written R packages to modify data\nThese packages do many of the same things as base functions in R\nHowever, they are specifically designed to do them faster and more easily\nWickham also wrote the package ggplot2 for elegant graphics creations"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#example-of-a-tibble",
    "href": "Lecture_Folder/Week3a.html#example-of-a-tibble",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Example of a tibble",
    "text": "Example of a tibble"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#example-of-a-tibble-1",
    "href": "Lecture_Folder/Week3a.html#example-of-a-tibble-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Example of a tibble",
    "text": "Example of a tibble"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#types-of-vectors-of-data",
    "href": "Lecture_Folder/Week3a.html#types-of-vectors-of-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\nint stands for integers\ndbl stands for doubles, or real numbers\nchr stands for character vectors, or strings\ndttm stands for date-times (a date + a time)\nlgl stands for logical, vectors that contain only TRUE or FALSE\nfctr stands for factors, which R uses to represent categorical variables with fixed possible values\ndate stands for dates"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#types-of-vectors-of-data-1",
    "href": "Lecture_Folder/Week3a.html#types-of-vectors-of-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\n\nLogical vectors can take only three possible values:\n\nFALSE\nTRUE\nNA which is ‘not available’.\n\nInteger and double vectors are known collectively as numeric vectors.\n\nIn R numbers are doubles by default.\n\nIntegers have one special value: NA, while doubles have four:\n\nNA\nNaN which is ‘not a number’\nInf\n-Inf"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#tidyverse-packages-cont.",
    "href": "Lecture_Folder/Week3a.html#tidyverse-packages-cont.",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Tidyverse packages (cont.)",
    "text": "Tidyverse packages (cont.)\nThe tidyverse actually comes with a lot more packages than those that are just loaded automatically.1\n\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nWe’ll use several of these additional packages during the remainder of this course.\n\nE.g. The lubridate package for working with dates and the rvest package for webscraping.\nHowever, bear in mind that these packages will have to be loaded separately."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#key-dplyr-verbs",
    "href": "Lecture_Folder/Week3a.html#key-dplyr-verbs",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Key dplyr verbs",
    "text": "Key dplyr verbs\nThere are five key dplyr verbs that you need to learn.\n\nfilter: Filter (i.e. subset) observations (rows) based on their values.\n\nselect: Select (i.e. subset) variables (columns) by their names:\n\narrange: Arrange (i.e. reorder) rows based on their values.\n\nmutate: Create new columns.\n\nsummarise: Collapse multiple rows into a single summary value.1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#filter-arrange-select",
    "href": "Lecture_Folder/Week3a.html#filter-arrange-select",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "filter(), arrange() & select()",
    "text": "filter(), arrange() & select()\n\nfilter(flights, month == 11 | month == 12)\n\n\narrange(flights, year, month, day)\n\n\nselect(flights, year)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#conditionals",
    "href": "Lecture_Folder/Week3a.html#conditionals",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "conditionals",
    "text": "conditionals\n\n== equals exactly\n&lt;, &lt;= is smaller than, is smaller than or equal to\n&gt;, &gt;=` is bigger than, is bigger than or equal to\n!= not equal to\n! NOT operator, to specify things that should be omitted\n& AND operator, allows you to chain two conditions which must both be met\n\\| OR operator, to chains two conditions when at least one should be met\n%in% belongs to one of the following (usually followed by a vector of possible values)\n\nThe AND (&) and the OR (|`) operators are also super useful when you want to separate data based on multiple conditions."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#mutate-transmutate",
    "href": "Lecture_Folder/Week3a.html#mutate-transmutate",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "mutate() & transmutate()",
    "text": "mutate() & transmutate()\nThis function will add a new variable that is a function of other variable(s)\n\nmutate(flights_sml,\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#group_by-summarize",
    "href": "Lecture_Folder/Week3a.html#group_by-summarize",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "group_by( ) & summarize( )",
    "text": "group_by( ) & summarize( )\nThis first function allows you to aggregate data by values of categorical variables\n\nby_day &lt;- group_by(flights, year, month, day)\n\nOnce you have done this aggregation, you can then calculate values (in this case the mean) of other variables split by the new aggregated levels of the categorical variable\n\nsummarise(by_day, delay = mean(dep_delay, na.rm = TRUE))\n\n\nNote - you can get a lot of missing values!\nThat’s because aggregation functions obey the usual rule of missing values:\n\nif there’s any missing value in the input, the output will be a missing value.\nfortunately, all aggregation functions have an na.rm argument which removes the missing values prior to computation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#other-dplyr-goodies",
    "href": "Lecture_Folder/Week3a.html#other-dplyr-goodies",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Other dplyr goodies",
    "text": "Other dplyr goodies\n\ngroup_by and ungroup: For (un)grouping. - Particularly useful with the summarise and mutate commands, as we’ve already seen.\n\nslice: Subset rows by position rather than filtering by values. - E.g. starwars %&gt;% slice(c(1, 5))\n\npull: Extract a column from as a data frame as a vector or scalar. - E.g. starwars %&gt;% filter(gender==\"female\") %&gt;% pull(height)\n\ncount and distinct: Number and isolate unique observations. - E.g. starwars %&gt;% count(species), or starwars %&gt;% distinct(species)\n\nYou could also use a combination of mutate, group_by, and n(), e.g. starwars %&gt;% group_by(species) %&gt;% mutate(num = n())."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-playing-with-tidyverse-functions",
    "href": "Lecture_Folder/Week3a.html#r-interlude-playing-with-tidyverse-functions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Playing with Tidyverse functions",
    "text": "R INTERLUDE | Playing with Tidyverse functions\n\nStep 1 - Read in the Week1b_Stickle_RNAseq.tsv dataset\nStep 2 - Make the dataset into a tibble\nStep 3 - Select all of the categorical variables and only 4 of the gene count variables and put them into a new data object\nStep 4 - Mutate each of the 4 gene expression values by performing a square root transformation making a new variable for each of the original (keep all 8 in the dataset).\nStep 5 - Summarize the mean and standard deviation for each of the gene count variables grouped by the ‘sex’ and ‘population’ and ‘treatment’ categorical variables\nStep 6 - Create a histogram for one of the original gene expression variables, and one of the derived variables\n\nStep 7 - Create a box plot for one of the original gene expression variables, and one of the derived variables, split by treatment\nStep 8 - Write the final data table to a .csv file and one of the figures to a .pdf file\n\n\n\n\nBioE_Stats_2025 - Knight Campus"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#discrete-probability-distributions",
    "href": "Lecture_Folder/Week3a.html#discrete-probability-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Discrete Probability Distributions",
    "text": "Discrete Probability Distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-2",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-3",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-4",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-4",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week3a.html#testing-geometric-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\n#dgeom(x=20, p=0.1)\n# 0.01215767\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week3a.html#testing-geometric-distributions-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution-1",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-probability-distribution",
    "href": "Lecture_Folder/Week3a.html#binomial-probability-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution-2",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution-3",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-probability-distribution-1",
    "href": "Lecture_Folder/Week3a.html#binomial-probability-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-binomial-distributions",
    "href": "Lecture_Folder/Week3a.html#testing-binomial-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\ndbinom gives the density (probability) of number successes (x) in number trials (size), with (prob) probability between 0-1\n\n\n# dbinom(x=5, size=10, p=0.5)\n# 0.246\nplot(dbinom(x=1:10, size=10, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-binomial-distributions-1",
    "href": "Lecture_Folder/Week3a.html#testing-binomial-distributions-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\npbinom gives the cumulative probability of reaching at least (q) number of successes after (size) number of trials\n\n\nplot(pbinom(q=1:100, size=100, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “ones” have appeared.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “one” appearing on the \\(k^{th}\\) trial:\n\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r-1}(1-p)^{k-r}p\\]\n\nwhich simplifies to\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r}(1-p)^{k-r}\\]\n\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution-2",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “successes” have happened.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “success” appearing on the \\(k^{th}\\) trial\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution-3",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 AA\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-3",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 AA\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-4",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-4",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-5",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-5",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-1",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-1",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week3a.html#testing-poisson-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-6",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-6",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete but number of observations of each outcome is observed\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 amino acids in length\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to an arbitrarily large number"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-7",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-7",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nFor example, you can examine 100 plots of land\n\ncount the number of snails in each plot\nwhat is the probability of observing a plot with ‘r’ snails is\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\), and the two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another, a hypothesis that you can test\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-2",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-2",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#continuous-probability-distributions",
    "href": "Lecture_Folder/Week3a.html#continuous-probability-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Continuous probability distributions",
    "text": "Continuous probability distributions\n\nP(observation lies within dx of x) = f(x)dx\n\\[P(a\\leq X \\leq b) = \\int_{a}^{b} f(x) dx\\]\n\nRemember that the indefinite integral sums to one\n\\[\\int_{-\\infty}^{\\infty} f(x) dx = 1\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#continuous-probabilities",
    "href": "Lecture_Folder/Week3a.html#continuous-probabilities",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Continuous probabilities",
    "text": "Continuous probabilities\n\nE[X] may be found by integrating the product of x and the probability density function over all possible values of x:\n\\[E[X] = \\int_{-\\infty}^{\\infty} xf(x) dx \\]\n\n\\(Var(X) = E[X^2] - (E[X])^2\\), where the expectation of \\(X^2\\) is\n\\[E[X^2] = \\int_{-\\infty}^{\\infty} x^2f(x) dx \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#uniform-distribution",
    "href": "Lecture_Folder/Week3a.html#uniform-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\n\\[E[X] = \\int_{a}^{b} x\\frac{1}{b-a} dx = \\frac{(a+b)}{2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week3a.html#uniform-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#uniform-distribution-2",
    "href": "Lecture_Folder/Week3a.html#uniform-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\n\\[f(x)=\\lambda e^{-\\lambda x}\\]\n\n\nE[X] can be found be integrating \\(xf(x)\\) from 0 to infinity\n\n\n\nleading to the result that\n\n\n\n\\(E[X] = \\frac{1}{\\lambda}\\)\n\\(E[X^2] = \\frac{1}{\\lambda^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution-2",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution-3",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\) :\n\n\n\\[f(x) = \\frac{e^{-\\lambda x}\\lambda x^{r-1}}{(r-1)!}\\lambda\\]\n\n\\[ Mean =  \\frac{r}{\\lambda} \\] \\[ Variance = \\frac{r}{\\lambda^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\n\n\n\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution-2",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution-3",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nPretend that you want to create your own binomial distribution\n\nyou could flip 20 fair coins: 20 independent Bernoulli “trials”\nyou could then replicate this 100 times: 100 “observations”\nfor each one of your replicates you record the number of heads\nprobability of heads (“success”) for any flip of a fair coin is 0.5\n\nDraw a diagram of what you think the distribution would look like\n\nwhat will the x-axis represent, and what are its values?\nwhat will the y-axis represent, and what are its values?\nwhere will the ‘center of mass’ be?\nwhat parameter determines the value of the center of mass?\nwhat parameter determines the spread of the distribution?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-1",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nUsing R, simulate these experimental data\n\nusing the \\(rbinom()\\) function\nlook at the arguments to see how they map on to the trials, probability of each trial, and number of replicates\nuse the \\(hist()\\) function to plot the simulated data.\nwhat do the y- and x-axes represent?\nwhat is the most common outcome, in terms of the number of “successes” per trial? Does this make sense?\n\nNow just change you script to do the following\n\nperform 200 trials for each of the 100 replicates\nperform 2000 trials for each of the 100 replicate\nhow do the distributions change when you go from 20 to 200 to 2000 trials?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-2",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nNote that the binomial function incorporates both the ‘and’ and ‘or’ rules of probability\nThis part is the probability of each outcome (multiplication)\n\n\\[\\large p^{k} (1-p)^{n-k}\\]\nThis part (called the binomial coefficient) is the number of different ways each combination of outcomes can be achieved (summation)\n\\[\\large {n \\choose k}\\] Together they equal the probability of a specified number of successes\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-3",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nNow perform your experiment using R\nUse the rbinom function to replicate what you sketched out for coin flipping\nBe sure to check out the other functions in the binom family\nMake sure you know how you are mapping the parameeters to values\nTake the output and create a histogram\nDoes it look similar to what you expected?\nNow change the values around so that\n\nYou have more or fewer coin flips per trial\nYou replicate the process with more or fewer trials\nYou change the coin from being fair to being slightly biased\nYou change the coin from being slightly to heavily biased"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-gaussian-or-normal-distribution",
    "href": "Lecture_Folder/Week3a.html#the-gaussian-or-normal-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The Gaussian or Normal Distribution",
    "text": "The Gaussian or Normal Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "href": "Lecture_Folder/Week3a.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Log-normal PDF | Continuous version of Poisson (-ish)",
    "text": "Log-normal PDF | Continuous version of Poisson (-ish)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#transformations-to-normalize-data",
    "href": "Lecture_Folder/Week3a.html#transformations-to-normalize-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#transformations-to-normalize-data-1",
    "href": "Lecture_Folder/Week3a.html#transformations-to-normalize-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-to-normal-categorical-to-continuous",
    "href": "Lecture_Folder/Week3a.html#binomial-to-normal-categorical-to-continuous",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial to Normal | Categorical to continuous",
    "text": "Binomial to Normal | Categorical to continuous"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "href": "Lecture_Folder/Week3a.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The Normal (aka Gaussian) | Probability Density Function (PDF)",
    "text": "The Normal (aka Gaussian) | Probability Density Function (PDF)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf",
    "href": "Lecture_Folder/Week3a.html#normal-pdf",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf-a-function-of-two-parameters",
    "href": "Lecture_Folder/Week3a.html#normal-pdf-a-function-of-two-parameters",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF | A function of two parameters",
    "text": "Normal PDF | A function of two parameters\n\n(\\(\\mu\\) and \\(\\sigma\\))\n\n\n\n\n\n\n\n\n\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\epsilon \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf-estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week3a.html#normal-pdf-estimates-of-mean-and-variance",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF | estimates of mean and variance",
    "text": "Normal PDF | estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf-1",
    "href": "Lecture_Folder/Week3a.html#normal-pdf-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology",
    "href": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-1",
    "href": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-2",
    "href": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week3a.html#parent-offspring-resemblance",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week3a.html#genetic-model-of-complex-traits",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week3a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week3a.html#why-else-is-the-normal-special",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nThe normal distribution is immensely useful because of the central limit theorem, which says that the mean of many random variables independently drawn from the same distribution is distributed approximately normally\nOne can think of numerous situations, such as\n\nwhen multiple genes contribute to a phenotype\nor that many factors contribute to a biological process\n\nIn addition, whenever there is variance introduced by stochastic factors the central limit theorem holds\nThus, normal distributions occur throughout genomics\nIt’s also the basis of the majority of classical statistics"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have a mean of 0 and a standard deviation of 1\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it",
    "href": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Simulate a population and sample it!",
    "text": "R INTERLUDE | Simulate a population and sample it!\nSimulate a population of 10,000 individual values for a variable x:\n\nx &lt;- rnorm(10000, mean=50.5, sd=5.5) \n\nTake 1000 random samples of size 20, take the mean of each sample, and plot the distribution of these 1000 sample means.\n\nx_sample_means &lt;- NULL\nfor(i in 1:1000){\nx_samp &lt;- sample(x, 20, replace=FALSE)\nx_sample_means[i] &lt;- mean(x_samp)\n}\n\nFor one of your samples, use the equation from the previous slide to transform the values to z-scores.\nPlot the distribution of the z-scores, and calculate the mean and the standard deviation."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it-1",
    "href": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Simulate a population and sample it!",
    "text": "R INTERLUDE | Simulate a population and sample it!\n\nNow, create a second population (called x.lognorm) by log-transforming all 10,000 values from population “x”\nPlot the histogram of these data\nRepeat the taking of 1000 samples of size 20\nTake the mean of each sample\nPlot the distribution of these 1000 sample means from the known lognormal population.\nWhat does the distribution of the sampled means look like?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "href": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "href": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#covariance-and-correlation",
    "href": "Lecture_Folder/Week3a.html#covariance-and-correlation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#linear-models",
    "href": "Lecture_Folder/Week3a.html#linear-models",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Linear Models",
    "text": "Linear Models"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet",
    "href": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet-1",
    "href": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet\n\nMean of x in each case 9 (exact)\nVariance of x in each case 11 (exact)\nMean of y in each case 7.50 (to 2 decimal places)\nVariance of y in each case 4.122 or 4.127 (to 3 decimal places)\nCorrelation between x and y in each case 0.816 (to 3 decimal places)\nLinear regression line in each case \\(y =3.00 + 0.50x\\) (to 2 decimal places)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#understanding-populations-and-their-parameters",
    "href": "Lecture_Folder/Week3a.html#understanding-populations-and-their-parameters",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Understanding Populations and their Parameters",
    "text": "Understanding Populations and their Parameters\n\nWe often think about the samples we are collecting as a part of a larger population\nSince we can’t measure every member of that population, we instead use sampling to estimate the parameters of the population as a whole\n\nSome common parameters: mean, range, median\nIf we performed random sampling, we assume that the parameter estimates of our sample are equitable to the true population parameters"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#accuracy-vs.-precision",
    "href": "Lecture_Folder/Week3a.html#accuracy-vs.-precision",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#accuracy-vs.-precision-1",
    "href": "Lecture_Folder/Week3a.html#accuracy-vs.-precision-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision\n\nAccuracy is the closeness of an estimated value to its true value\nPrecision is the closeness of repeated estimates to one another\nOur goal is to have unbiased estimates that are the most precise\nWe have to estimate parameters and test hypotheses by taking samples that approximate the underlying distribution\nThe goal of replication is to quantify variation at as many levels in a study as possible\nThe goal of randomization is to avoid bias as much as possible"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nParametric (a few special exceptions, like the sample mean and its standard error)\nOrdinary Least Squares (OLS) - optimized procedure that produces one definitive result, easy to use but no estimates of confidence\nResampling - bootstrapping and randomization\nMaximum Likelihood (ML) - Can provide model-based estimates with confidence, but harder to calculate\nBayesian Approaches - Incorporates prior information into ML estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-variation-of-a-parameter",
    "href": "Lecture_Folder/Week3a.html#sampling-variation-of-a-parameter",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling variation of a parameter",
    "text": "Sampling variation of a parameter"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation",
    "href": "Lecture_Folder/Week3a.html#estimation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation",
    "text": "Estimation\n\nEstimation is the process of inferring a population parameter from sample data\nThe value of one sample estimate is almost never the same as the population parameter because of random sampling error\nImagine taking multiple samples, each will be different from the true value\nMost will be close, but some will be far away\nThe expected value of a very large number of sample estimates is the value of the parameter being estimated\nSampling distribution of an estimate\n\nall values we might have obtained from our sample\nprobabilities of occurrence\n\nStandard error of an estimate\n\nstandard deviation of a sampling distribution\nmeasures the precision of the parameter estimate\nNO ESTIMATE IS USEFUL WITHOUT IT!"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-1",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-2",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-3",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week3a.html#standard-error-of-the-mean-sem",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\\[\\huge \\sigma_{\\bar{x}} \\approx s_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\]\n\nwhere \\(s_{\\bar{x}}\\) is the estimated standard error of the distribution of the mean estimates\nwhich is usually just referred to as the ’standard error of the mean (SEM)\nnote that this is not the standard deviation of the original distribution\nimportantly, the SEM will go down as the sample size increases"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error",
    "href": "Lecture_Folder/Week3a.html#standard-error",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard Error",
    "text": "Standard Error\n\nSadly, most other kinds of estimates do not have this amazing property.\nWhat to do?\nOne answer: make your own sampling distribution for the estimate using the “bootstrap”.\nMethod invented by Efron (1979)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation-bootstrap-algorithm",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation-bootstrap-algorithm",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation | Bootstrap Algorithm",
    "text": "Parameter Estimation | Bootstrap Algorithm\n\nUse R to take a random sample of individuals from the original data\nCalculate the estimate using the measurements in the bootstrap sample (step 1)\nThis is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3\nThe resulting quantity is called the bootstrap standard error"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-etymology-of-the-term-bootstrap",
    "href": "Lecture_Folder/Week3a.html#the-etymology-of-the-term-bootstrap",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The etymology of the term ‘bootstrap’",
    "text": "The etymology of the term ‘bootstrap’"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-the-bootstrap-is-good",
    "href": "Lecture_Folder/Week3a.html#why-the-bootstrap-is-good",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why the bootstrap is good",
    "text": "Why the bootstrap is good\n\nCan be applied to almost any sample statistic\n\nThis includes means, proportions, correlations, regression\n\nWorks when there is no ready formula for a standard error\n\nFor example the median, trimmed mean, correlation, eigenvalue, etc.\n\nIs nonparametric, so doesn’t require normally-distributed data\nWorks for estimates based on complicated sampling procedures or calculations\n\nFor example, it is used in phylogeny estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "href": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\nExamine the data_frames.R script\nExamine the simple_boostrap.R script\nOn your own - use R to figure out the bootstrap distribution for other parameters (such as variance)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "href": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\nx &lt;- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 1.6, 2.0, 2.0)\n\nUse R to make 1000 “pseudo-samples” of size 10 (with replacement), using a for loop as before.\nName the pseudo-sample object “xboot”, and name the means of the xboot samples “z”.\nPlot the histogram of the resampled means, and calculate the standard deviation of the sample means (the bootstrap SEM) using the sd() function.\nHow does it compare with the ordinary standard error of the mean calculated from the original, real sample?\n\nsd(x)/sqrt(10)\n\nNow take one of the genes from the GacuRNAseq_Subset.csv data and obtain a bootstrapped estimate of the mean expression level."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-2",
    "href": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\n\nThe 2.5th and 97.5th percentiles of the bootstrap sampling distribution are a passable 95% confidence interval\nNote that no transformations or normality assumptions needed\nYou can use the quantile() function to calculate these\nOn your own - use R to figure out the bootstrap distribution for other parameters (such as variance)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation | Ordinary Least Squares (OLS)",
    "text": "Parameter Estimation | Ordinary Least Squares (OLS)\n\nAlgorithmic approach to parameter estimations\nOne of the oldest and best developed statistical approaches\nUsed extensively in linear models (ANOVA and regression)\nBy itself only produces a single best estimate (No C.I.’s)\nCan use resampling approaches to get C.I.’s\nMany OLS estimators have been duplicated by ML estimators"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols-1",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation | Ordinary Least Squares (OLS)",
    "text": "Parameter Estimation | Ordinary Least Squares (OLS)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-exercise",
    "href": "Lecture_Folder/Week3a.html#sampling-exercise",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#test-it-out",
    "href": "Lecture_Folder/Week3a.html#test-it-out",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\n\n[1] 2.24649"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-exercise-1",
    "href": "Lecture_Folder/Week3a.html#sampling-exercise-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\n\n\n\n\n\n\n\n\n[1] \"Mean: \" \"4.95\"  \n\n\n[1] \"Range: \" \"1\"       \"10\""
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week3a.html#randomness-in-sampling",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week3a.html#surveying-your-sampling",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week3a.html#surveying-your-sampling-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\ntable(samps_var_means &gt; 4.5 & samps_var_means &lt; 5.5)\n\n\nFALSE  TRUE \n   19    31"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#surveying-your-sampling-2",
    "href": "Lecture_Folder/Week3a.html#surveying-your-sampling-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-distributions---its-been-normal-this-whole-time",
    "href": "Lecture_Folder/Week3a.html#sampling-distributions---its-been-normal-this-whole-time",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling Distributions - It’s been Normal this whole time?!",
    "text": "Sampling Distributions - It’s been Normal this whole time?!"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-central-limit-theorem-1",
    "href": "Lecture_Folder/Week3a.html#the-central-limit-theorem-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error-1",
    "href": "Lecture_Folder/Week3a.html#standard-error-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard Error",
    "text": "Standard Error\n\nThe sample size and the spread of the distribution (range) - contribute to what is known as the standard error of a random variable.\nThe standard error for any given sample attribute (such as a sample mean), can be calculated either based on distributional assumptions, or by a process called “resampling.”"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error-2",
    "href": "Lecture_Folder/Week3a.html#standard-error-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard error",
    "text": "Standard error"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#calculating-the-standard-error",
    "href": "Lecture_Folder/Week3a.html#calculating-the-standard-error",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nStandard Error of the Mean (SEM)\nSEM = SD / sqrt(sample size)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#calculating-the-standard-error-1",
    "href": "Lecture_Folder/Week3a.html#calculating-the-standard-error-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week3a.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#bootstrapping-1",
    "href": "Lecture_Folder/Week3a.html#bootstrapping-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned. - - It works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#confidence-intervals",
    "href": "Lecture_Folder/Week3a.html#confidence-intervals",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#relationship-between-mean-and-variance-1",
    "href": "Lecture_Folder/Week3a.html#relationship-between-mean-and-variance-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Relationship between mean and variance",
    "text": "Relationship between mean and variance\n\nThis means it is inappropriate to compare variations of different populations with largely different means\n\nFor instance, comparing the standard deviation for a body measurement in a population of mice, with the same body measurement in a population of elephants is not meaningful."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#test-it-out-1",
    "href": "Lecture_Folder/Week3a.html#test-it-out-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nprint(sd(true_pop))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week3a.html#coefficient-of-variation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Homework.html",
    "href": "Homework.html",
    "title": "Homeworks",
    "section": "",
    "text": "Homework 1"
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html",
    "href": "Homework_Folder/HW1_2025.html",
    "title": "BioE_Stats_2025_HW1 - EDA, t-test and Power Calculations",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use both the microbiota/RNAseq data set that you have been using in class, as well as the dataset that you’ve identified for your term long project. Try to accomplish a version of the tasks I lay out below on your own dataset, but you’re undoubtedly going to need to make some modifications and adjustments. In addition, you will be performing one set of power analyses using simulation on a hypothetical problem\nDue: Submit your work via Canvas by the end of the day (midnight) on Tuesday, April 29th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#directions",
    "href": "Homework_Folder/HW1_2025.html#directions",
    "title": "BioE_Stats_2025_HW1 - EDA, t-test and Power Calculations",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use both the microbiota/RNAseq data set that you have been using in class, as well as the dataset that you’ve identified for your term long project. Try to accomplish a version of the tasks I lay out below on your own dataset, but you’re undoubtedly going to need to make some modifications and adjustments. In addition, you will be performing one set of power analyses using simulation on a hypothetical problem\nDue: Submit your work via Canvas by the end of the day (midnight) on Tuesday, April 29th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#problem-1---exploratory-data-analysis",
    "href": "Homework_Folder/HW1_2025.html#problem-1---exploratory-data-analysis",
    "title": "BioE_Stats_2025_HW1 - EDA, t-test and Power Calculations",
    "section": "Problem 1 - Exploratory Data Analysis",
    "text": "Problem 1 - Exploratory Data Analysis\n\nRead in the data\n\nRead in the files\nUse str, head and glimpse to get an idea of the data structure\nCreate a tibble data object using this dataset (the function is as_tibble)\n\n\n\nPerform some wrangling\n\nSelect all of the categorical variables and only 4 of the gene count variables and put them into a new data object.\nMutate each of the 4 gene expression values by performing a square root transformation making a new variable for each of the original (keep all eight variables in the dataset).\nSummarise the mean and standard deviation for each of the gene count variables grouped by the ‘Microbiota’ and ‘Genotype’ categorical variables (hint, using group_by may make this easier; also remember your na.rm=TRUE to remove the na values)\n\n\n\nGraphical Communication with ggplot2\nInsert a code chunk and complete the following tasks using your gene expression tibble:\n\nCreate a barplot of microbiota and genotype- what does this tell you about experimental design?\nCreate a histogram and frequency polygram of the expression of one particular gene.\nCreate a boxplot of the expression of one gene by microbiota/genotype combination. Reorder it by median expression and flip the coordinates.\nExplore the coexpression patterns among your genes by plotting a couple pairwise combinations using geom_point. Plot your most interesting coexpression by treatment using facet_wrap."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#problem-2---parametric-t-test-in-r",
    "href": "Homework_Folder/HW1_2025.html#problem-2---parametric-t-test-in-r",
    "title": "BioE_Stats_2025_HW1 - EDA, t-test and Power Calculations",
    "section": "Problem 2 - Parametric t-test in R",
    "text": "Problem 2 - Parametric t-test in R\n\nUsing R to make a dummy data set that contains one continuous and one categorical value with two levels. To do so draw individuals of the two different factor levels from normal distributions (check the ‘norm’ family of functions) with slightly different means but equal standard deviations. Take 100 observations per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another (see below)\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level). How does the sample size affect the statistics?\nWhat if you run the test again and make the means of the categorical groups more dissimilar?\nWhat happens if you change the standard deviation of your normal distributions to be very small or very large?\nNow perform the t-test using the dataset provided in class and your own data for two variables."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#problem-3---a-priori-power-analyses-via-simulation",
    "href": "Homework_Folder/HW1_2025.html#problem-3---a-priori-power-analyses-via-simulation",
    "title": "BioE_Stats_2025_HW1 - EDA, t-test and Power Calculations",
    "section": "Problem 3 - a priori power analyses via simulation",
    "text": "Problem 3 - a priori power analyses via simulation\nYou have been asked by your colleagues to aid in the design of an experiment to determine how many mice might be needed to test the efficacy of a specific medical device on bone growth. The in vivo trials are expensive, and so the researchers would like your help to figure out how many mice are needed to achieve a reasonable level of precision. In particular, they are interested in both the number of microns that bones grow over a 3 month period, and whether mice that have the implant have a greater rate of growth than those that do not.\nTo help them, you should do a power analysis, and write up the results in a short, readable section. Your colleagues will be interested in the cost-precision tradeoff, so you should include graphical displays that convey both (a) how accurately the mean number microns of growth can be estimated, and (b) how likely it is that a real difference in mean between treated and control of a given, reasonable size will be detected (have a \\(p\\)-value less than 0.05), both as a function of sample size. I’m leaving it up to you precisely how to convey these things.\nI’d like you to do this power analysis using simulation: by using the computer to do the experiment in silico in the case where you know the truth, and seeing how close your estimates are to the truth. To do this, you’ll have to make some stuff up: for instance, plausible values for what the mean growth rate is, and what sort of mean difference between the treated and control that your colleagues might plausibly care about. You don’t have to do independent research to find good values, but you should discuss the choices you made. You will also have to decide what a good range of sample sizes is to display your results across. I’ll save you the burden of making one thing up: you can assume that the distribution of distances traveled is Poisson distributed, so you can simulate your fake surveys using the function rpois( ). Your final report for this section should be readable and not include visible code in the compiled version. However, you should explain clearly in words what you did to arrive at your answers.\nThe purposes of this section of the homework are to practice writing reports in Quarto markdown; doing simulation-based power analyses, and communicating results in plain language."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html",
    "href": "Lecture_Folder/Week3a.html",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#today-we-will",
    "href": "Lecture_Folder/Week3a.html#today-we-will",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Today we will",
    "text": "Today we will\n\nWrangle some data and explore it\nFoundations of probability\nSampling and point estimations\n\n\n\n\n\n\n\nNote\n\n\nHomeworks will be assigned this evening and be due in 2 weeks"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#key-dplyr-verbs",
    "href": "Lecture_Folder/Week3b.html#key-dplyr-verbs",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Key dplyr verbs",
    "text": "Key dplyr verbs\nThere are five key dplyr verbs that you need to learn.\n\nfilter: Filter (i.e. subset) observations (rows) based on their values.\n\nselect: Select (i.e. subset) variables (columns) by their names:\n\narrange: Arrange (i.e. reorder) rows based on their values.\n\nmutate: Create new columns.\n\nsummarise: Collapse multiple rows into a single summary value.1"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#filter-arrange-select",
    "href": "Lecture_Folder/Week3b.html#filter-arrange-select",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "filter(), arrange() & select()",
    "text": "filter(), arrange() & select()\n\nfilter(flights, month == 11 | month == 12)\n\n\narrange(flights, year, month, day)\n\n\nselect(flights, year)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#conditionals",
    "href": "Lecture_Folder/Week3b.html#conditionals",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "conditionals",
    "text": "conditionals\n\n== equals exactly\n&lt;, &lt;= is smaller than, is smaller than or equal to\n&gt;, &gt;=` is bigger than, is bigger than or equal to\n!= not equal to\n! NOT operator, to specify things that should be omitted\n& AND operator, allows you to chain two conditions which must both be met\n\\| OR operator, to chains two conditions when at least one should be met\n%in% belongs to one of the following (usually followed by a vector of possible values)\n\nThe AND (&) and the OR (|`) operators are also super useful when you want to separate data based on multiple conditions."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#mutate-transmutate",
    "href": "Lecture_Folder/Week3b.html#mutate-transmutate",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "mutate() & transmutate()",
    "text": "mutate() & transmutate()\n\nlibrary(nycflights23)\n\nmutate(flights,\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)\n\n\nflights %&gt;%\n  mutate(\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)\n\n\nflights_updated &lt;- flights %&gt;%\n  mutate(\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#group_by-summarize",
    "href": "Lecture_Folder/Week3b.html#group_by-summarize",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "group_by( ) & summarize( )",
    "text": "group_by( ) & summarize( )\nThis first function allows you to aggregate data by values of categorical variables\n\nby_day &lt;- group_by(flights, year, month, day)\n\nOnce you have done this aggregation, you can then calculate values (in this case the mean) of other variables split by the new aggregated levels of the categorical variable\n\nsummarise(by_day, delay = mean(dep_delay, na.rm = TRUE))\n\n\nNote - you can get a lot of missing values!\nThat’s because aggregation functions obey the usual rule of missing values:\n\nif there’s any missing value in the input, the output will be a missing value.\nfortunately, all aggregation functions have an na.rm argument which removes the missing values prior to computation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#other-dplyr-goodies",
    "href": "Lecture_Folder/Week3b.html#other-dplyr-goodies",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Other dplyr goodies",
    "text": "Other dplyr goodies\n\ngroup_by and ungroup: For (un)grouping. - Particularly useful with the summarise and mutate commands, as we’ve already seen.\n\nslice: Subset rows by position rather than filtering by values. - E.g. starwars %&gt;% slice(c(1, 5))\n\npull: Extract a column from as a data frame as a vector or scalar. - E.g. starwars %&gt;% filter(gender==\"female\") %&gt;% pull(height)\n\ncount and distinct: Number and isolate unique observations. - E.g. starwars %&gt;% count(species), or starwars %&gt;% distinct(species)\n\nYou could also use a combination of mutate, group_by, and n(), e.g. starwars %&gt;% group_by(species) %&gt;% mutate(num = n())."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#random-variables-probability",
    "href": "Lecture_Folder/Week3b.html#random-variables-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nProbability is the expression of belief in some future outcome\nA random variable can take on different values with different probabilities\nThe sample space of a random variable is the universe of all possible values\nThe sample space can be represented by a\n\nprobability mass distribution (discrete)\nprobability density function (PDF) (continuous)\nalgebra and calculus are used for each respectively\nprobabilities of a sample space always sum to 1.0\n\nHow does it make sense that a sample space will always sum to 1?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#bernoulli-distribution",
    "href": "Lecture_Folder/Week3b.html#bernoulli-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nDescribes the expected outcome of a single event with probability p\nExample of flipping of a fair coin once\n\n\\[Pr(X=\\text{Head}) = \\frac{1}{2} = 0.5 = p \\]\n\\[Pr(X=\\text{Tails}) = \\frac{1}{2} = 0.5 = 1 - p = q \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#bernoulli-distribution-1",
    "href": "Lecture_Folder/Week3b.html#bernoulli-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nIf the coin isn’t fair then \\(p \\neq 0.5\\)\nHowever, the probabilities still sum to 1\n\n\\[ p + (1-p) = 1 \\] \\[ p + q = 1 \\]\n\nSame is true for other binary possibilities\n\nsuccess or failure\nyes or no answers\nchoosing an allele from a population based upon allele frequencies (Hardy-Weinberg ring any bells??)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#probability-rules",
    "href": "Lecture_Folder/Week3b.html#probability-rules",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nFlip a coin twice\nRepresent the first flip as ‘X’ and the second flip as ‘Y’\n\n\\[ Pr(\\text{X=H and Y=H}) = p*p = p^2 \\] \\[ Pr(\\text{X=H and Y=T}) = p*q = pq = p^2 \\] \\[ Pr(\\text{X=T and Y=H}) = q*p = pq \\] \\[ Pr(\\text{X=T and Y=T}) = q*q = q^2 \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#probability-rules-1",
    "href": "Lecture_Folder/Week3b.html#probability-rules-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nProbability that the H and T can occur in any order\n\n\\[ \\text{Pr(X=H) or Pr(X=T)} = p+q=1\\]\n\\[ \\text{Pr(X=H and Y=T) or Pr(X=T and Y=H)} = \\] \\[ (p*q) + (p*q) = 2pq \\]\n\nThese are the ‘and’ and ‘or’ rules of probability\n\n‘and’ means multiply the probabilities\n‘or’ means sum the probabilities\nmost probability distributions can be built up from these simple rules"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips",
    "href": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\n# tossing a fair coin\ncoin &lt;- c(\"heads\", \"tails\")\n\nsample(coin)\n\n[1] \"heads\" \"tails\""
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips-1",
    "href": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\nWhat happens when we change the probabilities or the sample size? How confident are we that our coin is fair?\n\n\nflips &lt;- sample(coin, prob = c(0.5, 0.5), size=13, replace=TRUE)\nbarplot(table(flips))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#joint-probability",
    "href": "Lecture_Folder/Week3b.html#joint-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Joint probability",
    "text": "Joint probability\n\\[Pr(X,Y) = Pr(X) * Pr(Y)\\]\n\nNote that this is true for two independent events\nHowever, for two non-independent events we also have to take into account their covariance\nTo do this we need conditional probabilities"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#conditional-probability",
    "href": "Lecture_Folder/Week3b.html#conditional-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nFor two independent variables: Probability of Y, given X, or the probability of X, given Y.\n\n\\[Pr(Y|X) = Pr(Y)\\text{ and }Pr(X|Y) = Pr(X)\\]\n\nFor two non-independent variables\n\n\\[Pr(Y|X) \\neq Pr(Y)\\text{ and }Pr(X|Y) \\neq Pr(X)\\]\n\nVariables that are non-independent have a shared variance, which is also known as the covariance\nCovariance standardized to a mean of zero and a unit standard deviation is correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#expectation-and-moments-of-distributions",
    "href": "Lecture_Folder/Week3b.html#expectation-and-moments-of-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Expectation and Moments of Distributions",
    "text": "Expectation and Moments of Distributions\n\nDistributions have moments that can be estimated\n1st moment - The expectation or mean of a discrete random variable X is:\n\n\\[E[X] = \\sum_{\\text{all x}}^{}xP(X=x) = \\mu\\]\n\nOften we want to know how dispersed the random variable is around its mean.\n2nd moment - the measure of dispersion is the variance\n\n\\[Var(X) = E[X^2] = \\sigma^2\\] - and the standard deviation is just the square root of the variance\n\\[ \\sqrt{\\sigma^2}\\] - There are higher moments of distributions (e.g. skew and kurtosis)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-likelihood-vs.-probability",
    "href": "Lecture_Folder/Week3b.html#what-is-likelihood-vs.-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is Likelihood vs. Probability?",
    "text": "What is Likelihood vs. Probability?\n\nThe probability of an event is the proportion of times that the event would occur if we repeated a random trial over and over again under the same conditions.\nThe likelihood is a conditional probability of a parameter value given a set of data\nThe likelihood of a population parameter equaling a specific value, given the data\n\nL[parameter|data] = Pr[data|parameter]\n\nLikelihood function is the range of likelihoods over the parameter space\nMaximum likelihood is the highest value of the likelihood function\nWhat is a Bayesian estimate? - the use of prior distribution to update a posterior distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-distribution",
    "href": "Lecture_Folder/Week3b.html#binomial-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-distribution-1",
    "href": "Lecture_Folder/Week3b.html#binomial-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-probability-distribution",
    "href": "Lecture_Folder/Week3b.html#binomial-probability-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution\n\nNote that the binomial function incorporates both the ‘and’ and ‘or’ rules of probability\nThis part is the probability of each outcome (multiplication)\n\n\\[\\large p^{k} (1-p)^{n-k}\\]\nThis part (called the binomial coefficient) is the number of different ways each combination of outcomes can be achieved (summation)\n\\[\\large {n \\choose k}\\] Together they equal the probability of a specified number of successes"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-probability-distribution-1",
    "href": "Lecture_Folder/Week3b.html#binomial-probability-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-binomial-distributions",
    "href": "Lecture_Folder/Week3b.html#testing-binomial-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\ndbinom gives the density (probability) of number successes (x) in number trials (size), with (prob) probability between 0-1\n\n\n# dbinom(x=5, size=10, p=0.5)\n# 0.246\nplot(dbinom(x=1:10, size=10, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-binomial-distributions-1",
    "href": "Lecture_Folder/Week3b.html#testing-binomial-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\npbinom gives the cumulative probability of reaching at least (q) number of successes after (size) number of trials\n\n\nplot(pbinom(q=1:100, size=100, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in bioengineering is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500kb\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week3b.html#testing-poisson-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#geometric-distribution",
    "href": "Lecture_Folder/Week3b.html#geometric-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week3b.html#geometric-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week3b.html#testing-geometric-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\ndgeom(x=20, p=0.1)\n\n[1] 0.01215767\n\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week3b.html#testing-geometric-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581\n\nplot(pgeom(q=1:20, p=0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week3b.html#negative-binomial-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “ones” have appeared.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “one” appearing on the \\(k^{th}\\) trial:\n\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r-1}(1-p)^{k-r}p\\]\n\nwhich simplifies to\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r}(1-p)^{k-r}\\]\n\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week3b.html#negative-binomial-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#continuous-probability-distributions-1",
    "href": "Lecture_Folder/Week3b.html#continuous-probability-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Continuous probability distributions",
    "text": "Continuous probability distributions\nP(observation lies within dx of x) = f(x)dx\n\\[P(a\\leq X \\leq b) = \\int_{a}^{b} f(x) dx\\]\nRemember that the indefinite integral sums to one\n\\[\\int_{-\\infty}^{\\infty} f(x) dx = 1\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#continuous-probabilities",
    "href": "Lecture_Folder/Week3b.html#continuous-probabilities",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Continuous probabilities",
    "text": "Continuous probabilities\n\nE[X] may be found by integrating the product of x and the probability density function over all possible values of x:\n\\[E[X] = \\int_{-\\infty}^{\\infty} xf(x) dx \\]\n\n\\(Var(X) = E[X^2] - (E[X])^2\\), where the expectation of \\(X^2\\) is\n\\[E[X^2] = \\int_{-\\infty}^{\\infty} x^2f(x) dx \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#uniform-distribution",
    "href": "Lecture_Folder/Week3b.html#uniform-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\n\\[E[X] = \\int_{a}^{b} x\\frac{1}{b-a} dx = \\frac{(a+b)}{2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week3b.html#uniform-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#uniform-distribution-2",
    "href": "Lecture_Folder/Week3b.html#uniform-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#exponential-distribution",
    "href": "Lecture_Folder/Week3b.html#exponential-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\n\\[f(x)=\\lambda e^{-\\lambda x}\\]\n\n\nE[X] can be found be integrating \\(xf(x)\\) from 0 to infinity\n\n\n\nleading to the result that\n\n\n\n\\(E[X] = \\frac{1}{\\lambda}\\)\n\\(E[X^2] = \\frac{1}{\\lambda^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week3b.html#exponential-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#exponential-distribution-2",
    "href": "Lecture_Folder/Week3b.html#exponential-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\ndexp(10, rate = 0.1)\n\n[1] 0.03678794\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#gamma-distribution",
    "href": "Lecture_Folder/Week3b.html#gamma-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\) :\n\n\n\\[f(x) = \\frac{e^{-\\lambda x}\\lambda x^{r-1}}{(r-1)!}\\lambda\\]\n\n\\[ Mean =  \\frac{r}{\\lambda} \\] \\[ Variance = \\frac{r}{\\lambda^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week3b.html#gamma-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber.\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#common-theme-in-r-for-distributions",
    "href": "Lecture_Folder/Week3b.html#common-theme-in-r-for-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Common theme in R for distributions",
    "text": "Common theme in R for distributions\n\n\n\n\n\n\n\n\n\n\n\nd\nprobability mass function\np\ncumulative distribution\nq\nquantile function\nr\npseudorandom number generate\n\n\n\n\nbinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\npoisson\ndpois\nppois\nqpois\nrpois\n\n\nexponential\ndexp\npexp\nqexp\nrexp\n\n\nnormal\ndnorm\npnorm\nqnorm\nrnorm"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "href": "Lecture_Folder/Week3b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Normal (aka Gaussian) | Probability Density Function (PDF)",
    "text": "The Normal (aka Gaussian) | Probability Density Function (PDF)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf",
    "href": "Lecture_Folder/Week3b.html#normal-pdf",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf-a-function-of-two-parameters",
    "href": "Lecture_Folder/Week3b.html#normal-pdf-a-function-of-two-parameters",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF | A function of two parameters",
    "text": "Normal PDF | A function of two parameters\n(\\(\\mu\\) and \\(\\sigma\\))\n\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\epsilon \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf-estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week3b.html#normal-pdf-estimates-of-mean-and-variance",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF | estimates of mean and variance",
    "text": "Normal PDF | estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have a mean of 0 and a standard deviation of 1\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf-1",
    "href": "Lecture_Folder/Week3b.html#normal-pdf-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences",
    "href": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-1",
    "href": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-2",
    "href": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week3b.html#parent-offspring-resemblance",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week3b.html#genetic-model-of-complex-traits",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week3b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week3b.html#why-else-is-the-normal-special",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nIt is the basis of estimation and precision of the expected value of all distributions\nProvides a mathematical basis for moving from single samples to point estimates.\nProvides a way to use simulation to generate empirical sample and test distributions through Monte Carlo approaches"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#understanding-populations-and-their-parameters",
    "href": "Lecture_Folder/Week3b.html#understanding-populations-and-their-parameters",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Understanding Populations and their Parameters",
    "text": "Understanding Populations and their Parameters\n\nWe often think about the samples we are collecting as a part of a larger population\nSince we can’t measure every member of that population, we instead use sampling to estimate the parameters of the population as a whole\n\nSome common parameters: mean, range, median\nIf we performed random sampling, we assume that the parameter estimates of our sample are equitable to the true population parameters"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#accuracy-vs.-precision",
    "href": "Lecture_Folder/Week3b.html#accuracy-vs.-precision",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#accuracy-vs.-precision-1",
    "href": "Lecture_Folder/Week3b.html#accuracy-vs.-precision-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision\n\nAccuracy is the closeness of an estimated value to its true value\nPrecision is the closeness of repeated estimates to one another\nOur goal is to have unbiased estimates that are the most precise\nWe have to estimate parameters and test hypotheses by taking samples that approximate the underlying distribution\nThe goal of replication is to quantify variation at as many levels in a study as possible\nThe goal of randomization is to avoid bias as much as possible"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#parameter-estimation",
    "href": "Lecture_Folder/Week3b.html#parameter-estimation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nParametric (a few special exceptions, like the sample mean and its standard error)\nOrdinary Least Squares (OLS) - optimized procedure that produces one definitive result, easy to use but no estimates of confidence\nResampling - bootstrapping and randomization\nMaximum Likelihood (ML) - Can provide model-based estimates with confidence, but harder to calculate\nBayesian Approaches - Incorporates prior information into ML estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation",
    "href": "Lecture_Folder/Week3b.html#estimation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation",
    "text": "Estimation\n\nEstimation is the process of inferring a population parameter from sample data\nThe value of one sample estimate is almost never the same as the population parameter because of random sampling error\nMost will be close, but some will be far away\nSampling distribution of an estimate\n\nall values we might have obtained from our sample\nprobabilities of occurrence\n\nStandard error of an estimate\n\nstandard deviation of a sampling distribution\nmeasures the precision of the parameter estimate\nNO ESTIMATE IS USEFUL WITHOUT IT!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-central-limit-theorem-1",
    "href": "Lecture_Folder/Week3b.html#the-central-limit-theorem-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculating-the-standard-error",
    "href": "Lecture_Folder/Week3b.html#calculating-the-standard-error",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculating-the-standard-error-1",
    "href": "Lecture_Folder/Week3b.html#calculating-the-standard-error-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 50))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.04635888"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals",
    "href": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-1",
    "href": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-2",
    "href": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\\[\\huge \\sigma_{\\bar{x}} \\approx s_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\]\n\nwhere \\(s_{\\bar{x}}\\) is the estimated standard error of the distribution of the mean estimates\nwhich is usually just referred to as the ’standard error of the mean (SEM)\nnote that this is not the standard deviation of the original distribution\nimportantly, the SEM will go down as the sample size increases"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem-1",
    "href": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\nSadly, most other kinds of estimates of other parameters do not have this amazing property.\nWhat to do?\nOne answer: make your own sampling distribution for the estimate using the “bootstrap”.\nMethod invented by Efron (1979)."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#loops-in-r",
    "href": "Lecture_Folder/Week3b.html#loops-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Loops in R",
    "text": "Loops in R\n\nR is very good at performing repetitive tasks.\nIf we want a set of operations to be repeated several times we use what’s known as a loop.\nWhen you create a loop, R will execute the instructions in the loop a specified number of times or until a specified condition is met.\nThere are two common types of loop in R: the for loop and the while loop"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#for-loops",
    "href": "Lecture_Folder/Week3b.html#for-loops",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "For loops",
    "text": "For loops\n\nThe most commonly used loop structure when you want to repeat a task a defined number of times is the for loop. The most basic example of a for loop is:\nHow does this appear to be working?\n\n\n# Notice the sequence of parentheses and brackets used in this example\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#while-loops",
    "href": "Lecture_Folder/Week3b.html#while-loops",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "While loops",
    "text": "While loops\n\nAnother type of loop that you may use is the while loop.\nThe while loop is used when you want to keep looping until a specific logical condition is satisfied.\n\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n  i &lt;- i + 1\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#if-and-else-statements",
    "href": "Lecture_Folder/Week3b.html#if-and-else-statements",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "If and Else Statements",
    "text": "If and Else Statements\n\nConditional statements are how you inject some logic into your code.\nThe most commonly used conditional statement is if.\n\nWhenever you see an if statement, read it as ‘If X is TRUE, then do a thing’.\n\nAnother statement is else, which extends the logic to ‘If X is TRUE, do a thing, or else do something different’."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-programming-joke-for-conditional-statements",
    "href": "Lecture_Folder/Week3b.html#a-programming-joke-for-conditional-statements",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A programming joke for conditional statements",
    "text": "A programming joke for conditional statements\nA programmer’s partner says: ‘Please go to the store and buy a carton of milk and if they have eggs, get six.’\nThe programmer returned with 6 cartons of milk.\nWhen the partner sees this, and exclaims ‘Why the heck did you buy six cartons of milk?’\nThe programmer replied ‘They had eggs’\n\neggs &lt;- TRUE # Whether there were eggs in the store\n\n  if (eggs == TRUE) { # If there are eggs\n  n.milk &lt;- 6 # Get 6 cartons of milk\n    } else { # If there are not eggs\n  n.milk &lt;- 1 # Get 1 carton of milk\n  }"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-simulate-a-population-and-sample-it",
    "href": "Lecture_Folder/Week3b.html#r-interlude-simulate-a-population-and-sample-it",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Simulate a population and sample it!",
    "text": "R INTERLUDE | Simulate a population and sample it!\nSimulate a population of 10,000 individual values for a variable x:\n\nx &lt;- rnorm(10000, mean=50.5, sd=5.5) \n\nTake 1000 random samples of size 20, take the mean of each sample, and plot the distribution of these 1000 sample means.\n\nx_sample_means &lt;- NULL\nfor(i in 1:1000){\nx_samp &lt;- sample(x, 20, replace=FALSE)\nx_sample_means[i] &lt;- mean(x_samp)\n}\n\nFor one of your samples, use the equation from the previous slide to transform the values to z-scores.\nPlot the distribution of the z-scores, and calculate the mean and the standard deviation."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#simulations-to-compare-parameter-estimates-1",
    "href": "Lecture_Folder/Week3b.html#simulations-to-compare-parameter-estimates-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Simulations to compare parameter estimates",
    "text": "Simulations to compare parameter estimates\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nhist(true_pop, xlim = c(0,16))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculating-parameters",
    "href": "Lecture_Folder/Week3b.html#calculating-parameters",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?\n\n\nmean(true_pop)\n\n[1] 4.927\n\nrange(true_pop)\n\n[1]  0 13\n\nmedian(true_pop)\n\n[1] 5\n\n\n\nhow about the variance and the standard deviation?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-exercise",
    "href": "Lecture_Folder/Week3b.html#sampling-exercise",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#test-it-out",
    "href": "Lecture_Folder/Week3b.html#test-it-out",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nprint(sd(true_pop))\n\n[1] 2.24649"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week3b.html#randomness-in-sampling",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\n\n\nFALSE  TRUE \n   17    33"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-2",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-distributions---its-been-normal-this-whole-time",
    "href": "Lecture_Folder/Week3b.html#sampling-distributions---its-been-normal-this-whole-time",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Distributions - It’s been Normal this whole time?!",
    "text": "Sampling Distributions - It’s been Normal this whole time?!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-exercise-1",
    "href": "Lecture_Folder/Week3b.html#sampling-exercise-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-exercise-2",
    "href": "Lecture_Folder/Week3b.html#sampling-exercise-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nsample1 &lt;- sample(true_pop, size = 20)\nhist(sample1,  xlim =  c(0,16))\n\nprint(c(\"Mean: \", mean(sample1))) \n\n[1] \"Mean: \" \"5.15\"  \n\nprint(c(\"Range: \", range(sample1)))\n\n[1] \"Range: \" \"1\"       \"12\""
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#randomness-in-sampling-1",
    "href": "Lecture_Folder/Week3b.html#randomness-in-sampling-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-3",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-4",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\ntable(samps_var_means &gt; 4.5 & samps_var_means &lt; 5.5)\n\n\nFALSE  TRUE \n   27    23"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-5",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-etymology-of-the-term-bootstrap",
    "href": "Lecture_Folder/Week3b.html#the-etymology-of-the-term-bootstrap",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The etymology of the term ‘bootstrap’",
    "text": "The etymology of the term ‘bootstrap’"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-the-bootstrap-is-good",
    "href": "Lecture_Folder/Week3b.html#why-the-bootstrap-is-good",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why the bootstrap is good",
    "text": "Why the bootstrap is good\n\nCan be applied to almost any sample statistic\n\nThis includes means, proportions, correlations, regression\n\nWorks when there is no ready formula for a standard error\n\nFor example the median, trimmed mean, correlation, eigenvalue, etc.\n\nIs nonparametric, so doesn’t require normally-distributed data\nWorks for estimates based on complicated sampling procedures or calculations\n\nFor example, it is used in phylogeny estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#parameter-estimation-bootstrap-algorithm",
    "href": "Lecture_Folder/Week3b.html#parameter-estimation-bootstrap-algorithm",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Parameter Estimation | Bootstrap Algorithm",
    "text": "Parameter Estimation | Bootstrap Algorithm\n\nUse R to take a random sample of individuals from the original data\nCalculate the estimate using the measurements in the bootstrap sample (step 1)\nThis is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3\nThe resulting quantity is called the bootstrap standard error"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "href": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\nx &lt;- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 1.6, 2.0, 2.0)\n\nUse R to make 1000 “pseudo-samples” of size 10 (with replacement), using a for loop as before.\nName the pseudo-sample object “xboot”, and name the means of the xboot samples “z”.\nPlot the histogram of the resampled means, and calculate the standard deviation of the sample means (the bootstrap SEM) using the sd() function.\nHow does it compare with the ordinary standard error of the mean calculated from the original, real sample?\n\nsd(x)/sqrt(10)\n\nNow take one of the genes from the GacuRNAseq_Subset.csv data and obtain a bootstrapped estimate of the mean expression level."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\n\nThe 2.5th and 97.5th percentiles of the bootstrap sampling distribution are a passable 95% confidence interval\nNote that no transformations or normality assumptions needed\nYou can use the quantile() function to calculate these\nOn your own - use R to figure out the bootstrap distribution for other parameters (such as variance).\n\n-_____________"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week3b.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#bootstrapping-1",
    "href": "Lecture_Folder/Week3b.html#bootstrapping-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned. - - It works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#confidence-intervals",
    "href": "Lecture_Folder/Week3b.html#confidence-intervals",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week3b.html#coefficient-of-variation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\n\nA statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models\n\nThis is where statistical sampling distributions come into play\nStatistical distributions are built upon sampling distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\n\nStatistical tests provide a way to perform critical tests of hypotheses\nJust like raw data, statistics are random variables and depend on sampling distributions of the underlying data\nThe particular form of the statistical distribution depends on the test statistic and parameters such as the degrees of freedom that are determined by sample size."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-1",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data\nThen see how probable it was by comparing against the null distribution\nThe probability of seeing that value or greater is called the p-value of the statistic"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#four-common-statistical-distributions",
    "href": "Lecture_Folder/Week3b.html#four-common-statistical-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\[\\large t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests",
    "href": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors",
    "href": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\n\\(\\alpha\\) = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\n\\(\\beta\\) = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power",
    "href": "Lecture_Folder/Week3b.html#statistical-power",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know",
    "href": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | the things one needs to know",
    "text": "Power | the things one needs to know\n\n\\[ Power \\propto \\frac{(ES)(\\alpha)(\\sqrt n)}{\\sigma}\\]\n\nPower is proportional to the combination of these parameters\n\nES - effect size; how large is the change of interest?\n\\(\\alpha\\) - significance level (usually 0.05)\nn - sample size\n\\(\\sigma\\) - standard deviation among experimental units within the same group."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know",
    "href": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | what we usually want to know",
    "text": "Power | what we usually want to know"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-rough-calculation",
    "href": "Lecture_Folder/Week3b.html#power-rough-calculation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | rough calculation",
    "text": "Power | rough calculation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-complete-exercises-3.2-3.4",
    "href": "Lecture_Folder/Week3b.html#r-interlude-complete-exercises-3.2-3.4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R Interlude | Complete Exercises 3.2-3.4",
    "text": "R Interlude | Complete Exercises 3.2-3.4"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-1",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\nalpha = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\nbeta = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "href": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nMake a dummy data set that contains one continuous and one categorical value (with two levels). Draw individuals of the two different factor levels from normal distributions with slightly different means. Take 100 obsv. per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level)\nRepeat steps 1 and 2 above but now test between a categorical and continuous variable in the perchlorate data set (or any of your favorite data sets)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nNow, apply the equations for the t-statistic above to your simulated sample to perform the same test, but using a resampling approach\n\nhint: go back to your Bootstrapping script\n\nUse this approach to calculate a distribution of random t statistics assuming the the null hypothesis of no difference is true.\nNow, compare your observed value to your created null distribution.\nWhat is the probability of that value occurring by chance under the null?\n\nThis is your p-value! (Assume you’re doing a one-tailed test)\nhint: Proportion of values in the null distribution equal to or larger than the observed t-value = p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nRandomization test example 1\nData: The number of successful broods of pseudoscorpion females that were mated twice to either a single male (SM) or two different males (DM).\n\nSM: 4 0 3 1 2 3 4 2 4 2 0 2 0 1 2 6 0 2 3 3\nDM: 2 0 2 6 4 3 4 4 2 7 4 1 6 3 6 4\n\nObserved difference in the means between the two\n\n\\(\\bar{Y}_{SM}\\) − \\(\\bar{Y}_{DM}\\) = 2.2−3.625 = −1.425"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nSteps of the randomization test\nFirst, create a randomized data set in which the measurements are randomly reassigned (without replacement) to the two groups\n\nFor example, the following\nSM: 4 0 7 4 2 2 2 1 4 4 0 3 3 4 6 2 4 6 0 0\nDM: 2 2 3 3 2 3 3 4 1 2 1 4 6 6 2 0\n\nSecond, calculate the test statistic measuring the association between variables\n\ndifference between group means\nthis is the first bootstrap replicate\n\nRepeat steps 1 and 2 many times to produce many bootstrap replicates"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-2",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nBelow is the null distribution of the test statistic from 10,000 replications\n\nThis is produced by the randomized assignment of values to each group (SM or DM)\nThus this is the distribution we’d expect under the null hypothesis of no difference\n\nThe observed value from the data is –1.425\nThe area in red is the tail beyond this observed value and is therefore the bootstrap p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-3",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nOf these 10,000 randomizations, only 176 had a test statistic (difference between means) equal to or less than the observed value, –1.425.\nYou can use the simulated null distribution in the same way as t or F distribution in conventional tests.\nProportion of values in the null distribution equal or larger than the observed value of the test statistic is 176/10000 = 0.0176."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power",
    "href": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nRead in the perchlorate data again\nPerform an ANOVA to test Strain on T4_Hormone_Level, but log-transform (base 10) the T4 variable\n\n\nperc &lt;- read.table('perchlorate_data.tsv', header=T, sep='\\t')\nx &lt;- perc$Strain\ny &lt;- log10(perc$T4_Hormone_Level)\n\nMyANOVA &lt;- aov(y ~ x)\nsummary (MyANOVA)\nboxplot(y ~ x)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nConsider the parameters of this test related to power:\n\nThe per-group sample sizes\nThe standard deviation (use the higher within-group sd)\nThe effect size (|difference between means| / within-grp sd)\n\nFor more complex ANOVA power calculations (&gt;2 groups):\n\nThe total variance\nThe within-group variance (use the higher one)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "href": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\nBased on your results, calculate the power for your ANOVA.\n\n   pwr.t2n.test(n1=xxx, n2=xxx, d=xxx, sig.level=.05, power=NULL)\n\nCheck out the functions in the ‘pwr’ library (Unnecessary in this case, but could use ANOVA version):\n\n   pwr.anova.test(k=2, n=190, f=0.25, sig.level=.05, power=NULL)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\neffect size approximations:\n\nf=0.1 (small)\nf=0.25 (medium)\nf=0.4 (large)\n\nsee http://www.statmethods.net/stats/power.html"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "href": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\nLet’s say you have to repeat the experiment, but your IACUC wants you to get by by using fewer fish.\nYou want to be able to detect a minimum mean difference of 1.3 T4 units (about 0.114 on the log10 scale), at a power of 90%.\nFirst, divide 0.114 by std.dev. of transformed WK values (the higher std. dev. of the two groups) to get a conservative “d”.\nWhat kind of sample size for the WK group would you need???\n(Again use the pwr.t2n.test() function, but this time specify the WK sample size as the unknown parameter)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-1",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\nA statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models\n\nThis is where statistical sampling distributions come into play"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests-1",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height on average as Douglas fir trees"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests-2",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-1",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-2",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-2",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nStatistical tests provide a way to perform critical tests of hypotheses\nJust like raw data, statistics are random variables and depend on sampling distributions of the underlying data\nThe particular form of the statistical distribution depends on the test statistic and parameters such as the degrees of freedom that are determined by sample size."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-3",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data\nThen see how probable it was by comparing against the null distribution\nThe probability of seeing that value or greater is called the p-value of the statistic"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-1",
    "href": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-1",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\[H_0 : \\mu_1 = \\mu_2\\]\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height as Douglas fir trees\n\\[H_A : \\mu_1 \\neq \\mu_2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-2",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\[\\huge t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | under different degrees of freedom",
    "text": "The t-test and t sampling distribution | under different degrees of freedom"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one tailed test",
    "text": "The t-test and t sampling distribution | one tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two tailed test",
    "text": "The t-test and t sampling distribution | two tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-1",
    "href": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-1",
    "href": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-2",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\nalpha = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\nbeta = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-1",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "href": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-2",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nMake a dummy data set that contains one continuous and one categorical value (with two levels). Draw individuals of the two different factor levels from normal distributions with slightly different means. Take 100 obsv. per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level)\nRepeat steps 1 and 2 above but now test between a categorical and continuous variable in the perchlorate data set (or any of your favorite data sets)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-3",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nNow, apply the equations for the t-statistic above to your simulated sample to perform the same test, but using a resampling approach\n\nhint: go back to your Bootstrapping script\n\nUse this approach to calculate a distribution of random t statistics assuming the the null hypothesis of no difference is true.\nNow, compare your observed value to your created null distribution.\nWhat is the probability of that value occurring by chance under the null?\n\nThis is your p-value! (Assume you’re doing a one-tailed test)\nhint: Proportion of values in the null distribution equal to or larger than the observed t-value = p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-4",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nRandomization test example 1\nData: The number of successful broods of pseudoscorpion females that were mated twice to either a single male (SM) or two different males (DM).\n\nSM: 4 0 3 1 2 3 4 2 4 2 0 2 0 1 2 6 0 2 3 3\nDM: 2 0 2 6 4 3 4 4 2 7 4 1 6 3 6 4\n\nObserved difference in the means between the two\n\n\\(\\bar{Y}_{SM}\\) − \\(\\bar{Y}_{DM}\\) = 2.2−3.625 = −1.425"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-5",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nSteps of the randomization test\nFirst, create a randomized data set in which the measurements are randomly reassigned (without replacement) to the two groups\n\nFor example, the following\nSM: 4 0 7 4 2 2 2 1 4 4 0 3 3 4 6 2 4 6 0 0\nDM: 2 2 3 3 2 3 3 4 1 2 1 4 6 6 2 0\n\nSecond, calculate the test statistic measuring the association between variables\n\ndifference between group means\nthis is the first bootstrap replicate\n\nRepeat steps 1 and 2 many times to produce many bootstrap replicates"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-6",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-6",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nBelow is the null distribution of the test statistic from 10,000 replications\n\nThis is produced by the randomized assignment of values to each group (SM or DM)\nThus this is the distribution we’d expect under the null hypothesis of no difference\n\nThe observed value from the data is –1.425\nThe area in red is the tail beyond this observed value and is therefore the bootstrap p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-7",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-7",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nOf these 10,000 randomizations, only 176 had a test statistic (difference between means) equal to or less than the observed value, –1.425.\nYou can use the simulated null distribution in the same way as t or F distribution in conventional tests.\nProportion of values in the null distribution equal or larger than the observed value of the test statistic is 176/10000 = 0.0176."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-2",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nWe can compare estimated parameters, while also including measures of uncertainty, using frequentist methods\nRequires statistical hypotheses: a statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-3",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nThis is where statistical sampling distributions come into play\n\nStatistical distributions are built upon sampling distributions\nWill tell us how “frequently” we expect to see a result as extreme as ours"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and Alternative Hypotheses",
    "text": "Null and Alternative Hypotheses\n\nBecause of the nature of logic and deduction, we can never prove a positive\n\nHave we really observed all possible circumstances that could disprove our hypothesis?\n\nBut we can reject a hypothesis based on our observations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-1",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and Alternative Hypotheses",
    "text": "Null and Alternative Hypotheses\n\nEasiest examples: we want to know if two populations differ from one another\n\nWe make a simple statement, for example, “I hypothesize that on average the variable X differs between the treatment and control groups.”\nWe can make an opposite statement: “I hypothesize that on average the variable X does not differ between the treatment and control groups.”\n\nNow we have our null hypothesis and alternative hypothesis"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-2",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses",
    "text": "Null and alternative hypotheses\n\nThink on the work you are doing: rotation project, dissertation aim, etc.\nDoes your question have a null and alternative hypothesis?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests-3",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-3",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions\n\nWhich scenario do you think will be easier to find a difference?\nWhat factor(s) will make our statistical tests better?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-5",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data.\nThen see how probable it was by comparing against the null distribution.\nThe probability of seeing that value or greater is called the p-value of the statistic."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-6",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-6",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nAn example of a test statistic is the t-statistic.\nThe t-statistic is a standardized difference between two sample means\n\nt = 0 indicates no difference between population means\nt-distribution is Normal, with the center and peak at 0\n\nWe can evaluate the t-statistic for our sample data and see whether it falls far enough away from zero - then we reject the null hypothesis"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-2",
    "href": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-distributions",
    "href": "Lecture_Folder/Week3b.html#statistical-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical Distributions",
    "text": "Statistical Distributions\n\nThe shape and associated parameters of a distribution used to evaluate a test statistic also depend on sample properties such as sample size.\nDegrees of freedom are also an important parameter for critical tests."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-tangent-on-degrees-of-freedom",
    "href": "Lecture_Folder/Week3b.html#a-tangent-on-degrees-of-freedom",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A tangent on degrees of freedom",
    "text": "A tangent on degrees of freedom\n\nIn statistics, degrees of freedom refers to the number of values in a calculation that are free to vary.\nExample: you have a set of numbers, like 1, 2, 3, and 4. If you know the average (mean) of these numbers is 3, you can actually choose three of the numbers freely, but the fourth number will be determined by the other three. So in this case, you have three degrees of freedom.\nThis answer comes from ChatGPT!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#degrees-of-freedom-exercise",
    "href": "Lecture_Folder/Week3b.html#degrees-of-freedom-exercise",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Degrees of freedom exercise",
    "text": "Degrees of freedom exercise\n\nTry out this concept in R\n\nRandomly sample from a list of numbers (1-10) 5 numbers\nCalculate the mean for that group of numbers\nIf you were to add a sixth number, what would it have to be for the mean to = 7?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "href": "Lecture_Folder/Week3b.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "On a scale of Murica to 10, how many degrees of freedom do you have?",
    "text": "On a scale of Murica to 10, how many degrees of freedom do you have?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-2",
    "href": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-2",
    "href": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-4",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power-1",
    "href": "Lecture_Folder/Week3b.html#statistical-power-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know-1",
    "href": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | the things one needs to know",
    "text": "Power | the things one needs to know\n\n\\[ Power \\propto \\frac{(ES)(\\alpha)(\\sqrt n)}{\\sigma}\\]\n\nPower is proportional to the combination of these parameters\n\nES - effect size; how large is the change of interest?\n\\(\\alpha\\) - significance level (usually 0.05)\nn - sample size\n\\(\\sigma\\) - standard deviation among experimental units within the same group."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know-1",
    "href": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | what we usually want to know",
    "text": "Power | what we usually want to know"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-4",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\nTo calculate the t-statistic for two populations:\n\n\\[\\large t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere s is the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-2",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-2",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-2",
    "href": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-try-it-out",
    "href": "Lecture_Folder/Week3b.html#lets-try-it-out",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nUse the below code to set up two simulated populations:"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-try-it-out-1",
    "href": "Lecture_Folder/Week3b.html#lets-try-it-out-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "LEt’s try it out",
    "text": "LEt’s try it out"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#first-is-the-distributionspread-the-same",
    "href": "Lecture_Folder/Week3b.html#first-is-the-distributionspread-the-same",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "First, is the distribution/spread the same?",
    "text": "First, is the distribution/spread the same?\n\nUse the function var.test() in R\nHow do we interpret this?\n\n\n\n\n    F test to compare two variances\n\ndata:  pop1 and pop2\nF = 0.8257, num df = 99, denom df = 99, p-value = 0.3423\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5555635 1.2271791\nsample estimates:\nratio of variances \n         0.8256973"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#now-for-the-t-test",
    "href": "Lecture_Folder/Week3b.html#now-for-the-t-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Now for the t-test!",
    "text": "Now for the t-test!\n\nUse the function t.test() in R\nHow do we interpret this? How would you write this conclusion as a sentence?\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  pop1 and pop2\nt = -41.396, df = 196.21, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.075616 -2.795896\nsample estimates:\nmean of x mean of y \n 2.035190  4.970946"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#mann-whitney-wilcoxon-tests",
    "href": "Lecture_Folder/Week3b.html#mann-whitney-wilcoxon-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Mann-Whitney-Wilcoxon Tests",
    "text": "Mann-Whitney-Wilcoxon Tests\n\nThe Mann-Whitney U (also called “Mann-Whitney-Wilcoxon) Test tests for distributional differences between the ranks of two samples.\nIn R the function wilcox.test() can be used to perform it, in much the same way the t.test() function is used."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-try-it-out-2",
    "href": "Lecture_Folder/Week3b.html#lets-try-it-out-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#test-the-variance",
    "href": "Lecture_Folder/Week3b.html#test-the-variance",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Test the variance",
    "text": "Test the variance\n\nUse the function we used before to see if the variance is the same or different between pop1 and pop2\nHow do we interpret this?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-mann-whit-u-test",
    "href": "Lecture_Folder/Week3b.html#the-mann-whit-u-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nUse the function wilcox.test() in R to compare pop1 and pop2\nHow do we interpret that result? How would you write it as a sentence for a paper?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-mann-whit-u-test-1",
    "href": "Lecture_Folder/Week3b.html#the-mann-whit-u-test-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  pop1 and pop2\nW = 440, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-2",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values\n\nWe can also create a null statistical distribution that models the distribution of a test statistic under the null hypothesis\nTo create the null distribution we can use either randomization or resampling"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#creating-a-null-distribution-through-randomization",
    "href": "Lecture_Folder/Week3b.html#creating-a-null-distribution-through-randomization",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Creating a null distribution through randomization",
    "text": "Creating a null distribution through randomization\n\nCombine values from both populations into a single vector\nRandomly shuffle the vector using the sample() function\nCalculate a t statistic based on the first n1 and n2 observations as our “pseudo samples” from “populations” 1 and 2, respectively, and save the value\nRepeat steps 2 and 3 many times (e.g. 1000)\nCalculate the proportion of pseudo replicates in which t is ≥ to our original, observed value of t. This proportion is our estimated p-value for the test."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-do-it---the-starting-populations",
    "href": "Lecture_Folder/Week3b.html#lets-do-it---the-starting-populations",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s do it - the starting populations",
    "text": "Let’s do it - the starting populations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculate-the-t-test",
    "href": "Lecture_Folder/Week3b.html#calculate-the-t-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculate the t-test",
    "text": "Calculate the t-test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "href": "Lecture_Folder/Week3b.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Combine the populations, sample from that, and calculate t-tests",
    "text": "Combine the populations, sample from that, and calculate t-tests"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#plot-the-null-distribution",
    "href": "Lecture_Folder/Week3b.html#plot-the-null-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Plot the null distribution",
    "text": "Plot the null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-3",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#whats-our-result",
    "href": "Lecture_Folder/Week3b.html#whats-our-result",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What’s our result?",
    "text": "What’s our result?\n\nHow do we interpret this?\n\n\n\n[1] 0.016"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#today-were-going-to",
    "href": "Lecture_Folder/Week3b.html#today-were-going-to",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Today we’re going to",
    "text": "Today we’re going to\n\nPractice some more with exploratory data analysis and hypothesis testing\nRun through an example of a power analysis"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-brief-note-on-problem-sets",
    "href": "Lecture_Folder/Week3b.html#a-brief-note-on-problem-sets",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A Brief Note on Problem Sets",
    "text": "A Brief Note on Problem Sets\n\nYour next problem set has you analyzing some of my own data, since most of you did not have data of your own yet\nWe’re going to get you started on that today!\nOn the problem set you turned in today, I asked whether you would prefer to re-do an old assignment or have a new assignment as your final Problem Set - with mixed results!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#part-1-exploratory-data-analysis",
    "href": "Lecture_Folder/Week3b.html#part-1-exploratory-data-analysis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Part 1 Exploratory Data Analysis",
    "text": "Part 1 Exploratory Data Analysis\n\nFor this assignment, you will use the data set, “Mostoufi2022_Recombination”, available in the Problem Set 5 directory.\nFrom: Mostoufi, S. L., & Singh, N. D. (2022). Diet-induced changes in titer support a discrete response of Wolbachia-associated plastic recombination in Drosophila melanogaster. G3 (Bethesda, Md.), 12(1), jkab375. https://doi.org/10.1093/g3journal/jkab375"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-background",
    "href": "Lecture_Folder/Week3b.html#the-background",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Background",
    "text": "The Background\n\nWe tested how Wolbachia, diet, and Wolbachia concentration (titer) affected recombination\nGroup levels: Wolbachia infected and uninfected; control, sucrose-enriched, and yeast-enriched diets; and interactions between infection and diet to change bacterial titer"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#recombination",
    "href": "Lecture_Folder/Week3b.html#recombination",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Recombination",
    "text": "Recombination\n\nMeasured recombination rate using classic backcrossing scheme with visible markers across the yellow-vermillion interval of the X chromosome\nCompare “recombinants” to total offspring per vial\n\n\\[ RF = \\frac{Recombinants}{Total} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-take-a-look",
    "href": "Lecture_Folder/Week3b.html#lets-take-a-look",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s take a look",
    "text": "Let’s take a look\n\nOpen up the appropriate file in either R or Excel and take a look at it\nCan you identify what each column indicates?\n\nParentals: wild type or yellow-vermillion\nRecombinants: yellow or vermillion only"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations",
    "href": "Lecture_Folder/Week3b.html#some-calculations",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nCreate a “Parental” column by adding up the “wild wild” (++) and “yellow vermillion” (yv) columns for each row. Print out the first 3 rows of the data set to show that your calculations worked. (9pts)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-1",
    "href": "Lecture_Folder/Week3b.html#some-calculations-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nCreate a “Recombinant” column by adding up the “yellow wild” and “wild vermillion” columns for each row. Print out the first 3 rows of the data set to show that your calculations worked. (9pts)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-2",
    "href": "Lecture_Folder/Week3b.html#some-calculations-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nCreate a “RecombinantFraction” column by dividing the “Recombinant” column by the sum of the Parental and Recombinant columns. Print out the first 3 rows of the data set to show that your calculations worked. (10pts)\n\n\\[ RF = \\frac{Recombinants}{Total} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-3",
    "href": "Lecture_Folder/Week3b.html#some-calculations-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nUsing an R command, determine whether the variance of RecombinantFraction of the Wolbachia infected and uninfected groups are approximately equal. (10 pts)\n\n\nA good first step would be to plot the values for each group (Part 2 from homework)\nWhat are you measuring? What are the groups?\nWhat plot would you use? How would you describe the disribution of the data?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-4",
    "href": "Lecture_Folder/Week3b.html#some-calculations-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nWhat are you measuring? What are the groups? What R command should you use?\nHow do you interpret this result?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-5",
    "href": "Lecture_Folder/Week3b.html#some-calculations-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nDepending on your results in 1.5, use the appropriate statistical test to evaluate the difference in the means of RecombinantFraction between the Wolbachia-infected and uninfected groups. (20 pts)\nBased on your results in 1.6, write a description of your analysis results in 1-2 complete sentences. (10 pts)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-power-analysis",
    "href": "Lecture_Folder/Week3b.html#what-is-a-power-analysis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a power analysis?",
    "text": "What is a power analysis?\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power-2",
    "href": "Lecture_Folder/Week3b.html#statistical-power-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power-3",
    "href": "Lecture_Folder/Week3b.html#statistical-power-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?\n\nSample size\nEffect size (difference between the groups)\nVariance (range of values for this trait/measure)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-priori-power-analyses",
    "href": "Lecture_Folder/Week3b.html#a-priori-power-analyses",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A priori Power analyses",
    "text": "A priori Power analyses\n\nBefore we start an experiment, we are interested in what sample size we should collect\nWe can use simulations to test different sample sizes"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#an-example",
    "href": "Lecture_Folder/Week3b.html#an-example",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "An example",
    "text": "An example\n\nLet’s say we’re studying college students again, and we’re interested in seeing if there’s a difference in study hours between freshman and seniors\nHow many students should we sample?\n\nThis will depend on our predictions about the effect size of this measurement"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#steps-to-power-analysis",
    "href": "Lecture_Folder/Week3b.html#steps-to-power-analysis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Steps to power analysis",
    "text": "Steps to power analysis\n\nSimulate the true distributions of our populations (decide on effect size, distribution type, and variance)\nDraw random samples of different sizes from those populations\nPerform our statistical test (t-test) on these samples\nRepeat 2 & 3 ~1000 times\nPlot our resulting p-values against sample size"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations",
    "href": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nWhat is the distribution type?\nWhat is the effect size: difference in means between populations?\nWhat is the variance?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-1",
    "href": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-2",
    "href": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample",
    "href": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample-1",
    "href": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-3-statistical-test",
    "href": "Lecture_Folder/Week3b.html#step-3-statistical-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 3: statistical test",
    "text": "Step 3: statistical test\n\n\n\n    Welch Two Sample t-test\n\ndata:  sample_f and sample_s\nt = 0, df = 17.678, p-value = 1\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.002509  4.002509\nsample estimates:\nmean of x mean of y \n      9.9       9.9"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-setting-up-our-replicates",
    "href": "Lecture_Folder/Week3b.html#step-4-setting-up-our-replicates",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4: setting up our replicates",
    "text": "Step 4: setting up our replicates\n\nTake a look at the “samps_var” vectors, how are they arranged? How would we begin conducting t-tests using each replicate from the two populations?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-testing-our-replicates",
    "href": "Lecture_Folder/Week3b.html#step-4-testing-our-replicates",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4: Testing our replicates",
    "text": "Step 4: Testing our replicates\n\n\n\nFALSE  TRUE \n   77    23"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-contd-changing-the-sample-size",
    "href": "Lecture_Folder/Week3b.html#step-4-contd-changing-the-sample-size",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4 contd: changing the sample size",
    "text": "Step 4 contd: changing the sample size"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-contd-multiple-sample-sizes",
    "href": "Lecture_Folder/Week3b.html#step-4-contd-multiple-sample-sizes",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4 contd: multiple sample sizes",
    "text": "Step 4 contd: multiple sample sizes\n\nRequires a more complex for loop"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "href": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "href": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#covariance-and-correlation",
    "href": "Lecture_Folder/Week3b.html#covariance-and-correlation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#linear-models",
    "href": "Lecture_Folder/Week3b.html#linear-models",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Linear Models",
    "text": "Linear Models"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet",
    "href": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet-1",
    "href": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet\n\nMean of x in each case 9 (exact)\nVariance of x in each case 11 (exact)\nMean of y in each case 7.50 (to 2 decimal places)\nVariance of y in each case 4.122 or 4.127 (to 3 decimal places)\nCorrelation between x and y in each case 0.816 (to 3 decimal places)\nLinear regression line in each case \\(y =3.00 + 0.50x\\) (to 2 decimal places)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html",
    "href": "Lecture_Folder/Week3b.html",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(nycflights23)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html",
    "href": "Lecture_Folder/Week4a.html",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(nycflights23)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#this-week",
    "href": "Lecture_Folder/Week4a.html#this-week",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nFinish parameter estimation\nt-test\nHypothesis testing\nPower\nStart linear models"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in bioengineering is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\nthe number of muscle contractions during a bout of exercise\ncount of genes in a genome binned to units of 500kb\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\n\nFor example, you can examine 100 participants\n\ncount the number of jumps they can perform in 2 minutes\nwhat is the probability of observing a particpant with r jumps?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that the Poisson is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution with gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution with gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-increasing-parameter-values-of-lambda",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution with increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution with increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week4a.html#testing-poisson-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#geometric-distribution",
    "href": "Lecture_Folder/Week4a.html#geometric-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week4a.html#geometric-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week4a.html#testing-geometric-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\ndgeom(x=20, p=0.1)\n\n[1] 0.01215767\n\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week4a.html#testing-geometric-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581\n\nplot(pgeom(q=1:20, p=0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week4a.html#negative-binomial-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “ones” have appeared.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “one” appearing on the \\(k^{th}\\) trial:\n\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r-1}(1-p)^{k-r}p\\]\n\nwhich simplifies to\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r}(1-p)^{k-r}\\]\n\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week4a.html#negative-binomial-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#continuous-probability-distributions-1",
    "href": "Lecture_Folder/Week4a.html#continuous-probability-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Continuous probability distributions",
    "text": "Continuous probability distributions\nP(observation lies within dx of x) = f(x)dx\n\\[P(a\\leq X \\leq b) = \\int_{a}^{b} f(x) dx\\]\nRemember that the indefinite integral sums to one\n\\[\\int_{-\\infty}^{\\infty} f(x) dx = 1\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#continuous-probabilities",
    "href": "Lecture_Folder/Week4a.html#continuous-probabilities",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Continuous probabilities",
    "text": "Continuous probabilities\n\nE[X] may be found by integrating the product of x and the probability density function over all possible values of x:\n\\[E[X] = \\int_{-\\infty}^{\\infty} xf(x) dx \\]\n\n\\(Var(X) = E[X^2] - (E[X])^2\\), where the expectation of \\(X^2\\) is\n\\[E[X^2] = \\int_{-\\infty}^{\\infty} x^2f(x) dx \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#uniform-distribution",
    "href": "Lecture_Folder/Week4a.html#uniform-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\n\\[E[X] = \\int_{a}^{b} x\\frac{1}{b-a} dx = \\frac{(a+b)}{2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week4a.html#uniform-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#exponential-distribution",
    "href": "Lecture_Folder/Week4a.html#exponential-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\n\\[f(x)=\\lambda e^{-\\lambda x}\\]\n\n\nE[X] can be found be integrating \\(xf(x)\\) from 0 to infinity\n\n\n\nleading to the result that\n\n\n\n\\(E[X] = \\frac{1}{\\lambda}\\)\n\\(E[X^2] = \\frac{1}{\\lambda^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week4a.html#exponential-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#exponential-distribution-2",
    "href": "Lecture_Folder/Week4a.html#exponential-distribution-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\ndexp(10, rate = 0.1)\n\n[1] 0.03678794\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#gamma-distribution",
    "href": "Lecture_Folder/Week4a.html#gamma-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\) :\n\n\n\\[f(x) = \\frac{e^{-\\lambda x}\\lambda x^{r-1}}{(r-1)!}\\lambda\\]\n\n\\[ Mean =  \\frac{r}{\\lambda} \\] \\[ Variance = \\frac{r}{\\lambda^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week4a.html#gamma-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber.\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#normal-pdf---mu-and-sigma",
    "href": "Lecture_Folder/Week4a.html#normal-pdf---mu-and-sigma",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Normal PDF - (\\(\\mu\\) and \\(\\sigma\\))",
    "text": "Normal PDF - (\\(\\mu\\) and \\(\\sigma\\))\n\\[f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma}} \\, \\mathrm{e}^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\mathrm{e} \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week4a.html#estimates-of-mean-and-variance",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimates of mean and variance",
    "text": "Estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#normal-pdf",
    "href": "Lecture_Folder/Week4a.html#normal-pdf",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences",
    "href": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-1",
    "href": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-2",
    "href": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week4a.html#parent-offspring-resemblance",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week4a.html#genetic-model-of-complex-traits",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week4a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week4a.html#why-else-is-the-normal-special",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nIt is the basis of estimation and precision of the expected value of all distributions\nProvides a mathematical basis for moving from single samples to point estimates.\nProvides a way to use simulation to generate empirical sample and test distributions through Monte Carlo approaches"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have\n\na mean of 0 and\na standard deviation of 1\n\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#common-theme-in-r-for-distributions",
    "href": "Lecture_Folder/Week4a.html#common-theme-in-r-for-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Common theme in R for distributions",
    "text": "Common theme in R for distributions\n\n\n\n\n\n\n\n\n\n\n\nd\nprobability mass function\np\ncumulative distribution\nq\nquantile function\nr\npseudorandom number generate\n\n\n\n\nbinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\npoisson\ndpois\nppois\nqpois\nrpois\n\n\nexponential\ndexp\npexp\nqexp\nrexp\n\n\nnormal\ndnorm\npnorm\nqnorm\nrnorm"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#parameter-estimation",
    "href": "Lecture_Folder/Week4a.html#parameter-estimation",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nEstimation is the process of inferring a population parameter from sample data\nThe value of one sample estimate is almost never the same as the population parameter because of random sampling error\nMost will be close, but some will be far away\nSampling distribution of an estimate\n\nall values we might have obtained from our sample\nprobabilities of occurrence\n\nStandard error of an estimate\n\nstandard deviation of a sampling distribution\nmeasures the precision of the parameter estimate\nNO ESTIMATE IS USEFUL WITHOUT IT!"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#parameter-estimation-1",
    "href": "Lecture_Folder/Week4a.html#parameter-estimation-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nParametric (a few special exceptions, like the sample mean and its standard error)\nResampling - bootstrapping and randomization to create empirical null distributions\nOrdinary Least Squares (OLS) - optimized procedure that produces one definitive result, easy to use but no estimates of confidence\nMaximum Likelihood (ML) - Can provide model-based estimates with confidence, but harder to calculate\nBayesian Approaches - Incorporates prior information into ML estimation"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#accuracy-vs.-precision",
    "href": "Lecture_Folder/Week4a.html#accuracy-vs.-precision",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#accuracy-vs.-precision-1",
    "href": "Lecture_Folder/Week4a.html#accuracy-vs.-precision-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision\n\nAccuracy is the closeness of an estimated value to its true value\nPrecision is the closeness of repeated estimates to one another\nOur goal is to have unbiased estimates that are the most precise\nWe have to estimate parameters and test hypotheses by taking samples that approximate the underlying distribution\nThe goal of replication is to quantify variation at as many levels in a study as possible\nThe goal of randomization is to avoid bias as much as possible"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-central-limit-theorem-1",
    "href": "Lecture_Folder/Week4a.html#the-central-limit-theorem-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week4a.html#standard-error-of-the-mean-sem",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\\[\\huge \\sigma_{\\bar{x}} \\approx s_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\]\n\nwhere \\(s_{\\bar{x}}\\) is the estimated standard error of the distribution of the mean estimates\nwhich is usually just referred to as the ’standard error of the mean (SEM)\nnote that this is not the standard deviation of the original distribution\nimportantly, the SEM will go down as the sample size increases"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#calculating-the-standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week4a.html#calculating-the-standard-error-of-the-mean-sem",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Calculating the Standard Error of the Mean (SEM)",
    "text": "Calculating the Standard Error of the Mean (SEM)\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rnorm(n=1000, mean=2, sd=5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.2646669\n\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607\n\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 50))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.04635888"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals",
    "href": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-1",
    "href": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-2",
    "href": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#confidence-intervals",
    "href": "Lecture_Folder/Week4a.html#confidence-intervals",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week4a.html#coefficient-of-variation",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#bootstrapping",
    "href": "Lecture_Folder/Week4a.html#bootstrapping",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n-Unfortunately, most other kinds of estimates (anything not the mean) do not have this amazing property, but we can rely on another approach to calculate the standard error. - This involves generating your own sampling distribution for the estimate using the “bootstrap,” a method invented by Efron (1979). - We call the bootstrap, and other methods that do not rely on distributional assumptions of the variable itself, “nonparametric” approaches."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-etymology-of-the-term-bootstrap",
    "href": "Lecture_Folder/Week4a.html#the-etymology-of-the-term-bootstrap",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The etymology of the term ‘bootstrap’",
    "text": "The etymology of the term ‘bootstrap’"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-the-bootstrap-is-good",
    "href": "Lecture_Folder/Week4a.html#why-the-bootstrap-is-good",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why the bootstrap is good",
    "text": "Why the bootstrap is good\n\nCan be applied to almost any sample statistic\n\nThis includes means, proportions, correlations, regression\n\nWorks when there is no ready formula for a standard error\n\nFor example the median, trimmed mean, correlation, eigenvalue, etc.\n\nIs nonparametric, so doesn’t require normally-distributed data\nWorks for estimates based on complicated sampling procedures or calculations"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week4a.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#bootstrapping-1",
    "href": "Lecture_Folder/Week4a.html#bootstrapping-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned.\nIt works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#loops-in-r",
    "href": "Lecture_Folder/Week4a.html#loops-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Loops in R",
    "text": "Loops in R\n\nR is very good at performing repetitive tasks.\nIf we want a set of operations to be repeated several times we use what’s known as a loop.\nWhen you create a loop, R will execute the instructions in the loop a specified number of times or until a specified condition is met.\nThere are two common types of loop in R: the for loop and the while loop"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#for-loops",
    "href": "Lecture_Folder/Week4a.html#for-loops",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "For loops",
    "text": "For loops\n\nThe most commonly used loop structure when you want to repeat a task a defined number of times is the for loop. The most basic example of a for loop is:\nHow does this appear to be working?\n\n\n# Notice the sequence of parentheses and brackets used in this example\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#while-loops",
    "href": "Lecture_Folder/Week4a.html#while-loops",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "While loops",
    "text": "While loops\n\nAnother type of loop that you may use is the while loop.\nThe while loop is used when you want to keep looping until a specific logical condition is satisfied.\n\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n  i &lt;- i + 1\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#if-and-else-statements",
    "href": "Lecture_Folder/Week4a.html#if-and-else-statements",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "If and Else Statements",
    "text": "If and Else Statements\n\nConditional statements are how you inject some logic into your code.\nThe most commonly used conditional statement is if.\n\nWhenever you see an if statement, read it as ‘If X is TRUE, then do a thing’.\n\nAnother statement is else, which extends the logic to ‘If X is TRUE, do a thing, or else do something different’."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#a-programming-joke-for-conditional-statements",
    "href": "Lecture_Folder/Week4a.html#a-programming-joke-for-conditional-statements",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "A programming joke for conditional statements",
    "text": "A programming joke for conditional statements\nA programmer’s partner says: ‘Please go to the store and buy a carton of milk and if they have eggs, get six.’\nThe programmer returned with 6 cartons of milk.\nWhen the partner sees this, and exclaims ‘Why the heck did you buy six cartons of milk?’\nThe programmer replied ‘They had eggs’\n\neggs &lt;- TRUE # Whether there were eggs in the store\n\n  if (eggs == TRUE) { # If there are eggs\n  n.milk &lt;- 6 # Get 6 cartons of milk\n    } else { # If there are not eggs\n  n.milk &lt;- 1 # Get 1 carton of milk\n  }"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude---simulate-a-population-and-sample-it",
    "href": "Lecture_Folder/Week4a.html#r-interlude---simulate-a-population-and-sample-it",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE - Simulate a population and sample it!",
    "text": "R INTERLUDE - Simulate a population and sample it!"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#simulations-to-compare-parameter-estimates",
    "href": "Lecture_Folder/Week4a.html#simulations-to-compare-parameter-estimates",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Simulations to compare parameter estimates",
    "text": "Simulations to compare parameter estimates\n\nLet’s use our distribution functions from last time to set up some data to play with\nLet’s imagine our data is made up of counts, with an average of 3 counts - which distribution would fit that data best?\nEx: number of hours per day spent doing homework by UO undergraduates\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=10000, lambda = 3)\nhist(true_pop, xlim = c(0,16))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#calculating-parameters",
    "href": "Lecture_Folder/Week4a.html#calculating-parameters",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?\n\n\nmean(true_pop)\n\n[1] 2.9817\n\nrange(true_pop)\n\n[1]  0 12\n\nmedian(true_pop)\n\n[1] 3\n\n\n\nhow about the variance and the standard deviation?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#sampling-exercise",
    "href": "Lecture_Folder/Week4a.html#sampling-exercise",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week4a.html#randomness-in-sampling",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size\nBut your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week4a.html#surveying-your-sampling",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\nStep 1 - take 50 samples of size 10 Step 2 - Calculate the mean from each sample Step 3 - Plot the distribution of sample mean estimates\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=10000, lambda = 3)\nsamps_var &lt;- replicate(50, sample(true_pop, 10))\nsamps_var_means &lt;- apply(samps_var, 2, mean)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#histograms",
    "href": "Lecture_Folder/Week4a.html#histograms",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Histograms",
    "text": "Histograms\n\n\n\nhist(true_pop)\n\n\n\n\n\n\n\n\n\n\nhist(samps_var_means)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week4a.html#surveying-your-sampling-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#challenge---bootstrapping-to-produce-a-confidence-interval",
    "href": "Lecture_Folder/Week4a.html#challenge---bootstrapping-to-produce-a-confidence-interval",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "CHALLENGE - Bootstrapping to produce a confidence interval",
    "text": "CHALLENGE - Bootstrapping to produce a confidence interval\n\nThe 2.5th and 97.5th percentiles of the bootstrap sampling distribution are a passable 95% confidence interval\nNote that no transformations or normality assumptions needed\nYou can use the quantile() function to calculate these\nYou can also use qnorm\nUse R to figure out the bootstrap distribution for other parameters (such as variance).\nTry to produce bootstrap distributions for the mean and variance of gene expresssion of one gene from the stickleback data set\nPlot the resulting distributions\nDetermine the value of the 2.5th and 97.5th percentiles"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-hypothesis",
    "href": "Lecture_Folder/Week4a.html#what-is-a-hypothesis",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\nA statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models\n\nThis is where statistical sampling distributions come into play"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-1",
    "href": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nWe can compare estimated parameters, while also including measures of uncertainty, using frequentist methods\nRequires statistical hypotheses: a statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-2",
    "href": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nThis is where statistical sampling distributions come into play\n\nStatistical distributions are built upon sampling distributions\nWill tell us how “frequently” we expect to see a result as extreme as ours"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#hypothesis-tests",
    "href": "Lecture_Folder/Week4a.html#hypothesis-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height on average as Douglas fir trees"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#hypothesis-tests-1",
    "href": "Lecture_Folder/Week4a.html#hypothesis-tests-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions",
    "href": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions\n\nWhich scenario do you think will be easier to find a difference?\nWhat factor(s) will make our statistical tests better?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-1",
    "href": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data.\nThen see how probable it was by comparing against the null distribution.\nThe probability of seeing that value or greater is called the p-value of the statistic."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-2",
    "href": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nAn example of a test statistic is the t-statistic.\nThe t-statistic is a standardized difference between two sample means\n\nt = 0 indicates no difference between population means\nt-distribution is Normal, with the center and peak at 0\n\nWe can evaluate the t-statistic for our sample data and see whether it falls far enough away from zero - then we reject the null hypothesis"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-1",
    "href": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-2",
    "href": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#four-common-statistical-distributions",
    "href": "Lecture_Folder/Week4a.html#four-common-statistical-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\[\\huge t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere\n\n\n\n\n\n\n\n\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | under different degrees of freedom",
    "text": "The t-test and t sampling distribution | under different degrees of freedom"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-1",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\[H_0 : \\mu_1 = \\mu_2\\]\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height as Douglas fir trees\n\\[H_A : \\mu_1 \\neq \\mu_2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-2",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\nwhere\n\n\n\n\n\n\n\n\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests",
    "href": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#a-tangent-on-degrees-of-freedom",
    "href": "Lecture_Folder/Week4a.html#a-tangent-on-degrees-of-freedom",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "A tangent on degrees of freedom",
    "text": "A tangent on degrees of freedom\n\nIn statistics, degrees of freedom refers to the number of values in a calculation that are free to vary.\nExample: you have a set of numbers, like 1, 2, 3, and 4. If you know the average (mean) of these numbers is 3, you can actually choose three of the numbers freely, but the fourth number will be determined by the other three. So in this case, you have three degrees of freedom.\nThis answer comes from ChatGPT!"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#degrees-of-freedom-exercise",
    "href": "Lecture_Folder/Week4a.html#degrees-of-freedom-exercise",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Degrees of freedom exercise",
    "text": "Degrees of freedom exercise\n\nTry out this concept in R\n\nRandomly sample from a list of numbers (1-10) 5 numbers\nCalculate the mean for that group of numbers\nIf you were to add a sixth number, what would it have to be for the mean to = 7?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "href": "Lecture_Folder/Week4a.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "On a scale of Murica to 10, how many degrees of freedom do you have?",
    "text": "On a scale of Murica to 10, how many degrees of freedom do you have?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#type-1-and-type-2-errors",
    "href": "Lecture_Folder/Week4a.html#type-1-and-type-2-errors",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing",
    "href": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\n\\(\\alpha\\) = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\n\\(\\beta\\) = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power",
    "href": "Lecture_Folder/Week4a.html#statistical-power",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "href": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-1",
    "href": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power-1",
    "href": "Lecture_Folder/Week4a.html#statistical-power-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#power-the-things-one-needs-to-know",
    "href": "Lecture_Folder/Week4a.html#power-the-things-one-needs-to-know",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Power | the things one needs to know",
    "text": "Power | the things one needs to know\n\\[ Power \\propto \\frac{(ES)(\\alpha)(\\sqrt n)}{\\sigma}\\]\n\nPower is proportional to the combination of these parameters\n\nES - effect size; how large is the change of interest?\n\\(\\alpha\\) - significance level (usually 0.05)\nn - sample size\n\\(\\sigma\\) - standard deviation among experimental units within the same group."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#power-what-we-usually-want-to-know",
    "href": "Lecture_Folder/Week4a.html#power-what-we-usually-want-to-know",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Power | what we usually want to know",
    "text": "Power | what we usually want to know"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#power-rough-calculation",
    "href": "Lecture_Folder/Week4a.html#power-rough-calculation",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Power | rough calculation",
    "text": "Power | rough calculation"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-power-analysis",
    "href": "Lecture_Folder/Week4a.html#what-is-a-power-analysis",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a power analysis?",
    "text": "What is a power analysis?\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power-2",
    "href": "Lecture_Folder/Week4a.html#statistical-power-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power-3",
    "href": "Lecture_Folder/Week4a.html#statistical-power-3",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?\n\nSample size\nEffect size (difference between the groups)\nVariance (range of values for this trait/measure)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#a-priori-power-analyses",
    "href": "Lecture_Folder/Week4a.html#a-priori-power-analyses",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "A priori Power analyses",
    "text": "A priori Power analyses\n\nBefore we start an experiment, we are interested in what sample size we should collect\nWe can use simulations to test different sample sizes"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#an-example",
    "href": "Lecture_Folder/Week4a.html#an-example",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "An example",
    "text": "An example\n\nLet’s say we’re studying college students again, and we’re interested in seeing if there’s a difference in study hours between freshman and seniors\nHow many students should we sample?\n\nThis will depend on our predictions about the effect size of this measurement"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#steps-to-power-analysis",
    "href": "Lecture_Folder/Week4a.html#steps-to-power-analysis",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Steps to power analysis",
    "text": "Steps to power analysis\n\nSimulate the true distributions of our populations (decide on effect size, distribution type, and variance)\nDraw random samples of different sizes from those populations\nPerform our statistical test (t-test) on these samples\nRepeat 2 & 3 ~1000 times\nPlot our resulting p-values against sample size"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations",
    "href": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nWhat is the distribution type?\nWhat is the effect size: difference in means between populations?\nWhat is the variance?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-1",
    "href": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nsenior &lt;- rpois(5000, lambda = 10)\nfresh &lt;- rpois(5000, lambda = 12)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-2",
    "href": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample",
    "href": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample\n\nsample_s &lt;- sample(senior, size = 10, replace = FALSE)\nsample_f &lt;- sample(fresh, size = 10, replace = FALSE)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample-1",
    "href": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-3-statistical-test",
    "href": "Lecture_Folder/Week4a.html#step-3-statistical-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 3: statistical test",
    "text": "Step 3: statistical test\n\nt.test(sample_f, sample_s)\n\n\n    Welch Two Sample t-test\n\ndata:  sample_f and sample_s\nt = 1.1234, df = 16.683, p-value = 0.2772\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.497353  4.897353\nsample estimates:\nmean of x mean of y \n     12.0      10.3"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-setting-up-our-replicates",
    "href": "Lecture_Folder/Week4a.html#step-4-setting-up-our-replicates",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4: setting up our replicates",
    "text": "Step 4: setting up our replicates\n\nTake a look at the “samps_var” vectors, how are they arranged? How would we begin conducting t-tests using each replicate from the two populations?\n\n\n## sample size of 10\nsamps_var_s &lt;- replicate(n = 100, sample(senior, size = 10))\nsamps_var_f &lt;- replicate(n = 100, sample(fresh, size = 10))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-testing-our-replicates",
    "href": "Lecture_Folder/Week4a.html#step-4-testing-our-replicates",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4: Testing our replicates",
    "text": "Step 4: Testing our replicates\n\n# setting up a \"test\" dataframe\ntests &lt;- data.frame(1:100)\ntests$SampleSize &lt;- rep(\"10\", 100)\n\nfor (i in 1:ncol(samps_var_f)){\n  tests$result[i] &lt;- t.test(samps_var_s[,i], samps_var_f[,i])$p.value\n}\ntable(tests$result &lt; 0.05)\n\n\nFALSE  TRUE \n   85    15"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-contd-changing-the-sample-size",
    "href": "Lecture_Folder/Week4a.html#step-4-contd-changing-the-sample-size",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4 contd: changing the sample size",
    "text": "Step 4 contd: changing the sample size"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-contd-multiple-sample-sizes",
    "href": "Lecture_Folder/Week4a.html#step-4-contd-multiple-sample-sizes",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4 contd: multiple sample sizes",
    "text": "Step 4 contd: multiple sample sizes\n\nRequires a more complex for loop"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-complete-exercises-3.2-3.4",
    "href": "Lecture_Folder/Week4a.html#r-interlude-complete-exercises-3.2-3.4",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R Interlude | Complete Exercises 3.2-3.4",
    "text": "R Interlude | Complete Exercises 3.2-3.4"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-2",
    "href": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\nalpha = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\nbeta = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-distributions-and-p-values",
    "href": "Lecture_Folder/Week4a.html#null-distributions-and-p-values",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "href": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-4",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-4",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\nTo calculate the t-statistic for two populations:\n\n\\[\\large t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere s is the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests-1",
    "href": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-try-it-out",
    "href": "Lecture_Folder/Week4a.html#lets-try-it-out",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nUse the below code to set up two simulated populations:\n\n\nset.seed(518)\npop1 &lt;- sample(rnorm(n=10000, mean=2, sd=0.5), size = 100)\npop2 &lt;- sample(rnorm(n=10000, mean=5, sd=0.5), size = 100)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-try-it-out-1",
    "href": "Lecture_Folder/Week4a.html#lets-try-it-out-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "LEt’s try it out",
    "text": "LEt’s try it out"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#first-is-the-distributionspread-the-same",
    "href": "Lecture_Folder/Week4a.html#first-is-the-distributionspread-the-same",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "First, is the distribution/spread the same?",
    "text": "First, is the distribution/spread the same?\n\nUse the function var.test() in R\nHow do we interpret this?\n\n\nvar.test(pop1, pop2)\n\n\n    F test to compare two variances\n\ndata:  pop1 and pop2\nF = 0.8257, num df = 99, denom df = 99, p-value = 0.3423\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5555635 1.2271791\nsample estimates:\nratio of variances \n         0.8256973"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#now-for-the-t-test",
    "href": "Lecture_Folder/Week4a.html#now-for-the-t-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Now for the t-test!",
    "text": "Now for the t-test!\n\nUse the function t.test() in R\nHow do we interpret this? How would you write this conclusion as a sentence?\n\n\nt.test(pop1, pop2)\n\n\n    Welch Two Sample t-test\n\ndata:  pop1 and pop2\nt = -41.396, df = 196.21, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.075616 -2.795896\nsample estimates:\nmean of x mean of y \n 2.035190  4.970946"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#mann-whitney-wilcoxon-tests",
    "href": "Lecture_Folder/Week4a.html#mann-whitney-wilcoxon-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Mann-Whitney-Wilcoxon Tests",
    "text": "Mann-Whitney-Wilcoxon Tests\n\nThe Mann-Whitney U (also called “Mann-Whitney-Wilcoxon) Test tests for distributional differences between the ranks of two samples.\nIn R the function wilcox.test() can be used to perform it, in much the same way the t.test() function is used."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-try-it-out-2",
    "href": "Lecture_Folder/Week4a.html#lets-try-it-out-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nset.seed(518)\npop1 &lt;- sample(rnorm(n=10000, mean=2, sd=0.5), size = 100)\npop2 &lt;- sample(rnorm(n=10000, mean=5, sd=1.5), size = 100)\nhist(pop2)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#test-the-variance",
    "href": "Lecture_Folder/Week4a.html#test-the-variance",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Test the variance",
    "text": "Test the variance\n\nUse the function we used before to see if the variance is the same or different between pop1 and pop2\nHow do we interpret this?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-mann-whit-u-test",
    "href": "Lecture_Folder/Week4a.html#the-mann-whit-u-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nUse the function wilcox.test() in R to compare pop1 and pop2\nHow do we interpret that result? How would you write it as a sentence for a paper?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-mann-whit-u-test-1",
    "href": "Lecture_Folder/Week4a.html#the-mann-whit-u-test-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nwilcox.test(pop1, pop2)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  pop1 and pop2\nW = 440, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-1",
    "href": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values\n\nWe can also create a null statistical distribution that models the distribution of a test statistic under the null hypothesis\nTo create the null distribution we can use either randomization or resampling"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#creating-a-null-distribution-through-randomization",
    "href": "Lecture_Folder/Week4a.html#creating-a-null-distribution-through-randomization",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Creating a null distribution through randomization",
    "text": "Creating a null distribution through randomization\n\nCombine values from both populations into a single vector\nRandomly shuffle the vector using the sample() function\nCalculate a t statistic based on the first n1 and n2 observations as our “pseudo samples” from “populations” 1 and 2, respectively, and save the value\nRepeat steps 2 and 3 many times (e.g. 1000)\nCalculate the proportion of pseudo replicates in which t is ≥ to our original, observed value of t. This proportion is our estimated p-value for the test."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-do-it---the-starting-populations",
    "href": "Lecture_Folder/Week4a.html#lets-do-it---the-starting-populations",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Let’s do it - the starting populations",
    "text": "Let’s do it - the starting populations\n\nset.seed(56)\npop_1 &lt;- rnorm(n=50, mean=20.1, sd=2)#simulate population 1 for this example\npop_2 &lt;- rnorm(n=50, mean=19.3, sd=2)#simulate population 2 for this example"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#calculate-the-t-test",
    "href": "Lecture_Folder/Week4a.html#calculate-the-t-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Calculate the t-test",
    "text": "Calculate the t-test\n\n# Store the t statistic calculated from our samples, using t.test()\nt_obs &lt;- t.test(x=pop_1, y=pop_2, alternative=\"greater\")$statistic"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "href": "Lecture_Folder/Week4a.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Combine the populations, sample from that, and calculate t-tests",
    "text": "Combine the populations, sample from that, and calculate t-tests\n\n# Combine both population vectors into one\npops_comb &lt;- c(pop_1, pop_2)\n\n# Randomly shuffle and calculate t statistic 1000 times\nt_rand &lt;- replicate(1000, {\n  pops_shuf &lt;- sample(pops_comb)\n  t.test(x=pops_shuf[1:50], y=pops_shuf[51:100], alternative=\"greater\")$statistic\n  })"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#plot-the-null-distribution",
    "href": "Lecture_Folder/Week4a.html#plot-the-null-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Plot the null distribution",
    "text": "Plot the null distribution\n\n# Plot the \"null distribution\" from the randomization-based t-values\nhist(t_rand)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-2",
    "href": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#whats-our-result",
    "href": "Lecture_Folder/Week4a.html#whats-our-result",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What’s our result?",
    "text": "What’s our result?\n\nHow do we interpret this?\n\n\n# Calculate the p-value for the test as the number of randomization t-values greater\n# than or equal to our actual t-value observed from the data\np &lt;- sum(t_rand&gt;=t_obs)/1000\n\np\n\n[1] 0.016"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r",
    "href": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nMake a dummy data set that contains one continuous and one categorical value (with two levels). Draw individuals of the two different factor levels from normal distributions with slightly different means. Take 100 obsv. per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level)\nRepeat steps 1 and 2 above but now test between a categorical and continuous variable in the perchlorate data set (or any of your favorite data sets)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nNow, apply the equations for the t-statistic above to your simulated sample to perform the same test, but using a resampling approach\n\nhint: go back to your Bootstrapping script\n\nUse this approach to calculate a distribution of random t statistics assuming the the null hypothesis of no difference is true.\nNow, compare your observed value to your created null distribution.\nWhat is the probability of that value occurring by chance under the null?\n\nThis is your p-value! (Assume you’re doing a one-tailed test)\nhint: Proportion of values in the null distribution equal to or larger than the observed t-value = p-value"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nRandomization test example 1\nData: The number of successful broods of pseudoscorpion females that were mated twice to either a single male (SM) or two different males (DM).\n\nSM: 4 0 3 1 2 3 4 2 4 2 0 2 0 1 2 6 0 2 3 3\nDM: 2 0 2 6 4 3 4 4 2 7 4 1 6 3 6 4\n\nObserved difference in the means between the two\n\n\\(\\bar{Y}_{SM}\\) − \\(\\bar{Y}_{DM}\\) = 2.2−3.625 = −1.425"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nSteps of the randomization test\nFirst, create a randomized data set in which the measurements are randomly reassigned (without replacement) to the two groups\n\nFor example, the following\nSM: 4 0 7 4 2 2 2 1 4 4 0 3 3 4 6 2 4 6 0 0\nDM: 2 2 3 3 2 3 3 4 1 2 1 4 6 6 2 0\n\nSecond, calculate the test statistic measuring the association between variables\n\ndifference between group means\nthis is the first bootstrap replicate\n\nRepeat steps 1 and 2 many times to produce many bootstrap replicates"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-2",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nBelow is the null distribution of the test statistic from 10,000 replications\n\nThis is produced by the randomized assignment of values to each group (SM or DM)\nThus this is the distribution we’d expect under the null hypothesis of no difference\n\nThe observed value from the data is –1.425\nThe area in red is the tail beyond this observed value and is therefore the bootstrap p-value"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-3",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-3",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nOf these 10,000 randomizations, only 176 had a test statistic (difference between means) equal to or less than the observed value, –1.425.\nYou can use the simulated null distribution in the same way as t or F distribution in conventional tests.\nProportion of values in the null distribution equal or larger than the observed value of the test statistic is 176/10000 = 0.0176."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power",
    "href": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nRead in the perchlorate data again\nPerform an ANOVA to test Strain on T4_Hormone_Level, but log-transform (base 10) the T4 variable\n\n\nperc &lt;- read.table('perchlorate_data.tsv', header=T, sep='\\t')\nx &lt;- perc$Strain\ny &lt;- log10(perc$T4_Hormone_Level)\n\nMyANOVA &lt;- aov(y ~ x)\nsummary (MyANOVA)\nboxplot(y ~ x)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nConsider the parameters of this test related to power:\n\nThe per-group sample sizes\nThe standard deviation (use the higher within-group sd)\nThe effect size (|difference between means| / within-grp sd)\n\nFor more complex ANOVA power calculations (&gt;2 groups):\n\nThe total variance\nThe within-group variance (use the higher one)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "href": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\nBased on your results, calculate the power for your ANOVA.\n\n   pwr.t2n.test(n1=xxx, n2=xxx, d=xxx, sig.level=.05, power=NULL)\n\nCheck out the functions in the ‘pwr’ library (Unnecessary in this case, but could use ANOVA version):\n\n   pwr.anova.test(k=2, n=190, f=0.25, sig.level=.05, power=NULL)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\neffect size approximations:\n\nf=0.1 (small)\nf=0.25 (medium)\nf=0.4 (large)\n\nsee http://www.statmethods.net/stats/power.html"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "href": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\nLet’s say you have to repeat the experiment, but your IACUC wants you to get by by using fewer fish.\nYou want to be able to detect a minimum mean difference of 1.3 T4 units (about 0.114 on the log10 scale), at a power of 90%.\nFirst, divide 0.114 by std.dev. of transformed WK values (the higher std. dev. of the two groups) to get a conservative “d”.\nWhat kind of sample size for the WK group would you need???\n(Again use the pwr.t2n.test() function, but this time specify the WK sample size as the unknown parameter)"
  }
]