[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BioEngineering Statistics 2025",
    "section": "",
    "text": "I created this course website using Quarto. To learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to the website for BioE610 - Statistics for Bioengineers.\nBelow you will find the core information for the course.\nMore detailed information can be found under the ‘Syllabus’ and ‘Policies’ links.\nThe course schedule can be found under the ‘Schedule’ header.\nI will be posting the lectures after each class under the ‘Lectures’ header.\nAdditional resources for the class will gradually accrue under the ‘Resources’ Header."
  },
  {
    "objectID": "Syllabus.html",
    "href": "Syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course in an introduction to data management, data visualization and statistical inference that is intended for early-stage bioengineering and bioscience graduate students with no background in statistics. This is a practical course with a foundation of conceptual intuition matched with hands-on coding each week. The primary objective of the course is to provide foundational training in the organization, manipulation, visualization, and analysis of data, using the R statistical language in a reproducible manner. After this course students will be able to analyze their own data sets with confidence using reasonable approaches, and to provide a foundation for more advanced courses in statistics, data science and machine learning. The course is designed to primarily for the analysis of univariate (single response variable) data. For students interested in multivariate analysis, other courses in Department of Data Science are available. Examples and assignments in class will largely be drawn from bioengineering and the life sciences."
  },
  {
    "objectID": "Lecture_1.html",
    "href": "Lecture_1.html",
    "title": "lecture_1",
    "section": "",
    "text": "x\nxx\nblue"
  },
  {
    "objectID": "Lecture_1.html#slide-1",
    "href": "Lecture_1.html#slide-1",
    "title": "lecture_1",
    "section": "slide 1",
    "text": "slide 1\n\nx\nxx\nblue"
  },
  {
    "objectID": "Lecture_1.html#slide-2",
    "href": "Lecture_1.html#slide-2",
    "title": "lecture_1",
    "section": "slide 2",
    "text": "slide 2\n\nyy\ny\ngray"
  },
  {
    "objectID": "Lectures.html",
    "href": "Lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "Lecture_1a\nLecture_1b\nLecture_2a\nLecture_2b\nLecture_3a\nLecture_3b\nLecture_4a\nLecture_4b\nLecture_5a\nLecture_5b\nLecture_6a\nLecture_6b\nLecture_7a\nLecture_7b\nLecture_8a\nLecture_8b\nLecture_9a\nLecture_9b\nLecture_10a\nLecture_10b"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html",
    "href": "Lecture_Folder/Lecture_1.html",
    "title": "lecture_1 - placeholder",
    "section": "",
    "text": "x\nxx\nblue"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#slide-1",
    "href": "Lecture_Folder/Lecture_1.html#slide-1",
    "title": "lecture_1",
    "section": "slide 1",
    "text": "slide 1\n\nx\nxx\nblue"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#slide-2",
    "href": "Lecture_Folder/Lecture_1.html#slide-2",
    "title": "lecture_1",
    "section": "slide 2",
    "text": "slide 2\n\nyy\ny\ngray"
  },
  {
    "objectID": "Syllabus.html#course-schedule",
    "href": "Syllabus.html#course-schedule",
    "title": "BioE 610 - Bioengineering Statistics - Syllabus 2025",
    "section": "",
    "text": "Date\nTopics\nReadings\n\n\n\n\n01 April\nxxxxssssssssssssssssssssssssssssssssssss\nxxxx\n\n\n03 April\n\n\n\n\n\n08 April\n\n\n\n\n10 April\n\n\n\n\n\n15 April\n\n\n\n\n17 April\n\n\n\n\n\n22 April\n\n\n\n\n24 April\n\n\n\n\n\n29 April\n\n\n\n\n01 May\n\n\n\n\n\n06 May\n\n\n\n\n08 May\n\n\n\n\n\n13 May\n\n\n\n\n15 May\n\n\n\n\n\n20 May\n\n\n\n\n22 May\n\n\n\n\n\n27 May\n\n\n\n\n29 May\n\n\n\n\n\n3 June\n\n\n\n\n5 June\n\n\n\n\n\n10 June\nFINALS WEEK"
  },
  {
    "objectID": "about.html#instructor-and-class-information",
    "href": "about.html#instructor-and-class-information",
    "title": "About the Course",
    "section": "Instructor and class information",
    "text": "Instructor and class information\n\n\n\n\nInstructor\nBill Cresko\n\n\nClass times\nTuesday/Thursday 4:00 to 5:50\n\n\nClass room\nKC158\n\n\nOffice Hours\nMonday 3:30 to 4:30\n\n\ne-mail\nwcresko@uoregon.edu"
  },
  {
    "objectID": "about.html#course-description",
    "href": "about.html#course-description",
    "title": "About the Course",
    "section": "Course Description",
    "text": "Course Description\nThis course in an introduction to data management, data visualization and statistical inference that is intended for early-stage graduate students with no background in statistics. The primary objective of the course is to get students up to speed with respect to organization, manipulation, visualization, and analysis of data, using the R statistical language. Students will learn to organize and analyze data sets in the form of RStudio projects, using R Markdown files to reproducibly capture and render code, visualizations and analyses. This is a practical course with a foundation of conceptual intuition with the goal of enabling students to analyze their own data sets with confidence using reasonable approaches, and to provide a foundation for more advanced courses in statistics, data science and machine learning. The course is designed to primarily on univariate (single response variable) analysis. For students interested in multivariate analysis, other courses in Department of Data Science will be available. Examples and assignments in class will largely be drawn from the life sciences in general, and bioengineering in particular. For learning outcomes, and specific topics covered in class, please see the course goals below and the schedule on the ‘Syllabus’ page of this website."
  },
  {
    "objectID": "about.html#course-objectives",
    "href": "about.html#course-objectives",
    "title": "About the Course",
    "section": "Course Objectives",
    "text": "Course Objectives\n\nScientific Computing Fundamentals\n\nDescribe fundamental aspects of computer systems, including file types, storage structure, and the logic of programming languages.\nRead and write code in Unix.\nRead and write code in R using RStudio.\nProperly organize and format primary data and metadata files for analysis\nLearn programming fundamentals of the R statistical language, including objects, functions, iteration, and simulation.\nArticulate the importance of and requirements for reproducible science in bioinformatics.\nUtilize the UO’s supercomputer cluster, Talapas, for computationally intensive tasks.\n\nProbability and Exploratory Data Analysis\n\nDescribe the history of data analysis and statistics, particularly its eugenics origins.\nExplain probability in the context of distributions and sampling.\nDescribe the meaning of p-values, test statistics, and types of errors.\n\nStatistical Visualization\n\nProduce well-designed and informative figures in RStudio.\nMake publication-quality data visualizations, including scatterplots, boxplots, frequency distributions, mosaic plots, etc.\n\nPoint Estimation\n\nParameters and statistics\nConfidence intervals\nStatistical distributions\nT-statistics\n\nExperimental Design and Linear Models\n\nDesign experiments and clinical trials to produce the necessary types of data required to answer a given scientific question.\nUnderstand Type I and Type II statistical error, including p-values and power analysis.\nUnderstand ordinary least-squares regression and linear models in general\nLearn to apply general linear models to basic univariate analysis problems,including Analysis of Variance (ANOVA)\n\nApplication of Linear Models to Machine Learning\n\nxxx\nxxx\nxxx\n\nNonparameteric Statistics\n\nLearn nonparametric approaches to parameter estimate and statistical inference,\nincluding resampling (bootstrapping), permutation, and rank-based analysis.\nUnderstand how to analyze binary response variables and frequency-based (e.g. contingency table) data sets.\n\n\n/"
  },
  {
    "objectID": "about.html#instructor-information",
    "href": "about.html#instructor-information",
    "title": "About",
    "section": "Instructor information",
    "text": "Instructor information\n\n\n\nInstructor\nBill Cresko\n\n\nOffices\nM306 KC East Tower & Pacific 312\n\n\ne-mail\nwcresko@uoregon.edu"
  },
  {
    "objectID": "about.html#class-information",
    "href": "about.html#class-information",
    "title": "About",
    "section": "Class information",
    "text": "Class information\n\n\n\nClass times\nTuesday/Thursday 4:00 to 5:50\n\n\nClass room\nKC158\n\n\nOffice Hours\nMonday 3:30 to 4:30\n\n\nOffice hour location\nTBD"
  },
  {
    "objectID": "about.html#course-structure",
    "href": "about.html#course-structure",
    "title": "About the Course",
    "section": "Course Structure",
    "text": "Course Structure\nWe will hold on Tuesdays and Thursdays from 4:00PM to 5:50PM. These meetings will be relatively informal, and will usually begin with a 20-30 min. review of the most salient topics from the course book, possibly including some R coding demonstrations. I will post all lecture slides as Markdown and HTML after class to the course website under the ‘Lectures’ tab. The remaining meeting time will be reserved for questions, answers, and discussion (similar to a “recitation”, or additional “office hours”). I encourage students to work on exercises and assignments during these periods so that questions can be directly addressed as they emerge."
  },
  {
    "objectID": "Syllabus.html#course-description",
    "href": "Syllabus.html#course-description",
    "title": "Syllabus",
    "section": "",
    "text": "This course in an introduction to data management, data visualization and statistical inference that is intended for early-stage bioengineering and bioscience graduate students with no background in statistics. This is a practical course with a foundation of conceptual intuition matched with hands-on coding each week. The primary objective of the course is to provide foundational training in the organization, manipulation, visualization, and analysis of data, using the R statistical language in a reproducible manner. After this course students will be able to analyze their own data sets with confidence using reasonable approaches, and to provide a foundation for more advanced courses in statistics, data science and machine learning. The course is designed to primarily for the analysis of univariate (single response variable) data. For students interested in multivariate analysis, other courses in Department of Data Science are available. Examples and assignments in class will largely be drawn from bioengineering and the life sciences."
  },
  {
    "objectID": "Syllabus.html#course-structure",
    "href": "Syllabus.html#course-structure",
    "title": "Syllabus",
    "section": "Course Structure",
    "text": "Course Structure\nWe will hold on Tuesdays and Thursdays from 4:00PM to 5:50PM. These meetings will be relatively informal, and will usually begin with a 30-45 min. conceptual overview of topics with R coding demonstrations. I will post all lecture slides as Markdown and HTML after class to the course website under the ‘Lectures’ tab. The remaining meeting time will be reserved for group work, questions, answers, and discussion (similar to a “recitation”, or additional “office hours”). I encourage students to work on exercises and assignments during these periods so that questions can be directly addressed as they emerge."
  },
  {
    "objectID": "Syllabus.html#course-objectives",
    "href": "Syllabus.html#course-objectives",
    "title": "Syllabus",
    "section": "Course Objectives",
    "text": "Course Objectives\n\nScientific Computing Fundamentals\n\nDescribe fundamental aspects of computer systems, including file types, storage structure, and the logic of programming languages.\nRead and write code in Unix.\nRead and write code in R using RStudio.\nProperly organize and format primary data and metadata files for analysis\nLearn programming fundamentals of the R statistical language, including objects, functions, iteration, and simulation.\nArticulate the importance of and requirements for reproducible science in bioinformatics.\nUtilize the UO’s supercomputer cluster, Talapas, for computationally intensive tasks.\n\nProbability and Exploratory Data Analysis\n\nDescribe the history of data analysis and statistics, particularly its eugenics origins.\nExplain probability in the context of distributions and sampling.\nDescribe the meaning of p-values, test statistics, and types of errors.\n\nStatistical Visualization\n\nProduce well-designed and informative figures in RStudio.\nMake publication-quality data visualizations, including scatterplots, boxplots, frequency distributions, mosaic plots, etc.\n\nPoint Estimation\n\nParameters and statistics\nConfidence intervals\nStatistical distributions\nT-statistics\n\nExperimental Design and Linear Models\n\nDesign experiments and clinical trials to produce the necessary types of data required to answer a given scientific question.\nUnderstand Type I and Type II statistical error, including p-values and power analysis.\nUnderstand ordinary least-squares regression and linear models in general\nLearn to apply general linear models to basic univariate analysis problems,including Analysis of Variance (ANOVA)\n\nApplication of Linear Models to Machine Learning\n\nExamining linear models as classical machine learning\nPrediction and estimation\nShrinkage and regularization\nCross-validation\n\nNonparameteric Statistics\n\nLearn nonparametric approaches to parameter estimate and statistical inference,\nincluding resampling (bootstrapping), permutation, and rank-based analysis.\nUnderstand how to analyze binary response variables and frequency-based (e.g. contingency table) data sets."
  },
  {
    "objectID": "Policies.html",
    "href": "Policies.html",
    "title": "Policies",
    "section": "",
    "text": "This is a 4-credit hour course, so you should expect to complete ~ 120 hours of work for the course—an average, or about 12 hours each week (this includes time in-class).\nMy estimate for time usage for activities and assignments in an average week is below – some weeks may have shorter or longer time commitments either by design or due to course scheduling.\n\n\n\nActivity\nHours per Week\n\n\n\n\nIn-class meetings\n3-4\n\n\nPre-class reading\n4\n\n\nInformal exercises\n1\n\n\nHomework assignments\n2\n\n\nResearch, drafting, editing for final project\n1\n\n\nTOTAL\n12"
  },
  {
    "objectID": "Schedule.html",
    "href": "Schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "I’ve started putting together out online textbook\nHere’s a link\n\n\n\n\n\nR for Data Science (RDS). 2025. Wickham, Çetinkaya-Rundel, and Grolemund. O’Reilly Press.\nModern Statistics with R (MSR). 2025. Måns Thulin, CRC Press.\nAn Introduction to Statistical Learning (ISLR). 2023. James, Witten, Hastie, Tibshirani. Springer\n\n\n\n\n\nModern Statistics for Modern Biology. 2019. Holmes and Huber. Cambridge University Press.\nggPlot2: Elegant Graphics for Data Analysis, 3rd Edition. Wickham, Navarro, Pedersen. Springer.\nThe Visual Display of Quantitative Information. Tufte, E.R. Graphics Press, Cheshire CT\n\n\n\n\n\nYou will be working on your own laptop computeri\nIf you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account\nLaTeX installed on your computer"
  },
  {
    "objectID": "Resources.html",
    "href": "Resources.html",
    "title": "Resources",
    "section": "",
    "text": "Base R Cheat Sheet\nRStudio Collection of Cheat Sheets\nGit Cheat Sheet\nMarkdown Cheat Sheet\nLaTeX Cheat Sheet"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#xxx",
    "href": "Lecture_Folder/Lecture_1.html#xxx",
    "title": "lecture_1 - placeholder",
    "section": "",
    "text": "x\nxx\nblue"
  },
  {
    "objectID": "Lecture_Folder/Lecture_1.html#xxx-1",
    "href": "Lecture_Folder/Lecture_1.html#xxx-1",
    "title": "lecture_1 - placeholder",
    "section": "xxx",
    "text": "xxx\n\nyy\ny\ngray"
  },
  {
    "objectID": "Syllabus.html#online-course-resources",
    "href": "Syllabus.html#online-course-resources",
    "title": "Syllabus",
    "section": "Online Course Resources",
    "text": "Online Course Resources\n\nWe will be using Canvas as well as this GitHub Pages website for the course.\nTo access our course Canvas site, log into canvas.uoregon.edu using your DuckID.\nIf you have questions about using Canvas, visit the Canvas support page.\nCanvas and Technology Support also is available by phone (541-346-4357) or by live chat."
  },
  {
    "objectID": "Syllabus.html#technical-requirements",
    "href": "Syllabus.html#technical-requirements",
    "title": "Syllabus",
    "section": "Technical Requirements",
    "text": "Technical Requirements\n\nYou will be working on your own laptop computer, but if you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)"
  },
  {
    "objectID": "Syllabus.html#graded-assignments",
    "href": "Syllabus.html#graded-assignments",
    "title": "Syllabus",
    "section": "Graded Assignments",
    "text": "Graded Assignments\nProblem sets: Students will be assigned four problem sets (roughly one every 2 weeks) to complete independently. These will mostly focus on one or a few data sets each, and the goal will be for the students to organize, visualize, analyze, and interpret the data sets in light of specific scientific motivations. - 80% of grade.\nTerm project: Students will choose to analyze a dataset of their choice from their own research. The goal of this project is allow students agency in applying what they are learning in class to their own data, and to format the results in an appropriate Rmarkdown or Quarto document that can form the nucleus of a subsequent publication - 20% of grade.\nPreparing and submitting assignments: The information required to complete all in-class assignments and problem sets will be given in instructions on Canvas. Students should carefully follow the detailed instructions associated with each assignment. Students are encouraged to work together and share information. In particular, some students will have a higher skill level than others, and we encourage those students with more experience to help their peers. However, no direct sharing of code is allowed.\nPreparing and submitting assignments: Assignments will be submitted on Canvas in the form of Quarto files, with the rendered html output. Be sure to include your name on the document. Be professional – appropriately name your files, make sure they are organized, and submit only the information requested. Late assignments will not be accepted.\n\nGrading\n\n\n\nAssignment\nPercentage of Total Grade\n\n\n\n\nProblem Sets - 4 in total, 20% each\n80%\n\n\nTerm-long Projects\n20%\n\n\n\n\n\n\nGrade Percentage\nLetter Grade\nPass/No Pass Grade\n\n\n\n\n100% - 90%\nA\nPass\n\n\n89% - 80%\nB\nPass\n\n\n79% - 80%\nC\nNo Pass\n\n\n69% - 60%\nD\nNo Pass\n\n\n60% - 0%\nF\nNo Pass"
  },
  {
    "objectID": "Syllabus.html#grading",
    "href": "Syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\n\n\n\nAssignment\nPercentage of Total Grade\n\n\n\n\nProblem Sets - 4 in total, 20% each\n80%\n\n\nTerm-long Projects\n20%\n\n\n\n\n\n\nGrade Percentage\nLetter Grade\nPass/No Pass Grade\n\n\n\n\n100% - 90%\nA\nPass\n\n\n89% - 80%\nB\nPass\n\n\n79% - 80%\nC\nNo Pass\n\n\n69% - 60%\nD\nNo Pass\n\n\n60% - 0%\nF\nNo Pass"
  },
  {
    "objectID": "Schedule.html#books-reading-materials-and-tools",
    "href": "Schedule.html#books-reading-materials-and-tools",
    "title": "Schedule",
    "section": "",
    "text": "R for Data Science (RDS). 2025. Wickham, Çetinkaya-Rundel, and Grolemund. O’Reilly Press.\nModern Statistics with R (MSR). 2025. Måns Thulin, CRC Press.\nAn Introduction to Statistical Learning (ISLR). 2023. James, Witten, Hastie, Tibshirani. Springer\n\n\n\n\n\nModern Statistics for Modern Biology. 2019. Holmes and Huber. Cambridge University Press.\nggPlot2: Elegant Graphics for Data Analysis, 3rd Edition. Wickham, Navarro, Pedersen. Springer.\nThe Visual Display of Quantitative Information. Tufte, E.R. Graphics Press, Cheshire CT\n\n\n\n\n\nYou will be working on your own laptop computer, but if you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)"
  },
  {
    "objectID": "Schedule.html#course-schedule",
    "href": "Schedule.html#course-schedule",
    "title": "Schedule",
    "section": "Course schedule",
    "text": "Course schedule\n\n\n\nWeek\nDates\nTopics\nReadings\nAssignments\n\n\n\n\n1\nApril1/3\n\nUnix & shell commands\nR scripts & reproducible analysis\nUse of GenAI\nTidy data and data wrangling\nGit, GitHub & Markdown\nSundry history of statistics\n\n\nRDS: 1-8; 27-29\nMSR: 1-2\nHappy Git\n\n\n\n\n2\nApril8/10\n\nExploratory data analysis\nData visualization\nParameters & statistics\nProbability distributions\nEstimates & confidence intervals\nClinical trials & experimental design\n\n\nRDS: 9-11\nMSR: 3-5\n\n\n\n\n3\nApril15/17\n\nHypothesis testing & significance\nType I & II errors\nT-tests\n\n\nMSR: 6-7\n\nHW1 Due\n\n\n4\nApril22/24\n\nFrequency analyses\nContingency tests\nNon-parametric tests\n\n\n\n\n\n5\nApril29/May1\n\nCorrelation & covariance\nOrdinary Linear Models (OLMs)\nSimple linear regression\n\n\nMSR: 8\n\nHW2 Due\n\n\n6\nMay 6/8\n\nAnalysis of Variance (ANOVA)\nSingle factor ANOVA\nPlanned & post hoc comparisons\n\n\nMSR: 8\n\n\n\n\n7\nMay 13/15\n\nMultiple factor ANOVA\nFactorial & Nested ANOVA\nRandom effects\n\n\nMSR: 8\n\nHW3 Due\n\n\n8\nMay 20/22\n\nHierarchical & mixed models\nGeneralized Linear Models (GLMs)\nLogistic & Poisson regression\n\n\nISLR: 1-3\n\n\n\n\n9\nMay 27/29\n\nIntro to statistical learning\nClassification & prediction\nValidation\nSimulation in statistics\n\n\nMSR: 11\nISLR: 4-6\n\nHW4 Due\n\n\n10\nJune 3/5\n\nRemote super computing\nTalapas and SLURM\nAWS Azure\n\n\n\n\n\n11\n10 June\nFINALS WEEK\n\nProject Due"
  },
  {
    "objectID": "Schedule.html#reading-materials-and-tools",
    "href": "Schedule.html#reading-materials-and-tools",
    "title": "Schedule",
    "section": "",
    "text": "I’ve started putting together out online textbook\nHere’s a link\n\n\n\n\n\nR for Data Science (RDS). 2025. Wickham, Çetinkaya-Rundel, and Grolemund. O’Reilly Press.\nModern Statistics with R (MSR). 2025. Måns Thulin, CRC Press.\nAn Introduction to Statistical Learning (ISLR). 2023. James, Witten, Hastie, Tibshirani. Springer\n\n\n\n\n\nModern Statistics for Modern Biology. 2019. Holmes and Huber. Cambridge University Press.\nggPlot2: Elegant Graphics for Data Analysis, 3rd Edition. Wickham, Navarro, Pedersen. Springer.\nThe Visual Display of Quantitative Information. Tufte, E.R. Graphics Press, Cheshire CT\n\n\n\n\n\nYou will be working on your own laptop computeri\nIf you would like to borrow a laptop let me know.\nLatest version of R (install here)\nLatest version of RStudio (install here)\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account\nLaTeX installed on your computer"
  },
  {
    "objectID": "about.html#online-course-resources",
    "href": "about.html#online-course-resources",
    "title": "About",
    "section": "Online Course Resources",
    "text": "Online Course Resources\n\nWe will be using Canvas as well as this GitHub Pages website (https://wcresko.github.io/BioE_Stats/).\nTo access our course Canvas site, log into canvas.uoregon.edu using your DuckID.\nIf you have questions about using Canvas, visit the Canvas support page.\nCanvas and Technology Support also is available by phone (541-346-4357) or by live chat."
  },
  {
    "objectID": "about.html#technical-requirements",
    "href": "about.html#technical-requirements",
    "title": "About",
    "section": "Technical Requirements",
    "text": "Technical Requirements\n\nYou will be working on your own laptop computer.\nIf you would like to borrow a laptop let me know.\nLatest version of R (install here).\nLatest version of RStudio (install here).\nA terminal that allows ssh connection to the UO computing cluster (Talapas)."
  },
  {
    "objectID": "Policies.html#workload-expectations",
    "href": "Policies.html#workload-expectations",
    "title": "Policies",
    "section": "",
    "text": "This is a 4-credit hour course, so you should expect to complete ~ 120 hours of work for the course—an average, or about 12 hours each week (this includes time in-class).\nMy estimate for time usage for activities and assignments in an average week is below – some weeks may have shorter or longer time commitments either by design or due to course scheduling.\n\n\n\nActivity\nHours per Week\n\n\n\n\nIn-class meetings\n3-4\n\n\nPre-class reading\n4\n\n\nInformal exercises\n1\n\n\nHomework assignments\n2\n\n\nResearch, drafting, editing for final project\n1\n\n\nTOTAL\n12"
  },
  {
    "objectID": "Policies.html#communication",
    "href": "Policies.html#communication",
    "title": "Policies",
    "section": "Communication",
    "text": "Communication\n\nElectronic\n\nOur class will communicate through our Canvas site. Announcements and emails are archived there, automatically forwarded to your UO email, and can even reach you by text. Check and adjust your settings under Account &gt; Notifications.\nWe will also be using this GitHub Pages website (https://wcresko.github.io/BioE_Stats/) for the course as the repository for lecture schedule, syllabus, lecture slides and other materials.\nEvery Monday I will post an Announcement that previews critical concepts we’ll work on that week and a checklist of the week’s due dates.\nI will contact individual students when needed through email, and I try to respond to questions within one business day.\nWhen giving feedback on assignments, I do so in Canvas, and turnaround time for feedback is generally one week.\n\n\n\nOffice hours\n\nI will host office hours each week on Monday and from 3:30 to 4:30. The end of many class periods will also function as a form of office hour.\nI welcome meetings outside my regular office hours as well - please email me to set a time.\nDuring office hours, students bring in a wide range of concerns, questions, and successes. We might\n\ntalk through a specific concept or problem to clarify it\nthink together about an issue a student is curious about that relates to the class\ndiscuss a student’s post-graduation goals\nidentify more supportive methods to study for a future exam or to begin a project\nor any number of other topics"
  },
  {
    "objectID": "Policies.html#classroom-community-expectations",
    "href": "Policies.html#classroom-community-expectations",
    "title": "Policies",
    "section": "Classroom Community Expectations",
    "text": "Classroom Community Expectations\n\nParticipate and Contribute:\nAll students are expected to participate by sharing ideas and contributing to the learning environment. This entails preparing, following instructions, and engaging respectfully and thoughtfully with others. While all students should participate, participation is not just talking, and a range of participation activities support learning. Participation might look like speaking aloud in the full class and in small groups, and working collaboratively on coding projects. We will establish more specific participation guidelines and criteria for contributions in our first weeks of the term.\n\n\nExpect and Respect Diversity\nAll classes at the University of Oregon welcome and respect diverse experiences, perspectives, and approaches. What is not welcome are behaviors or contributions that undermine, demean, or marginalize others based on race, ethnicity, gender, sex, age, sexual orientation, religion, ability, or socioeconomic status. We will value differences and communicate disagreements with respect. We may establish more specific guidelines and protocols to ensure inclusion and equity for all members of our learning community.\n\n\nHelp Everyone Learn\nPart of how we learn together is by learning from one another. To do this effectively, we need to be patient with each other, identify ways we can assist others, and be open-minded to receiving help and feedback from others. Don’t hesitate to contact me to ask for assistance or offer suggestions that might help us learn better."
  },
  {
    "objectID": "Policies.html#generative-artificial-intelligence-genai-use",
    "href": "Policies.html#generative-artificial-intelligence-genai-use",
    "title": "Policies",
    "section": "Generative Artificial Intelligence (GenAI) Use",
    "text": "Generative Artificial Intelligence (GenAI) Use\nStudents can use GenAI tools in this class to help with certain aspects of coding. We will discuss during the first week how GenAI can be a tool to help you, but it cannot replace your statistical intuition and knowledge. However, you cannot use content such as text, graphics and code created by GenAI tools in your work. You must be the author/creator of your work submissions. For example, you can use a GenAI tool to suggest a paper outline based on a draft you provide it, or suggest some code, but you cannot submit a paper with text or code generated by GenAI as if the text or code is your own writing. If you are in doubt or have questions about a particular GenAI tool and if its use is okay, check in with me and let’s discuss!"
  },
  {
    "objectID": "Policies.html#university-course-policies",
    "href": "Policies.html#university-course-policies",
    "title": "Policies",
    "section": "University Course Policies",
    "text": "University Course Policies\nPlease read and make sure you are familiar with the important policies that apply to all UO courses, which can be found here."
  },
  {
    "objectID": "Software.html",
    "href": "Software.html",
    "title": "Software",
    "section": "",
    "text": "Latest version of R\nLatest version of RStudio\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account for version control and collaboration\nLaTeX installed on your computer for mathematical typesetting"
  },
  {
    "objectID": "Software.html#software-tools-to-install",
    "href": "Software.html#software-tools-to-install",
    "title": "Software",
    "section": "",
    "text": "Latest version of R\nLatest version of RStudio\nA terminal that allows ssh connection to the UO computing cluster (Talapas)\nGit installed and a GitHub account for version control and collaboration\nLaTeX installed on your computer for mathematical typesetting"
  },
  {
    "objectID": "Software.html#r-and-rstudio",
    "href": "Software.html#r-and-rstudio",
    "title": "Software",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nLatest version of R (install here)\nLatest version of RStudio (install here)"
  },
  {
    "objectID": "Software.html#accessing-the-shell-via-a-terminal-application",
    "href": "Software.html#accessing-the-shell-via-a-terminal-application",
    "title": "Software",
    "section": "Accessing the shell via a terminal application",
    "text": "Accessing the shell via a terminal application\n\nMac or Linux users\n\nopen the native “Terminal” app on Mac or Linux\ninstall another terminal like “iTerm2”\n\n\n\nWindows users\n\nGuide: https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10#1-overview\nRun Windows PowerShell as administrator\nInstall WSL2 by typing wsl --install\nRestart your computer\nSearch for and install Ubuntu from Microsoft store app\nOR type wsl --install -d ubuntu on PowerShell to do both at once\n\n\n\nAccessing the shell on Windows\n\nOpen Ubuntu and set up a username and password\nDoes not have to match your login info for Windows\nRun sudo apt update then sudo apt upgrade to ensure everything is up to date\nWill need to create folders and files within your Ubuntu folder on your computer"
  },
  {
    "objectID": "Software.html#git-and-github",
    "href": "Software.html#git-and-github",
    "title": "Software",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\nLastest version of Git (install here)\nA GitHub account (information here)"
  },
  {
    "objectID": "Software.html#latex",
    "href": "Software.html#latex",
    "title": "Software",
    "section": "LaTeX",
    "text": "LaTeX\n\nLastest version of LaTeX (install here)"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html",
    "href": "Lecture_Folder/Week1a.html",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "",
    "text": "{height = “50”}"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#statistics-for-bioengineers",
    "href": "Lecture_Folder/Week1a.html#statistics-for-bioengineers",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "",
    "text": "{height = “50”}"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#goals-of-the-course",
    "href": "Lecture_Folder/Week1a.html#goals-of-the-course",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Goals of the course",
    "text": "Goals of the course\n\n\n\n\n\n\nThis is a practical course and we will learn by doing\n\n\n\n\nTeach fundamental skills for your scientific careers\nProvide a broad coverage of the core components of modern statistics\nProvide you with the computational tools necessary to carry out your work\nTo prepare you for more advanced statistics and programming education"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#class-introductions",
    "href": "Lecture_Folder/Week1a.html#class-introductions",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Class Introductions",
    "text": "Class Introductions\n\n\n\n\n\n\nWho are you?\n\n\n\n\nYour name\nYear in grad school\nHome lab or rotation lab\nWhat is your good news this week?\nWhat has your experience with programming/statistics been like?"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#what-will-you-learn",
    "href": "Lecture_Folder/Week1a.html#what-will-you-learn",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "What will you learn?",
    "text": "What will you learn?\n\n\nRead and write code in Unix and R\nImplement reproducible research practices through\n\nMarkdown\nGitHub\nTalapas and Amazon Web Services (AWS)"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#what-will-you-learn-1",
    "href": "Lecture_Folder/Week1a.html#what-will-you-learn-1",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "What will you learn?",
    "text": "What will you learn?\n\n\nExploratory data analysis and visualization\nProbability in the context of distributions and sampling\nExperimental design\np-values, test statistics, and types of errors\nStatistical analyses such as t-tests and contigency tests\nLinear and non-linear modeling\nClassical machine learning"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#class-logistics",
    "href": "Lecture_Folder/Week1a.html#class-logistics",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Class Logistics",
    "text": "Class Logistics\n\n\nMeet Tuesdays and Thursdays from 4:00pm - 5:50pm in KC158\n\nMost of class time will be hands-on coding practice, less time lecturing\n\nCoding and statistics practice via homework in Weeks 2-9\n\nAvailable Tuesday of that week, due before class on Tuesday in two weeks\n\nWeeks 10-11 you will complete a final coding project\n\nDesign script(s) that works with your research and interests using the skills you’ve learned this term"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#required-materials",
    "href": "Lecture_Folder/Week1a.html#required-materials",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Required Materials",
    "text": "Required Materials\n\nNo textbooks or purchases required\nAccess to a laptop or computer running Windows, MacOS, or Linux operating systems\nAn account on Talapas (through your lab, or through CBDS)\nAnnouncements and assignments posted on Canvas\nThe majority of course material on our class website https://wcresko.github.io/BioE_Stats/"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#section-5",
    "href": "Lecture_Folder/Week1a.html#section-5",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "",
    "text": "Note\n\n\n\n\nMac and Linux systems run using the same language, but previous versions of Windows lacks some of the basic features found on other systems\nTo help you practice and learn how to code in Unix, we will help you install some programs on your computer for running Unix\nR and RStudio should work on any computer"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#running-r",
    "href": "Lecture_Folder/Week1a.html#running-r",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Running R",
    "text": "Running R\n\nNeed to make sure that you have R installed\n\nlocally or on a server\nhttps://www.r-project.org\n\nCan run R from the command line\n\njust type R\ncan run it locally as well as on clusters"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#running-r-1",
    "href": "Lecture_Folder/Week1a.html#running-r-1",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Running R",
    "text": "Running R\n\nInstall an R Integrated Development Environment (IDE)\n\nRStudio: http://www.rstudio.com\nMakes working with R much easier, particularly for a new R user\nRun on Windows, Mac or Linux OS\nUse the RStudio Desktop Open Source (Free)"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#rstudio",
    "href": "Lecture_Folder/Week1a.html#rstudio",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#accessing-the-shell",
    "href": "Lecture_Folder/Week1a.html#accessing-the-shell",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Accessing the shell",
    "text": "Accessing the shell\n\nMac users: open the “Terminal” app, or use another app like ‘iTerm2’\nLinux users: open one of several “Terminal” apps\n\n\n\n\n\n\nWindows users have a little more work to do\n\n\n\nSee the next slides"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#accessing-the-shell-1",
    "href": "Lecture_Folder/Week1a.html#accessing-the-shell-1",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Accessing the shell",
    "text": "Accessing the shell\n\nWindows users\n\nGuide: https://ubuntu.com/tutorials/install-ubuntu-on-wsl2-on-windows-10#1-overview\nRun Windows PowerShell as administrator\nInstall WSL2 by typing wsl --install\nRestart your computer\nSearch for and install Ubuntu from Microsoft store app\nOR type wsl --install -d ubuntu on PowerShell to do both at once"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#accessing-the-shell-on-windows",
    "href": "Lecture_Folder/Week1a.html#accessing-the-shell-on-windows",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Accessing the shell on Windows",
    "text": "Accessing the shell on Windows\n\nOpen Ubuntu and set up a username and password\nDoes not have to match your login info for Windows\nRun sudo apt update then sudo apt upgrade to ensure everything is up to date\nWill need to create folders and files within your Ubuntu folder on your computer"
  },
  {
    "objectID": "Lecture_Folder/Week1a.html#terminal-in-rstudio",
    "href": "Lecture_Folder/Week1a.html#terminal-in-rstudio",
    "title": "Week 1a Statistics for Bioengineering",
    "section": "Terminal in RStudio",
    "text": "Terminal in RStudio\n\n\n\n\n\n\nImportant\n\n\n\nRStudio has a terminal pane all it's own that you can use"
  },
  {
    "objectID": "Resources.html#week-1",
    "href": "Resources.html#week-1",
    "title": "Resources",
    "section": "",
    "text": "Data_Set_1"
  },
  {
    "objectID": "Resources.html#cheat-sheets",
    "href": "Resources.html#cheat-sheets",
    "title": "Resources",
    "section": "",
    "text": "Base R Cheat Sheet\nRStudio Collection of Cheat Sheets\nGit Cheat Sheet\nMarkdown Cheat Sheet\nLaTeX Cheat Sheet"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-do-we-need-coding-and-scripting",
    "href": "Lecture_Folder/Week1b.html#why-do-we-need-coding-and-scripting",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "",
    "text": "It is incredibly fast and powerful, particularly for repeated actions\nIt allows you to do thousands of ‘clicks’ with single commands\nAbility to analyze large datasets that Excel and other GUIs can’t handle well\nAccess to thousands of free programs made for and by scientists\nThe commands work almost identically across platforms\nAbility to use computer clusters like Talapas"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#what-is-the-difference-between-coding-and-scripting",
    "href": "Lecture_Folder/Week1b.html#what-is-the-difference-between-coding-and-scripting",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "",
    "text": "coding generally involves computer languages that use compilers\n\nC^{++}, Fortran, etc\n\nscripting generally involves computer languages that are interpreted on the fly\n\nPython, R, Julia, etc.\n\ncoding - faster but less flexible; scripting - flexible but slower\nThe distinction between the two has become somewhat fuzzy and most modern analytical pipelines contain a combination of both"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-do-we-need-statistics",
    "href": "Lecture_Folder/Week1b.html#why-do-we-need-statistics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "",
    "text": "We almost never know the world perfectly, but still want to draw conclusions or make decisions\nWe need to estimate underlying parameters from samples of data\nSometimes we need to test hypotheses using data\nOther times we need to more succinctly summarize and/or visualize large amounts of data\nThere are well known mathematical rules that help us\nStatistics can be done by hand, but computers let us do most of the mathematics quickly"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-do-we-need-statistics-1",
    "href": "Lecture_Folder/Week1b.html#why-do-we-need-statistics-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "",
    "text": "We want to turn data into conclusions about the world\n\npoint estimates and confidence intervals\nexperimental design\nhypothesis testing\ndata reduction of highly dimensional data\n\nWe need a firm understanding of probability, sampling and distributions"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#what-is-unix",
    "href": "Lecture_Folder/Week1b.html#what-is-unix",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "What is Unix?",
    "text": "What is Unix?\n\n\nA scripting language developed in 1969, released in 1973\nServes as the base language for many programs and computers\nIs the operating system for computers\nLinux is an open-source version of the same language"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#what-is-a-shell",
    "href": "Lecture_Folder/Week1b.html#what-is-a-shell",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "What is a shell?",
    "text": "What is a shell?\n\nThe ‘shell’ is a program that runs UNIX and takes in commands and gives them to the operating system\nBash acts as the shell in macs, linux, and now windows\nYou can access the shell via a terminal window"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#recipes-for-a-shell-command",
    "href": "Lecture_Folder/Week1b.html#recipes-for-a-shell-command",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Recipes for a shell command",
    "text": "Recipes for a shell command\n\nPrompt: notation used to indicate your computer is ready to accept a new command\nCommand: the building blocks of programming, tell computer to do a specific task\nOptions: change the behavior of a command\nArgument: what the command should operate on"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-use-the-shell",
    "href": "Lecture_Folder/Week1b.html#why-use-the-shell",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why use the shell?",
    "text": "Why use the shell?\n\n\nSpeed\nExamine large and/or unique files\nAccess super computers\nUse programs only available via shell\nThe commands work almost identically across platforms\nYou can even use them on a large computer cluster like Talapas\nIt is incredibly powerful particularly for repeated actions\nIt allows you to do thousands of ‘clicks’ with single commands"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#where-do-you-get-help",
    "href": "Lecture_Folder/Week1b.html#where-do-you-get-help",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Where do you get help?",
    "text": "Where do you get help?\n\nManual pages!\n\nThe shell has manuals for all basic commands\nType man [command_name] to access the manual for a specific command\nType q to exit\n\nAlso…the internet!"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#common-navigation-commands-1",
    "href": "Lecture_Folder/Week1b.html#common-navigation-commands-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Common navigation commands",
    "text": "Common navigation commands"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#the-way-you-normally-navigate",
    "href": "Lecture_Folder/Week1b.html#the-way-you-normally-navigate",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "The way you normally navigate",
    "text": "The way you normally navigate"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#how-is-a-computer-organized",
    "href": "Lecture_Folder/Week1b.html#how-is-a-computer-organized",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "How is a computer organized?",
    "text": "How is a computer organized?\n\nSystem of directories (folders) and files\n/ = the root directory, which holds all other directories\nMost of your files will be located under /Users in a directory of your username\nthe ~ is shorthand for your home folder\nNavigation in the shell consists of jumping up and down between directories and seeing what’s in them\nThe “path” refers to the location a file is in\n\nex: “/Users/wcresko/Documents”"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#common-navigation-commands-2",
    "href": "Lecture_Folder/Week1b.html#common-navigation-commands-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Common navigation commands",
    "text": "Common navigation commands\n\n\npwd = “print working directory”, which will print where you currently are in the system\n\nIn Windows, cd will print your working directory\n\nls = “list”, list all directories and files in your current position\n\nls –F = denote which results are directories, files, etc.\nls –l = ”long format”, lists total file sizes\nls –r = “reverse”, lists the results in reverse order\nls –S = “size”, sort results by size\nls –t = “time”, sort results by time created, from most recent to last"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#common-navigation-commands-3",
    "href": "Lecture_Folder/Week1b.html#common-navigation-commands-3",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Common Navigation Commands",
    "text": "Common Navigation Commands\n\ncd = “change directory”, will place you in a new position based on your path argument\n\ncd .. = go up one directory\ncd – = go to the directory you were at last (like the back arrow on an internet browser)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#lets-practice",
    "href": "Lecture_Folder/Week1b.html#lets-practice",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Let’s practice!",
    "text": "Let’s practice!\n\nTry navigating around your computer using cd and ls\nIf you are on Ubuntu, you may need to create some empty directories in your Ubuntu folder before navigating in the terminal"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#making-new-files",
    "href": "Lecture_Folder/Week1b.html#making-new-files",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Making new files",
    "text": "Making new files\n\n\nMake new folders: mkdir\nMake new files: nano, touch\nRename files: mv\nMove files: mv\nCopy files: cp\nDelete files: rm\nExamining file length: wc\nReading files: cat\nLooking at beginning or end: head or tail"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#things-to-keep-in-mind",
    "href": "Lecture_Folder/Week1b.html#things-to-keep-in-mind",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Things to keep in mind",
    "text": "Things to keep in mind\n\nThe shell trusts you\n\nIt will delete files you say to delete\nIt will override files if you name 2 things the same\n\nNaming conventions\n\nAvoid spaces\nDon’t start with a –\nStick to letters, numbers, . , -, and _\n\nUse appropriate file extensions in file names\n\nSome software expect files with certain extensions (.fasta, .txt, etc.)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#lets-try-it-out",
    "href": "Lecture_Folder/Week1b.html#lets-try-it-out",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nMake a new directory called whatever you’d like.\nAdd a file named “Practice.txt” to the directory and add some text to it\nRead the contents of the file and get its length\nRename the file to “Super_practice.txt”\nMove the file to a new folder named “Testing”\nMake a copy of the file named “Super_practice_copy.txt”\nRead the contents of the file and get its length to make sure it’s the same as Super_practice.txt\nDelete the original “Super_practice.txt”"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#break",
    "href": "Lecture_Folder/Week1b.html#break",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Break",
    "text": "Break"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#an-example-to-get-us-started",
    "href": "Lecture_Folder/Week1b.html#an-example-to-get-us-started",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "An example to get us started",
    "text": "An example to get us started"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#data-set-rules-of-thumb-aka-tidy-data",
    "href": "Lecture_Folder/Week1b.html#data-set-rules-of-thumb-aka-tidy-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Data set rules of thumb (aka Tidy Data)",
    "text": "Data set rules of thumb (aka Tidy Data)\n\nStore a copy of data in nonproprietary software and hardware formats, such as plain ASCII text (aka a flat file)\nLeave an uncorrected file when doing analyses\nUse descriptive names for your data files and variables\nInclude a header line with descriptive variable names\nMaintain effective metadata about the data\nWhen you add observations to a database, add rows\nWhen you add variables to a database, add columns, not rows\nA column of data should contain only one data type"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#computational-tools---r-and-rstudio",
    "href": "Lecture_Folder/Week1b.html#computational-tools---r-and-rstudio",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Computational Tools - R and RStudio",
    "text": "Computational Tools - R and RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-use-r",
    "href": "Lecture_Folder/Week1b.html#why-use-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nGood general scripting tool for statistics and mathematics\nPowerful and flexible and free\nRuns on all computer platforms\nNew enhancements coming out all the time\nSuperb data management & graphics capabilities"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#why-use-r-1",
    "href": "Lecture_Folder/Week1b.html#why-use-r-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nReproducibility - can keep your scripts to see exactly what was done\nYou can write your own functions\nLots of online help available\nCan use a nice GUI front end such as Rstudio\nCan embed your R analyses in dynamic, polished files using Markdown\nMarkdown can be reused for websites, papers, books, presentations…"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#r-scripts-and-markdown-files",
    "href": "Lecture_Folder/Week1b.html#r-scripts-and-markdown-files",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "R scripts and Markdown files",
    "text": "R scripts and Markdown files\n\nOften we want to write scripts that can just be run\nWe can also embed code in Markdown files that provide more annotations\nhttps://quarto.org/docs/authoring/markdown-basics.html\nYou can insert Rchunks into Quarto markdown documents"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#rscript-basics",
    "href": "Lecture_Folder/Week1b.html#rscript-basics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Rscript basics",
    "text": "Rscript basics\n\nA series of R commands that will be executed\nCan add comments using hashtags #\nCan have pipes (|&gt;) to connect one step to the next"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#markdown-basics",
    "href": "Lecture_Folder/Week1b.html#markdown-basics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Markdown basics",
    "text": "Markdown basics\n\na very simplified way for standard typesetting\nsimple markdown can be rendered in numerous different ways\nLists, codeblocks, images and more can all be inserted"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#inserting-equations-in-markdown",
    "href": "Lecture_Folder/Week1b.html#inserting-equations-in-markdown",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Inserting equations in markdown",
    "text": "Inserting equations in markdown\n$$e=mc^2$$\n\\[e=mc^2\\]\n$$\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy$$\n\\[\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy\\]"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#basics-of-r",
    "href": "Lecture_Folder/Week1b.html#basics-of-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "BASICS of R",
    "text": "BASICS of R\n\nCommands can be submitted through the terminal, console or scripts\nIn your scripts, anything that follows ‘#’ symbol (aka hash) is just for humans\nNotice on these slides I’m evaluating the code chunks and showing output\nThe output is shown here after the two # symbols and the number of output items is in []\nAlso notice that R follows the normal priority of mathematical evaluation\n\n\n4*4\n\n[1] 16\n\n\n\n(4+3*2^2)\n\n[1] 16"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#assigning-variables",
    "href": "Lecture_Folder/Week1b.html#assigning-variables",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nA better way to do this is to assign variables\nVariables are assigned values using the &lt;- operator.\nVariable names must begin with a letter, but other than that, just about anything goes.\nDo keep in mind that R is case sensitive."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#assigning-variables-1",
    "href": "Lecture_Folder/Week1b.html#assigning-variables-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nx &lt;- 2\nx*3\n\n[1] 6\n\ny &lt;- x * 3\ny-2\n\n[1] 4\n\n\nThese do not work\n\n3y &lt;- 3\n3*y &lt;- 3"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions",
    "href": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\nArithmetic operations can be performed easily on functions as well as numbers.\nTry the following, and then your own.\n\n\nx+2\nx^2\nlog(x)\n\n\nNote that the last of these - log - is a built in function of R, and therefore the object of the function needs to be put in parentheses\nThese parentheses will be important, and we’ll come back to them later when we add arguments after the object in the parentheses\n\nThe outcome of calculations can be assigned to new variables as well, and the results can be checked using the ‘print’ command"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions-1",
    "href": "Lecture_Folder/Week1b.html#arithmetic-operations-on-functions-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\ny &lt;- 67\nprint(y)\n\n[1] 67\n\nx &lt;- 124\nz &lt;- (x*y)^2\nprint(z)\n\n[1] 69022864"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#strings",
    "href": "Lecture_Folder/Week1b.html#strings",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nVariables and operations can be performed on characters as well\nNote that characters need to be set off by quotation marks to differentiate them from numbers\nThe c stands for concatenate\nNote that we are using the same variable names as we did previously, which means that we’re overwriting our previous assignment\nA good rule of thumb is to use new names for each variable, and make them short but still descriptive"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#strings-1",
    "href": "Lecture_Folder/Week1b.html#strings-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nx &lt;- \"I Love\"\nprint (x)\n\n[1] \"I Love\"\n\ny &lt;- \"Biostatistics\"\nprint (y)\n\n[1] \"Biostatistics\"\n\nz &lt;- c(x,y)\nprint (z)\n\n[1] \"I Love\"        \"Biostatistics\""
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#factors",
    "href": "Lecture_Folder/Week1b.html#factors",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nThe variable z is now what is called a list of character values.\nSometimes we would like to treat the characters as if they were units for subsequent calculations.\nThese are called factors, and we can redefine our character variables as factors.\nThis might seem a bit strange, but it’s important for statistical analyses where we might want to see the mean or variance for two different treatments."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#factors-1",
    "href": "Lecture_Folder/Week1b.html#factors-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nz_factor &lt;- as.factor(z)\nprint (z_factor)\n\n\nNote that factor levels are reported alphabetically"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#vectors",
    "href": "Lecture_Folder/Week1b.html#vectors",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nIn general R thinks in terms of vectors (a list of characters, factors or numerical values) and it will benefit any R user to try to write programs with that in mind, as it will simplify most things.\nVectors can be assigned directly using the ‘c()’ function and then entering the exact values."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#vectors-1",
    "href": "Lecture_Folder/Week1b.html#vectors-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nx &lt;- c(2,3,4,2,1,2,4,5,10,8,9)\nprint(x)\n\n [1]  2  3  4  2  1  2  4  5 10  8  9"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#basic-statistics",
    "href": "Lecture_Folder/Week1b.html#basic-statistics",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nMany functions exist to operate on vectors.\nCombine these with your previous variable to see what happens.\nAlso, try to find other functions (e.g. standard deviation)."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#basic-statistics-1",
    "href": "Lecture_Folder/Week1b.html#basic-statistics-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nmean(x)\nmedian(x)\nvar(x)\nlog(x)\nln(x)\nsqrt(x)\nsum(x)\nlength(x)\nsample(x, replace = T)\n\n\nNotice that the last function (sample) has an argument (replace=T)\nArguments simply modify or direct the function in some way\nThere are many arguments for each function, some of which are defaults"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#getting-help",
    "href": "Lecture_Folder/Week1b.html#getting-help",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\nGetting Help on any function is very easy - just type a question mark and the name of the function.\nThere are functions for just about anything within R and it is easy enough to write your own functions if none already exist to do what you want to do.\nIn general, function calls have a simple structure: a function name, a set of parentheses and an optional set of parameters to send to the function.\nHelp pages exist for all functions that, at a minimum, explain what parameters exist for the function.\n\nHelp can be accessed a few ways - try them :"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#getting-help-1",
    "href": "Lecture_Folder/Week1b.html#getting-help-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\n- help(mean)\n- ?mean\n- example(mean)\n- help.search(\"mean\")\n- apropos(\"mean\")\n- args(mean)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors",
    "href": "Lecture_Folder/Week1b.html#creating-vectors",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nCreating vector of new data by entering it by hand can be a drag\nHowever, it is also very easy to use functions such as seq and sample\nTry the examples below Can you figure out what the three arguments in the parentheses mean?\nTry varying the arguments to see what happens.\nDon’t go too crazy with the last one or your computer might slow way down"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors-1",
    "href": "Lecture_Folder/Week1b.html#creating-vectors-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nprint(seq_1)\n\n  [1]  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.0  1.1  1.2  1.3  1.4\n [16]  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9\n [31]  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.0  4.1  4.2  4.3  4.4\n [46]  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9\n [61]  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.0  7.1  7.2  7.3  7.4\n [76]  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4  8.5  8.6  8.7  8.8  8.9\n [91]  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9 10.0\n\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)\nprint(seq_2)\n\n  [1] 10.0  9.9  9.8  9.7  9.6  9.5  9.4  9.3  9.2  9.1  9.0  8.9  8.8  8.7  8.6\n [16]  8.5  8.4  8.3  8.2  8.1  8.0  7.9  7.8  7.7  7.6  7.5  7.4  7.3  7.2  7.1\n [31]  7.0  6.9  6.8  6.7  6.6  6.5  6.4  6.3  6.2  6.1  6.0  5.9  5.8  5.7  5.6\n [46]  5.5  5.4  5.3  5.2  5.1  5.0  4.9  4.8  4.7  4.6  4.5  4.4  4.3  4.2  4.1\n [61]  4.0  3.9  3.8  3.7  3.6  3.5  3.4  3.3  3.2  3.1  3.0  2.9  2.8  2.7  2.6\n [76]  2.5  2.4  2.3  2.2  2.1  2.0  1.9  1.8  1.7  1.6  1.5  1.4  1.3  1.2  1.1\n [91]  1.0  0.9  0.8  0.7  0.6  0.5  0.4  0.3  0.2  0.1  0.0"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors-2",
    "href": "Lecture_Folder/Week1b.html#creating-vectors-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square &lt;- (seq_2)*(seq_2)\nprint(seq_square)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-vectors-3",
    "href": "Lecture_Folder/Week1b.html#creating-vectors-3",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square_new &lt;- (seq_2)^2\nprint(seq_square_new)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nHere is a way to create your own data sets that are random samples.\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-1",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(x,y)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-2",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(xy)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-3",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-3",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nhist(x)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-4",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-4",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nYou’ve probably figured out that y from the last example is drawing numbers with equal probability.\nWhat if you want to draw from a distribution?\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-5",
    "href": "Lecture_Folder/Week1b.html#drawing-samples-from-distributions-5",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;-rnorm(1000, 0, 100)\nhist(x, xlim = c(-500,500))\ncurve(50000*dnorm(x, 0, 100), xlim = c(-500,500), add=TRUE, col='Red')\n\n\n\n\n\n\n\n\n\ndnorm() generates the probability density, which can be plotted using the curve() function.\nNote that is curve is added to the plot using add=TRUE"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#visualizing-data",
    "href": "Lecture_Folder/Week1b.html#visualizing-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nSo far you’ve been visualizing just the list of output numbers\nExcept for the last example where I snuck in a hist function.\nYou can also visualize all of the variables that you’ve created using the plot function (as well as a number of more sophisticated plotting functions).\nEach of these is called a high level plotting function, which sets the stage\nLow level plotting functions will tweak the plots and make them beautiful"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#visualizing-data-1",
    "href": "Lecture_Folder/Week1b.html#visualizing-data-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nWhat do you think that each of the arguments means for the plot function?\nA cool thing about R is that the options for the arguments make sense.\nTry adjusting an argument and see if it works\nNote next week we will be exploring the plotting in GGPlot2"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#visualizing-data-2",
    "href": "Lecture_Folder/Week1b.html#visualizing-data-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1) \nplot (seq_1, xlab=\"space\", ylab =\"function of space\", type = \"p\", col = \"red\")"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure",
    "href": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\nOn the next slide\nThe first line of the lower script tells R that you are going to create a composite figure that has two rows and two columns. Can you tell how?\nNow, modify the code to add two more variables and add one more row of two panels.\n\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure-1",
    "href": "Lecture_Folder/Week1b.html#putting-plots-in-a-single-figure-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\npar(mfrow=c(2,2))\nplot (seq_1, xlab=\"time\", ylab =\"p in population 1\", type = \"p\", col = 'red')\nplot (seq_2, xlab=\"time\", ylab =\"p in population 2\", type = \"p\", col = 'green')\nplot (seq_square, xlab=\"time\", ylab =\"p2 in population 2\", type = \"p\", col = 'blue')\nplot (seq_square_new, xlab=\"time\", ylab =\"p in population 1\", type = \"l\", col = 'yellow')"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#example-using-binomial-distribution",
    "href": "Lecture_Folder/Week1b.html#example-using-binomial-distribution",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nAs above for the normal distribution, data can be generated by being sampled from nearly any distribution and then visualized.\nBelow I’m having you use the ‘histogram’ function. What does it do?"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-1",
    "href": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\n10 successes (out of 20 trials) is the most frequent outcome\n\n\nheads &lt;- rbinom(n=1000, size=20, prob=0.5)\nhist(heads)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-2",
    "href": "Lecture_Folder/Week1b.html#example-using-binomial-distribution-2",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nThis kind of statement can be run in one line as well, which is sometimes easier.\n\n\nhist(rbinom(n=1000, size=20, prob=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#creating-data-frames-in-r",
    "href": "Lecture_Folder/Week1b.html#creating-data-frames-in-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Creating Data Frames in R",
    "text": "Creating Data Frames in R\n\nAs you have seen, in R you can generate your own random data set drawn from nearly any distribution very easily.\nOften we will want to use collected data.\nNow, let’s make a dummy dataset to get used to dealing with data frames\nSet up three variables (hydrogel_concentration, compression and conductivity) as vectors\n\n\nhydrogel_concentration &lt;- factor(c(\"low\", \"high\", \"high\", \"high\", \"medium\", \"medium\", \"medium\",\"low\"))\ncompression &lt;- c(3.4, 3.4, 8.4, 3, 5.6, 8.1, 8.3, 4.5)\nconductivity &lt;- c(0, 9.2, 3.8, 5, 5.6, 4.1, 7.1, 5.3)\n\n\nCreate a data frame where vectors become columns\n\n\nmydata &lt;- data.frame(hydrogel_concentration, compression, conductivity)\nrow.names(mydata) &lt;- c(\"Sample_1\", \"Sample_2\", \"Sample_3\", \"Sample_4\", \n                       \"Sample_5\", \"Sample_6\", \"Sample_7\", \"Sample_8\")\n\n\nNow you have a hand-made data frame with row names\nTake a look at it in the data section of RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r",
    "href": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nA strength of R is being able to import data from an external source\nCreate the same table that you did above in a spreadsheet like Excel\nExport it to comma separated and tab separated text files for importing into R.\nThe first will read in a comma-delimited file, whereas the second is a tab-delimited\nIn both cases the header and row.names arguments indicate that there is a header row and row label column\nNote that the name of the file by itself will have R look in the CWD, whereas a full path can also be used"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r-1",
    "href": "Lecture_Folder/Week1b.html#reading-in-data-frames-in-r-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nYourFile &lt;- read.table('yourfile.csv', header=T, row.names=1, sep=',')\nYourFile &lt;- read.table('yourfile.txt', header=T, row.names=1, sep='\\t')"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#exporting-data-frames-in-r",
    "href": "Lecture_Folder/Week1b.html#exporting-data-frames-in-r",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Exporting Data Frames in R",
    "text": "Exporting Data Frames in R\n\nwrite.table(YourFile, \"yourfile.csv\", quote=F, row.names=T, sep=\",\")\nwrite.table(YourFile, \"yourfile.txt\", quote=F, row.names=T, sep=\"\\t\")"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#indexing-in-data-frames",
    "href": "Lecture_Folder/Week1b.html#indexing-in-data-frames",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nNext up - indexing just a subset of the data\nThis is a very important idea in R, that you can analyze just a subset of the data.\nThis is analyzing only the data in the file you made that has the factor value ‘mixed’.\n\n\nprint (YourFile[,2])\nprint (YourFile$temp)\nprint (YourFile[2,])\nplot (YourFile$temp, YourFile$elevation)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#indexing-in-data-frames-1",
    "href": "Lecture_Folder/Week1b.html#indexing-in-data-frames-1",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nYou can perform operations on particular levels of a factor\nCalculating the mean of the ‘mixed’ and ‘gipps’ levels of habitat.\nNote that the first argument is the numerical column vector, and the second is the factor column vector.\nThe third is the operation. Reversing the first two does not work (the one below).\n\n\ntapply(YourFile$temp, YourFile$habitat, mean)\ntapply(YourFile$temp, YourFile$habitat, var)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#r-interlude-some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week1b.html#r-interlude-some-real-transcriptomic-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Some real transcriptomic data",
    "text": "R INTERLUDE | Some real transcriptomic data\n\nExamine the data file\nHow many many rows and columns are there?\nHow many different variables are there?\nWhat are the general types of variables?\nNow let’s read the data file into R and analyze it\nThis exercise will help you get used to reading in and manipulating genomic data files\nFirst off, remember to set your working directory to find your file correctly"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week1b.html#some-real-transcriptomic-data",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Some real transcriptomic data",
    "text": "Some real transcriptomic data\n\nRNAseq_Data &lt;- read.table('&lt;name_of_file&gt;', header=TRUE, sep=',')\n\nprint (RNAseq_Data)\nhead (RNAseq_Data)\ntail (RNAseq_Data)\n\nprint (RNAseq_Data[,2])\nprint (RNAseq_Data[1,])\nprint (RNAseq_Data[1,2])\nprint (RNAseq_Data$ENSGACG00000000010)\nprint (RNAseq_Data$ENSGACG00000000010&gt;45.0)"
  },
  {
    "objectID": "Lecture_Folder/Week1b.html#summary-stats-and-figures",
    "href": "Lecture_Folder/Week1b.html#summary-stats-and-figures",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "Summary stats and figures",
    "text": "Summary stats and figures\n\nsummary1 &lt;- summary(RNAseq_Data $ENSGACG00000000003)\nprint (summary1)\n\nhist(RNAseq_Data $ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003~RNAseq_Data$Population)\nplot(RNAseq_Data $ENSGACG00000000003, RNAseq_Data$ENSGACG00000000003)\n\nboxplot(RNAseq_Data $ENSGACG00000000003~RNAseq_Data$Treatment, \n        col = \"red\", ylab = \"Expression Level\", xlab = \"Treatment level\", \n        border =\"orange\", \n        main = \"Boxplot of variation in gene expression across microbiota treatments\")"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html",
    "href": "Lecture_Folder/Week2b.html",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "",
    "text": "Finish Markdown, Latex\nExploratory data analysis with ggplot2\nProbability and distributions\n\n\n\n\n\n\n\nNote\n\n\n\nHomeworks will be assigned this evening and be due in 2 weeks"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#today-we-will",
    "href": "Lecture_Folder/Week2b.html#today-we-will",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "",
    "text": "Finish Markdown, Latex\nExploratory data analysis with ggplot2\nProbability and distributions\n\n\n\n\n\n\n\nNote\n\n\n\nHomeworks will be assigned this evening and be due in 2 weeks"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-markdown",
    "href": "Lecture_Folder/Week2b.html#what-is-markdown",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is markdown?",
    "text": "What is markdown?\n\nLightweight formal markup languages are used to add formatting to plaintext documents\n\nAdding basic syntax to the text will make elements look different once rendered/knit\nAvailable in many base editors\n\nYou then need a markdown application with a markdown processor/parser to render your text files into something more exciting\n\nStatic and dynamic outputs!\npdf, HTML, presentations, websites, scientific articles, books etc"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-text",
    "href": "Lecture_Folder/Week2b.html#formatting-text",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting text",
    "text": "Formatting text\n\n*Italic* or _Italic_\n**Bold** or __Bold__\n\n\nItalic or Italic\nBold or Bold"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-text-1",
    "href": "Lecture_Folder/Week2b.html#formatting-text-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting text",
    "text": "Formatting text\n\n&gt; \"You know the greatest danger facing us is ourselves, an irrational fear of the unknown. \nBut there’s no such thing as the unknown — only things temporarily hidden, temporarily not understood.\"\n&gt;\n&gt; --- Captain James T. Kirk\n\n\n“You know the greatest danger facing us is ourselves, an irrational fear of the unknown. But there’s no such thing as the unknown — only things temporarily hidden, temporarily not understood.”\n— Captain James T. Kirk"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-lists",
    "href": "Lecture_Folder/Week2b.html#formatting-lists",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting lists",
    "text": "Formatting lists\n\n- list_element\n    - sub_list_element #double tab to indent\n    - sub_list_element #double tab to indent\n    - sub_list_element #double tab to indent\n- list_element\n    - sub_list_element #double tab to indent\n#note the space after each dash- this is important!\n\n\nlist_element\n\nsub_list_element\nsub_list_element\nsub_list_element\n\nlist_element\n\nsub_list_element"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#formatting-lists-1",
    "href": "Lecture_Folder/Week2b.html#formatting-lists-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Formatting lists",
    "text": "Formatting lists\n\n1. One\n2. Two\n3. Three\n4. Four\n\n\nOne\nTwo\nThree\nFour"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#inserting-images-or-urls",
    "href": "Lecture_Folder/Week2b.html#inserting-images-or-urls",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Inserting images or URLs",
    "text": "Inserting images or URLs\n\n[Link](https://commonmark.org/help/)\n![Image](https://i1.wp.com/evomics.org/wp-content/uploads/2012/07/20120115-IMG_0297.jpg)\n\nLink"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#including-code-chunks",
    "href": "Lecture_Folder/Week2b.html#including-code-chunks",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Including code chunks",
    "text": "Including code chunks\n\nx &lt;- 2\nx^2\n\n[1] 4"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-latex",
    "href": "Lecture_Folder/Week2b.html#what-is-latex",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is LaTeX?",
    "text": "What is LaTeX?\n\nPronounced «Lah-tech» or «Lay-tech» (to rhyme with «Bertolt Brecht»)\nA document preparation system for high-quality typesetting\nIt is most often used for medium-to-large technical or scientific documents\nCan be used for almost any form of publishing.\nTypesetting journal articles, technical reports, books, and slide presentations\nAllows for precise mathematical statements\nhttps://www.latex-project.org\nImportantly, LaTeX can be included right into Markdown documents"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#operators-and-symbols",
    "href": "Lecture_Folder/Week2b.html#operators-and-symbols",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Operators and Symbols",
    "text": "Operators and Symbols\n\n$$ \\large a^x, \\sqrt[n]{x}, \\vec{\\jmath}, \\tilde{\\imath}$$\n\n\\[ \\large a^x, \\sqrt[n]{x}, \\vec{\\jmath}, \\tilde{\\imath}\\]\n\n$$ \\large \\alpha, \\beta, \\gamma$$\n\n\\[ \\large \\alpha, \\beta, \\gamma\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#operators-and-symbols-1",
    "href": "Lecture_Folder/Week2b.html#operators-and-symbols-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Operators and Symbols",
    "text": "Operators and Symbols\n\n$$ \\large\\approx, \\neq, \\nsim $$\n\n\\[ \\large\\approx, \\neq, \\nsim \\]\n\n$$\\large \\partial, \\mathbb{R}, \\flat$$\n\n\\[\\large \\partial, \\mathbb{R}, \\flat\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#equations",
    "href": "Lecture_Folder/Week2b.html#equations",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Equations",
    "text": "Equations\nBinomial sampling equation\n\n$$\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}$$\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\nPoisson Sampling Equation\n\n$$\\large Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}$$\n\n\\[\\large Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#differential-equations",
    "href": "Lecture_Folder/Week2b.html#differential-equations",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Differential Equations",
    "text": "Differential Equations\n\n$$\\iint xy^2\\,dx\\,dy =\\frac{1}{6}x^2y^3$$\n\n\\[\\iint xy^2\\,dx\\,dy =\\frac{1}{6}x^2y^3\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#matrix-formulations",
    "href": "Lecture_Folder/Week2b.html#matrix-formulations",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Matrix formulations",
    "text": "Matrix formulations\n\n$$  \\begin{matrix}\n        -2 & 1 & 0 & 0 & \\cdots & 0  \\\\\n        1 & -2 & 1 & 0 & \\cdots & 0  \\\\\n        0 & 1 & -2 & 1 & \\cdots & 0  \\\\\n        0 & 0 & 1 & -2 & \\ddots & \\vdots \\\\\n        \\vdots & \\vdots & \\vdots & \\ddots & \\ddots & 1  \\\\\n        0 & 0 & 0 & \\cdots & 1 & -2\n    \\end{matrix} $$\n\n\\[  \\begin{matrix}\n        -2 & 1 & 0 & 0 & \\cdots & 0  \\\\\n        1 & -2 & 1 & 0 & \\cdots & 0  \\\\\n        0 & 1 & -2 & 1 & \\cdots & 0  \\\\\n        0 & 0 & 1 & -2 & \\ddots & \\vdots \\\\\n        \\vdots & \\vdots & \\vdots & \\ddots & \\ddots & 1  \\\\\n        0 & 0 & 0 & \\cdots & 1 & -2\n    \\end{matrix} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#in-line-versus-fenced",
    "href": "Lecture_Folder/Week2b.html#in-line-versus-fenced",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "In-line versus fenced",
    "text": "In-line versus fenced\n\nThis equation, $y=\\frac{1}{2}$, is included inline\n\nThis equation, \\(y=\\frac{1}{2}\\), is included inline\n\nWhereas this equation, $$y=\\frac{1}{2}$$, is put on a separate line\n\nWhereas this equation \\[y=\\frac{1}{2}\\] is put on a separate line"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#markdown-is-very-flexible",
    "href": "Lecture_Folder/Week2b.html#markdown-is-very-flexible",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Markdown is very flexible",
    "text": "Markdown is very flexible\n\nYou can import RMarkdown templates into RStudio and open as a new Rmarkdown file\nBetter yet there are packages that add functionality\n\nbooks\njournal articles\nslide shows (these slides!)\ninteractive exercises"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#reading-in-and-exporting-data-frames",
    "href": "Lecture_Folder/Week2b.html#reading-in-and-exporting-data-frames",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Reading in and Exporting Data Frames",
    "text": "Reading in and Exporting Data Frames\n\n\n\n\nYourFile &lt;- read.table('yourfile.csv', header=T, row.names=1, sep=',')\nYourFile &lt;- read.table('yourfile.txt', header=T, row.names=1, sep='\\t')\n\n\n\n\n\nwrite.table(YourFile, \"yourfile.csv\", quote=F, row.names=T, sep=\",\")\nwrite.table(YourFile, \"yourfile.txt\", quote=F, row.names=T, sep=\"\\t\")"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#indexing-in-data-frames",
    "href": "Lecture_Folder/Week2b.html#indexing-in-data-frames",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nNext up - indexing just a subset of the data\nThis is a very important idea in R, that you can analyze just a subset of the data.\nThis is analyzing only the data in the file you made that has the factor value ‘mixed’.\n\n\nprint (YourFile[,2])\nprint (YourFile$variable)\nprint (YourFile[2,])\nplot (YourFile$variable1, YourFile$variable2)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#types-of-vectors-of-data",
    "href": "Lecture_Folder/Week2b.html#types-of-vectors-of-data",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\n\nint stands for integers\ndbl stands for doubles, or real numbers\nchr stands for character vectors, or strings\ndttm stands for date-times (a date + a time)\nlgl stands for logical, vectors that contain only TRUE or FALSE\nfctr stands for factors, which R uses to represent categorical variables with fixed possible values\ndate stands for dates\n\n\n\n\n\n\n\nNote\n\n\n\n\nInteger and double vectors are known collectively as numeric vectors.\nIn R numbers are doubles by default."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#types-of-vectors-of-data-1",
    "href": "Lecture_Folder/Week2b.html#types-of-vectors-of-data-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\n\nLogical vectors can take only three possible values:\n\nFALSE\nTRUE\nNA which is ‘not available’.\n\nIntegers have one special value: NA, while doubles have four:\n\nNA\nNaN which is ‘not a number’\nInf\n-Inf"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#plotting-using-ggplot2",
    "href": "Lecture_Folder/Week2b.html#plotting-using-ggplot2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Plotting using ggplot2()",
    "text": "Plotting using ggplot2()\n\nPart of the tidyverse suite of packages\nIn most cases, you start with ggplot2()\nSupply a dataset and aesthetic mapping with aes()\nDetermine the type of plot using geom_point() or geom_histogram() or others\nMany more options and controls available!\nMore info: https://ggplot2.tidyverse.org/"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics",
    "href": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "GGPlot2 and the Grammar of Graphics",
    "text": "GGPlot2 and the Grammar of Graphics\n\nGG stands for ‘Grammar of Graphics’\nA good paragraph uses good grammar to convey information\nA good figure uses good grammar in the same way\nSeven general components can be used to create most figures"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics-1",
    "href": "Lecture_Folder/Week2b.html#ggplot2-and-the-grammar-of-graphics-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "GGPlot2 and the Grammar of Graphics",
    "text": "GGPlot2 and the Grammar of Graphics"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#plotting-using-ggplot",
    "href": "Lecture_Folder/Week2b.html#plotting-using-ggplot",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Plotting using ggplot()",
    "text": "Plotting using ggplot()\n\nInstall and load ggplot2\n\n\n# install.packages(\"ggplot2\")\nlibrary(\"ggplot2\")"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#scatterplots-with-ggplot",
    "href": "Lecture_Folder/Week2b.html#scatterplots-with-ggplot",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Scatterplots with ggplot",
    "text": "Scatterplots with ggplot\n\nUse the preloaded mpg dataset available in RStudio\n\n\nggplot(mpg, aes(displ, hwy, color = class)) + \n  geom_point(size = 6,\n             shape = \"square\",\n             alpha = 0.4)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#boxplots-in-ggplot",
    "href": "Lecture_Folder/Week2b.html#boxplots-in-ggplot",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Boxplots in ggplot",
    "text": "Boxplots in ggplot\n\nggplot(mpg, aes(manufacturer, hwy, colour = class)) + \n  geom_boxplot() + \n  theme_classic() + \n  theme(axis.text.x = element_text(angle = 45, hjust=1))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_bar-function",
    "href": "Lecture_Folder/Week2b.html#the-geom_bar-function",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_bar function",
    "text": "The geom_bar function\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut))\n\nNow try this…\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut, color=cut))\n\nand this…\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut, fill=cut))\n\nand finally this…\n\nggplot(data=diamonds) +\n  geom_bar(mapping=aes(x=cut, fill=clarity), position=\"dodge\")"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_histogram-and-geom_freqpolyfunction",
    "href": "Lecture_Folder/Week2b.html#the-geom_histogram-and-geom_freqpolyfunction",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_histogram and geom_freqpolyfunction",
    "text": "The geom_histogram and geom_freqpolyfunction\nWith this function you can make a histogram\n\nggplot(data=diamonds) +\n  geom_histogram(mapping=aes(x=carat), binwidth=0.5)\n\nThis allows you to make a frequency polygram\n\nggplot(data=diamonds) +\n  geom_histogram(mapping=aes(x=carat), binwidth=0.5)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_boxplot-function",
    "href": "Lecture_Folder/Week2b.html#the-geom_boxplot-function",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_boxplot function",
    "text": "The geom_boxplot function\nBoxplots are very useful for visualizing data\n\nggplot(data=diamonds, mapping=aes(x=cut, y=price)) +\n  geom_boxplot()\n\n\n\n\nggplot(data=mpg, mapping=aes(x=reorder(class, hwy, FUN=median), y=hwy)) +\n  coordflip()\n\n\n\n\nggplot(data=mpg, mapping=aes(x=class, y=hwy)) +\n  geom_boxplot() +\n  coordflip"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-geom_point-geom_smooth-functions",
    "href": "Lecture_Folder/Week2b.html#the-geom_point-geom_smooth-functions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The geom_point & geom_smooth functions",
    "text": "The geom_point & geom_smooth functions\n\nggplot(data=diamonds2, mapping=aes(x=x, y=y)) +\n  geompoint()\n\n\n\n\nggplot(data=mpg) +\n  geompoint(mapping=aes(x=displ, y=hwy)) +\n  facet_wrap(~class, nrow=2)\n\n\n\n\nggplot(data=mpg) +\n  geompoint(mapping=aes(x=displ, y=hwy)) +\n  facet_grid(drv~cyl)\n\n\n\n\nggplot(data=mpg) +\n  geomsmooth(mapping=aes(x=displ, y=hwy))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#combining-geoms",
    "href": "Lecture_Folder/Week2b.html#combining-geoms",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Combining geoms",
    "text": "Combining geoms\n\nggplot(data=mpg) +\n  geom_point(mapping=aes(x=displ, y=hwy)) +\n  geom_smooth(mapping=aes(x=displ, y=hwy))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#adding-labels",
    "href": "Lecture_Folder/Week2b.html#adding-labels",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Adding labels",
    "text": "Adding labels\n\nggplot(data=mpg, aes(displ, hwy)) +\n  geom_point(aes(color=class)) +\n  geom_smooth(se=FALSE) +\n  labs(\n    title = \"Fuel efficiency generally decreases with engine size\",\n    caption = \"Data from fueleconomy.gov\"\n  )"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-type-of-plot-do-i-use-for-each-data-type",
    "href": "Lecture_Folder/Week2b.html#what-type-of-plot-do-i-use-for-each-data-type",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What type of plot do I use for each data type?",
    "text": "What type of plot do I use for each data type?\n\n\n\nFlow chart to determine what type of data visualization and which ggplot geom to use"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#different-flavors-of-inferential-statistics",
    "href": "Lecture_Folder/Week2b.html#different-flavors-of-inferential-statistics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Different flavors of inferential statistics",
    "text": "Different flavors of inferential statistics\n\nFrequentist Statistics\n\nClassical or standard approaches\nNull hypothesis testing\n\n\n\nHierarchical Probabilistic Modeling\n\nMaximum Likelihood\nBayesian Analyses\nMachine Learning"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-probability",
    "href": "Lecture_Folder/Week2b.html#what-is-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is probability",
    "text": "What is probability\n\nFrequency interpretation\n\n“Probabilities are understood as mathematically convenient approximations to long run relative frequencies.”\n\nSubjective (Bayesian) interpretation\n\n“A probability statement expresses the opinion of some individual regarding how certain an event is to occur.”"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#random-variables-probability",
    "href": "Lecture_Folder/Week2b.html#random-variables-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nProbability is the expression of belief in some future outcome\nA random variable can take on different values with different probabilities\nThe sample space of a random variable is the universe of all possible values"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#random-variables-probability-1",
    "href": "Lecture_Folder/Week2b.html#random-variables-probability-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nThe sample space can be represented by a\n\nprobability distribution (discrete)\nprobability density function (PDF) (continuous)\nalgebra and calculus are used for each respectively\nprobabilities of a sample space always sum to 1.0\n\nHow does it make sense that a sample space will always sum to 1?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#bernoulli-distribution",
    "href": "Lecture_Folder/Week2b.html#bernoulli-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nDescribes the expected outcome of a single event with probability p\nExample of flipping of a fair coin once\n\n\\[Pr(X=\\text{Head}) = \\frac{1}{2} = 0.5 = p \\]\n\\[Pr(X=\\text{Tails}) = \\frac{1}{2} = 0.5 = 1 - p = q \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#bernoulli-distribution-1",
    "href": "Lecture_Folder/Week2b.html#bernoulli-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nIf the coin isn’t fair then \\(p \\neq 0.5\\)\nHowever, the probabilities still sum to 1\n\n\\[ p + (1-p) = 1 \\] \\[ p + q = 1 \\]\n\nSame is true for other binary possibilities\n\nsuccess or failure\nyes or no answers\nchoosing an allele from a population based upon allele frequencies (Hardy-Weinberg ring any bells??)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#probability-rules",
    "href": "Lecture_Folder/Week2b.html#probability-rules",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nFlip a coin twice\nRepresent the first flip as ‘X’ and the second flip as ‘Y’\n\n\\[ Pr(\\text{X=H and Y=H}) = p*p = p^2 \\] \\[ Pr(\\text{X=H and Y=T}) = p*q = pq = p^2 \\] \\[ Pr(\\text{X=T and Y=H}) = q*p = pq \\] \\[ Pr(\\text{X=T and Y=T}) = q*q = q^2 \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#probability-rules-1",
    "href": "Lecture_Folder/Week2b.html#probability-rules-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nProbability that the H and T can occur in any order\n\n\\[ \\text{Pr(X=H) or Pr(X=T)} = p+q=1\\]\n\\[ \\text{Pr(X=H and Y=T) or Pr(X=T and Y=H)} = \\] \\[ (p*q) + (p*q) = 2pq \\]\n\nThese are the ‘and’ and ‘or’ rules of probability\n\n‘and’ means multiply the probabilities\n‘or’ means sum the probabilities\nmost probability distributions can be built up from these simple rules"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips",
    "href": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\n# tossing a fair coin\ncoin &lt;- c(\"heads\", \"tails\")\n\nsample(coin)\n\n[1] \"tails\" \"heads\""
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips-1",
    "href": "Lecture_Folder/Week2b.html#lets-simulate-some-coin-flips-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\nWhat happens when we change the probabilities or the sample size? How confident are we that our coin is fair?\n\n\nflips &lt;- sample(coin, prob = c(0.5, 0.5), size=10, replace=TRUE)\nbarplot(table(flips))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#expectation-and-moments-of-distributions",
    "href": "Lecture_Folder/Week2b.html#expectation-and-moments-of-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Expectation and Moments of Distributions",
    "text": "Expectation and Moments of Distributions\n\nDistributions have moments that can be estimated\n1st, 2nd, 3rd and 4th moments of a distribution?\nThe expectation or mean of a random variable X is:\n\n\\[E[X] = \\sum_{\\text{all x}}^{}xP(X=x) = \\mu\\]\n\nOften we want to know how dispersed the random variable is around its mean.\nOne measure of dispersion is the variance\n\n\\[Var(X) = E[X^2] = \\sigma^2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#joint-probability",
    "href": "Lecture_Folder/Week2b.html#joint-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Joint probability",
    "text": "Joint probability\n\\[Pr(X,Y) = Pr(X) * Pr(Y)\\]\n\nNote that this is true for two independent events\nHowever, for two non-independent events we also have to take into account their covariance\nTo do this we need conditional probabilities"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#conditional-probability",
    "href": "Lecture_Folder/Week2b.html#conditional-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nFor two independent variables: Probability of Y, given X, or the probability of X, given Y.\n\n\\[Pr(Y|X) = Pr(Y)\\text{ and }Pr(X|Y) = Pr(X)\\]\n\nFor two non-independent variables\n\n\\[Pr(Y|X) \\neq Pr(Y)\\text{ and }Pr(X|Y) \\neq Pr(X)\\]\n\nVariables that are non-independent have a shared variance, which is also known as the covariance\nCovariance standardized to a mean of zero and a unit standard deviation is correlation"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#what-is-likelihood-vs.-probability",
    "href": "Lecture_Folder/Week2b.html#what-is-likelihood-vs.-probability",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "What is Likelihood vs. Probability?",
    "text": "What is Likelihood vs. Probability?\n\nThe probability of an event is the proportion of times that the event would occur if we repeated a random trial over and over again under the same conditions.\nThe likelihood is a conditional probability of a parameter value given a set of data\nThe likelihood of a population parameter equaling a specific value, given the data\n\nL[parameter|data] = Pr[data|parameter]\n\nLikelihood function which can have a maximum"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#extra-bayesian-material",
    "href": "Lecture_Folder/Week2b.html#extra-bayesian-material",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Extra Bayesian material",
    "text": "Extra Bayesian material"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#who-wants-to-win-a-car",
    "href": "Lecture_Folder/Week2b.html#who-wants-to-win-a-car",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Who wants to win a car?",
    "text": "Who wants to win a car?\n\nPretend that there are three doors, and behind one is a car. Behind the other doors are cats.\nYou choose one of the doors, and then Monte Hall opens one of the two remaining doors to reveal a cat.\nAt this point you have the choice of changing doors or staying with your original choice.\nWhat should you do?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#geometric-distribution",
    "href": "Lecture_Folder/Week2b.html#geometric-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week2b.html#geometric-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#geometric-distribution-2",
    "href": "Lecture_Folder/Week2b.html#geometric-distribution-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week2b.html#testing-geometric-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\n#dgeom(x=20, p=0.1)\n# 0.01215767\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week2b.html#testing-geometric-distributions-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-distribution",
    "href": "Lecture_Folder/Week2b.html#binomial-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-distribution-1",
    "href": "Lecture_Folder/Week2b.html#binomial-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-probability-distribution",
    "href": "Lecture_Folder/Week2b.html#binomial-probability-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-binomial-distributions",
    "href": "Lecture_Folder/Week2b.html#testing-binomial-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\ndbinom gives the density (probability) of number successes (x) in number trials (size), with (prob) probability between 0-1\n\n\n# dbinom(x=5, size=10, p=0.5)\n# 0.246\nplot(dbinom(x=1:10, size=10, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-binomial-distributions-1",
    "href": "Lecture_Folder/Week2b.html#testing-binomial-distributions-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\npbinom gives the cumulative probability of reaching at least (q) number of successes after (size) number of trials\n\n\nplot(pbinom(q=1:100, size=100, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week2b.html#negative-binomial-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “successes” have happened.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “success” appearing on the \\(k^{th}\\) trial\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week2b.html#negative-binomial-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 AA\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week2b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week2b.html#testing-poisson-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#uniform-distribution",
    "href": "Lecture_Folder/Week2b.html#uniform-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week2b.html#uniform-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#exponential-distribution",
    "href": "Lecture_Folder/Week2b.html#exponential-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week2b.html#exponential-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gamma-distribution",
    "href": "Lecture_Folder/Week2b.html#gamma-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week2b.html#gamma-distribution-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-gaussian-or-normal-distribution",
    "href": "Lecture_Folder/Week2b.html#the-gaussian-or-normal-distribution",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The Gaussian or Normal Distribution",
    "text": "The Gaussian or Normal Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "href": "Lecture_Folder/Week2b.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Log-normal PDF | Continuous version of Poisson (-ish)",
    "text": "Log-normal PDF | Continuous version of Poisson (-ish)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#transformations-to-normalize-data",
    "href": "Lecture_Folder/Week2b.html#transformations-to-normalize-data",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#transformations-to-normalize-data-1",
    "href": "Lecture_Folder/Week2b.html#transformations-to-normalize-data-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#binomial-to-normal-categorical-to-continuous",
    "href": "Lecture_Folder/Week2b.html#binomial-to-normal-categorical-to-continuous",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Binomial to Normal | Categorical to continuous",
    "text": "Binomial to Normal | Categorical to continuous"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "href": "Lecture_Folder/Week2b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The Normal (aka Gaussian) | Probability Density Function (PDF)",
    "text": "The Normal (aka Gaussian) | Probability Density Function (PDF)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf",
    "href": "Lecture_Folder/Week2b.html#normal-pdf",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf-a-function-of-two-parameters",
    "href": "Lecture_Folder/Week2b.html#normal-pdf-a-function-of-two-parameters",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF | A function of two parameters",
    "text": "Normal PDF | A function of two parameters\n\n(\\(\\mu\\) and \\(\\sigma\\))\n\n\n\n\n\n\n\n\n\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\epsilon \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf-estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week2b.html#normal-pdf-estimates-of-mean-and-variance",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF | estimates of mean and variance",
    "text": "Normal PDF | estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-pdf-1",
    "href": "Lecture_Folder/Week2b.html#normal-pdf-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology",
    "href": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-1",
    "href": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-2",
    "href": "Lecture_Folder/Week2b.html#why-is-the-normal-special-in-biology-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week2b.html#parent-offspring-resemblance",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week2b.html#genetic-model-of-complex-traits",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week2b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week2b.html#why-else-is-the-normal-special",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nThe normal distribution is immensely useful because of the central limit theorem, which says that the mean of many random variables independently drawn from the same distribution is distributed approximately normally\nOne can think of numerous situations, such as\n\nwhen multiple genes contribute to a phenotype\nor that many factors contribute to a biological process\n\nIn addition, whenever there is variance introduced by stochastic factors the central limit theorem holds\nThus, normal distributions occur throughout genomics\nIt’s also the basis of the majority of classical statistics"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week2b.html#z-scores-of-normal-variables-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have a mean of 0 and a standard deviation of 1\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#resources",
    "href": "Lecture_Folder/Week2b.html#resources",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Resources:",
    "text": "Resources:\n\nVignette (from the tidyr package)\nOriginal paper (Hadley Wickham, 2014 JSS)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#r-packages-youll-need-today",
    "href": "Lecture_Folder/Week2b.html#r-packages-youll-need-today",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "R packages you’ll need today",
    "text": "R packages you’ll need today\ntidyverse\nnycflights13"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-vs.-base-r-cont.",
    "href": "Lecture_Folder/Week2b.html#tidyverse-vs.-base-r-cont.",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse vs. base R (cont.)",
    "text": "Tidyverse vs. base R (cont.)\nOne point of convenience is that there is often a direct correspondence between a tidyverse command and its base R equivalent.\nThese generally follow a tidyverse::snake_case vs base::period.case rule. E.g. Compare:\n\n\n\ntidyverse\nbase\n\n\n\n\n?readr::read_csv\n?utils::read.csv\n\n\n?dplyr::if_else\n?base::ifelse\n\n\n?tibble::tibble\n?base::data.frame\n\n\n\nEtcetera.\nIf you call up the above examples, you’ll see that the tidyverse alternative typically offers some enhancements or other useful options (and sometimes restrictions) over its base counterpart.\n–\nRemember: There are (almost) always multiple ways to achieve a single goal in R."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-packages",
    "href": "Lecture_Folder/Week2b.html#tidyverse-packages",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse packages",
    "text": "Tidyverse packages\nLet’s load the tidyverse meta-package and check the output.\n\nlibrary(tidyverse)\n\n–\nWe see that we have actually loaded a number of packages (which could also be loaded individually): ggplot2, tibble, dplyr, etc. - We can also see information about the package versions and some namespace conflicts."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.",
    "href": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse packages (cont.)",
    "text": "Tidyverse packages (cont.)\nThe tidyverse actually comes with a lot more packages than those that are just loaded automatically.1\n\ntidyverse_packages()\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nWe’ll use several of these additional packages during the remainder of this course.\n\nE.g. The lubridate package for working with dates and the rvest package for webscraping.\nHowever, bear in mind that these packages will have to be loaded separately.\n\n.footnote[ 1 It also includes a lot of dependencies upon installation. This is a matter of some controversy.]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.-1",
    "href": "Lecture_Folder/Week2b.html#tidyverse-packages-cont.-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Tidyverse packages (cont.)",
    "text": "Tidyverse packages (cont.)\nI hope to cover most of the tidyverse packages over the length of this course.\nToday, however, I’m only really going to focus on two packages: 1. dplyr 2. tidyr\nThese are the workhorse packages for cleaning and wrangling data. They are thus the ones that you will likely make the most use of (alongside ggplot2, which we already met back in Lecture 1). - Data cleaning and wrangling occupies an inordinate amount of time, no matter where you are in your research career."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#an-aside-on-pipes",
    "href": "Lecture_Folder/Week2b.html#an-aside-on-pipes",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "An aside on pipes: %>%",
    "text": "An aside on pipes: %&gt;%\nThe tidyverse loads its own pipe operator, denoted %&gt;%.\n\n## These next two lines of code do exactly the same thing.\nmpg %&gt;% filter(manufacturer==\"audi\") %&gt;% group_by(model) %&gt;% summarise(hwy_mean = mean(hwy))\nsummarise(group_by(filter(mpg, manufacturer==\"audi\"), model), hwy_mean = mean(hwy))\n\n–\nThe first line reads from left to right, exactly how I thought of the operations in my head. - Take this object (mpg), do this (filter), then do this (group_by), etc.\nThe second line totally inverts this logical order (the final operation comes first!) - Who wants to read things inside out?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#an-aside-on-pipes-cont.",
    "href": "Lecture_Folder/Week2b.html#an-aside-on-pipes-cont.",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "An aside on pipes: %>% (cont.)",
    "text": "An aside on pipes: %&gt;% (cont.)\nThe piped version of the code is even more readable if we write it over several lines. Here it is again and, this time, I’ll run it for good measure so you can see the output:\n\nmpg %&gt;% \n  filter(manufacturer==\"audi\") %&gt;% \n  group_by(model) %&gt;% \n  summarise(hwy_mean = mean(hwy))\n\n# A tibble: 3 × 2\n  model      hwy_mean\n  &lt;chr&gt;         &lt;dbl&gt;\n1 a4             28.3\n2 a4 quattro     25.8\n3 a6 quattro     24  \n\n\nRemember: Using vertical space costs nothing and makes for much more readable/writeable code than cramming things horizontally."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#dplyr",
    "href": "Lecture_Folder/Week2b.html#dplyr",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "dplyr",
    "text": "dplyr"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#key-dplyr-verbs",
    "href": "Lecture_Folder/Week2b.html#key-dplyr-verbs",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Key dplyr verbs",
    "text": "Key dplyr verbs\nThere are five key dplyr verbs that you need to learn.\n\nfilter: Filter (i.e. subset) rows based on their values.\narrange: Arrange (i.e. reorder) rows based on their values.\nselect: Select (i.e. subset) columns by their names:\nmutate: Create new columns.\nsummarise: Collapse multiple rows into a single summary value.1"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#other-dplyr-goodies",
    "href": "Lecture_Folder/Week2b.html#other-dplyr-goodies",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Other dplyr goodies",
    "text": "Other dplyr goodies\ngroup_by and ungroup: For (un)grouping. - Particularly useful with the summarise and mutate commands, as we’ve already seen.\n\n\nslice: Subset rows by position rather than filtering by values. - E.g. starwars %&gt;% slice(c(1, 5))\n\n\npull: Extract a column from as a data frame as a vector or scalar. - E.g. starwars %&gt;% filter(gender==\"female\") %&gt;% pull(height)\n\n\ncount and distinct: Number and isolate unique observations. - E.g. starwars %&gt;% count(species), or starwars %&gt;% distinct(species) - You could also use a combination of mutate, group_by, and n(), e.g. starwars %&gt;% group_by(species) %&gt;% mutate(num = n())."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#data-cleaning-and-manipulation",
    "href": "Lecture_Folder/Week2b.html#data-cleaning-and-manipulation",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Data cleaning and manipulation",
    "text": "Data cleaning and manipulation\n\nHere, we differentiate “data cleaning” from “data manipulation”, which is perhaps an arbitrary distinction.\n“Data cleaning” typically refers to altering variable class information, fixing mistakes that could have arisen in the data (e.g., an extra ‘.’ symbol in a numeric value), and things of this nature.\n“Data manipulation”, in my mind, refers to altering the structure of the data in a way that changes the functional structure the data (e.g., an addition of a column, deletion of rows, long/wide formatting change)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data",
    "href": "Lecture_Folder/Week2b.html#gapminder-data",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nThe gapminder data are commonly used to explore concepts of data exploration and manipulation, maybe because of the combination of character and numeric variables, nested structure in terms of country and year, or maybe it is just out of ease in copying notes from other people.\n\ndat &lt;- read.delim(file = \"http://www.stat.ubc.ca/~jenny/notOcto/STAT545A/examples/gapminder/data/gapminderDataFiveYear.txt\")\n\n\nhead(dat)\n\n      country year      pop continent lifeExp gdpPercap\n1 Afghanistan 1952  8425333      Asia  28.801  779.4453\n2 Afghanistan 1957  9240934      Asia  30.332  820.8530\n3 Afghanistan 1962 10267083      Asia  31.997  853.1007\n4 Afghanistan 1967 11537966      Asia  34.020  836.1971\n5 Afghanistan 1972 13079460      Asia  36.088  739.9811\n6 Afghanistan 1977 14880372      Asia  38.438  786.1134\n\nstr(dat)\n\n'data.frame':   1704 obs. of  6 variables:\n $ country  : chr  \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" \"Afghanistan\" ...\n $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...\n $ pop      : num  8425333 9240934 10267083 11537966 13079460 ...\n $ continent: chr  \"Asia\" \"Asia\" \"Asia\" \"Asia\" ...\n $ lifeExp  : num  28.8 30.3 32 34 36.1 ...\n $ gdpPercap: num  779 821 853 836 740 ..."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-1",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nWe can use what we learned before in terms of base R functions to calculate summary statistics.\n\n# mean life expectancy\nmean(dat$lifeExp)\n\n[1] 59.47444\n\n\nBut what does mean life expectancy really tell us, when we also have information on space (country) and time (year)? So we may wish to subset the data to a specific country or time period. We can do this using which statements.\n\ndat[which(dat$country == 'Afghanistan'), ]\ndat[which(dat$year &lt; 1960), ]\n\nRecall that which evaluates a condition, and then determines the index of each TRUE value. So for the first example, the which tells us the indices where the vector dat$country is equal to “Afghanistan”. Putting this result vector of indices within the square brackets allows us to subset the data.frame based on these indices (specifically, we are subsetting specific rows of data).\nIn the second example, we want to see all data that was recorded prior to 1960. As you will quickly realize, there are always multiple ways to do the same thing when programming. For instance, this second statement could be done in base R using the subset function.\n\nsubset(dat, dat$year &lt; 1960)\n\nThe subset function also allows you to ‘select’ specific columns in the output.\n\nsubset(dat, dat$year &lt; 1955, select=c(lifeExp,gdpPercap))\n\nHowever, this is the same as\n\ndat[which(dat$year &lt; 1960), c(\"lifeExp\",\"gdpPercap\")]"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-2",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nTo refresh your memory and clarify the use of conditionals, the list below provides a bit more information.\n\n==: equals exactly\n&lt;, &lt;=: is smaller than, is smaller than or equal to\n&gt;, &gt;=: is bigger than, is bigger than or equal to\n!=: not equal to"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-3",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-3",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nAnd some that we did not go into before, but will go into a bit more detail on now:\n\n!: NOT operator, to specify things that should be omitted\n&: AND operator, allows you to chain two conditions which must both be met\n|: OR operator, to chains two conditions when at least one should be met\n%in%: belongs to one of the following (usually followed by a vector of possible values)\n\nThe AND (&) and the OR (|) operators are also super useful when you want to separate data based on multiple conditions."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-4",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-4",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\n\ndat[which(dat$country=='Afghanistan' & dat$year==1977),]\ndat[which(dat$lifeExp &lt; 40 | dat$gdpPercap &lt; 500), ]\n\nFinally, the %in% operator is super useful when you want to subset data based on multiple conditions\n\n#fails\ndat[which(dat$country == c('Afghanistan', 'Turkey')), ]\n\n         country year      pop continent lifeExp gdpPercap\n1    Afghanistan 1952  8425333      Asia  28.801  779.4453\n3    Afghanistan 1962 10267083      Asia  31.997  853.1007\n5    Afghanistan 1972 13079460      Asia  36.088  739.9811\n7    Afghanistan 1982 12881816      Asia  39.854  978.0114\n9    Afghanistan 1992 16317921      Asia  41.674  649.3414\n11   Afghanistan 2002 25268405      Asia  42.129  726.7341\n1574      Turkey 1957 25670939    Europe  48.079 2218.7543\n1576      Turkey 1967 33411317    Europe  54.336 2826.3564\n1578      Turkey 1977 42404033    Europe  59.507 4269.1223\n1580      Turkey 1987 52881328    Europe  63.108 5089.0437\n1582      Turkey 1997 63047647    Europe  68.835 6601.4299\n1584      Turkey 2007 71158647    Europe  71.777 8458.2764\n\n#does not fail\ndat[which(dat$country %in% c('Afghanistan', 'Turkey')), ]\n\n         country year      pop continent lifeExp gdpPercap\n1    Afghanistan 1952  8425333      Asia  28.801  779.4453\n2    Afghanistan 1957  9240934      Asia  30.332  820.8530\n3    Afghanistan 1962 10267083      Asia  31.997  853.1007\n4    Afghanistan 1967 11537966      Asia  34.020  836.1971\n5    Afghanistan 1972 13079460      Asia  36.088  739.9811\n6    Afghanistan 1977 14880372      Asia  38.438  786.1134\n7    Afghanistan 1982 12881816      Asia  39.854  978.0114\n8    Afghanistan 1987 13867957      Asia  40.822  852.3959\n9    Afghanistan 1992 16317921      Asia  41.674  649.3414\n10   Afghanistan 1997 22227415      Asia  41.763  635.3414\n11   Afghanistan 2002 25268405      Asia  42.129  726.7341\n12   Afghanistan 2007 31889923      Asia  43.828  974.5803\n1573      Turkey 1952 22235677    Europe  43.585 1969.1010\n1574      Turkey 1957 25670939    Europe  48.079 2218.7543\n1575      Turkey 1962 29788695    Europe  52.098 2322.8699\n1576      Turkey 1967 33411317    Europe  54.336 2826.3564\n1577      Turkey 1972 37492953    Europe  57.005 3450.6964\n1578      Turkey 1977 42404033    Europe  59.507 4269.1223\n1579      Turkey 1982 47328791    Europe  61.036 4241.3563\n1580      Turkey 1987 52881328    Europe  63.108 5089.0437\n1581      Turkey 1992 58179144    Europe  66.146 5678.3483\n1582      Turkey 1997 63047647    Europe  68.835 6601.4299\n1583      Turkey 2002 67308928    Europe  70.845 6508.0857\n1584      Turkey 2007 71158647    Europe  71.777 8458.2764"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-5",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-5",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nRelated to %in%, is match. match is best for identifying the index of single types in a vector of unique values. For instance,\n\ndat[match(c('Afghanistan', 'Turkey'), dat$country),]\n\n         country year      pop continent lifeExp gdpPercap\n1    Afghanistan 1952  8425333      Asia  28.801  779.4453\n1573      Turkey 1952 22235677    Europe  43.585 1969.1010"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-6",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-6",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nonly returns two rows, because it only matches the first instance of both countries in the data. We can use match to get the index associated with a single value (useful when writing functions).\n\nmatch('dog', c('dog', 'cat', 'snake'))\n\n[1] 1\n\n#not ideal behavior\nmatch('dog', c('dog', 'cat', 'snake', 'dog'))\n\n[1] 1\n\n\nor it can be used to identify multiple instances of a single value across a vector of values.\n\nmatch(c('dog', 'cat', 'snake', 'dog'), 'dog')\n\n[1]  1 NA NA  1\n\nmatch(c('dog', 'cat', 'snake', 'dog'), c('dog', 'cat'))\n\n[1]  1  2 NA  1"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#gapminder-data-7",
    "href": "Lecture_Folder/Week2b.html#gapminder-data-7",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "gapminder data",
    "text": "gapminder data\nWhile a bit opaque, these functions are pretty useful in a variety of situations. Speaking of data manipulation functions that are useful but a bit conceptually difficult, do.call and Reduce are solid base R functions.\ndo.call is a way of calling the same function recursively on multiple objects, and may have similar output to Reduce, which is also a way to recursively apply a function.\n\nlst &lt;- list(1:10, 1:10, 1:10, 1:10, 1:10)\nlst\n\n[[1]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[2]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[3]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[4]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n[[5]]\n [1]  1  2  3  4  5  6  7  8  9 10\n\n#this makes a single rbind call with each element of the list as an argument\nstr(do.call(rbind, lst))\n\n int [1:5, 1:10] 1 1 1 1 1 2 2 2 2 2 ...\n\n#this does it iteratively (so makes n-1 rbind calls)\nReduce(rbind, lst)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\ninit    1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10\n        1    2    3    4    5    6    7    8    9    10"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-tidyverse",
    "href": "Lecture_Folder/Week2b.html#the-tidyverse",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The tidyverse",
    "text": "The tidyverse\n\nThere are many R libraries designed to manipulate data and work with specific data structures (e.g., purrr for list objects, lubridate for dates, etc.).\nFor the sake of brevity and generality, we will examine one main useful packages for data manipulation: dplyr."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#rename",
    "href": "Lecture_Folder/Week2b.html#rename",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "rename",
    "text": "rename\n\ndf &lt;- data.frame(A=runif(100), B=runif(100), D=rnorm(100,1,1))\ndf2 &lt;- dplyr::rename(df, a=A, b=B, d=D)\n\nThis is the same functionality as the base R function colnames (or names for a data.frame)\nnames(df2) &lt;- c('a', 'b', 'd')\n#or \nnames(df2) &lt;- tolower(names(df))\nThe nice part about dplyr::rename() is that we specify the old and new column names, meaning that there is little risk of an indexing error as with using the colnames() or names() functions."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#select",
    "href": "Lecture_Folder/Week2b.html#select",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "select",
    "text": "select\nMany of the next functions are directly analogs of functions from another programming language used to query databases (SQL). This makes it really nice to learn, as you can essentially learn two languages while learning one. SQL is pretty powerful when working with relational data. I will not go into what I mean by this, unless there is time during lecture and interest among you all.\nWe use dplyr::select when we want to…select…columns.\n\ndplyr::select(df2, a)\ndplyr::select(df2, obs = starts_with('a'))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#filter",
    "href": "Lecture_Folder/Week2b.html#filter",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "filter",
    "text": "filter\ndplyr::filter is another one of those useful functions that we already know how to use in base R. Previously, we have used which statements or the subset function. dplyr::filter is used to filter down a data.frame by some condition applied to rows.\n\ndplyr::filter(df2, a &lt; 0.5)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#mutate",
    "href": "Lecture_Folder/Week2b.html#mutate",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "mutate",
    "text": "mutate\ndplyr::mutate is used when we wish to create a new covariate based on our existing covariates. For instance, if we wanted to create a column e on df2 that was the sum of a+b divided by d…\n\ndf2 &lt;- dplyr::mutate(df2, e=(a+b)/d)\nhead(df2,5)\n\n          a          b          d           e\n1 0.3243548 0.79117276  1.5810743  0.70555041\n2 0.2800363 0.28220355 -0.4963027 -1.13285681\n3 0.9318768 0.75790762  0.9595241  1.76106510\n4 0.7583689 0.04228768  1.2519443  0.63953053\n5 0.1081216 0.07187200  2.8208981  0.06380719\n\n\nNotice that the function creates a new column and appends it to the existing data.frame, but does not “write in place”. That is, the df2 object is not modified unless it is stored (which we do above)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#group_by",
    "href": "Lecture_Folder/Week2b.html#group_by",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "group_by",
    "text": "group_by\ndplyr::group_by is really useful as an intermediate step to getting at summary statistics which take into account grouping by a character or factor variable. For instance, if we wanted to calculate the mean life expectancy (lifeExp) for every country in the gapminder data (dat), we would first have to group by country.\n\ndatG &lt;- dplyr::group_by(dat, country)\n\nThis is a bit like a non-function, since dat and datG are essentially the same….but they are not for the purposes of computing group-wise statistics. This is done using the dplyr::summarise function."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#summarise",
    "href": "Lecture_Folder/Week2b.html#summarise",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "summarise",
    "text": "summarise\nSo if we wanted to calculate mean life expectancy (lifeExp) per country, we could use the grouped data.frame datG and the dplyr::summarise function to do so.\n\ndplyr::summarise(datG, mnLife=mean(lifeExp))\n\n# A tibble: 142 × 2\n   country     mnLife\n   &lt;chr&gt;        &lt;dbl&gt;\n 1 Afghanistan   37.5\n 2 Albania       68.4\n 3 Algeria       59.0\n 4 Angola        37.9\n 5 Argentina     69.1\n 6 Australia     74.7\n 7 Austria       73.1\n 8 Bahrain       65.6\n 9 Bangladesh    49.8\n10 Belgium       73.6\n# ℹ 132 more rows"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#joins",
    "href": "Lecture_Folder/Week2b.html#joins",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "joins",
    "text": "joins\njoins are something taken directly from SQL. Table joins are ways of combining relational data by some index variable. That is, we often have situations where our data are inherently multi-dimensional. If we have a data.frame containing rows corresponding to observations of a species at a given location, we could have another data.frame containing species-level morphometric or trait data. While we could mash this into a single data.frame, it would repeat many values, which is not ideal for data clarity or memory management.\n\ndf$species &lt;- sample(c('dog', 'cat', 'bird'),100, replace=TRUE)\n\ninfo &lt;- data.frame(species=c('dog', 'cat', 'bird', 'snake'),\n    annoying=c(10, 2, 100, 1), \n    meanBodySize=c(20, 5, 1, 2))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#joins-1",
    "href": "Lecture_Folder/Week2b.html#joins-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "joins",
    "text": "joins\nNow we can join some stuff together, combining data on mean species-level characteristics with individual-level observations.\n\n# maintains the structure of df (the \"left\" data structure)\nleft_join(df, info, by='species')\n\n# maintains the structure of info (the \"right\" data structure)\nright_join(df,info, by='species')\n\n# return things that are in info but not in df\nanti_join(info, df, by='species')\n\nThere are other forms of joins (full_join, inner_join, etc.), but I find that I mostly use the left or right variations of the joins, as it specifically allows me to control the output (i.e., using dplyr::left_join, I know that the resulting data.frame will have the same number of rows as the left hand data.frame)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#piping",
    "href": "Lecture_Folder/Week2b.html#piping",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "piping",
    "text": "piping\nAlright. So before we discussed joins, we were describing the different main verbs of dplyr. We discussed rename, select, mutate, group_by, and summarise. A final point, and something tidyverse folks really love, is the use of these functions in nested statements through the use of piping.\nPipes in bash scripting look like |, pipes in R syntax look like %&gt;%. It does not matter what it looks like though, it matter what it does. Here is a simple example of the use of piping. We can go back to the example of calculating the mean life expectancy per country from the gapminder data.\nThe usual way\n\ntmp &lt;- dplyr::group_by(dat, country)\ntmp2 &lt;- dplyr::summarise(tmp, mnLifeExp=mean(lifeExp))\n\nThe piped way\n\ntmp3 &lt;- dat %&gt;%\n    dplyr::group_by(country) %&gt;%\n    dplyr::summarise(mnLifeExp=mean(lifeExp))\n\nThe results of these two are identical (all(tmp3==tmp2) returns TRUE).\nThis is useful, as commands can be chained together, including the creation of new variables, subsetting and summarising of existing variables, etc. One thing to keep in mind is to check intermediate results – instead of just piping all the way through – as data manipulation errors can be introduced mid-statement and go unnoticed. That is, in some situations, piping does not help reproducibility. Many proponents argue that it helps with code readability, while many others say that actively makes code less human readable. It definitely does require adopting a certain syntax and the assumption that every end user is on the tidyverse train, which is not ideal when reproducibility involves everyone, not just the cool tidy/Hadley/RStudio crowd."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#midterm-feedback",
    "href": "Lecture_Folder/Week2b.html#midterm-feedback",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Midterm Feedback",
    "text": "Midterm Feedback\n\nThank you all for providing thoughtful feedback on the last Problem Set!\nYou all really enjoy in-class exercises - we’ll do more of that!\nThe homework difficulty doesn’t always align well with the lectures - will try to remedy this"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#understanding-populations-and-their-parameters",
    "href": "Lecture_Folder/Week2b.html#understanding-populations-and-their-parameters",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Understanding Populations and their Parameters",
    "text": "Understanding Populations and their Parameters\n\nWe often think about the samples we are collecting as a part of a larger population\nSince we can’t measure every member of that population, we instead use sampling to estimate the parameters of the population as a whole\n\nSome common parameters: mean, range, median\nIf we performed random sampling, we assume that the parameter estimates of our sample are equitable to the true population parameters"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#simulations-to-compare-parameter-estimates-2",
    "href": "Lecture_Folder/Week2b.html#simulations-to-compare-parameter-estimates-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Simulations to compare parameter estimates",
    "text": "Simulations to compare parameter estimates\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nhist(true_pop, xlim = c(0,16))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-parameters",
    "href": "Lecture_Folder/Week2b.html#calculating-parameters",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-parameters-1",
    "href": "Lecture_Folder/Week2b.html#calculating-parameters-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?\n\n\nmean(true_pop)\n\n[1] 4.927\n\nrange(true_pop)\n\n[1]  0 13\n\nmedian(true_pop)\n\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-exercise",
    "href": "Lecture_Folder/Week2b.html#sampling-exercise",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-exercise-1",
    "href": "Lecture_Folder/Week2b.html#sampling-exercise-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\n\n\n\n\n\n\n\n\n[1] \"Mean: \" \"4.95\"  \n\n\n[1] \"Range: \" \"1\"       \"10\""
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week2b.html#randomness-in-sampling",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week2b.html#surveying-your-sampling",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week2b.html#surveying-your-sampling-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\ntable(samps_var_means &gt; 4.5 & samps_var_means &lt; 5.5)\n\n\nFALSE  TRUE \n   19    31"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#surveying-your-sampling-2",
    "href": "Lecture_Folder/Week2b.html#surveying-your-sampling-2",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-sampling-distributions",
    "href": "Lecture_Folder/Week2b.html#normal-sampling-distributions",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal Sampling Distributions",
    "text": "Normal Sampling Distributions"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#normal-sampling-distributions-1",
    "href": "Lecture_Folder/Week2b.html#normal-sampling-distributions-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Normal Sampling Distributions",
    "text": "Normal Sampling Distributions"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-distributions---its-been-normal-this-whole-time",
    "href": "Lecture_Folder/Week2b.html#sampling-distributions---its-been-normal-this-whole-time",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Distributions - It’s been Normal this whole time?!",
    "text": "Sampling Distributions - It’s been Normal this whole time?!"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sampling-distributions---exercise",
    "href": "Lecture_Folder/Week2b.html#sampling-distributions---exercise",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sampling Distributions - Exercise",
    "text": "Sampling Distributions - Exercise\n\nTry creating some data using one of the other distributions we discussed last time (Exponential Distribution) and then create a sampling distribution. Is it normal?\n\n\ntrue_pop &lt;- rexp(n, rate)\nsamps_var &lt;- replicate(n = , sample(true_pop, size = ))\nsamps_var_means &lt;- apply(samps_var, 2, mean)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#the-central-limit-theorem",
    "href": "Lecture_Folder/Week2b.html#the-central-limit-theorem",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#standard-error",
    "href": "Lecture_Folder/Week2b.html#standard-error",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Standard Error",
    "text": "Standard Error\n\nThe sample size and the spread of the distribution (range) - contribute to what is known as the standard error of a random variable.\nThe standard error for any given sample attribute (such as a sample mean), can be calculated either based on distributional assumptions, or by a process called “resampling.”"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#standard-error-1",
    "href": "Lecture_Folder/Week2b.html#standard-error-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Standard error",
    "text": "Standard error"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-the-standard-error",
    "href": "Lecture_Folder/Week2b.html#calculating-the-standard-error",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nStandard Error of the Mean (SEM)\nSEM = SD / sqrt(sample size)"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#calculating-the-standard-error-1",
    "href": "Lecture_Folder/Week2b.html#calculating-the-standard-error-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week2b.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#bootstrapping-1",
    "href": "Lecture_Folder/Week2b.html#bootstrapping-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned. - - It works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#confidence-intervals",
    "href": "Lecture_Folder/Week2b.html#confidence-intervals",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#relationship-between-mean-and-variance-1",
    "href": "Lecture_Folder/Week2b.html#relationship-between-mean-and-variance-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Relationship between mean and variance",
    "text": "Relationship between mean and variance\n\nThis means it is inappropriate to compare variations of different populations with largely different means\n\nFor instance, comparing the standard deviation for a body measurement in a population of mice, with the same body measurement in a population of elephants is not meaningful."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#test-it-out",
    "href": "Lecture_Folder/Week2b.html#test-it-out",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nprint(sd(true_pop))"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week2b.html#coefficient-of-variation",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#today-well-be-talking-about",
    "href": "Lecture_Folder/Week2b.html#today-well-be-talking-about",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Today we’ll be talking about",
    "text": "Today we’ll be talking about\n\nA roadmap for the rest of the term\nThe unethical history of statistics and data science\nLast week’s homework"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#thinking-about-your-final-project",
    "href": "Lecture_Folder/Week2b.html#thinking-about-your-final-project",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Thinking about your final project",
    "text": "Thinking about your final project\n\nAs we’re going through these statistical techniques, think about which one(s) might be most appropriate for your data analysis.\nThe project ideally will take in some sort of raw data, analyze it (summary statistics, significance tests), and plot your findings.\nCan incorporate Unix and/or R, can be presented via a script and/or RMarkdown document."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics",
    "href": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\nFrancis Galton: Darwin’s half cousin\nStudied human variation and genetic inheritance\n\nHuman height, fingerprints, intelligence\nCorrelation, regression toward the mean, and “nature versus nurture”\nPioneered twin studies\n\n\n\n\n\nGalton"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics-1",
    "href": "Lecture_Folder/Week2b.html#galton-as-the-father-of-eugenics-1",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\nBelieved that intelligence was hereditary based on surveying prominent academics in Europe\nUsed the ideas of correlation and regression towards the mean to argue that the upper class should breed amongst themselves to keep those “good genes” pure\nWanted to provide monetary incentives for “good” couples to marry and reproduce as a way to avoid the upper class being genetically muddied by the lower class"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "href": "Lecture_Folder/Week2b.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "A common sight at state fairs around the U.S. in the 1930s",
    "text": "A common sight at state fairs around the U.S. in the 1930s\n\nCompetitions for the “perfect family” to encourage public consciousness and support for eugenics"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#galton-with-charles-davenport-and-g.-stanley-hall",
    "href": "Lecture_Folder/Week2b.html#galton-with-charles-davenport-and-g.-stanley-hall",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Galton with Charles Davenport and G. Stanley Hall",
    "text": "Galton with Charles Davenport and G. Stanley Hall\n\nAmerican Eugenics Record Office (ERO) founded in Cold Springs Harbor"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#logo-of-the-us-eugenics-society",
    "href": "Lecture_Folder/Week2b.html#logo-of-the-us-eugenics-society",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Logo of the US eugenics society",
    "text": "Logo of the US eugenics society"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#eugenics-societies-in-america",
    "href": "Lecture_Folder/Week2b.html#eugenics-societies-in-america",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Eugenics societies in America",
    "text": "Eugenics societies in America\n\nAdvocated for state laws to ban interracial marriages and promote sterilization of “unfit” individuals (negative eugenics) - especially black, Latinx, and Native American women\n30 states passed laws to force mental institution patients to be sterilized\nBetween 1907 and 1963, over 64,000 individuals were forcibly sterilized under eugenic legislation in the United States"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics-in-london",
    "href": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics-in-london",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics in London",
    "text": "RA Fisher and Eugenics in London\n\nDeveloper of Fishers exact test, analysis of variance (ANOVA), null hypothesis, p values, maximum likelihood, probability density functions\nFounding Chairman of the University of Cambridge Eugenics Society"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics",
    "href": "Lecture_Folder/Week2b.html#ra-fisher-and-eugenics",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics",
    "text": "RA Fisher and Eugenics\n\n1/3rd of his work “The Genetical Theory of Natural Selection” discussed eugenics and his theory that the fall of civilizations was due to the fertility of their upper classes being diminished\nUsed these statistical methods to test data on human variation to prove biological differences between human races\nEugenics and racism were the primary motivators for many of these statistical tests that we use today"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#eugenics-has-a-direct-line-to-hitler-and-nazism",
    "href": "Lecture_Folder/Week2b.html#eugenics-has-a-direct-line-to-hitler-and-nazism",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Eugenics has a direct line to Hitler and Nazism",
    "text": "Eugenics has a direct line to Hitler and Nazism\n\nEugenics existed in America (and England) before it became popular in Germany.\nBy 1933, California had subjected more people to forceful sterilization than all other U.S. states combined.\nThe forced sterilization program engineered by the Nazis was partly inspired by California’s."
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#sterilizations-continue-in-america",
    "href": "Lecture_Folder/Week2b.html#sterilizations-continue-in-america",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Sterilizations continue in America",
    "text": "Sterilizations continue in America\n\nOur history books paint Nazi Germany as the primary evil of that time, while we try to cover up our significant role in eugenics\nIt wasn’t until 1978 that the US passed regulations on sterilization procedures\nCalifornia only passed a bill to outlaw sterilization of inmates in 2014\nCertain members of the genetic engineering community threaten to bring back eugenics ideas"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#so-what-do-we-do-from-here",
    "href": "Lecture_Folder/Week2b.html#so-what-do-we-do-from-here",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "So, what do we do from here?",
    "text": "So, what do we do from here?\n\nThe statistical methods that Galton, Fisher, and others developed are useful science tools\nImportant to use these tools for good - improving our planet, human health, and technology\nImportant to acknowledge and not forget the history of science - educate others to avoid repeating history"
  },
  {
    "objectID": "Lecture_Folder/Week2b.html#interested-in-learning-more",
    "href": "Lecture_Folder/Week2b.html#interested-in-learning-more",
    "title": "Week 2b - Statistics for Bioengineering",
    "section": "Interested in learning more?",
    "text": "Interested in learning more?\n\n\n\n\n\n\n\n\n\n\nSee also “The Gene” by Siddhartha Mukherjee"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html",
    "href": "Lecture_Folder/Week2a.html",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#an-example-to-get-us-started",
    "href": "Lecture_Folder/Week2a.html#an-example-to-get-us-started",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "An example to get us started",
    "text": "An example to get us started"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#data-set-rules-of-thumb-aka-tidy-data",
    "href": "Lecture_Folder/Week2a.html#data-set-rules-of-thumb-aka-tidy-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Data set rules of thumb (aka Tidy Data)",
    "text": "Data set rules of thumb (aka Tidy Data)\n\nStore a copy of data in nonproprietary software and hardware formats, such as plain ASCII text (aka a flat file)\nLeave an uncorrected file when doing analyses\nUse descriptive names for your data files and variables\nInclude a header line with descriptive variable names\nMaintain effective metadata about the data (data dictionary)\nWhen you add observations to a database, add rows\nWhen you add variables to a database, add columns, not rows\nA column of data should contain only one data type"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#not-all-data-are-tidy-to-begin-with",
    "href": "Lecture_Folder/Week2a.html#not-all-data-are-tidy-to-begin-with",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Not all data are tidy to begin with",
    "text": "Not all data are tidy to begin with\n\nSometimes need to do some data wrangling\nBut also contingency tables"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#types-of-data",
    "href": "Lecture_Folder/Week2a.html#types-of-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Types of data",
    "text": "Types of data\n\n\n\n\n\n\n\n\n\nCategorical\n\nQuantitative\n\n\n\nOrdinal\nNominal\nRatio\nInterval\n\n\nsmall, medium, large\napples, oranges, bananas\nkilograms, dollars, years\ntemperature, calendar year\n\n\nordered character\ncharacter\nnumeric\ninteger\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n‘Factor’ is a special type of character variable that we will explore more later"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#computational-tools---r-and-rstudio",
    "href": "Lecture_Folder/Week2a.html#computational-tools---r-and-rstudio",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Computational Tools - R and RStudio",
    "text": "Computational Tools - R and RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#why-use-r",
    "href": "Lecture_Folder/Week2a.html#why-use-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nGood general scripting tool for statistics and mathematics\nPowerful and flexible and free\nRuns on all computer platforms\nNew enhancements coming out all the time\nSuperb data management & graphics capabilities"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#why-use-r-1",
    "href": "Lecture_Folder/Week2a.html#why-use-r-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nReproducibility - can keep your scripts to see exactly what was done\nYou can write your own functions\nLots of online help available\nCan use a nice GUI front end such as Rstudio\nCan embed your R analyses in dynamic, polished files using Markdown\nMarkdown can be reused for websites, papers, books, presentations…"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#r-scripts-and-markdown-files",
    "href": "Lecture_Folder/Week2a.html#r-scripts-and-markdown-files",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "R scripts and Markdown files",
    "text": "R scripts and Markdown files\n\nOften we want to write scripts that can just be run\nWe can also embed code in Markdown files that provide more annotations\nhttps://quarto.org/docs/authoring/markdown-basics.html\nYou can insert Rchunks into Quarto markdown documents"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#rscript-basics",
    "href": "Lecture_Folder/Week2a.html#rscript-basics",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Rscript basics",
    "text": "Rscript basics\n\nA series of R commands that will be executed\nCan add comments using hashtags #\nCan have pipes (|&gt;) to connect one step to the next"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#markdown-basics",
    "href": "Lecture_Folder/Week2a.html#markdown-basics",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Markdown basics",
    "text": "Markdown basics\n\na very simplified way for standard typesetting\nsimple markdown can be rendered in numerous different ways\nLists, codeblocks, images and more can all be inserted"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#inserting-equations-in-markdown",
    "href": "Lecture_Folder/Week2a.html#inserting-equations-in-markdown",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Inserting equations in markdown",
    "text": "Inserting equations in markdown\n$$e=mc^2$$\n\\[e=mc^2\\]\n$$\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy$$\n\\[\\iint\\limits_{a}^{b} f(x,y) \\, dx \\, dy\\]"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#basics-of-r",
    "href": "Lecture_Folder/Week2a.html#basics-of-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "BASICS of R",
    "text": "BASICS of R\n\nCommands can be submitted through the terminal, console or scripts\nIn your scripts, anything that follows ‘#’ symbol (aka hash) is just for humans\nNotice on these slides I’m evaluating the code chunks and showing output\nThe output is shown here after the two # symbols and the number of output items is in []\nAlso notice that R follows the normal priority of mathematical evaluation\n\n\n4*4\n\n[1] 16\n\n\n\n(4+3*2^2)\n\n[1] 16"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#assigning-variables",
    "href": "Lecture_Folder/Week2a.html#assigning-variables",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nA better way to do this is to assign variables\nVariables are assigned values using the &lt;- operator.\nVariable names must begin with a letter, but other than that, just about anything goes.\nDo keep in mind that R is case sensitive."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#assigning-variables-1",
    "href": "Lecture_Folder/Week2a.html#assigning-variables-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Assigning Variables",
    "text": "Assigning Variables\n\nx &lt;- 2\nx*3\n\n[1] 6\n\ny &lt;- x * 3\ny-2\n\n[1] 4\n\n\nThese do not work\n\n3y &lt;- 3\n3*y &lt;- 3"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions",
    "href": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\nArithmetic operations can be performed easily on functions as well as numbers.\nTry the following, and then your own.\n\n\nx+2\nx^2\nlog(x)\n\n\nNote that the last of these - log - is a built in function of R, and therefore the object of the function needs to be put in parentheses\nThese parentheses will be important, and we’ll come back to them later when we add arguments after the object in the parentheses\n\nThe outcome of calculations can be assigned to new variables as well, and the results can be checked using the ‘print’ command"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions-1",
    "href": "Lecture_Folder/Week2a.html#arithmetic-operations-on-functions-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Arithmetic operations on functions",
    "text": "Arithmetic operations on functions\n\ny &lt;- 67\nprint(y)\n\n[1] 67\n\nx &lt;- 124\nz &lt;- (x*y)^2\nprint(z)\n\n[1] 69022864"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#strings",
    "href": "Lecture_Folder/Week2a.html#strings",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nVariables and operations can be performed on characters as well\nNote that characters need to be set off by quotation marks to differentiate them from numbers\nThe c stands for concatenate\nNote that we are using the same variable names as we did previously, which means that we’re overwriting our previous assignment\nA good rule of thumb is to use new names for each variable, and make them short but still descriptive"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#strings-1",
    "href": "Lecture_Folder/Week2a.html#strings-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "STRINGS",
    "text": "STRINGS\n\nx &lt;- \"I Love\"\nprint (x)\n\n[1] \"I Love\"\n\ny &lt;- \"Biostatistics\"\nprint (y)\n\n[1] \"Biostatistics\"\n\nz &lt;- c(x,y)\nprint (z)\n\n[1] \"I Love\"        \"Biostatistics\""
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#factors",
    "href": "Lecture_Folder/Week2a.html#factors",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nThe variable z is now what is called a list of character values.\nSometimes we would like to treat the characters as if they were units for subsequent calculations.\nThese are called factors, and we can redefine our character variables as factors.\nThis might seem a bit strange, but it’s important for statistical analyses where we might want to see the mean or variance for two different treatments."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#factors-1",
    "href": "Lecture_Folder/Week2a.html#factors-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "FACTORS",
    "text": "FACTORS\n\nz_factor &lt;- as.factor(z)\nprint (z_factor)\n\n\nNote that factor levels are reported alphabetically"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#vectors",
    "href": "Lecture_Folder/Week2a.html#vectors",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nIn general R thinks in terms of vectors (a list of characters, factors or numerical values)\nit will benefit any R user to try to write programs with that in mind, as it will simplify most things.\nVectors can be assigned directly using the ‘c()’ function and then entering the exact values."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#vectors-1",
    "href": "Lecture_Folder/Week2a.html#vectors-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "VECTORS",
    "text": "VECTORS\n\nx &lt;- c(2,3,4,2,1,2,4,5,10,8,9)\nprint(x)\n\n [1]  2  3  4  2  1  2  4  5 10  8  9"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#basic-statistics",
    "href": "Lecture_Folder/Week2a.html#basic-statistics",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nMany functions exist to operate on vectors.\nCombine these with your previous variable to see what happens.\nAlso, try to find other functions (e.g. standard deviation)."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#basic-statistics-1",
    "href": "Lecture_Folder/Week2a.html#basic-statistics-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Basic Statistics",
    "text": "Basic Statistics\n\nmean(x)\nmedian(x)\nvar(x)\nlog(x)\nln(x)\nsqrt(x)\nsum(x)\nlength(x)\nsample(x, replace = T)\n\n\nNotice that the last function (sample) has an argument (replace=T)\nArguments simply modify or direct the function in some way\nThere are many arguments for each function, some of which are defaults"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#getting-help",
    "href": "Lecture_Folder/Week2a.html#getting-help",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\nGetting Help on any function is very easy - just type a question mark and the name of the function.\nThere are functions for just about anything within R and it is easy enough to write your own functions if none already exist to do what you want to do.\nIn general, function calls have a simple structure: a function name, a set of parentheses and an optional set of parameters to send to the function.\nHelp pages exist for all functions that, at a minimum, explain what parameters exist for the function.\n\nHelp can be accessed a few ways - try them :"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#getting-help-1",
    "href": "Lecture_Folder/Week2a.html#getting-help-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Getting Help",
    "text": "Getting Help\n\n- help(mean)\n- ?mean\n- example(mean)\n- help.search(\"mean\")\n- apropos(\"mean\")\n- args(mean)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors",
    "href": "Lecture_Folder/Week2a.html#creating-vectors",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nCreating vector of new data by entering it by hand can be a drag\nHowever, it is also very easy to use functions such as seq and sample\nTry the examples below Can you figure out what the three arguments in the parentheses mean?\nTry varying the arguments to see what happens.\nDon’t go too crazy with the last one or your computer might slow way down"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors-1",
    "href": "Lecture_Folder/Week2a.html#creating-vectors-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nprint(seq_1)\n\n  [1]  0.0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1.0  1.1  1.2  1.3  1.4\n [16]  1.5  1.6  1.7  1.8  1.9  2.0  2.1  2.2  2.3  2.4  2.5  2.6  2.7  2.8  2.9\n [31]  3.0  3.1  3.2  3.3  3.4  3.5  3.6  3.7  3.8  3.9  4.0  4.1  4.2  4.3  4.4\n [46]  4.5  4.6  4.7  4.8  4.9  5.0  5.1  5.2  5.3  5.4  5.5  5.6  5.7  5.8  5.9\n [61]  6.0  6.1  6.2  6.3  6.4  6.5  6.6  6.7  6.8  6.9  7.0  7.1  7.2  7.3  7.4\n [76]  7.5  7.6  7.7  7.8  7.9  8.0  8.1  8.2  8.3  8.4  8.5  8.6  8.7  8.8  8.9\n [91]  9.0  9.1  9.2  9.3  9.4  9.5  9.6  9.7  9.8  9.9 10.0\n\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)\nprint(seq_2)\n\n  [1] 10.0  9.9  9.8  9.7  9.6  9.5  9.4  9.3  9.2  9.1  9.0  8.9  8.8  8.7  8.6\n [16]  8.5  8.4  8.3  8.2  8.1  8.0  7.9  7.8  7.7  7.6  7.5  7.4  7.3  7.2  7.1\n [31]  7.0  6.9  6.8  6.7  6.6  6.5  6.4  6.3  6.2  6.1  6.0  5.9  5.8  5.7  5.6\n [46]  5.5  5.4  5.3  5.2  5.1  5.0  4.9  4.8  4.7  4.6  4.5  4.4  4.3  4.2  4.1\n [61]  4.0  3.9  3.8  3.7  3.6  3.5  3.4  3.3  3.2  3.1  3.0  2.9  2.8  2.7  2.6\n [76]  2.5  2.4  2.3  2.2  2.1  2.0  1.9  1.8  1.7  1.6  1.5  1.4  1.3  1.2  1.1\n [91]  1.0  0.9  0.8  0.7  0.6  0.5  0.4  0.3  0.2  0.1  0.0"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors-2",
    "href": "Lecture_Folder/Week2a.html#creating-vectors-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square &lt;- (seq_2)*(seq_2)\nprint(seq_square)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-vectors-3",
    "href": "Lecture_Folder/Week2a.html#creating-vectors-3",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating vectors",
    "text": "Creating vectors\n\nseq_square_new &lt;- (seq_2)^2\nprint(seq_square_new)\n\n  [1] 100.00  98.01  96.04  94.09  92.16  90.25  88.36  86.49  84.64  82.81\n [11]  81.00  79.21  77.44  75.69  73.96  72.25  70.56  68.89  67.24  65.61\n [21]  64.00  62.41  60.84  59.29  57.76  56.25  54.76  53.29  51.84  50.41\n [31]  49.00  47.61  46.24  44.89  43.56  42.25  40.96  39.69  38.44  37.21\n [41]  36.00  34.81  33.64  32.49  31.36  30.25  29.16  28.09  27.04  26.01\n [51]  25.00  24.01  23.04  22.09  21.16  20.25  19.36  18.49  17.64  16.81\n [61]  16.00  15.21  14.44  13.69  12.96  12.25  11.56  10.89  10.24   9.61\n [71]   9.00   8.41   7.84   7.29   6.76   6.25   5.76   5.29   4.84   4.41\n [81]   4.00   3.61   3.24   2.89   2.56   2.25   1.96   1.69   1.44   1.21\n [91]   1.00   0.81   0.64   0.49   0.36   0.25   0.16   0.09   0.04   0.01\n[101]   0.00"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nHere is a way to create your own data sets that are random samples.\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-1",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(x,y)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-2",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nplot(xy)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-3",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-3",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;- rnorm (10000, 0, 10)\ny &lt;- sample (1:10000, 10000, replace = T)\nxy &lt;- cbind(x,y)\nhist(x)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-4",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-4",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nYou’ve probably figured out that y from the last example is drawing numbers with equal probability.\nWhat if you want to draw from a distribution?\nAgain, play around with the arguments in the parentheses to see what happens."
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-5",
    "href": "Lecture_Folder/Week2a.html#drawing-samples-from-distributions-5",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Drawing samples from distributions",
    "text": "Drawing samples from distributions\n\nx &lt;-rnorm(1000, 0, 100)\nhist(x, xlim = c(-500,500))\ncurve(50000*dnorm(x, 0, 100), xlim = c(-500,500), add=TRUE, col='Red')\n\n\n\n\n\n\n\n\n\ndnorm() generates the probability density, which can be plotted using the curve() function.\nNote that is curve is added to the plot using add=TRUE"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#visualizing-data",
    "href": "Lecture_Folder/Week2a.html#visualizing-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nSo far you’ve been visualizing just the list of output numbers\nExcept for the last example where I snuck in a hist function.\nYou can also visualize all of the variables that you’ve created using the plot function (as well as a number of more sophisticated plotting functions).\nEach of these is called a high level plotting function, which sets the stage\nLow level plotting functions will tweak the plots and make them beautiful"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#visualizing-data-1",
    "href": "Lecture_Folder/Week2a.html#visualizing-data-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nWhat do you think that each of the arguments means for the plot function?\nA cool thing about R is that the options for the arguments make sense.\nTry adjusting an argument and see if it works\nNote soon we will be exploring the plotting in ggplot2"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#visualizing-data-2",
    "href": "Lecture_Folder/Week2a.html#visualizing-data-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Visualizing Data",
    "text": "Visualizing Data\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1) \nplot (seq_1, xlab=\"space\", ylab =\"function of space\", type = \"p\", col = \"red\")"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure",
    "href": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\nOn the next slide\nThe first line of the lower script tells R that you are going to create a composite figure that has two rows and two columns. Can you tell how?\nNow, modify the code to add two more variables and add one more row of two panels.\n\n\nseq_1 &lt;- seq(0.0, 10.0, by = 0.1)\nseq_2 &lt;- seq(10.0, 0.0, by = -0.1)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure-1",
    "href": "Lecture_Folder/Week2a.html#putting-plots-in-a-single-figure-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Putting plots in a single figure",
    "text": "Putting plots in a single figure\n\npar(mfrow=c(2,2))\nplot (seq_1, xlab=\"time\", ylab =\"p in population 1\", type = \"p\", col = 'red')\nplot (seq_2, xlab=\"time\", ylab =\"p in population 2\", type = \"p\", col = 'green')\nplot (seq_square, xlab=\"time\", ylab =\"p2 in population 2\", type = \"p\", col = 'blue')\nplot (seq_square_new, xlab=\"time\", ylab =\"p in population 1\", type = \"l\", col = 'yellow')"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#example-using-binomial-distribution",
    "href": "Lecture_Folder/Week2a.html#example-using-binomial-distribution",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nAs above for the normal distribution, data can be generated by being sampled from nearly any distribution and then visualized.\nBelow I’m having you use the ‘histogram’ function. What does it do?"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-1",
    "href": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\n10 successes (out of 20 trials) is the most frequent outcome\n\n\nheads &lt;- rbinom(n=1000, size=20, prob=0.5)\nhist(heads)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-2",
    "href": "Lecture_Folder/Week2a.html#example-using-binomial-distribution-2",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Example using binomial distribution",
    "text": "Example using binomial distribution\n\nThis kind of statement can be run in one line as well, which is sometimes easier.\n\n\nhist(rbinom(n=1000, size=20, prob=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#creating-data-frames-in-r",
    "href": "Lecture_Folder/Week2a.html#creating-data-frames-in-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Creating Data Frames in R",
    "text": "Creating Data Frames in R\n\nAs you have seen, in R you can generate your own random data set drawn from nearly any distribution very easily.\nOften we will want to use collected data.\nNow, let’s make a dummy dataset to get used to dealing with data frames\nSet up three variables (hydrogel_concentration, compression and conductivity) as vectors\n\n\nhydrogel_concentration &lt;- factor(c(\"low\", \"high\", \"high\", \"high\", \"medium\", \"medium\", \"medium\",\"low\"))\ncompression &lt;- c(3.4, 3.4, 8.4, 3, 5.6, 8.1, 8.3, 4.5)\nconductivity &lt;- c(0, 9.2, 3.8, 5, 5.6, 4.1, 7.1, 5.3)\n\n\nCreate a data frame where vectors become columns\n\n\nmydata &lt;- data.frame(hydrogel_concentration, compression, conductivity)\nrow.names(mydata) &lt;- c(\"Sample_1\", \"Sample_2\", \"Sample_3\", \"Sample_4\", \n                       \"Sample_5\", \"Sample_6\", \"Sample_7\", \"Sample_8\")\n\n\nNow you have a hand-made data frame with row names\nTake a look at it in the data section of RStudio"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r",
    "href": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nA strength of R is being able to import data from an external source\nCreate the same table that you did above in a spreadsheet like Excel\nExport it to comma separated and tab separated text files for importing into R.\nThe first will read in a comma-delimited file, whereas the second is a tab-delimited\nIn both cases the header and row.names arguments indicate that there is a header row and row label column\nNote that the name of the file by itself will have R look in the CWD, whereas a full path can also be used"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r-1",
    "href": "Lecture_Folder/Week2a.html#reading-in-data-frames-in-r-1",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Reading in Data Frames in R",
    "text": "Reading in Data Frames in R\n\nYourFile &lt;- read.table('yourfile.csv', header=T, row.names=1, sep=',')\nYourFile &lt;- read.table('yourfile.txt', header=T, row.names=1, sep='\\t')"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#exporting-data-frames-in-r",
    "href": "Lecture_Folder/Week2a.html#exporting-data-frames-in-r",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Exporting Data Frames in R",
    "text": "Exporting Data Frames in R\n\nwrite.table(YourFile, \"yourfile.csv\", quote=F, row.names=T, sep=\",\")\nwrite.table(YourFile, \"yourfile.txt\", quote=F, row.names=T, sep=\"\\t\")"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#indexing-in-data-frames",
    "href": "Lecture_Folder/Week2a.html#indexing-in-data-frames",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Indexing in data frames",
    "text": "Indexing in data frames\n\nNext up - indexing just a subset of the data\nThis is a very important idea in R, that you can analyze just a subset of the data.\nThis is analyzing only the data in the file you made that has the factor value ‘mixed’.\n\n\nprint (YourFile[,2])\nprint (YourFile$variable)\nprint (YourFile[2,])\nplot (YourFile$variable1, YourFile$variable2)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#r-interlude-some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week2a.html#r-interlude-some-real-transcriptomic-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Some real transcriptomic data",
    "text": "R INTERLUDE | Some real transcriptomic data\n\nExamine the data file\nHow many many rows and columns are there?\nHow many different variables are there?\nWhat are the general types of variables?\nNow let’s read the data file into R and analyze it\nThis exercise will help you get used to reading in and manipulating genomic data files\nFirst off, remember to set your working directory to find your file correctly"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#some-real-transcriptomic-data",
    "href": "Lecture_Folder/Week2a.html#some-real-transcriptomic-data",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Some real transcriptomic data",
    "text": "Some real transcriptomic data\n\nRNAseq_Data &lt;- read.table('&lt;name_of_file&gt;', header=TRUE, sep=',')\n\nprint (RNAseq_Data)\nhead (RNAseq_Data)\ntail (RNAseq_Data)\n\nprint (RNAseq_Data[,2])\nprint (RNAseq_Data[1,])\nprint (RNAseq_Data[1,2])\nprint (RNAseq_Data$ENSGACG00000000010)\nprint (RNAseq_Data$ENSGACG00000000010&gt;45.0)"
  },
  {
    "objectID": "Lecture_Folder/Week2a.html#summary-stats-and-figures",
    "href": "Lecture_Folder/Week2a.html#summary-stats-and-figures",
    "title": "Week 2a - Statistics for Bioengineering",
    "section": "Summary stats and figures",
    "text": "Summary stats and figures\n\nsummary1 &lt;- summary(RNAseq_Data $ENSGACG00000000003)\nprint (summary1)\n\nhist(RNAseq_Data $ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003)\nboxplot(RNAseq_Data$ENSGACG00000000003~RNAseq_Data$Population)\nplot(RNAseq_Data $ENSGACG00000000003, RNAseq_Data$ENSGACG00000000003)\n\nboxplot(RNAseq_Data $ENSGACG00000000003~RNAseq_Data$Treatment, \n        col = \"red\", ylab = \"Expression Level\", xlab = \"Treatment level\", \n        border =\"orange\", \n        main = \"Boxplot of variation in gene expression across microbiota treatments\")"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#what-type-of-plot-do-i-use-for-each-data-type",
    "href": "Lecture_Folder/Week3a.html#what-type-of-plot-do-i-use-for-each-data-type",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "What type of plot do I use for each data type?",
    "text": "What type of plot do I use for each data type?\n\n\n\nFlow chart to determine what type of data visualization and which ggplot geom to use"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#three-dimensional-data",
    "href": "Lecture_Folder/Week3a.html#three-dimensional-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Three dimensional data",
    "text": "Three dimensional data\n\nset.seed(345) # make the example reproducible\na &lt;- rnorm(100,10,10)\nb &lt;- rnorm(100,5,5)\nc &lt;- rnorm(100,1,1)\nd &lt;- data.frame(a,b,c)\n\nlibrary(MASS)\nDENS &lt;- kde2d(d$a,d$b)\ncontour(DENS)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#three-dimensional-data-1",
    "href": "Lecture_Folder/Week3a.html#three-dimensional-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Three dimensional data",
    "text": "Three dimensional data\n\nset.seed(345) # make the example reproducible\na &lt;- rnorm(100,10,10)\nb &lt;- rnorm(100,5,5)\nc &lt;- rnorm(100,1,1)\nd &lt;- data.frame(a,b,c)\n\nlibrary(MASS)\nDENS &lt;- kde2d(d$a,d$b)\nfilled.contour(DENS,plot.axes = {\n  axis(1)\n  axis(2)\ncontour(DENS,add = TRUE)})"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#three-dimensional-data-2",
    "href": "Lecture_Folder/Week3a.html#three-dimensional-data-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Three dimensional data",
    "text": "Three dimensional data\n\nset.seed(345) # make the example reproducible\na &lt;- rnorm(100,10,10)\nb &lt;- rnorm(100,5,5)\nc &lt;- rnorm(100,1,1)\nd &lt;- data.frame(a,b,c)\n\nlibrary(ggplot2)\nggplot(d,aes(x=a,y=b)) +\n  geom_density2d()"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#section",
    "href": "Lecture_Folder/Week3a.html#section",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "",
    "text": "Examples of bad graphs and how to improve them.\nCourtesy of K.W. Broman\n\nwww.biostat.wisc.edu/~kbroman/topten_worstgraphs/"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#ticker-tape-parade",
    "href": "Lecture_Folder/Week3a.html#ticker-tape-parade",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Ticker tape parade",
    "text": "Ticker tape parade\n\n\n\nRoeder K 1994 DNA fingerprinting: A review of the controversy with discussion . Statistical Science 9:222T278, Figure 4"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-line-to-no-understanding",
    "href": "Lecture_Folder/Week3a.html#a-line-to-no-understanding",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "A line to no understanding",
    "text": "A line to no understanding\n\n\n\nEpstein MP, Satten GA 2003 Inference on haplotype effects in caseTcontrol studies using unphased genotype data. American Journal of Human Genetics 73:1316T1329, Figure 1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-hot-cup-o-mixed-messages",
    "href": "Lecture_Folder/Week3a.html#a-hot-cup-o-mixed-messages",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "A hot cup o’ mixed messages",
    "text": "A hot cup o’ mixed messages"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#i-want-the-biggest-slice-of-the-tfbs-pie",
    "href": "Lecture_Folder/Week3a.html#i-want-the-biggest-slice-of-the-tfbs-pie",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "I want the biggest slice of the TFBS pie",
    "text": "I want the biggest slice of the TFBS pie\n\n\n\nCawley S, et al. 2004 Unbiased mapping of transcription factor binding sites along human chromosomes 21 and 22 points to widespread regulation of noncoding RNAs. Cell 116:499T509, Figure 1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-bake-sale-of-pie-charts",
    "href": "Lecture_Folder/Week3a.html#a-bake-sale-of-pie-charts",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "A bake sale of pie charts",
    "text": "A bake sale of pie charts\n\n\n\nBell ML, et al. 2007 Spatial and temporal variation in PM2.5 chemical composition in the United States for health effects studies. Environmental Health Perspectives 115:989T995, Figure 3"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#wack-a-mole",
    "href": "Lecture_Folder/Week3a.html#wack-a-mole",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Wack a mole",
    "text": "Wack a mole\n\n\n\nCotter DJ, et al. 2004 Hematocrit was not validated as a surrogate endpoint for survival amoung epoetinTtreated hemodialysis patients. Journal of Clinical Epidemiology 57:1086T1095, Figure 2"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#principles-of-effective-display",
    "href": "Lecture_Folder/Week3a.html#principles-of-effective-display",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Principles of effective display",
    "text": "Principles of effective display\n\n“Graphical excellence is that which gives to the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space”\n— Edward Tufte"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-best-statistical-graphic-ever-drawn-according-to-edward-tufte",
    "href": "Lecture_Folder/Week3a.html#the-best-statistical-graphic-ever-drawn-according-to-edward-tufte",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The best statistical graphic ever drawn according to Edward Tufte",
    "text": "The best statistical graphic ever drawn according to Edward Tufte\n\n\n\nThis map by Charles Joseph Minard portrays the losses suffered by Napoleon’s army in the Russian campaign of 1812"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#principles-of-effective-display-1",
    "href": "Lecture_Folder/Week3a.html#principles-of-effective-display-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Principles of effective display",
    "text": "Principles of effective display\n\nShow the data\n\nEncourage the eye to compare differences\nRepresent magnitudes honestly and accurately\n\nDraw graphical elements clearly, minimizing clutter\n\nMake displays easy to interpret"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#above-all-else-show-the-data-tufte-1983",
    "href": "Lecture_Folder/Week3a.html#above-all-else-show-the-data-tufte-1983",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "“Above all else show the data” | Tufte 1983",
    "text": "“Above all else show the data” | Tufte 1983\n\n\n\nThe relationship between the numbers of native tropical stingless bees and Africanized honey bees onflowering shrubs in French Guiana. The data have been erased in the left panel. Redrawn from Roubik 1978."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#maximize-the-data-to-ink-ratio-within-reason-tufte-1983",
    "href": "Lecture_Folder/Week3a.html#maximize-the-data-to-ink-ratio-within-reason-tufte-1983",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "“Maximize the data to ink ratio, within reason” | Tufte 1983",
    "text": "“Maximize the data to ink ratio, within reason” | Tufte 1983\nDraw graphical elements clearly, minimizing clutter\n\n\n\nThe percentage of adults over 18 with a “body mass index” greater than 25 in different years The Economist 2006 . Body mass index is a measure of weight relative to height."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#a-graphic-does-not-distort-if-the-visual-representation-of-the-data-is-consistent-with-the-numerical-representation-tufte-1983",
    "href": "Lecture_Folder/Week3a.html#a-graphic-does-not-distort-if-the-visual-representation-of-the-data-is-consistent-with-the-numerical-representation-tufte-1983",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "“A graphic does not distort if the visual representation of the data is consistent with the numerical representation” – Tufte 1983",
    "text": "“A graphic does not distort if the visual representation of the data is consistent with the numerical representation” – Tufte 1983\nRepresent magnitudes honestly and accurately\n\n\n\nSlow wave sleep in the brain hemispheres of mallard ducks sleeping with one eye open. From Rattenborg et al. 1999 Nature"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.",
    "href": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "How Fox News makes a figure ….",
    "text": "How Fox News makes a figure …."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.-1",
    "href": "Lecture_Folder/Week3a.html#how-fox-news-makes-a-figure-.-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "How Fox News makes a figure ….",
    "text": "How Fox News makes a figure ….\n\n“Graphical excellence begins with telling the truth about the data” – Tufte 1983"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude",
    "href": "Lecture_Folder/Week3a.html#r-interlude",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R Interlude",
    "text": "R Interlude\n\nread in the data set Week1b_Stickle_RNAseq.tsv and assign it to a data object\ntry out the command View for the whole data set\ntry out the command summary for one of the variables\nload the package tidyverse and try the command glimpse\ntry making some nice plots of the different types of data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#stochastic-processes-in-statistics",
    "href": "Lecture_Folder/Week3a.html#stochastic-processes-in-statistics",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Stochastic Processes in Statistics",
    "text": "Stochastic Processes in Statistics\n\nWe often want to know truths about the world, but the best we can do is estimate them\nUncertainty in those estimates is a given.\nThe process of statistics is largely about quantifying and managing uncertainty.\nRandom variables are the product of stochastic processes\nExpectations can be based on theoretical probability distributions\nWe are going to start with probability rules and then slowly experience different distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#different-flavors-of-inferential-statistics",
    "href": "Lecture_Folder/Week3a.html#different-flavors-of-inferential-statistics",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Different flavors of inferential statistics",
    "text": "Different flavors of inferential statistics\n\nFrequentist Statistics\n\nClassical or standard approaches\nNull hypothesis testing\n\n\n\nHierarchical Probabilistic Modeling\n\nMaximum Likelihood\nBayesian Analyses\nMachine Learning"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#what-is-probability",
    "href": "Lecture_Folder/Week3a.html#what-is-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "What is probability",
    "text": "What is probability\n\nFrequency interpretation\n\n“Probabilities are understood as mathematically convenient approximations to long run relative frequencies.”\n\nSubjective (Bayesian) interpretation\n\n“A probability statement expresses the opinion of some individual regarding how certain an event is to occur.”"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#random-variables-probability",
    "href": "Lecture_Folder/Week3a.html#random-variables-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nProbability is the expression of belief in some future outcome\nA random variable can take on different values with different probabilities\nThe sample space of a random variable is the universe of all possible values"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#random-variables-probability-1",
    "href": "Lecture_Folder/Week3a.html#random-variables-probability-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nThe sample space can be represented by a\n\nprobability mass distribution (discrete)\nprobability density function (PDF) (continuous)\nalgebra and calculus are used for each respectively\nprobabilities of a sample space always sum to 1.0\n\nHow does it make sense that a sample space will always sum to 1?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#bernoulli-distribution",
    "href": "Lecture_Folder/Week3a.html#bernoulli-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nDescribes the expected outcome of a single event with probability p\nExample of flipping of a fair coin once\n\n\\[Pr(X=\\text{Head}) = \\frac{1}{2} = 0.5 = p \\]\n\\[Pr(X=\\text{Tails}) = \\frac{1}{2} = 0.5 = 1 - p = q \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#bernoulli-distribution-1",
    "href": "Lecture_Folder/Week3a.html#bernoulli-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nIf the coin isn’t fair then \\(p \\neq 0.5\\)\nHowever, the probabilities still sum to 1\n\n\\[ p + (1-p) = 1 \\] \\[ p + q = 1 \\]\n\nSame is true for other binary possibilities\n\nsuccess or failure\nyes or no answers\nchoosing an allele from a population based upon allele frequencies (Hardy-Weinberg ring any bells??)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#probability-rules",
    "href": "Lecture_Folder/Week3a.html#probability-rules",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nFlip a coin twice\nRepresent the first flip as ‘X’ and the second flip as ‘Y’\n\n\\[ Pr(\\text{X=H and Y=H}) = p*p = p^2 \\] \\[ Pr(\\text{X=H and Y=T}) = p*q = pq = p^2 \\] \\[ Pr(\\text{X=T and Y=H}) = q*p = pq \\] \\[ Pr(\\text{X=T and Y=T}) = q*q = q^2 \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#probability-rules-1",
    "href": "Lecture_Folder/Week3a.html#probability-rules-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nProbability that the H and T can occur in any order\n\n\\[ \\text{Pr(X=H) or Pr(X=T)} = p+q=1\\]\n\\[ \\text{Pr(X=H and Y=T) or Pr(X=T and Y=H)} = \\] \\[ (p*q) + (p*q) = 2pq \\]\n\nThese are the ‘and’ and ‘or’ rules of probability\n\n‘and’ means multiply the probabilities\n‘or’ means sum the probabilities\nmost probability distributions can be built up from these simple rules"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips",
    "href": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\n# tossing a fair coin\ncoin &lt;- c(\"heads\", \"tails\")\n\nsample(coin)\n\n[1] \"tails\" \"heads\""
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips-1",
    "href": "Lecture_Folder/Week3a.html#lets-simulate-some-coin-flips-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\nWhat happens when we change the probabilities or the sample size? How confident are we that our coin is fair?\n\n\nflips &lt;- sample(coin, prob = c(0.5, 0.5), size=13, replace=TRUE)\nbarplot(table(flips))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#expectation-and-moments-of-distributions",
    "href": "Lecture_Folder/Week3a.html#expectation-and-moments-of-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Expectation and Moments of Distributions",
    "text": "Expectation and Moments of Distributions\n\nDistributions have moments that can be estimated\n1st, 2nd, 3rd and 4th moments of a distribution?\nThe expectation or mean of a random variable X is:\n\n\\[E[X] = \\sum_{\\text{all x}}^{}xP(X=x) = \\mu\\]\n\nOften we want to know how dispersed the random variable is around its mean.\nOne measure of dispersion is the variance\nThere are higher moments of distributions (e.g. skew and kurtosis)\n\n\\[Var(X) = E[X^2] = \\sigma^2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#joint-probability",
    "href": "Lecture_Folder/Week3a.html#joint-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Joint probability",
    "text": "Joint probability\n\\[Pr(X,Y) = Pr(X) * Pr(Y)\\]\n\nNote that this is true for two independent events\nHowever, for two non-independent events we also have to take into account their covariance\nTo do this we need conditional probabilities"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#conditional-probability",
    "href": "Lecture_Folder/Week3a.html#conditional-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nFor two independent variables: Probability of Y, given X, or the probability of X, given Y.\n\n\\[Pr(Y|X) = Pr(Y)\\text{ and }Pr(X|Y) = Pr(X)\\]\n\nFor two non-independent variables\n\n\\[Pr(Y|X) \\neq Pr(Y)\\text{ and }Pr(X|Y) \\neq Pr(X)\\]\n\nVariables that are non-independent have a shared variance, which is also known as the covariance\nCovariance standardized to a mean of zero and a unit standard deviation is correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#what-is-likelihood-vs.-probability",
    "href": "Lecture_Folder/Week3a.html#what-is-likelihood-vs.-probability",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "What is Likelihood vs. Probability?",
    "text": "What is Likelihood vs. Probability?\n\nThe probability of an event is the proportion of times that the event would occur if we repeated a random trial over and over again under the same conditions.\nThe likelihood is a conditional probability of a parameter value given a set of data\nThe likelihood of a population parameter equaling a specific value, given the data\n\nL[parameter|data] = Pr[data|parameter]\n\nLikelihood function which can have a maximum\nWhat is a Bayesian estimate? - the use of prior distribution to update a posterior distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#data-cleaning-and-manipulation",
    "href": "Lecture_Folder/Week3a.html#data-cleaning-and-manipulation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Data cleaning and manipulation",
    "text": "Data cleaning and manipulation\n\nHere, we differentiate “data cleaning” from “data manipulation”, which is perhaps an arbitrary distinction.\n“Data cleaning” typically refers to altering variable class information, fixing mistakes that could have arisen in the data (e.g., an extra ‘.’ symbol in a numeric value), and things of this nature.\n“Data manipulation”, in my mind, refers to altering the structure of the data in a way that changes the functional structure the data (e.g., an addition of a column, deletion of rows, long/wide formatting change)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages",
    "href": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Tidyverse family of packages",
    "text": "Tidyverse family of packages\n\n\n\n\n\n\n\n\n\nLet’s load the tidyverse meta-package and check the output.\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages-1",
    "href": "Lecture_Folder/Week3a.html#tidyverse-family-of-packages-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Tidyverse family of packages",
    "text": "Tidyverse family of packages\n\nHadley Wickham and others have written R packages to modify data\nThese packages do many of the same things as base functions in R\nHowever, they are specifically designed to do them faster and more easily\nWickham also wrote the package ggplot2 for elegant graphics creations"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#example-of-a-tibble",
    "href": "Lecture_Folder/Week3a.html#example-of-a-tibble",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Example of a tibble",
    "text": "Example of a tibble"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#example-of-a-tibble-1",
    "href": "Lecture_Folder/Week3a.html#example-of-a-tibble-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Example of a tibble",
    "text": "Example of a tibble"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#types-of-vectors-of-data",
    "href": "Lecture_Folder/Week3a.html#types-of-vectors-of-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\nint stands for integers\ndbl stands for doubles, or real numbers\nchr stands for character vectors, or strings\ndttm stands for date-times (a date + a time)\nlgl stands for logical, vectors that contain only TRUE or FALSE\nfctr stands for factors, which R uses to represent categorical variables with fixed possible values\ndate stands for dates"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#types-of-vectors-of-data-1",
    "href": "Lecture_Folder/Week3a.html#types-of-vectors-of-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Types of vectors of data",
    "text": "Types of vectors of data\n\nLogical vectors can take only three possible values:\n\nFALSE\nTRUE\nNA which is ‘not available’.\n\nInteger and double vectors are known collectively as numeric vectors.\n\nIn R numbers are doubles by default.\n\nIntegers have one special value: NA, while doubles have four:\n\nNA\nNaN which is ‘not a number’\nInf\n-Inf"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#tidyverse-packages-cont.",
    "href": "Lecture_Folder/Week3a.html#tidyverse-packages-cont.",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Tidyverse packages (cont.)",
    "text": "Tidyverse packages (cont.)\nThe tidyverse actually comes with a lot more packages than those that are just loaded automatically.1\n\n\n [1] \"broom\"         \"conflicted\"    \"cli\"           \"dbplyr\"       \n [5] \"dplyr\"         \"dtplyr\"        \"forcats\"       \"ggplot2\"      \n [9] \"googledrive\"   \"googlesheets4\" \"haven\"         \"hms\"          \n[13] \"httr\"          \"jsonlite\"      \"lubridate\"     \"magrittr\"     \n[17] \"modelr\"        \"pillar\"        \"purrr\"         \"ragg\"         \n[21] \"readr\"         \"readxl\"        \"reprex\"        \"rlang\"        \n[25] \"rstudioapi\"    \"rvest\"         \"stringr\"       \"tibble\"       \n[29] \"tidyr\"         \"xml2\"          \"tidyverse\"    \n\n\nWe’ll use several of these additional packages during the remainder of this course.\n\nE.g. The lubridate package for working with dates and the rvest package for webscraping.\nHowever, bear in mind that these packages will have to be loaded separately."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#key-dplyr-verbs",
    "href": "Lecture_Folder/Week3a.html#key-dplyr-verbs",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Key dplyr verbs",
    "text": "Key dplyr verbs\nThere are five key dplyr verbs that you need to learn.\n\nfilter: Filter (i.e. subset) observations (rows) based on their values.\n\nselect: Select (i.e. subset) variables (columns) by their names:\n\narrange: Arrange (i.e. reorder) rows based on their values.\n\nmutate: Create new columns.\n\nsummarise: Collapse multiple rows into a single summary value.1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#filter-arrange-select",
    "href": "Lecture_Folder/Week3a.html#filter-arrange-select",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "filter(), arrange() & select()",
    "text": "filter(), arrange() & select()\n\nfilter(flights, month == 11 | month == 12)\n\n\narrange(flights, year, month, day)\n\n\nselect(flights, year)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#conditionals",
    "href": "Lecture_Folder/Week3a.html#conditionals",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "conditionals",
    "text": "conditionals\n\n== equals exactly\n&lt;, &lt;= is smaller than, is smaller than or equal to\n&gt;, &gt;=` is bigger than, is bigger than or equal to\n!= not equal to\n! NOT operator, to specify things that should be omitted\n& AND operator, allows you to chain two conditions which must both be met\n\\| OR operator, to chains two conditions when at least one should be met\n%in% belongs to one of the following (usually followed by a vector of possible values)\n\nThe AND (&) and the OR (|`) operators are also super useful when you want to separate data based on multiple conditions."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#mutate-transmutate",
    "href": "Lecture_Folder/Week3a.html#mutate-transmutate",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "mutate() & transmutate()",
    "text": "mutate() & transmutate()\nThis function will add a new variable that is a function of other variable(s)\n\nmutate(flights_sml,\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#group_by-summarize",
    "href": "Lecture_Folder/Week3a.html#group_by-summarize",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "group_by( ) & summarize( )",
    "text": "group_by( ) & summarize( )\nThis first function allows you to aggregate data by values of categorical variables\n\nby_day &lt;- group_by(flights, year, month, day)\n\nOnce you have done this aggregation, you can then calculate values (in this case the mean) of other variables split by the new aggregated levels of the categorical variable\n\nsummarise(by_day, delay = mean(dep_delay, na.rm = TRUE))\n\n\nNote - you can get a lot of missing values!\nThat’s because aggregation functions obey the usual rule of missing values:\n\nif there’s any missing value in the input, the output will be a missing value.\nfortunately, all aggregation functions have an na.rm argument which removes the missing values prior to computation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#other-dplyr-goodies",
    "href": "Lecture_Folder/Week3a.html#other-dplyr-goodies",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Other dplyr goodies",
    "text": "Other dplyr goodies\n\ngroup_by and ungroup: For (un)grouping. - Particularly useful with the summarise and mutate commands, as we’ve already seen.\n\nslice: Subset rows by position rather than filtering by values. - E.g. starwars %&gt;% slice(c(1, 5))\n\npull: Extract a column from as a data frame as a vector or scalar. - E.g. starwars %&gt;% filter(gender==\"female\") %&gt;% pull(height)\n\ncount and distinct: Number and isolate unique observations. - E.g. starwars %&gt;% count(species), or starwars %&gt;% distinct(species)\n\nYou could also use a combination of mutate, group_by, and n(), e.g. starwars %&gt;% group_by(species) %&gt;% mutate(num = n())."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-playing-with-tidyverse-functions",
    "href": "Lecture_Folder/Week3a.html#r-interlude-playing-with-tidyverse-functions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Playing with Tidyverse functions",
    "text": "R INTERLUDE | Playing with Tidyverse functions\n\nStep 1 - Read in the Week1b_Stickle_RNAseq.tsv dataset\nStep 2 - Make the dataset into a tibble\nStep 3 - Select all of the categorical variables and only 4 of the gene count variables and put them into a new data object\nStep 4 - Mutate each of the 4 gene expression values by performing a square root transformation making a new variable for each of the original (keep all 8 in the dataset).\nStep 5 - Summarize the mean and standard deviation for each of the gene count variables grouped by the ‘sex’ and ‘population’ and ‘treatment’ categorical variables\nStep 6 - Create a histogram for one of the original gene expression variables, and one of the derived variables\n\nStep 7 - Create a box plot for one of the original gene expression variables, and one of the derived variables, split by treatment\nStep 8 - Write the final data table to a .csv file and one of the figures to a .pdf file"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#discrete-probability-distributions",
    "href": "Lecture_Folder/Week3a.html#discrete-probability-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Discrete Probability Distributions",
    "text": "Discrete Probability Distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-2",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-3",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#geometric-distribution-4",
    "href": "Lecture_Folder/Week3a.html#geometric-distribution-4",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week3a.html#testing-geometric-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\n#dgeom(x=20, p=0.1)\n# 0.01215767\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week3a.html#testing-geometric-distributions-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution-1",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-probability-distribution",
    "href": "Lecture_Folder/Week3a.html#binomial-probability-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution-2",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-distribution-3",
    "href": "Lecture_Folder/Week3a.html#binomial-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-probability-distribution-1",
    "href": "Lecture_Folder/Week3a.html#binomial-probability-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-binomial-distributions",
    "href": "Lecture_Folder/Week3a.html#testing-binomial-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\ndbinom gives the density (probability) of number successes (x) in number trials (size), with (prob) probability between 0-1\n\n\n# dbinom(x=5, size=10, p=0.5)\n# 0.246\nplot(dbinom(x=1:10, size=10, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-binomial-distributions-1",
    "href": "Lecture_Folder/Week3a.html#testing-binomial-distributions-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\npbinom gives the cumulative probability of reaching at least (q) number of successes after (size) number of trials\n\n\nplot(pbinom(q=1:100, size=100, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “ones” have appeared.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “one” appearing on the \\(k^{th}\\) trial:\n\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r-1}(1-p)^{k-r}p\\]\n\nwhich simplifies to\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r}(1-p)^{k-r}\\]\n\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution-2",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “successes” have happened.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “success” appearing on the \\(k^{th}\\) trial\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#negative-binomial-distribution-3",
    "href": "Lecture_Folder/Week3a.html#negative-binomial-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 AA\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-3",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 AA\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-4",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-4",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-5",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-5",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-1",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-1",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week3a.html#testing-poisson-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-6",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-6",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in biology is when each trial is discrete but number of observations of each outcome is observed\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500 amino acids in length\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to an arbitrarily large number"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-7",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-7",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nFor example, you can examine 100 plots of land\n\ncount the number of snails in each plot\nwhat is the probability of observing a plot with ‘r’ snails is\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\), and the two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another, a hypothesis that you can test\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-2",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-2",
    "href": "Lecture_Folder/Week3a.html#poisson-probability-distribution-increasing-parameter-values-of-lambda-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#continuous-probability-distributions",
    "href": "Lecture_Folder/Week3a.html#continuous-probability-distributions",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Continuous probability distributions",
    "text": "Continuous probability distributions\n\nP(observation lies within dx of x) = f(x)dx\n\\[P(a\\leq X \\leq b) = \\int_{a}^{b} f(x) dx\\]\n\nRemember that the indefinite integral sums to one\n\\[\\int_{-\\infty}^{\\infty} f(x) dx = 1\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#continuous-probabilities",
    "href": "Lecture_Folder/Week3a.html#continuous-probabilities",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Continuous probabilities",
    "text": "Continuous probabilities\n\nE[X] may be found by integrating the product of x and the probability density function over all possible values of x:\n\\[E[X] = \\int_{-\\infty}^{\\infty} xf(x) dx \\]\n\n\\(Var(X) = E[X^2] - (E[X])^2\\), where the expectation of \\(X^2\\) is\n\\[E[X^2] = \\int_{-\\infty}^{\\infty} x^2f(x) dx \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#uniform-distribution",
    "href": "Lecture_Folder/Week3a.html#uniform-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\n\\[E[X] = \\int_{a}^{b} x\\frac{1}{b-a} dx = \\frac{(a+b)}{2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week3a.html#uniform-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#uniform-distribution-2",
    "href": "Lecture_Folder/Week3a.html#uniform-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\n\\[f(x)=\\lambda e^{-\\lambda x}\\]\n\n\nE[X] can be found be integrating \\(xf(x)\\) from 0 to infinity\n\n\n\nleading to the result that\n\n\n\n\\(E[X] = \\frac{1}{\\lambda}\\)\n\\(E[X^2] = \\frac{1}{\\lambda^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution-2",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#exponential-distribution-3",
    "href": "Lecture_Folder/Week3a.html#exponential-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\) :\n\n\n\\[f(x) = \\frac{e^{-\\lambda x}\\lambda x^{r-1}}{(r-1)!}\\lambda\\]\n\n\\[ Mean =  \\frac{r}{\\lambda} \\] \\[ Variance = \\frac{r}{\\lambda^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\n\n\n\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution-2",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#gamma-distribution-3",
    "href": "Lecture_Folder/Week3a.html#gamma-distribution-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nPretend that you want to create your own binomial distribution\n\nyou could flip 20 fair coins: 20 independent Bernoulli “trials”\nyou could then replicate this 100 times: 100 “observations”\nfor each one of your replicates you record the number of heads\nprobability of heads (“success”) for any flip of a fair coin is 0.5\n\nDraw a diagram of what you think the distribution would look like\n\nwhat will the x-axis represent, and what are its values?\nwhat will the y-axis represent, and what are its values?\nwhere will the ‘center of mass’ be?\nwhat parameter determines the value of the center of mass?\nwhat parameter determines the spread of the distribution?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-1",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nUsing R, simulate these experimental data\n\nusing the \\(rbinom()\\) function\nlook at the arguments to see how they map on to the trials, probability of each trial, and number of replicates\nuse the \\(hist()\\) function to plot the simulated data.\nwhat do the y- and x-axes represent?\nwhat is the most common outcome, in terms of the number of “successes” per trial? Does this make sense?\n\nNow just change you script to do the following\n\nperform 200 trials for each of the 100 replicates\nperform 2000 trials for each of the 100 replicate\nhow do the distributions change when you go from 20 to 200 to 2000 trials?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-2",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nNote that the binomial function incorporates both the ‘and’ and ‘or’ rules of probability\nThis part is the probability of each outcome (multiplication)\n\n\\[\\large p^{k} (1-p)^{n-k}\\]\nThis part (called the binomial coefficient) is the number of different ways each combination of outcomes can be achieved (summation)\n\\[\\large {n \\choose k}\\] Together they equal the probability of a specified number of successes\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-3",
    "href": "Lecture_Folder/Week3a.html#r-interlude-binomially-distributed-data-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | binomially distributed data",
    "text": "R INTERLUDE | binomially distributed data\n\nNow perform your experiment using R\nUse the rbinom function to replicate what you sketched out for coin flipping\nBe sure to check out the other functions in the binom family\nMake sure you know how you are mapping the parameeters to values\nTake the output and create a histogram\nDoes it look similar to what you expected?\nNow change the values around so that\n\nYou have more or fewer coin flips per trial\nYou replicate the process with more or fewer trials\nYou change the coin from being fair to being slightly biased\nYou change the coin from being slightly to heavily biased"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-gaussian-or-normal-distribution",
    "href": "Lecture_Folder/Week3a.html#the-gaussian-or-normal-distribution",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The Gaussian or Normal Distribution",
    "text": "The Gaussian or Normal Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "href": "Lecture_Folder/Week3a.html#log-normal-pdf-continuous-version-of-poisson--ish",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Log-normal PDF | Continuous version of Poisson (-ish)",
    "text": "Log-normal PDF | Continuous version of Poisson (-ish)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#transformations-to-normalize-data",
    "href": "Lecture_Folder/Week3a.html#transformations-to-normalize-data",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#transformations-to-normalize-data-1",
    "href": "Lecture_Folder/Week3a.html#transformations-to-normalize-data-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Transformations to ‘normalize’ data",
    "text": "Transformations to ‘normalize’ data"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#binomial-to-normal-categorical-to-continuous",
    "href": "Lecture_Folder/Week3a.html#binomial-to-normal-categorical-to-continuous",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Binomial to Normal | Categorical to continuous",
    "text": "Binomial to Normal | Categorical to continuous"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "href": "Lecture_Folder/Week3a.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The Normal (aka Gaussian) | Probability Density Function (PDF)",
    "text": "The Normal (aka Gaussian) | Probability Density Function (PDF)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf",
    "href": "Lecture_Folder/Week3a.html#normal-pdf",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf-a-function-of-two-parameters",
    "href": "Lecture_Folder/Week3a.html#normal-pdf-a-function-of-two-parameters",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF | A function of two parameters",
    "text": "Normal PDF | A function of two parameters\n\n(\\(\\mu\\) and \\(\\sigma\\))\n\n\n\n\n\n\n\n\n\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\epsilon \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf-estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week3a.html#normal-pdf-estimates-of-mean-and-variance",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF | estimates of mean and variance",
    "text": "Normal PDF | estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#normal-pdf-1",
    "href": "Lecture_Folder/Week3a.html#normal-pdf-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology",
    "href": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-1",
    "href": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-2",
    "href": "Lecture_Folder/Week3a.html#why-is-the-normal-special-in-biology-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biology?",
    "text": "Why is the Normal special in biology?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week3a.html#parent-offspring-resemblance",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week3a.html#genetic-model-of-complex-traits",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week3a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week3a.html#why-else-is-the-normal-special",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nThe normal distribution is immensely useful because of the central limit theorem, which says that the mean of many random variables independently drawn from the same distribution is distributed approximately normally\nOne can think of numerous situations, such as\n\nwhen multiple genes contribute to a phenotype\nor that many factors contribute to a biological process\n\nIn addition, whenever there is variance introduced by stochastic factors the central limit theorem holds\nThus, normal distributions occur throughout genomics\nIt’s also the basis of the majority of classical statistics"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week3a.html#z-scores-of-normal-variables-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have a mean of 0 and a standard deviation of 1\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it",
    "href": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Simulate a population and sample it!",
    "text": "R INTERLUDE | Simulate a population and sample it!\nSimulate a population of 10,000 individual values for a variable x:\n\nx &lt;- rnorm(10000, mean=50.5, sd=5.5) \n\nTake 1000 random samples of size 20, take the mean of each sample, and plot the distribution of these 1000 sample means.\n\nx_sample_means &lt;- NULL\nfor(i in 1:1000){\nx_samp &lt;- sample(x, 20, replace=FALSE)\nx_sample_means[i] &lt;- mean(x_samp)\n}\n\nFor one of your samples, use the equation from the previous slide to transform the values to z-scores.\nPlot the distribution of the z-scores, and calculate the mean and the standard deviation."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it-1",
    "href": "Lecture_Folder/Week3a.html#r-interlude-simulate-a-population-and-sample-it-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Simulate a population and sample it!",
    "text": "R INTERLUDE | Simulate a population and sample it!\n\nNow, create a second population (called x.lognorm) by log-transforming all 10,000 values from population “x”\nPlot the histogram of these data\nRepeat the taking of 1000 samples of size 20\nTake the mean of each sample\nPlot the distribution of these 1000 sample means from the known lognormal population.\nWhat does the distribution of the sampled means look like?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "href": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "href": "Lecture_Folder/Week3a.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#covariance-and-correlation",
    "href": "Lecture_Folder/Week3a.html#covariance-and-correlation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#linear-models",
    "href": "Lecture_Folder/Week3a.html#linear-models",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Linear Models",
    "text": "Linear Models"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet",
    "href": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet-1",
    "href": "Lecture_Folder/Week3a.html#show-the-data-anscombes-quartet-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet\n\nMean of x in each case 9 (exact)\nVariance of x in each case 11 (exact)\nMean of y in each case 7.50 (to 2 decimal places)\nVariance of y in each case 4.122 or 4.127 (to 3 decimal places)\nCorrelation between x and y in each case 0.816 (to 3 decimal places)\nLinear regression line in each case \\(y =3.00 + 0.50x\\) (to 2 decimal places)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#understanding-populations-and-their-parameters",
    "href": "Lecture_Folder/Week3a.html#understanding-populations-and-their-parameters",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Understanding Populations and their Parameters",
    "text": "Understanding Populations and their Parameters\n\nWe often think about the samples we are collecting as a part of a larger population\nSince we can’t measure every member of that population, we instead use sampling to estimate the parameters of the population as a whole\n\nSome common parameters: mean, range, median\nIf we performed random sampling, we assume that the parameter estimates of our sample are equitable to the true population parameters"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#accuracy-vs.-precision",
    "href": "Lecture_Folder/Week3a.html#accuracy-vs.-precision",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#accuracy-vs.-precision-1",
    "href": "Lecture_Folder/Week3a.html#accuracy-vs.-precision-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision\n\nAccuracy is the closeness of an estimated value to its true value\nPrecision is the closeness of repeated estimates to one another\nOur goal is to have unbiased estimates that are the most precise\nWe have to estimate parameters and test hypotheses by taking samples that approximate the underlying distribution\nThe goal of replication is to quantify variation at as many levels in a study as possible\nThe goal of randomization is to avoid bias as much as possible"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nParametric (a few special exceptions, like the sample mean and its standard error)\nOrdinary Least Squares (OLS) - optimized procedure that produces one definitive result, easy to use but no estimates of confidence\nResampling - bootstrapping and randomization\nMaximum Likelihood (ML) - Can provide model-based estimates with confidence, but harder to calculate\nBayesian Approaches - Incorporates prior information into ML estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-variation-of-a-parameter",
    "href": "Lecture_Folder/Week3a.html#sampling-variation-of-a-parameter",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling variation of a parameter",
    "text": "Sampling variation of a parameter"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation",
    "href": "Lecture_Folder/Week3a.html#estimation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation",
    "text": "Estimation\n\nEstimation is the process of inferring a population parameter from sample data\nThe value of one sample estimate is almost never the same as the population parameter because of random sampling error\nImagine taking multiple samples, each will be different from the true value\nMost will be close, but some will be far away\nThe expected value of a very large number of sample estimates is the value of the parameter being estimated\nSampling distribution of an estimate\n\nall values we might have obtained from our sample\nprobabilities of occurrence\n\nStandard error of an estimate\n\nstandard deviation of a sampling distribution\nmeasures the precision of the parameter estimate\nNO ESTIMATE IS USEFUL WITHOUT IT!"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-1",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-2",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-3",
    "href": "Lecture_Folder/Week3a.html#estimation-and-confidence-intervals-3",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week3a.html#standard-error-of-the-mean-sem",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\\[\\huge \\sigma_{\\bar{x}} \\approx s_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\]\n\nwhere \\(s_{\\bar{x}}\\) is the estimated standard error of the distribution of the mean estimates\nwhich is usually just referred to as the ’standard error of the mean (SEM)\nnote that this is not the standard deviation of the original distribution\nimportantly, the SEM will go down as the sample size increases"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error",
    "href": "Lecture_Folder/Week3a.html#standard-error",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard Error",
    "text": "Standard Error\n\nSadly, most other kinds of estimates do not have this amazing property.\nWhat to do?\nOne answer: make your own sampling distribution for the estimate using the “bootstrap”.\nMethod invented by Efron (1979)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation-bootstrap-algorithm",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation-bootstrap-algorithm",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation | Bootstrap Algorithm",
    "text": "Parameter Estimation | Bootstrap Algorithm\n\nUse R to take a random sample of individuals from the original data\nCalculate the estimate using the measurements in the bootstrap sample (step 1)\nThis is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3\nThe resulting quantity is called the bootstrap standard error"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-etymology-of-the-term-bootstrap",
    "href": "Lecture_Folder/Week3a.html#the-etymology-of-the-term-bootstrap",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The etymology of the term ‘bootstrap’",
    "text": "The etymology of the term ‘bootstrap’"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#why-the-bootstrap-is-good",
    "href": "Lecture_Folder/Week3a.html#why-the-bootstrap-is-good",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Why the bootstrap is good",
    "text": "Why the bootstrap is good\n\nCan be applied to almost any sample statistic\n\nThis includes means, proportions, correlations, regression\n\nWorks when there is no ready formula for a standard error\n\nFor example the median, trimmed mean, correlation, eigenvalue, etc.\n\nIs nonparametric, so doesn’t require normally-distributed data\nWorks for estimates based on complicated sampling procedures or calculations\n\nFor example, it is used in phylogeny estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "href": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\nExamine the data_frames.R script\nExamine the simple_boostrap.R script\nOn your own - use R to figure out the bootstrap distribution for other parameters (such as variance)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "href": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\nx &lt;- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 1.6, 2.0, 2.0)\n\nUse R to make 1000 “pseudo-samples” of size 10 (with replacement), using a for loop as before.\nName the pseudo-sample object “xboot”, and name the means of the xboot samples “z”.\nPlot the histogram of the resampled means, and calculate the standard deviation of the sample means (the bootstrap SEM) using the sd() function.\nHow does it compare with the ordinary standard error of the mean calculated from the original, real sample?\n\nsd(x)/sqrt(10)\n\nNow take one of the genes from the GacuRNAseq_Subset.csv data and obtain a bootstrapped estimate of the mean expression level."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-2",
    "href": "Lecture_Folder/Week3a.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\n\nThe 2.5th and 97.5th percentiles of the bootstrap sampling distribution are a passable 95% confidence interval\nNote that no transformations or normality assumptions needed\nYou can use the quantile() function to calculate these\nOn your own - use R to figure out the bootstrap distribution for other parameters (such as variance)."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation | Ordinary Least Squares (OLS)",
    "text": "Parameter Estimation | Ordinary Least Squares (OLS)\n\nAlgorithmic approach to parameter estimations\nOne of the oldest and best developed statistical approaches\nUsed extensively in linear models (ANOVA and regression)\nBy itself only produces a single best estimate (No C.I.’s)\nCan use resampling approaches to get C.I.’s\nMany OLS estimators have been duplicated by ML estimators"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols-1",
    "href": "Lecture_Folder/Week3a.html#parameter-estimation-ordinary-least-squares-ols-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Parameter Estimation | Ordinary Least Squares (OLS)",
    "text": "Parameter Estimation | Ordinary Least Squares (OLS)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-exercise",
    "href": "Lecture_Folder/Week3a.html#sampling-exercise",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#test-it-out",
    "href": "Lecture_Folder/Week3a.html#test-it-out",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\n\n[1] 2.24649"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-exercise-1",
    "href": "Lecture_Folder/Week3a.html#sampling-exercise-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\n\n\n\n\n\n\n\n\n[1] \"Mean: \" \"4.95\"  \n\n\n[1] \"Range: \" \"1\"       \"10\""
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week3a.html#randomness-in-sampling",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week3a.html#surveying-your-sampling",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week3a.html#surveying-your-sampling-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\ntable(samps_var_means &gt; 4.5 & samps_var_means &lt; 5.5)\n\n\nFALSE  TRUE \n   19    31"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#surveying-your-sampling-2",
    "href": "Lecture_Folder/Week3a.html#surveying-your-sampling-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#sampling-distributions---its-been-normal-this-whole-time",
    "href": "Lecture_Folder/Week3a.html#sampling-distributions---its-been-normal-this-whole-time",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Sampling Distributions - It’s been Normal this whole time?!",
    "text": "Sampling Distributions - It’s been Normal this whole time?!"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#the-central-limit-theorem-1",
    "href": "Lecture_Folder/Week3a.html#the-central-limit-theorem-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error-1",
    "href": "Lecture_Folder/Week3a.html#standard-error-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard Error",
    "text": "Standard Error\n\nThe sample size and the spread of the distribution (range) - contribute to what is known as the standard error of a random variable.\nThe standard error for any given sample attribute (such as a sample mean), can be calculated either based on distributional assumptions, or by a process called “resampling.”"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#standard-error-2",
    "href": "Lecture_Folder/Week3a.html#standard-error-2",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Standard error",
    "text": "Standard error"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#calculating-the-standard-error",
    "href": "Lecture_Folder/Week3a.html#calculating-the-standard-error",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nStandard Error of the Mean (SEM)\nSEM = SD / sqrt(sample size)"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#calculating-the-standard-error-1",
    "href": "Lecture_Folder/Week3a.html#calculating-the-standard-error-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week3a.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#bootstrapping-1",
    "href": "Lecture_Folder/Week3a.html#bootstrapping-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned. - - It works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#confidence-intervals",
    "href": "Lecture_Folder/Week3a.html#confidence-intervals",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#relationship-between-mean-and-variance-1",
    "href": "Lecture_Folder/Week3a.html#relationship-between-mean-and-variance-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Relationship between mean and variance",
    "text": "Relationship between mean and variance\n\nThis means it is inappropriate to compare variations of different populations with largely different means\n\nFor instance, comparing the standard deviation for a body measurement in a population of mice, with the same body measurement in a population of elephants is not meaningful."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#test-it-out-1",
    "href": "Lecture_Folder/Week3a.html#test-it-out-1",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nprint(sd(true_pop))"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week3a.html#coefficient-of-variation",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Homework.html",
    "href": "Homework.html",
    "title": "Homeworks",
    "section": "",
    "text": "Homework 1\nHomework 2\nHomework 3\nHomework 4\nTerm Project"
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html",
    "href": "Homework_Folder/HW1_2025.html",
    "title": "EDA, t-test and Power Calculations",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use both the microbiota/RNAseq data set that you have been using in class, as well as the dataset that you’ve identified for your term long project. Try to accomplish a version of the tasks I lay out below on your own dataset, but you’re undoubtedly going to need to make some modifications and adjustments. In addition, you will be performing one set of power analyses using simulation on a hypothetical problem\nDue: Submit your work via Canvas by the end of the day (midnight) on Tuesday, April 29th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#directions",
    "href": "Homework_Folder/HW1_2025.html#directions",
    "title": "BioE_Stats_2025_HW1 - EDA, t-test and Power Calculations",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use both the microbiota/RNAseq data set that you have been using in class, as well as the dataset that you’ve identified for your term long project. Try to accomplish a version of the tasks I lay out below on your own dataset, but you’re undoubtedly going to need to make some modifications and adjustments. In addition, you will be performing one set of power analyses using simulation on a hypothetical problem\nDue: Submit your work via Canvas by the end of the day (midnight) on Tuesday, April 29th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#problem-1---exploratory-data-analysis",
    "href": "Homework_Folder/HW1_2025.html#problem-1---exploratory-data-analysis",
    "title": "EDA, t-test and Power Calculations",
    "section": "Problem 1 - Exploratory Data Analysis",
    "text": "Problem 1 - Exploratory Data Analysis\n\nRead in the data\n\nRead in the files\nUse str, head and glimpse to get an idea of the data structure\nCreate a tibble data object using this dataset (the function is as_tibble)\n\n\n\nPerform some wrangling\n\nSelect all of the categorical variables and only 4 of the gene count variables and put them into a new data object.\nMutate each of the 4 gene expression values by performing a square root transformation making a new variable for each of the original (keep all eight variables in the dataset).\nSummarise the mean and standard deviation for each of the gene count variables grouped by the ‘Microbiota’ and ‘Genotype’ categorical variables (hint, using group_by may make this easier; also remember your na.rm=TRUE to remove the na values)\n\n\n\nGraphical Communication with ggplot2\nInsert a code chunk and complete the following tasks using your gene expression tibble:\n\nCreate a barplot of microbiota and genotype- what does this tell you about experimental design?\nCreate a histogram and frequency polygram of the expression of one particular gene.\nCreate a boxplot of the expression of one gene by microbiota/genotype combination. Reorder it by median expression and flip the coordinates.\nExplore the coexpression patterns among your genes by plotting a couple pairwise combinations using geom_point. Plot your most interesting coexpression by treatment using facet_wrap."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#problem-2---parametric-t-test-in-r",
    "href": "Homework_Folder/HW1_2025.html#problem-2---parametric-t-test-in-r",
    "title": "EDA, t-test and Power Calculations",
    "section": "Problem 2 - Parametric t-test in R",
    "text": "Problem 2 - Parametric t-test in R\n\nUsing R to make a dummy data set that contains one continuous and one categorical value with two levels. To do so draw individuals of the two different factor levels from normal distributions (check the ‘norm’ family of functions) with slightly different means but equal standard deviations. Take 100 observations per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another (see below)\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level). How does the sample size affect the statistics?\nWhat if you run the test again and make the means of the categorical groups more dissimilar?\nWhat happens if you change the standard deviation of your normal distributions to be very small or very large?\nNow perform the t-test using the dataset provided in class and your own data for two variables."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#problem-3---a-priori-power-analyses-via-simulation",
    "href": "Homework_Folder/HW1_2025.html#problem-3---a-priori-power-analyses-via-simulation",
    "title": "EDA, t-test and Power Calculations",
    "section": "Problem 3 - a priori power analyses via simulation",
    "text": "Problem 3 - a priori power analyses via simulation\nYou have been asked by your colleagues to aid in the design of an experiment to determine how many mice might be needed to test the efficacy of a specific medical device on bone growth. The in vivo trials are expensive, and so the researchers would like your help to figure out how many mice are needed to achieve a reasonable level of precision. In particular, they are interested in both the number of microns that bones grow over a 3 month period, and whether mice that have the implant have a greater rate of growth than those that do not.\nTo help them, you should do a power analysis, and write up the results in a short, readable section. Your colleagues will be interested in the cost-precision tradeoff, so you should include graphical displays that convey both (a) how accurately the mean number microns of growth can be estimated, and (b) how likely it is that a real difference in mean between treated and control of a given, reasonable size will be detected (have a \\(p\\)-value less than 0.05), both as a function of sample size. I’m leaving it up to you precisely how to convey these things.\nI’d like you to do this power analysis using simulation: by using the computer to do the experiment in silico in the case where you know the truth, and seeing how close your estimates are to the truth. To do this, you’ll have to make some stuff up: for instance, plausible values for what the mean growth rate is, and what sort of mean difference between the treated and control that your colleagues might plausibly care about. You don’t have to do independent research to find good values, but you should discuss the choices you made. You will also have to decide what a good range of sample sizes is to display your results across. I’ll save you the burden of making one thing up: you can assume that the distribution of distances traveled is Poisson distributed, so you can simulate your fake surveys using the function rpois( ). Your final report for this section should be readable and not include visible code in the compiled version. However, you should explain clearly in words what you did to arrive at your answers.\nThe purposes of this section of the homework are to practice writing reports in Quarto markdown; doing simulation-based power analyses, and communicating results in plain language."
  },
  {
    "objectID": "Lecture_Folder/Week3a.html",
    "href": "Lecture_Folder/Week3a.html",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "",
    "text": "Wrangle some data and explore it\nFoundations of probability\nSampling and point estimations\n\n\n\n\n\n\n\nNote\n\n\n\nHomeworks will be assigned this evening and be due in 2 weeks"
  },
  {
    "objectID": "Lecture_Folder/Week3a.html#today-we-will",
    "href": "Lecture_Folder/Week3a.html#today-we-will",
    "title": "Week 3a - Statistics for Bioengineering",
    "section": "",
    "text": "Wrangle some data and explore it\nFoundations of probability\nSampling and point estimations\n\n\n\n\n\n\n\nNote\n\n\n\nHomeworks will be assigned this evening and be due in 2 weeks"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#key-dplyr-verbs",
    "href": "Lecture_Folder/Week3b.html#key-dplyr-verbs",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Key dplyr verbs",
    "text": "Key dplyr verbs\nThere are five key dplyr verbs that you need to learn.\n\nfilter: Filter (i.e. subset) observations (rows) based on their values.\n\nselect: Select (i.e. subset) variables (columns) by their names:\n\narrange: Arrange (i.e. reorder) rows based on their values.\n\nmutate: Create new columns.\n\nsummarise: Collapse multiple rows into a single summary value.1"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#filter-arrange-select",
    "href": "Lecture_Folder/Week3b.html#filter-arrange-select",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "filter(), arrange() & select()",
    "text": "filter(), arrange() & select()\n\nfilter(flights, month == 11 | month == 12)\n\n\narrange(flights, year, month, day)\n\n\nselect(flights, year)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#conditionals",
    "href": "Lecture_Folder/Week3b.html#conditionals",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "conditionals",
    "text": "conditionals\n\n== equals exactly\n&lt;, &lt;= is smaller than, is smaller than or equal to\n&gt;, &gt;=` is bigger than, is bigger than or equal to\n!= not equal to\n! NOT operator, to specify things that should be omitted\n& AND operator, allows you to chain two conditions which must both be met\n\\| OR operator, to chains two conditions when at least one should be met\n%in% belongs to one of the following (usually followed by a vector of possible values)\n\nThe AND (&) and the OR (|`) operators are also super useful when you want to separate data based on multiple conditions."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#mutate-transmutate",
    "href": "Lecture_Folder/Week3b.html#mutate-transmutate",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "mutate() & transmutate()",
    "text": "mutate() & transmutate()\n\nlibrary(nycflights23)\n\nmutate(flights,\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)\n\n\nflights %&gt;%\n  mutate(\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)\n\n\nflights_updated &lt;- flights %&gt;%\n  mutate(\n  gain = arr_delay - dep_delay,\n  hours = air_time / 60,\n  gain_per_hour = gain / hours\n)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#group_by-summarize",
    "href": "Lecture_Folder/Week3b.html#group_by-summarize",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "group_by( ) & summarize( )",
    "text": "group_by( ) & summarize( )\nThis first function allows you to aggregate data by values of categorical variables\n\nby_day &lt;- group_by(flights, year, month, day)\n\nOnce you have done this aggregation, you can then calculate values (in this case the mean) of other variables split by the new aggregated levels of the categorical variable\n\nsummarise(by_day, delay = mean(dep_delay, na.rm = TRUE))\n\n\nNote - you can get a lot of missing values!\nThat’s because aggregation functions obey the usual rule of missing values:\n\nif there’s any missing value in the input, the output will be a missing value.\nfortunately, all aggregation functions have an na.rm argument which removes the missing values prior to computation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#other-dplyr-goodies",
    "href": "Lecture_Folder/Week3b.html#other-dplyr-goodies",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Other dplyr goodies",
    "text": "Other dplyr goodies\n\ngroup_by and ungroup: For (un)grouping. - Particularly useful with the summarise and mutate commands, as we’ve already seen.\n\nslice: Subset rows by position rather than filtering by values. - E.g. starwars %&gt;% slice(c(1, 5))\n\npull: Extract a column from as a data frame as a vector or scalar. - E.g. starwars %&gt;% filter(gender==\"female\") %&gt;% pull(height)\n\ncount and distinct: Number and isolate unique observations. - E.g. starwars %&gt;% count(species), or starwars %&gt;% distinct(species)\n\nYou could also use a combination of mutate, group_by, and n(), e.g. starwars %&gt;% group_by(species) %&gt;% mutate(num = n())."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#random-variables-probability",
    "href": "Lecture_Folder/Week3b.html#random-variables-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Random variables & probability",
    "text": "Random variables & probability\n\nProbability is the expression of belief in some future outcome\nA random variable can take on different values with different probabilities\nThe sample space of a random variable is the universe of all possible values\nThe sample space can be represented by a\n\nprobability mass distribution (discrete)\nprobability density function (PDF) (continuous)\nalgebra and calculus are used for each respectively\nprobabilities of a sample space always sum to 1.0\n\nHow does it make sense that a sample space will always sum to 1?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#bernoulli-distribution",
    "href": "Lecture_Folder/Week3b.html#bernoulli-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nDescribes the expected outcome of a single event with probability p\nExample of flipping of a fair coin once\n\n\\[Pr(X=\\text{Head}) = \\frac{1}{2} = 0.5 = p \\]\n\\[Pr(X=\\text{Tails}) = \\frac{1}{2} = 0.5 = 1 - p = q \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#bernoulli-distribution-1",
    "href": "Lecture_Folder/Week3b.html#bernoulli-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\n\nIf the coin isn’t fair then \\(p \\neq 0.5\\)\nHowever, the probabilities still sum to 1\n\n\\[ p + (1-p) = 1 \\] \\[ p + q = 1 \\]\n\nSame is true for other binary possibilities\n\nsuccess or failure\nyes or no answers\nchoosing an allele from a population based upon allele frequencies (Hardy-Weinberg ring any bells??)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#probability-rules",
    "href": "Lecture_Folder/Week3b.html#probability-rules",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nFlip a coin twice\nRepresent the first flip as ‘X’ and the second flip as ‘Y’\n\n\\[ Pr(\\text{X=H and Y=H}) = p*p = p^2 \\] \\[ Pr(\\text{X=H and Y=T}) = p*q = pq = p^2 \\] \\[ Pr(\\text{X=T and Y=H}) = q*p = pq \\] \\[ Pr(\\text{X=T and Y=T}) = q*q = q^2 \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#probability-rules-1",
    "href": "Lecture_Folder/Week3b.html#probability-rules-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Probability rules",
    "text": "Probability rules\n\nProbability that the H and T can occur in any order\n\n\\[ \\text{Pr(X=H) or Pr(X=T)} = p+q=1\\]\n\\[ \\text{Pr(X=H and Y=T) or Pr(X=T and Y=H)} = \\] \\[ (p*q) + (p*q) = 2pq \\]\n\nThese are the ‘and’ and ‘or’ rules of probability\n\n‘and’ means multiply the probabilities\n‘or’ means sum the probabilities\nmost probability distributions can be built up from these simple rules"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips",
    "href": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\n# tossing a fair coin\ncoin &lt;- c(\"heads\", \"tails\")\n\nsample(coin)\n\n[1] \"heads\" \"tails\""
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips-1",
    "href": "Lecture_Folder/Week3b.html#lets-simulate-some-coin-flips-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s simulate some coin flips",
    "text": "Let’s simulate some coin flips\n\nWhat happens when we change the probabilities or the sample size? How confident are we that our coin is fair?\n\n\nflips &lt;- sample(coin, prob = c(0.5, 0.5), size=13, replace=TRUE)\nbarplot(table(flips))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#joint-probability",
    "href": "Lecture_Folder/Week3b.html#joint-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Joint probability",
    "text": "Joint probability\n\\[Pr(X,Y) = Pr(X) * Pr(Y)\\]\n\nNote that this is true for two independent events\nHowever, for two non-independent events we also have to take into account their covariance\nTo do this we need conditional probabilities"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#conditional-probability",
    "href": "Lecture_Folder/Week3b.html#conditional-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Conditional probability",
    "text": "Conditional probability\n\nFor two independent variables: Probability of Y, given X, or the probability of X, given Y.\n\n\\[Pr(Y|X) = Pr(Y)\\text{ and }Pr(X|Y) = Pr(X)\\]\n\nFor two non-independent variables\n\n\\[Pr(Y|X) \\neq Pr(Y)\\text{ and }Pr(X|Y) \\neq Pr(X)\\]\n\nVariables that are non-independent have a shared variance, which is also known as the covariance\nCovariance standardized to a mean of zero and a unit standard deviation is correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#expectation-and-moments-of-distributions",
    "href": "Lecture_Folder/Week3b.html#expectation-and-moments-of-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Expectation and Moments of Distributions",
    "text": "Expectation and Moments of Distributions\n\nDistributions have moments that can be estimated\n1st moment - The expectation or mean of a discrete random variable X is:\n\n\\[E[X] = \\sum_{\\text{all x}}^{}xP(X=x) = \\mu\\]\n\nOften we want to know how dispersed the random variable is around its mean.\n2nd moment - the measure of dispersion is the variance\n\n\\[Var(X) = E[X^2] = \\sigma^2\\] - and the standard deviation is just the square root of the variance\n\\[ \\sqrt{\\sigma^2}\\] - There are higher moments of distributions (e.g. skew and kurtosis)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-likelihood-vs.-probability",
    "href": "Lecture_Folder/Week3b.html#what-is-likelihood-vs.-probability",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is Likelihood vs. Probability?",
    "text": "What is Likelihood vs. Probability?\n\nThe probability of an event is the proportion of times that the event would occur if we repeated a random trial over and over again under the same conditions.\nThe likelihood is a conditional probability of a parameter value given a set of data\nThe likelihood of a population parameter equaling a specific value, given the data\n\nL[parameter|data] = Pr[data|parameter]\n\nLikelihood function is the range of likelihoods over the parameter space\nMaximum likelihood is the highest value of the likelihood function\nWhat is a Bayesian estimate? - the use of prior distribution to update a posterior distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-distribution",
    "href": "Lecture_Folder/Week3b.html#binomial-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nA binomial distribution results from the combination of several independent Bernoulli events\nExample\n\nPretend that you flip 20 fair coins\n\nor collect alleles from a heterozygote\n\nNow repeat that process and record the number of heads\nWe expect that most of the time we will get approximately 10 heads\nSometimes we get many fewer heads or many more heads"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-distribution-1",
    "href": "Lecture_Folder/Week3b.html#binomial-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Distribution",
    "text": "Binomial Distribution\n\nThe distribution of probabilities for each combination of outcomes is\n\n\\[\\large f(k) = {n \\choose k} p^{k} (1-p)^{n-k}\\]\n\nn is the total number of trials\nk is the number of successes\np is the probability of success\nq is the probability of not success\nFor binomial as with the Bernoulli p = 1-q"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-probability-distribution",
    "href": "Lecture_Folder/Week3b.html#binomial-probability-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution\n\nNote that the binomial function incorporates both the ‘and’ and ‘or’ rules of probability\nThis part is the probability of each outcome (multiplication)\n\n\\[\\large p^{k} (1-p)^{n-k}\\]\nThis part (called the binomial coefficient) is the number of different ways each combination of outcomes can be achieved (summation)\n\\[\\large {n \\choose k}\\] Together they equal the probability of a specified number of successes"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#binomial-probability-distribution-1",
    "href": "Lecture_Folder/Week3b.html#binomial-probability-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Binomial Probability Distribution",
    "text": "Binomial Probability Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-binomial-distributions",
    "href": "Lecture_Folder/Week3b.html#testing-binomial-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\ndbinom gives the density (probability) of number successes (x) in number trials (size), with (prob) probability between 0-1\n\n\n# dbinom(x=5, size=10, p=0.5)\n# 0.246\nplot(dbinom(x=1:10, size=10, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-binomial-distributions-1",
    "href": "Lecture_Folder/Week3b.html#testing-binomial-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Binomial Distributions",
    "text": "Testing Binomial Distributions\n\npbinom gives the cumulative probability of reaching at least (q) number of successes after (size) number of trials\n\n\nplot(pbinom(q=1:100, size=100, p=0.5))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in bioengineering is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\ncount of genes in a genome binned to units of 500kb\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\n\nFor example, you can examine 1000 genes\n\ncount the number of base pairs in the coding region of each gene\nwhat is the probability of observing a gene with ‘r’ bp?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that this is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution | gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week3b.html#poisson-probability-distribution-increasing-parameter-values-of-lambda",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution | increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week3b.html#testing-poisson-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#geometric-distribution",
    "href": "Lecture_Folder/Week3b.html#geometric-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week3b.html#geometric-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week3b.html#testing-geometric-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\ndgeom(x=20, p=0.1)\n\n[1] 0.01215767\n\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week3b.html#testing-geometric-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581\n\nplot(pgeom(q=1:20, p=0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week3b.html#negative-binomial-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “ones” have appeared.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “one” appearing on the \\(k^{th}\\) trial:\n\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r-1}(1-p)^{k-r}p\\]\n\nwhich simplifies to\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r}(1-p)^{k-r}\\]\n\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week3b.html#negative-binomial-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#continuous-probability-distributions-1",
    "href": "Lecture_Folder/Week3b.html#continuous-probability-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Continuous probability distributions",
    "text": "Continuous probability distributions\nP(observation lies within dx of x) = f(x)dx\n\\[P(a\\leq X \\leq b) = \\int_{a}^{b} f(x) dx\\]\nRemember that the indefinite integral sums to one\n\\[\\int_{-\\infty}^{\\infty} f(x) dx = 1\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#continuous-probabilities",
    "href": "Lecture_Folder/Week3b.html#continuous-probabilities",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Continuous probabilities",
    "text": "Continuous probabilities\n\nE[X] may be found by integrating the product of x and the probability density function over all possible values of x:\n\\[E[X] = \\int_{-\\infty}^{\\infty} xf(x) dx \\]\n\n\\(Var(X) = E[X^2] - (E[X])^2\\), where the expectation of \\(X^2\\) is\n\\[E[X^2] = \\int_{-\\infty}^{\\infty} x^2f(x) dx \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#uniform-distribution",
    "href": "Lecture_Folder/Week3b.html#uniform-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\n\\[E[X] = \\int_{a}^{b} x\\frac{1}{b-a} dx = \\frac{(a+b)}{2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week3b.html#uniform-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#uniform-distribution-2",
    "href": "Lecture_Folder/Week3b.html#uniform-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#exponential-distribution",
    "href": "Lecture_Folder/Week3b.html#exponential-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\n\\[f(x)=\\lambda e^{-\\lambda x}\\]\n\n\nE[X] can be found be integrating \\(xf(x)\\) from 0 to infinity\n\n\n\nleading to the result that\n\n\n\n\\(E[X] = \\frac{1}{\\lambda}\\)\n\\(E[X^2] = \\frac{1}{\\lambda^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week3b.html#exponential-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#exponential-distribution-2",
    "href": "Lecture_Folder/Week3b.html#exponential-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\ndexp(10, rate = 0.1)\n\n[1] 0.03678794\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#gamma-distribution",
    "href": "Lecture_Folder/Week3b.html#gamma-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\) :\n\n\n\\[f(x) = \\frac{e^{-\\lambda x}\\lambda x^{r-1}}{(r-1)!}\\lambda\\]\n\n\\[ Mean =  \\frac{r}{\\lambda} \\] \\[ Variance = \\frac{r}{\\lambda^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week3b.html#gamma-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber.\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#common-theme-in-r-for-distributions",
    "href": "Lecture_Folder/Week3b.html#common-theme-in-r-for-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Common theme in R for distributions",
    "text": "Common theme in R for distributions\n\n\n\n\n\n\n\n\n\n\n\nd\nprobability mass function\np\ncumulative distribution\nq\nquantile function\nr\npseudorandom number generate\n\n\n\n\nbinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\npoisson\ndpois\nppois\nqpois\nrpois\n\n\nexponential\ndexp\npexp\nqexp\nrexp\n\n\nnormal\ndnorm\npnorm\nqnorm\nrnorm"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "href": "Lecture_Folder/Week3b.html#the-normal-aka-gaussian-probability-density-function-pdf",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Normal (aka Gaussian) | Probability Density Function (PDF)",
    "text": "The Normal (aka Gaussian) | Probability Density Function (PDF)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf",
    "href": "Lecture_Folder/Week3b.html#normal-pdf",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf-a-function-of-two-parameters",
    "href": "Lecture_Folder/Week3b.html#normal-pdf-a-function-of-two-parameters",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF | A function of two parameters",
    "text": "Normal PDF | A function of two parameters\n(\\(\\mu\\) and \\(\\sigma\\))\n\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\epsilon \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf-estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week3b.html#normal-pdf-estimates-of-mean-and-variance",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF | estimates of mean and variance",
    "text": "Normal PDF | estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week3b.html#z-scores-of-normal-variables-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have a mean of 0 and a standard deviation of 1\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#normal-pdf-1",
    "href": "Lecture_Folder/Week3b.html#normal-pdf-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences",
    "href": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-1",
    "href": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-2",
    "href": "Lecture_Folder/Week3b.html#why-is-the-normal-special-in-biosciences-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week3b.html#parent-offspring-resemblance",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week3b.html#genetic-model-of-complex-traits",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week3b.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week3b.html#why-else-is-the-normal-special",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nIt is the basis of estimation and precision of the expected value of all distributions\nProvides a mathematical basis for moving from single samples to point estimates.\nProvides a way to use simulation to generate empirical sample and test distributions through Monte Carlo approaches"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#understanding-populations-and-their-parameters",
    "href": "Lecture_Folder/Week3b.html#understanding-populations-and-their-parameters",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Understanding Populations and their Parameters",
    "text": "Understanding Populations and their Parameters\n\nWe often think about the samples we are collecting as a part of a larger population\nSince we can’t measure every member of that population, we instead use sampling to estimate the parameters of the population as a whole\n\nSome common parameters: mean, range, median\nIf we performed random sampling, we assume that the parameter estimates of our sample are equitable to the true population parameters"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#accuracy-vs.-precision",
    "href": "Lecture_Folder/Week3b.html#accuracy-vs.-precision",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#accuracy-vs.-precision-1",
    "href": "Lecture_Folder/Week3b.html#accuracy-vs.-precision-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision\n\nAccuracy is the closeness of an estimated value to its true value\nPrecision is the closeness of repeated estimates to one another\nOur goal is to have unbiased estimates that are the most precise\nWe have to estimate parameters and test hypotheses by taking samples that approximate the underlying distribution\nThe goal of replication is to quantify variation at as many levels in a study as possible\nThe goal of randomization is to avoid bias as much as possible"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#parameter-estimation",
    "href": "Lecture_Folder/Week3b.html#parameter-estimation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nParametric (a few special exceptions, like the sample mean and its standard error)\nOrdinary Least Squares (OLS) - optimized procedure that produces one definitive result, easy to use but no estimates of confidence\nResampling - bootstrapping and randomization\nMaximum Likelihood (ML) - Can provide model-based estimates with confidence, but harder to calculate\nBayesian Approaches - Incorporates prior information into ML estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation",
    "href": "Lecture_Folder/Week3b.html#estimation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation",
    "text": "Estimation\n\nEstimation is the process of inferring a population parameter from sample data\nThe value of one sample estimate is almost never the same as the population parameter because of random sampling error\nMost will be close, but some will be far away\nSampling distribution of an estimate\n\nall values we might have obtained from our sample\nprobabilities of occurrence\n\nStandard error of an estimate\n\nstandard deviation of a sampling distribution\nmeasures the precision of the parameter estimate\nNO ESTIMATE IS USEFUL WITHOUT IT!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-central-limit-theorem-1",
    "href": "Lecture_Folder/Week3b.html#the-central-limit-theorem-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculating-the-standard-error",
    "href": "Lecture_Folder/Week3b.html#calculating-the-standard-error",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculating-the-standard-error-1",
    "href": "Lecture_Folder/Week3b.html#calculating-the-standard-error-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculating the Standard Error",
    "text": "Calculating the Standard Error\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 50))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.04635888"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals",
    "href": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-1",
    "href": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-2",
    "href": "Lecture_Folder/Week3b.html#estimation-and-confidence-intervals-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\\[\\huge \\sigma_{\\bar{x}} \\approx s_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\]\n\nwhere \\(s_{\\bar{x}}\\) is the estimated standard error of the distribution of the mean estimates\nwhich is usually just referred to as the ’standard error of the mean (SEM)\nnote that this is not the standard deviation of the original distribution\nimportantly, the SEM will go down as the sample size increases"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem-1",
    "href": "Lecture_Folder/Week3b.html#standard-error-of-the-mean-sem-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\nSadly, most other kinds of estimates of other parameters do not have this amazing property.\nWhat to do?\nOne answer: make your own sampling distribution for the estimate using the “bootstrap”.\nMethod invented by Efron (1979)."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#loops-in-r",
    "href": "Lecture_Folder/Week3b.html#loops-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Loops in R",
    "text": "Loops in R\n\nR is very good at performing repetitive tasks.\nIf we want a set of operations to be repeated several times we use what’s known as a loop.\nWhen you create a loop, R will execute the instructions in the loop a specified number of times or until a specified condition is met.\nThere are two common types of loop in R: the for loop and the while loop"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#for-loops",
    "href": "Lecture_Folder/Week3b.html#for-loops",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "For loops",
    "text": "For loops\n\nThe most commonly used loop structure when you want to repeat a task a defined number of times is the for loop. The most basic example of a for loop is:\nHow does this appear to be working?\n\n\n# Notice the sequence of parentheses and brackets used in this example\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#while-loops",
    "href": "Lecture_Folder/Week3b.html#while-loops",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "While loops",
    "text": "While loops\n\nAnother type of loop that you may use is the while loop.\nThe while loop is used when you want to keep looping until a specific logical condition is satisfied.\n\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n  i &lt;- i + 1\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#if-and-else-statements",
    "href": "Lecture_Folder/Week3b.html#if-and-else-statements",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "If and Else Statements",
    "text": "If and Else Statements\n\nConditional statements are how you inject some logic into your code.\nThe most commonly used conditional statement is if.\n\nWhenever you see an if statement, read it as ‘If X is TRUE, then do a thing’.\n\nAnother statement is else, which extends the logic to ‘If X is TRUE, do a thing, or else do something different’."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-programming-joke-for-conditional-statements",
    "href": "Lecture_Folder/Week3b.html#a-programming-joke-for-conditional-statements",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A programming joke for conditional statements",
    "text": "A programming joke for conditional statements\nA programmer’s partner says: ‘Please go to the store and buy a carton of milk and if they have eggs, get six.’\nThe programmer returned with 6 cartons of milk.\nWhen the partner sees this, and exclaims ‘Why the heck did you buy six cartons of milk?’\nThe programmer replied ‘They had eggs’\n\neggs &lt;- TRUE # Whether there were eggs in the store\n\n  if (eggs == TRUE) { # If there are eggs\n  n.milk &lt;- 6 # Get 6 cartons of milk\n    } else { # If there are not eggs\n  n.milk &lt;- 1 # Get 1 carton of milk\n  }"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-simulate-a-population-and-sample-it",
    "href": "Lecture_Folder/Week3b.html#r-interlude-simulate-a-population-and-sample-it",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Simulate a population and sample it!",
    "text": "R INTERLUDE | Simulate a population and sample it!\nSimulate a population of 10,000 individual values for a variable x:\n\nx &lt;- rnorm(10000, mean=50.5, sd=5.5) \n\nTake 1000 random samples of size 20, take the mean of each sample, and plot the distribution of these 1000 sample means.\n\nx_sample_means &lt;- NULL\nfor(i in 1:1000){\nx_samp &lt;- sample(x, 20, replace=FALSE)\nx_sample_means[i] &lt;- mean(x_samp)\n}\n\nFor one of your samples, use the equation from the previous slide to transform the values to z-scores.\nPlot the distribution of the z-scores, and calculate the mean and the standard deviation."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#simulations-to-compare-parameter-estimates-1",
    "href": "Lecture_Folder/Week3b.html#simulations-to-compare-parameter-estimates-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Simulations to compare parameter estimates",
    "text": "Simulations to compare parameter estimates\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nhist(true_pop, xlim = c(0,16))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculating-parameters",
    "href": "Lecture_Folder/Week3b.html#calculating-parameters",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?\n\n\nmean(true_pop)\n\n[1] 4.927\n\nrange(true_pop)\n\n[1]  0 13\n\nmedian(true_pop)\n\n[1] 5\n\n\n\nhow about the variance and the standard deviation?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-exercise",
    "href": "Lecture_Folder/Week3b.html#sampling-exercise",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#test-it-out",
    "href": "Lecture_Folder/Week3b.html#test-it-out",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Test it out",
    "text": "Test it out\n\nTry changing the lambda of the original population, and see how the SD changes\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nprint(sd(true_pop))\n\n[1] 2.24649"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week3b.html#randomness-in-sampling",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\n\n\nFALSE  TRUE \n   17    33"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-2",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-distributions---its-been-normal-this-whole-time",
    "href": "Lecture_Folder/Week3b.html#sampling-distributions---its-been-normal-this-whole-time",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Distributions - It’s been Normal this whole time?!",
    "text": "Sampling Distributions - It’s been Normal this whole time?!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-exercise-1",
    "href": "Lecture_Folder/Week3b.html#sampling-exercise-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#sampling-exercise-2",
    "href": "Lecture_Folder/Week3b.html#sampling-exercise-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nsample1 &lt;- sample(true_pop, size = 20)\nhist(sample1,  xlim =  c(0,16))\n\nprint(c(\"Mean: \", mean(sample1))) \n\n[1] \"Mean: \" \"5.15\"  \n\nprint(c(\"Range: \", range(sample1)))\n\n[1] \"Range: \" \"1\"       \"12\""
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#randomness-in-sampling-1",
    "href": "Lecture_Folder/Week3b.html#randomness-in-sampling-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size - but your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-3",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nsamps_var &lt;- replicate(50, sample(true_pop, 10)) #Take 50 samples of size 10\nsamps_var_means &lt;- apply(samps_var, 2, mean) #Calculate the mean from each sample\nhist(samps_var_means) #Plot the distribution of sample means"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-4",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nWe get close to the true mean (4.9) about 2/3rds of the time - is this good enough?\n\n\ntable(samps_var_means &gt; 4.5 & samps_var_means &lt; 5.5)\n\n\nFALSE  TRUE \n   27    23"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#surveying-your-sampling-5",
    "href": "Lecture_Folder/Week3b.html#surveying-your-sampling-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-etymology-of-the-term-bootstrap",
    "href": "Lecture_Folder/Week3b.html#the-etymology-of-the-term-bootstrap",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The etymology of the term ‘bootstrap’",
    "text": "The etymology of the term ‘bootstrap’"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-the-bootstrap-is-good",
    "href": "Lecture_Folder/Week3b.html#why-the-bootstrap-is-good",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why the bootstrap is good",
    "text": "Why the bootstrap is good\n\nCan be applied to almost any sample statistic\n\nThis includes means, proportions, correlations, regression\n\nWorks when there is no ready formula for a standard error\n\nFor example the median, trimmed mean, correlation, eigenvalue, etc.\n\nIs nonparametric, so doesn’t require normally-distributed data\nWorks for estimates based on complicated sampling procedures or calculations\n\nFor example, it is used in phylogeny estimation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#parameter-estimation-bootstrap-algorithm",
    "href": "Lecture_Folder/Week3b.html#parameter-estimation-bootstrap-algorithm",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Parameter Estimation | Bootstrap Algorithm",
    "text": "Parameter Estimation | Bootstrap Algorithm\n\nUse R to take a random sample of individuals from the original data\nCalculate the estimate using the measurements in the bootstrap sample (step 1)\nThis is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3\nThe resulting quantity is called the bootstrap standard error"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "href": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\nx &lt;- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 1.6, 2.0, 2.0)\n\nUse R to make 1000 “pseudo-samples” of size 10 (with replacement), using a for loop as before.\nName the pseudo-sample object “xboot”, and name the means of the xboot samples “z”.\nPlot the histogram of the resampled means, and calculate the standard deviation of the sample means (the bootstrap SEM) using the sd() function.\nHow does it compare with the ordinary standard error of the mean calculated from the original, real sample?\n\nsd(x)/sqrt(10)\n\nNow take one of the genes from the GacuRNAseq_Subset.csv data and obtain a bootstrapped estimate of the mean expression level."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-bootstrapping-to-produce-a-confidence-interval-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Bootstrapping to produce a confidence interval",
    "text": "R INTERLUDE | Bootstrapping to produce a confidence interval\n\nThe 2.5th and 97.5th percentiles of the bootstrap sampling distribution are a passable 95% confidence interval\nNote that no transformations or normality assumptions needed\nYou can use the quantile() function to calculate these\nOn your own - use R to figure out the bootstrap distribution for other parameters (such as variance).\n\n-_____________"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week3b.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#bootstrapping-1",
    "href": "Lecture_Folder/Week3b.html#bootstrapping-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned. - - It works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#confidence-intervals",
    "href": "Lecture_Folder/Week3b.html#confidence-intervals",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week3b.html#coefficient-of-variation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\n\nA statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models\n\nThis is where statistical sampling distributions come into play\nStatistical distributions are built upon sampling distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\n\nStatistical tests provide a way to perform critical tests of hypotheses\nJust like raw data, statistics are random variables and depend on sampling distributions of the underlying data\nThe particular form of the statistical distribution depends on the test statistic and parameters such as the degrees of freedom that are determined by sample size."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-1",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data\nThen see how probable it was by comparing against the null distribution\nThe probability of seeing that value or greater is called the p-value of the statistic"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#four-common-statistical-distributions",
    "href": "Lecture_Folder/Week3b.html#four-common-statistical-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\[\\large t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests",
    "href": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors",
    "href": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\n\\(\\alpha\\) = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\n\\(\\beta\\) = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power",
    "href": "Lecture_Folder/Week3b.html#statistical-power",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know",
    "href": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | the things one needs to know",
    "text": "Power | the things one needs to know\n\n\\[ Power \\propto \\frac{(ES)(\\alpha)(\\sqrt n)}{\\sigma}\\]\n\nPower is proportional to the combination of these parameters\n\nES - effect size; how large is the change of interest?\n\\(\\alpha\\) - significance level (usually 0.05)\nn - sample size\n\\(\\sigma\\) - standard deviation among experimental units within the same group."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know",
    "href": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | what we usually want to know",
    "text": "Power | what we usually want to know"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-rough-calculation",
    "href": "Lecture_Folder/Week3b.html#power-rough-calculation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | rough calculation",
    "text": "Power | rough calculation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-complete-exercises-3.2-3.4",
    "href": "Lecture_Folder/Week3b.html#r-interlude-complete-exercises-3.2-3.4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R Interlude | Complete Exercises 3.2-3.4",
    "text": "R Interlude | Complete Exercises 3.2-3.4"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-1",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\nalpha = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\nbeta = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "href": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nMake a dummy data set that contains one continuous and one categorical value (with two levels). Draw individuals of the two different factor levels from normal distributions with slightly different means. Take 100 obsv. per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level)\nRepeat steps 1 and 2 above but now test between a categorical and continuous variable in the perchlorate data set (or any of your favorite data sets)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nNow, apply the equations for the t-statistic above to your simulated sample to perform the same test, but using a resampling approach\n\nhint: go back to your Bootstrapping script\n\nUse this approach to calculate a distribution of random t statistics assuming the the null hypothesis of no difference is true.\nNow, compare your observed value to your created null distribution.\nWhat is the probability of that value occurring by chance under the null?\n\nThis is your p-value! (Assume you’re doing a one-tailed test)\nhint: Proportion of values in the null distribution equal to or larger than the observed t-value = p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nRandomization test example 1\nData: The number of successful broods of pseudoscorpion females that were mated twice to either a single male (SM) or two different males (DM).\n\nSM: 4 0 3 1 2 3 4 2 4 2 0 2 0 1 2 6 0 2 3 3\nDM: 2 0 2 6 4 3 4 4 2 7 4 1 6 3 6 4\n\nObserved difference in the means between the two\n\n\\(\\bar{Y}_{SM}\\) − \\(\\bar{Y}_{DM}\\) = 2.2−3.625 = −1.425"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nSteps of the randomization test\nFirst, create a randomized data set in which the measurements are randomly reassigned (without replacement) to the two groups\n\nFor example, the following\nSM: 4 0 7 4 2 2 2 1 4 4 0 3 3 4 6 2 4 6 0 0\nDM: 2 2 3 3 2 3 3 4 1 2 1 4 6 6 2 0\n\nSecond, calculate the test statistic measuring the association between variables\n\ndifference between group means\nthis is the first bootstrap replicate\n\nRepeat steps 1 and 2 many times to produce many bootstrap replicates"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-2",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nBelow is the null distribution of the test statistic from 10,000 replications\n\nThis is produced by the randomized assignment of values to each group (SM or DM)\nThus this is the distribution we’d expect under the null hypothesis of no difference\n\nThe observed value from the data is –1.425\nThe area in red is the tail beyond this observed value and is therefore the bootstrap p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-3",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nOf these 10,000 randomizations, only 176 had a test statistic (difference between means) equal to or less than the observed value, –1.425.\nYou can use the simulated null distribution in the same way as t or F distribution in conventional tests.\nProportion of values in the null distribution equal or larger than the observed value of the test statistic is 176/10000 = 0.0176."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power",
    "href": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nRead in the perchlorate data again\nPerform an ANOVA to test Strain on T4_Hormone_Level, but log-transform (base 10) the T4 variable\n\n\nperc &lt;- read.table('perchlorate_data.tsv', header=T, sep='\\t')\nx &lt;- perc$Strain\ny &lt;- log10(perc$T4_Hormone_Level)\n\nMyANOVA &lt;- aov(y ~ x)\nsummary (MyANOVA)\nboxplot(y ~ x)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nConsider the parameters of this test related to power:\n\nThe per-group sample sizes\nThe standard deviation (use the higher within-group sd)\nThe effect size (|difference between means| / within-grp sd)\n\nFor more complex ANOVA power calculations (&gt;2 groups):\n\nThe total variance\nThe within-group variance (use the higher one)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "href": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\nBased on your results, calculate the power for your ANOVA.\n\n   pwr.t2n.test(n1=xxx, n2=xxx, d=xxx, sig.level=.05, power=NULL)\n\nCheck out the functions in the ‘pwr’ library (Unnecessary in this case, but could use ANOVA version):\n\n   pwr.anova.test(k=2, n=190, f=0.25, sig.level=.05, power=NULL)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "href": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\neffect size approximations:\n\nf=0.1 (small)\nf=0.25 (medium)\nf=0.4 (large)\n\nsee http://www.statmethods.net/stats/power.html"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "href": "Lecture_Folder/Week3b.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\nLet’s say you have to repeat the experiment, but your IACUC wants you to get by by using fewer fish.\nYou want to be able to detect a minimum mean difference of 1.3 T4 units (about 0.114 on the log10 scale), at a power of 90%.\nFirst, divide 0.114 by std.dev. of transformed WK values (the higher std. dev. of the two groups) to get a conservative “d”.\nWhat kind of sample size for the WK group would you need???\n(Again use the pwr.t2n.test() function, but this time specify the WK sample size as the unknown parameter)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-1",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\nA statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models\n\nThis is where statistical sampling distributions come into play"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests-1",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height on average as Douglas fir trees"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests-2",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-1",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-2",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-2",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nStatistical tests provide a way to perform critical tests of hypotheses\nJust like raw data, statistics are random variables and depend on sampling distributions of the underlying data\nThe particular form of the statistical distribution depends on the test statistic and parameters such as the degrees of freedom that are determined by sample size."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-3",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data\nThen see how probable it was by comparing against the null distribution\nThe probability of seeing that value or greater is called the p-value of the statistic"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-1",
    "href": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-1",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\[H_0 : \\mu_1 = \\mu_2\\]\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height as Douglas fir trees\n\\[H_A : \\mu_1 \\neq \\mu_2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-2",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\[\\huge t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | under different degrees of freedom",
    "text": "The t-test and t sampling distribution | under different degrees of freedom"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one tailed test",
    "text": "The t-test and t sampling distribution | one tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two tailed test",
    "text": "The t-test and t sampling distribution | two tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-1",
    "href": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-1",
    "href": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-2",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\nalpha = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\nbeta = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-1",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "href": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-2",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nMake a dummy data set that contains one continuous and one categorical value (with two levels). Draw individuals of the two different factor levels from normal distributions with slightly different means. Take 100 obsv. per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level)\nRepeat steps 1 and 2 above but now test between a categorical and continuous variable in the perchlorate data set (or any of your favorite data sets)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-3",
    "href": "Lecture_Folder/Week3b.html#r-interlude-parametric-t-test-in-r-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nNow, apply the equations for the t-statistic above to your simulated sample to perform the same test, but using a resampling approach\n\nhint: go back to your Bootstrapping script\n\nUse this approach to calculate a distribution of random t statistics assuming the the null hypothesis of no difference is true.\nNow, compare your observed value to your created null distribution.\nWhat is the probability of that value occurring by chance under the null?\n\nThis is your p-value! (Assume you’re doing a one-tailed test)\nhint: Proportion of values in the null distribution equal to or larger than the observed t-value = p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-4",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nRandomization test example 1\nData: The number of successful broods of pseudoscorpion females that were mated twice to either a single male (SM) or two different males (DM).\n\nSM: 4 0 3 1 2 3 4 2 4 2 0 2 0 1 2 6 0 2 3 3\nDM: 2 0 2 6 4 3 4 4 2 7 4 1 6 3 6 4\n\nObserved difference in the means between the two\n\n\\(\\bar{Y}_{SM}\\) − \\(\\bar{Y}_{DM}\\) = 2.2−3.625 = −1.425"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-5",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nSteps of the randomization test\nFirst, create a randomized data set in which the measurements are randomly reassigned (without replacement) to the two groups\n\nFor example, the following\nSM: 4 0 7 4 2 2 2 1 4 4 0 3 3 4 6 2 4 6 0 0\nDM: 2 2 3 3 2 3 3 4 1 2 1 4 6 6 2 0\n\nSecond, calculate the test statistic measuring the association between variables\n\ndifference between group means\nthis is the first bootstrap replicate\n\nRepeat steps 1 and 2 many times to produce many bootstrap replicates"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-6",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-6",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nBelow is the null distribution of the test statistic from 10,000 replications\n\nThis is produced by the randomized assignment of values to each group (SM or DM)\nThus this is the distribution we’d expect under the null hypothesis of no difference\n\nThe observed value from the data is –1.425\nThe area in red is the tail beyond this observed value and is therefore the bootstrap p-value"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-7",
    "href": "Lecture_Folder/Week3b.html#r-interlude-permutation-t-test-in-r-7",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nOf these 10,000 randomizations, only 176 had a test statistic (difference between means) equal to or less than the observed value, –1.425.\nYou can use the simulated null distribution in the same way as t or F distribution in conventional tests.\nProportion of values in the null distribution equal or larger than the observed value of the test statistic is 176/10000 = 0.0176."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-2",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nWe can compare estimated parameters, while also including measures of uncertainty, using frequentist methods\nRequires statistical hypotheses: a statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-3",
    "href": "Lecture_Folder/Week3b.html#what-is-a-hypothesis-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nThis is where statistical sampling distributions come into play\n\nStatistical distributions are built upon sampling distributions\nWill tell us how “frequently” we expect to see a result as extreme as ours"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and Alternative Hypotheses",
    "text": "Null and Alternative Hypotheses\n\nBecause of the nature of logic and deduction, we can never prove a positive\n\nHave we really observed all possible circumstances that could disprove our hypothesis?\n\nBut we can reject a hypothesis based on our observations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-1",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and Alternative Hypotheses",
    "text": "Null and Alternative Hypotheses\n\nEasiest examples: we want to know if two populations differ from one another\n\nWe make a simple statement, for example, “I hypothesize that on average the variable X differs between the treatment and control groups.”\nWe can make an opposite statement: “I hypothesize that on average the variable X does not differ between the treatment and control groups.”\n\nNow we have our null hypothesis and alternative hypothesis"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-2",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses",
    "text": "Null and alternative hypotheses\n\nThink on the work you are doing: rotation project, dissertation aim, etc.\nDoes your question have a null and alternative hypothesis?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#hypothesis-tests-3",
    "href": "Lecture_Folder/Week3b.html#hypothesis-tests-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-3",
    "href": "Lecture_Folder/Week3b.html#null-and-alternative-hypotheses-population-distributions-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions\n\nWhich scenario do you think will be easier to find a difference?\nWhat factor(s) will make our statistical tests better?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-5",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data.\nThen see how probable it was by comparing against the null distribution.\nThe probability of seeing that value or greater is called the p-value of the statistic."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-6",
    "href": "Lecture_Folder/Week3b.html#statistical-sampling-distributions-6",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nAn example of a test statistic is the t-statistic.\nThe t-statistic is a standardized difference between two sample means\n\nt = 0 indicates no difference between population means\nt-distribution is Normal, with the center and peak at 0\n\nWe can evaluate the t-statistic for our sample data and see whether it falls far enough away from zero - then we reject the null hypothesis"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-2",
    "href": "Lecture_Folder/Week3b.html#four-common-statistical-distributions-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-distributions",
    "href": "Lecture_Folder/Week3b.html#statistical-distributions",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical Distributions",
    "text": "Statistical Distributions\n\nThe shape and associated parameters of a distribution used to evaluate a test statistic also depend on sample properties such as sample size.\nDegrees of freedom are also an important parameter for critical tests."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-tangent-on-degrees-of-freedom",
    "href": "Lecture_Folder/Week3b.html#a-tangent-on-degrees-of-freedom",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A tangent on degrees of freedom",
    "text": "A tangent on degrees of freedom\n\nIn statistics, degrees of freedom refers to the number of values in a calculation that are free to vary.\nExample: you have a set of numbers, like 1, 2, 3, and 4. If you know the average (mean) of these numbers is 3, you can actually choose three of the numbers freely, but the fourth number will be determined by the other three. So in this case, you have three degrees of freedom.\nThis answer comes from ChatGPT!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#degrees-of-freedom-exercise",
    "href": "Lecture_Folder/Week3b.html#degrees-of-freedom-exercise",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Degrees of freedom exercise",
    "text": "Degrees of freedom exercise\n\nTry out this concept in R\n\nRandomly sample from a list of numbers (1-10) 5 numbers\nCalculate the mean for that group of numbers\nIf you were to add a sixth number, what would it have to be for the mean to = 7?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "href": "Lecture_Folder/Week3b.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "On a scale of Murica to 10, how many degrees of freedom do you have?",
    "text": "On a scale of Murica to 10, how many degrees of freedom do you have?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-2",
    "href": "Lecture_Folder/Week3b.html#why-do-we-use-alpha-0.5-as-a-cutoff-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-2",
    "href": "Lecture_Folder/Week3b.html#type-1-and-type-2-errors-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-4",
    "href": "Lecture_Folder/Week3b.html#components-of-hypothesis-testing-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power-1",
    "href": "Lecture_Folder/Week3b.html#statistical-power-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know-1",
    "href": "Lecture_Folder/Week3b.html#power-the-things-one-needs-to-know-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | the things one needs to know",
    "text": "Power | the things one needs to know\n\n\\[ Power \\propto \\frac{(ES)(\\alpha)(\\sqrt n)}{\\sigma}\\]\n\nPower is proportional to the combination of these parameters\n\nES - effect size; how large is the change of interest?\n\\(\\alpha\\) - significance level (usually 0.05)\nn - sample size\n\\(\\sigma\\) - standard deviation among experimental units within the same group."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know-1",
    "href": "Lecture_Folder/Week3b.html#power-what-we-usually-want-to-know-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Power | what we usually want to know",
    "text": "Power | what we usually want to know"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-4",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\nTo calculate the t-statistic for two populations:\n\n\\[\\large t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere s is the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-2",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-one-tailed-test-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-2",
    "href": "Lecture_Folder/Week3b.html#the-t-test-and-t-sampling-distribution-two-tailed-test-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-2",
    "href": "Lecture_Folder/Week3b.html#assumptions-of-parameteric-t-tests-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-try-it-out",
    "href": "Lecture_Folder/Week3b.html#lets-try-it-out",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nUse the below code to set up two simulated populations:"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-try-it-out-1",
    "href": "Lecture_Folder/Week3b.html#lets-try-it-out-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "LEt’s try it out",
    "text": "LEt’s try it out"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#first-is-the-distributionspread-the-same",
    "href": "Lecture_Folder/Week3b.html#first-is-the-distributionspread-the-same",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "First, is the distribution/spread the same?",
    "text": "First, is the distribution/spread the same?\n\nUse the function var.test() in R\nHow do we interpret this?\n\n\n\n\n    F test to compare two variances\n\ndata:  pop1 and pop2\nF = 0.8257, num df = 99, denom df = 99, p-value = 0.3423\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5555635 1.2271791\nsample estimates:\nratio of variances \n         0.8256973"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#now-for-the-t-test",
    "href": "Lecture_Folder/Week3b.html#now-for-the-t-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Now for the t-test!",
    "text": "Now for the t-test!\n\nUse the function t.test() in R\nHow do we interpret this? How would you write this conclusion as a sentence?\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  pop1 and pop2\nt = -41.396, df = 196.21, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.075616 -2.795896\nsample estimates:\nmean of x mean of y \n 2.035190  4.970946"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#mann-whitney-wilcoxon-tests",
    "href": "Lecture_Folder/Week3b.html#mann-whitney-wilcoxon-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Mann-Whitney-Wilcoxon Tests",
    "text": "Mann-Whitney-Wilcoxon Tests\n\nThe Mann-Whitney U (also called “Mann-Whitney-Wilcoxon) Test tests for distributional differences between the ranks of two samples.\nIn R the function wilcox.test() can be used to perform it, in much the same way the t.test() function is used."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-try-it-out-2",
    "href": "Lecture_Folder/Week3b.html#lets-try-it-out-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#test-the-variance",
    "href": "Lecture_Folder/Week3b.html#test-the-variance",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Test the variance",
    "text": "Test the variance\n\nUse the function we used before to see if the variance is the same or different between pop1 and pop2\nHow do we interpret this?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-mann-whit-u-test",
    "href": "Lecture_Folder/Week3b.html#the-mann-whit-u-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nUse the function wilcox.test() in R to compare pop1 and pop2\nHow do we interpret that result? How would you write it as a sentence for a paper?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-mann-whit-u-test-1",
    "href": "Lecture_Folder/Week3b.html#the-mann-whit-u-test-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  pop1 and pop2\nW = 440, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-2",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values\n\nWe can also create a null statistical distribution that models the distribution of a test statistic under the null hypothesis\nTo create the null distribution we can use either randomization or resampling"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#creating-a-null-distribution-through-randomization",
    "href": "Lecture_Folder/Week3b.html#creating-a-null-distribution-through-randomization",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Creating a null distribution through randomization",
    "text": "Creating a null distribution through randomization\n\nCombine values from both populations into a single vector\nRandomly shuffle the vector using the sample() function\nCalculate a t statistic based on the first n1 and n2 observations as our “pseudo samples” from “populations” 1 and 2, respectively, and save the value\nRepeat steps 2 and 3 many times (e.g. 1000)\nCalculate the proportion of pseudo replicates in which t is ≥ to our original, observed value of t. This proportion is our estimated p-value for the test."
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-do-it---the-starting-populations",
    "href": "Lecture_Folder/Week3b.html#lets-do-it---the-starting-populations",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s do it - the starting populations",
    "text": "Let’s do it - the starting populations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#calculate-the-t-test",
    "href": "Lecture_Folder/Week3b.html#calculate-the-t-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Calculate the t-test",
    "text": "Calculate the t-test"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "href": "Lecture_Folder/Week3b.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Combine the populations, sample from that, and calculate t-tests",
    "text": "Combine the populations, sample from that, and calculate t-tests"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#plot-the-null-distribution",
    "href": "Lecture_Folder/Week3b.html#plot-the-null-distribution",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Plot the null distribution",
    "text": "Plot the null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-3",
    "href": "Lecture_Folder/Week3b.html#null-distributions-and-p-values-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#whats-our-result",
    "href": "Lecture_Folder/Week3b.html#whats-our-result",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What’s our result?",
    "text": "What’s our result?\n\nHow do we interpret this?\n\n\n\n[1] 0.016"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#today-were-going-to",
    "href": "Lecture_Folder/Week3b.html#today-were-going-to",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Today we’re going to",
    "text": "Today we’re going to\n\nPractice some more with exploratory data analysis and hypothesis testing\nRun through an example of a power analysis"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-brief-note-on-problem-sets",
    "href": "Lecture_Folder/Week3b.html#a-brief-note-on-problem-sets",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A Brief Note on Problem Sets",
    "text": "A Brief Note on Problem Sets\n\nYour next problem set has you analyzing some of my own data, since most of you did not have data of your own yet\nWe’re going to get you started on that today!\nOn the problem set you turned in today, I asked whether you would prefer to re-do an old assignment or have a new assignment as your final Problem Set - with mixed results!"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#part-1-exploratory-data-analysis",
    "href": "Lecture_Folder/Week3b.html#part-1-exploratory-data-analysis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Part 1 Exploratory Data Analysis",
    "text": "Part 1 Exploratory Data Analysis\n\nFor this assignment, you will use the data set, “Mostoufi2022_Recombination”, available in the Problem Set 5 directory.\nFrom: Mostoufi, S. L., & Singh, N. D. (2022). Diet-induced changes in titer support a discrete response of Wolbachia-associated plastic recombination in Drosophila melanogaster. G3 (Bethesda, Md.), 12(1), jkab375. https://doi.org/10.1093/g3journal/jkab375"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#the-background",
    "href": "Lecture_Folder/Week3b.html#the-background",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "The Background",
    "text": "The Background\n\nWe tested how Wolbachia, diet, and Wolbachia concentration (titer) affected recombination\nGroup levels: Wolbachia infected and uninfected; control, sucrose-enriched, and yeast-enriched diets; and interactions between infection and diet to change bacterial titer"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#recombination",
    "href": "Lecture_Folder/Week3b.html#recombination",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Recombination",
    "text": "Recombination\n\nMeasured recombination rate using classic backcrossing scheme with visible markers across the yellow-vermillion interval of the X chromosome\nCompare “recombinants” to total offspring per vial\n\n\\[ RF = \\frac{Recombinants}{Total} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#lets-take-a-look",
    "href": "Lecture_Folder/Week3b.html#lets-take-a-look",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Let’s take a look",
    "text": "Let’s take a look\n\nOpen up the appropriate file in either R or Excel and take a look at it\nCan you identify what each column indicates?\n\nParentals: wild type or yellow-vermillion\nRecombinants: yellow or vermillion only"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations",
    "href": "Lecture_Folder/Week3b.html#some-calculations",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nCreate a “Parental” column by adding up the “wild wild” (++) and “yellow vermillion” (yv) columns for each row. Print out the first 3 rows of the data set to show that your calculations worked. (9pts)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-1",
    "href": "Lecture_Folder/Week3b.html#some-calculations-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nCreate a “Recombinant” column by adding up the “yellow wild” and “wild vermillion” columns for each row. Print out the first 3 rows of the data set to show that your calculations worked. (9pts)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-2",
    "href": "Lecture_Folder/Week3b.html#some-calculations-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nCreate a “RecombinantFraction” column by dividing the “Recombinant” column by the sum of the Parental and Recombinant columns. Print out the first 3 rows of the data set to show that your calculations worked. (10pts)\n\n\\[ RF = \\frac{Recombinants}{Total} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-3",
    "href": "Lecture_Folder/Week3b.html#some-calculations-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nUsing an R command, determine whether the variance of RecombinantFraction of the Wolbachia infected and uninfected groups are approximately equal. (10 pts)\n\n\nA good first step would be to plot the values for each group (Part 2 from homework)\nWhat are you measuring? What are the groups?\nWhat plot would you use? How would you describe the disribution of the data?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-4",
    "href": "Lecture_Folder/Week3b.html#some-calculations-4",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nWhat are you measuring? What are the groups? What R command should you use?\nHow do you interpret this result?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#some-calculations-5",
    "href": "Lecture_Folder/Week3b.html#some-calculations-5",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Some calculations",
    "text": "Some calculations\n\nDepending on your results in 1.5, use the appropriate statistical test to evaluate the difference in the means of RecombinantFraction between the Wolbachia-infected and uninfected groups. (20 pts)\nBased on your results in 1.6, write a description of your analysis results in 1-2 complete sentences. (10 pts)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#what-is-a-power-analysis",
    "href": "Lecture_Folder/Week3b.html#what-is-a-power-analysis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "What is a power analysis?",
    "text": "What is a power analysis?\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power-2",
    "href": "Lecture_Folder/Week3b.html#statistical-power-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#statistical-power-3",
    "href": "Lecture_Folder/Week3b.html#statistical-power-3",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?\n\nSample size\nEffect size (difference between the groups)\nVariance (range of values for this trait/measure)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#a-priori-power-analyses",
    "href": "Lecture_Folder/Week3b.html#a-priori-power-analyses",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "A priori Power analyses",
    "text": "A priori Power analyses\n\nBefore we start an experiment, we are interested in what sample size we should collect\nWe can use simulations to test different sample sizes"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#an-example",
    "href": "Lecture_Folder/Week3b.html#an-example",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "An example",
    "text": "An example\n\nLet’s say we’re studying college students again, and we’re interested in seeing if there’s a difference in study hours between freshman and seniors\nHow many students should we sample?\n\nThis will depend on our predictions about the effect size of this measurement"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#steps-to-power-analysis",
    "href": "Lecture_Folder/Week3b.html#steps-to-power-analysis",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Steps to power analysis",
    "text": "Steps to power analysis\n\nSimulate the true distributions of our populations (decide on effect size, distribution type, and variance)\nDraw random samples of different sizes from those populations\nPerform our statistical test (t-test) on these samples\nRepeat 2 & 3 ~1000 times\nPlot our resulting p-values against sample size"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations",
    "href": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nWhat is the distribution type?\nWhat is the effect size: difference in means between populations?\nWhat is the variance?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-1",
    "href": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-2",
    "href": "Lecture_Folder/Week3b.html#step-1-simulating-our-true-populations-2",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample",
    "href": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample-1",
    "href": "Lecture_Folder/Week3b.html#step-2-drawing-a-sample-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-3-statistical-test",
    "href": "Lecture_Folder/Week3b.html#step-3-statistical-test",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 3: statistical test",
    "text": "Step 3: statistical test\n\n\n\n    Welch Two Sample t-test\n\ndata:  sample_f and sample_s\nt = 0, df = 17.678, p-value = 1\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.002509  4.002509\nsample estimates:\nmean of x mean of y \n      9.9       9.9"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-setting-up-our-replicates",
    "href": "Lecture_Folder/Week3b.html#step-4-setting-up-our-replicates",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4: setting up our replicates",
    "text": "Step 4: setting up our replicates\n\nTake a look at the “samps_var” vectors, how are they arranged? How would we begin conducting t-tests using each replicate from the two populations?"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-testing-our-replicates",
    "href": "Lecture_Folder/Week3b.html#step-4-testing-our-replicates",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4: Testing our replicates",
    "text": "Step 4: Testing our replicates\n\n\n\nFALSE  TRUE \n   77    23"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-contd-changing-the-sample-size",
    "href": "Lecture_Folder/Week3b.html#step-4-contd-changing-the-sample-size",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4 contd: changing the sample size",
    "text": "Step 4 contd: changing the sample size"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#step-4-contd-multiple-sample-sizes",
    "href": "Lecture_Folder/Week3b.html#step-4-contd-multiple-sample-sizes",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Step 4 contd: multiple sample sizes",
    "text": "Step 4 contd: multiple sample sizes\n\nRequires a more complex for loop"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "href": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "href": "Lecture_Folder/Week3b.html#more-than-one-variable-bivariate-normal-correlation-and-covariation-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "More than one variable | Bivariate normal, correlation and covariation",
    "text": "More than one variable | Bivariate normal, correlation and covariation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#covariance-and-correlation",
    "href": "Lecture_Folder/Week3b.html#covariance-and-correlation",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Covariance and Correlation",
    "text": "Covariance and Correlation"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#linear-models",
    "href": "Lecture_Folder/Week3b.html#linear-models",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Linear Models",
    "text": "Linear Models"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet",
    "href": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet-1",
    "href": "Lecture_Folder/Week3b.html#show-the-data-anscombes-quartet-1",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "Show the data! | Anscombe’s Quartet",
    "text": "Show the data! | Anscombe’s Quartet\n\nMean of x in each case 9 (exact)\nVariance of x in each case 11 (exact)\nMean of y in each case 7.50 (to 2 decimal places)\nVariance of y in each case 4.122 or 4.127 (to 3 decimal places)\nCorrelation between x and y in each case 0.816 (to 3 decimal places)\nLinear regression line in each case \\(y =3.00 + 0.50x\\) (to 2 decimal places)"
  },
  {
    "objectID": "Lecture_Folder/Week3b.html",
    "href": "Lecture_Folder/Week3b.html",
    "title": "Week 3b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(nycflights23)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html",
    "href": "Lecture_Folder/Week4a.html",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(nycflights23)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#this-week",
    "href": "Lecture_Folder/Week4a.html#this-week",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nFinish parameter estimation\nt-test\nHypothesis testing\nPower\nStart linear models"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nAnother common situation in bioengineering is when each trial is discrete, but the number of observations of each outcome is observed/counted\nSome examples are\n\ncounts of snails in several plots of land\nobservations of the firing of a neuron in a unit of time\nthe number of muscle contractions during a bout of exercise\ncount of genes in a genome binned to units of 500kb\n\nJust like before you have ‘successes’, but\n\nnow you count them for each replicate\nthe replicates now are units of area or time\nthe values can now range from 0 to a large number"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-1",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\n\nFor example, you can examine 100 participants\n\ncount the number of jumps they can perform in 2 minutes\nwhat is the probability of observing a particpant with r jumps?\n\nPr(Y=r) is the probability that the number of occurrences of an event y equals a count r in the total number of trials\n\n\n\\[Pr(Y=r) = \\frac{e^{-\\mu}\\mu^r}{r!}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-2",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution",
    "text": "Poisson Probability Distribution\n\nNote that the Poisson is a single parameter function because \\(\\mu = \\sigma^2\\)\nThe two together are often just represented by \\(\\lambda\\)\n\n\\[Pr(y=r) = \\frac{e^{-\\lambda}\\lambda^r}{r!}\\]\n\nThis means that for a variable that is truly Poisson distributed:\n\nthe mean and variance should be equal to one another\nvariables that are approximately Poisson distributed but have a larger variance than mean are often called ‘overdispersed’\nquite common in RNA-seq and microbiome data"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-gene-length-by-bins-of-500-nucleotides",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-gene-length-by-bins-of-500-nucleotides",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution with gene length by bins of 500 nucleotides",
    "text": "Poisson Probability Distribution with gene length by bins of 500 nucleotides"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-increasing-parameter-values-of-lambda",
    "href": "Lecture_Folder/Week4a.html#poisson-probability-distribution-with-increasing-parameter-values-of-lambda",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Poisson Probability Distribution with increasing parameter values of \\(\\lambda\\)",
    "text": "Poisson Probability Distribution with increasing parameter values of \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#testing-poisson-distributions",
    "href": "Lecture_Folder/Week4a.html#testing-poisson-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Testing Poisson Distributions",
    "text": "Testing Poisson Distributions\nNumber of counts (x) given a mean and variance of lambda\n\ndpois(x=2, lambda=1)\n\n[1] 0.1839397\n\nplot(dpois(x=1:10, lambda=3))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#geometric-distribution",
    "href": "Lecture_Folder/Week4a.html#geometric-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nIf a single event has two possible outcomes the probability of having to observe k trials before the first “one” appears is given by the geometric distribution\nThe probability that the first “one” would appear on the first trial is p, but the probability that the first “one” appears on the second trial is (1-p)*p\nBy generalizing this procedure, the probability that there will be k-1 failures before the first success is:\n\n\\[P(X=k)=(1-p)^{k-1}p\\]\n\nmean = \\(\\frac{1}{p}\\)\nvariance = \\(\\frac{(1-p)}{p^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#geometric-distribution-1",
    "href": "Lecture_Folder/Week4a.html#geometric-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Geometric Distribution",
    "text": "Geometric Distribution\n\nExample: If the probability of extinction of an endangered population is estimated to be 0.1 every year, what is the expected time until extinction?\nThe distribution gives the probability of extinction in a given year (requiring that the population did not go extinct in all of the years prior)\nIf we want to know the probability of the population going exticnt by year 4, we simply add up the probabilities for years 1-3 using “or” rules"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#testing-geometric-distributions",
    "href": "Lecture_Folder/Week4a.html#testing-geometric-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\ndgeom gives the density (probability) of an event (p) after (x) failures\n\n\ndgeom(x=20, p=0.1)\n\n[1] 0.01215767\n\nplot(dgeom(1:20,0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#testing-geometric-distributions-1",
    "href": "Lecture_Folder/Week4a.html#testing-geometric-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Testing Geometric Distributions",
    "text": "Testing Geometric Distributions\n\npgeom gives the cumulative probability of event (p) in (q) trials\n\n\npgeom(q=20, p=0.1)\n\n[1] 0.890581\n\nplot(pgeom(q=1:20, p=0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#negative-binomial-distribution",
    "href": "Lecture_Folder/Week4a.html#negative-binomial-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExtension of the geometric distribution describing the waiting time until r “ones” have appeared.\nGeneralizes the geometric distribution\nProbability of the \\(r^{th}\\) “one” appearing on the \\(k^{th}\\) trial:\n\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r-1}(1-p)^{k-r}p\\]\n\nwhich simplifies to\n\\[P(X=k)=(\\frac{k-1}{r-1})p^{r}(1-p)^{k-r}\\]\n\nmean = \\(\\frac{r}{p}\\)\nvariance = \\(r(1-p)/p^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#negative-binomial-distribution-1",
    "href": "Lecture_Folder/Week4a.html#negative-binomial-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Negative Binomial Distribution",
    "text": "Negative Binomial Distribution\n\nExample: If a predator must capture 10 prey before it can grow large enough to reproduce\nWhat would the mean age of onset of reproduction be if the probability of capturing a prey on any given day is 0.1?\nNotice that the variance is quite high (~1000) and that the distribution looks quite skewed"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#continuous-probability-distributions-1",
    "href": "Lecture_Folder/Week4a.html#continuous-probability-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Continuous probability distributions",
    "text": "Continuous probability distributions\nP(observation lies within dx of x) = f(x)dx\n\\[P(a\\leq X \\leq b) = \\int_{a}^{b} f(x) dx\\]\nRemember that the indefinite integral sums to one\n\\[\\int_{-\\infty}^{\\infty} f(x) dx = 1\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#continuous-probabilities",
    "href": "Lecture_Folder/Week4a.html#continuous-probabilities",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Continuous probabilities",
    "text": "Continuous probabilities\n\nE[X] may be found by integrating the product of x and the probability density function over all possible values of x:\n\\[E[X] = \\int_{-\\infty}^{\\infty} xf(x) dx \\]\n\n\\(Var(X) = E[X^2] - (E[X])^2\\), where the expectation of \\(X^2\\) is\n\\[E[X^2] = \\int_{-\\infty}^{\\infty} x^2f(x) dx \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#uniform-distribution",
    "href": "Lecture_Folder/Week4a.html#uniform-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\n\\[E[X] = \\int_{a}^{b} x\\frac{1}{b-a} dx = \\frac{(a+b)}{2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#uniform-distribution-1",
    "href": "Lecture_Folder/Week4a.html#uniform-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Uniform Distribution",
    "text": "Uniform Distribution\n\nMeans that the probability is equal for all possible outcomes\nLike drawing m&m out of a bag with equal proportions of colors\n\n\ndunif(x=1,min=0, max=10)\n\n[1] 0.1\n\nplot(dunif(1:10, 0, 10))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#exponential-distribution",
    "href": "Lecture_Folder/Week4a.html#exponential-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\n\\[f(x)=\\lambda e^{-\\lambda x}\\]\n\n\nE[X] can be found be integrating \\(xf(x)\\) from 0 to infinity\n\n\n\nleading to the result that\n\n\n\n\\(E[X] = \\frac{1}{\\lambda}\\)\n\\(E[X^2] = \\frac{1}{\\lambda^2}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#exponential-distribution-1",
    "href": "Lecture_Folder/Week4a.html#exponential-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\nFor example, let equal the instantaneous death rate of an individual.\nThe lifespan of the individual would be described by an exponential distribution (assuming that does not change over time)."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#exponential-distribution-2",
    "href": "Lecture_Folder/Week4a.html#exponential-distribution-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Exponential Distribution",
    "text": "Exponential Distribution\n\ndexp(10, rate = 0.1)\n\n[1] 0.03678794\n\nplot(dexp(1:100, rate = 0.1))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#gamma-distribution",
    "href": "Lecture_Folder/Week4a.html#gamma-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\) :\n\n\n\\[f(x) = \\frac{e^{-\\lambda x}\\lambda x^{r-1}}{(r-1)!}\\lambda\\]\n\n\\[ Mean =  \\frac{r}{\\lambda} \\] \\[ Variance = \\frac{r}{\\lambda^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week4a.html#gamma-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\nAssume that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber.\nThe gamma distribution generalizes the exponential distribution.\nIt describes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#normal-pdf---mu-and-sigma",
    "href": "Lecture_Folder/Week4a.html#normal-pdf---mu-and-sigma",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Normal PDF - (\\(\\mu\\) and \\(\\sigma\\))",
    "text": "Normal PDF - (\\(\\mu\\) and \\(\\sigma\\))\n\\[f(x) = \\frac{1}{\\sqrt{2\\pi\\sigma}} \\, \\mathrm{e}^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\\]\nwhere \\[\\large \\pi \\approx 3.14159\\]\n\\[\\large \\mathrm{e} \\approx 2.71828\\]\nTo write that a variable (v) is distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), we write the following:\n\\[\\large v \\sim \\mathcal{N} (\\mu,\\sigma^2)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimates-of-mean-and-variance",
    "href": "Lecture_Folder/Week4a.html#estimates-of-mean-and-variance",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimates of mean and variance",
    "text": "Estimates of mean and variance\nEstimate of the mean from a single sample\n\\[\\Large \\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n}{x_i} \\]\nEstimate of the variance from a single sample\n\\[\\Large s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}{(x_i - \\bar{x})^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#normal-pdf",
    "href": "Lecture_Folder/Week4a.html#normal-pdf",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Normal PDF",
    "text": "Normal PDF"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences",
    "href": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-1",
    "href": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-2",
    "href": "Lecture_Folder/Week4a.html#why-is-the-normal-special-in-biosciences-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why is the Normal special in biosciences?",
    "text": "Why is the Normal special in biosciences?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#parent-offspring-resemblance",
    "href": "Lecture_Folder/Week4a.html#parent-offspring-resemblance",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Parent-offspring resemblance",
    "text": "Parent-offspring resemblance"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#genetic-model-of-complex-traits",
    "href": "Lecture_Folder/Week4a.html#genetic-model-of-complex-traits",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Genetic model of complex traits",
    "text": "Genetic model of complex traits"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "href": "Lecture_Folder/Week4a.html#distribution-of-f_2-genotypes-really-just-binomial-sampling",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Distribution of \\(F_2\\) genotypes | really just binomial sampling",
    "text": "Distribution of \\(F_2\\) genotypes | really just binomial sampling"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-else-is-the-normal-special",
    "href": "Lecture_Folder/Week4a.html#why-else-is-the-normal-special",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why else is the Normal special?",
    "text": "Why else is the Normal special?\n\nIt is the basis of estimation and precision of the expected value of all distributions\nProvides a mathematical basis for moving from single samples to point estimates.\nProvides a way to use simulation to generate empirical sample and test distributions through Monte Carlo approaches"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables",
    "href": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nOften we want to make variables more comparable to one another\nFor example, consider measuring the leg length of mice and of elephants\n\nWhich animal has longer legs in absolute terms?\nProportional to their body size?\n\nA good way to answer these last questions is to use ‘z-scores’"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables-1",
    "href": "Lecture_Folder/Week4a.html#z-scores-of-normal-variables-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "z-scores of normal variables",
    "text": "z-scores of normal variables\n\nz-scores are standardized to a mean of 0 and a standard deviation of 1\nWe can modify any normal distribution to have\n\na mean of 0 and\na standard deviation of 1\n\nAnother term for this is the standard normal distribution\n\n\\[\\huge z_i = \\frac{(x_i - \\bar{x})}{s}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#common-theme-in-r-for-distributions",
    "href": "Lecture_Folder/Week4a.html#common-theme-in-r-for-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Common theme in R for distributions",
    "text": "Common theme in R for distributions\n\n\n\n\n\n\n\n\n\n\n\nd\nprobability mass function\np\ncumulative distribution\nq\nquantile function\nr\npseudorandom number generate\n\n\n\n\nbinomial\ndbinom\npbinom\nqbinom\nrbinom\n\n\npoisson\ndpois\nppois\nqpois\nrpois\n\n\nexponential\ndexp\npexp\nqexp\nrexp\n\n\nnormal\ndnorm\npnorm\nqnorm\nrnorm"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#parameter-estimation",
    "href": "Lecture_Folder/Week4a.html#parameter-estimation",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nEstimation is the process of inferring a population parameter from sample data\nThe value of one sample estimate is almost never the same as the population parameter because of random sampling error\nMost will be close, but some will be far away\nSampling distribution of an estimate\n\nall values we might have obtained from our sample\nprobabilities of occurrence\n\nStandard error of an estimate\n\nstandard deviation of a sampling distribution\nmeasures the precision of the parameter estimate\nNO ESTIMATE IS USEFUL WITHOUT IT!"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#parameter-estimation-1",
    "href": "Lecture_Folder/Week4a.html#parameter-estimation-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Parameter Estimation",
    "text": "Parameter Estimation\n\nParametric (a few special exceptions, like the sample mean and its standard error)\nResampling - bootstrapping and randomization to create empirical null distributions\nOrdinary Least Squares (OLS) - optimized procedure that produces one definitive result, easy to use but no estimates of confidence\nMaximum Likelihood (ML) - Can provide model-based estimates with confidence, but harder to calculate\nBayesian Approaches - Incorporates prior information into ML estimation"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#accuracy-vs.-precision",
    "href": "Lecture_Folder/Week4a.html#accuracy-vs.-precision",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#accuracy-vs.-precision-1",
    "href": "Lecture_Folder/Week4a.html#accuracy-vs.-precision-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Accuracy vs. Precision",
    "text": "Accuracy vs. Precision\n\nAccuracy is the closeness of an estimated value to its true value\nPrecision is the closeness of repeated estimates to one another\nOur goal is to have unbiased estimates that are the most precise\nWe have to estimate parameters and test hypotheses by taking samples that approximate the underlying distribution\nThe goal of replication is to quantify variation at as many levels in a study as possible\nThe goal of randomization is to avoid bias as much as possible"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-central-limit-theorem-1",
    "href": "Lecture_Folder/Week4a.html#the-central-limit-theorem-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The Central Limit Theorem",
    "text": "The Central Limit Theorem\n\nFor most real world data sets we can’t empirically determine a sampling distribution by taking many actual samples, because we often have just the one sample.\nFortunately, we can rely on the Central Limit Theorem to make some assumptions about sampling distributions, particularly when estimating a mean from a single sample, or when estimating most any parameter using a “pseudo” or re-sampling process we refer to as “bootstrapping”"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week4a.html#standard-error-of-the-mean-sem",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Standard Error of the Mean (SEM)",
    "text": "Standard Error of the Mean (SEM)\n\\[\\huge \\sigma_{\\bar{x}} \\approx s_{\\bar{x}} = \\frac{s}{\\sqrt{n}} \\]\n\nwhere \\(s_{\\bar{x}}\\) is the estimated standard error of the distribution of the mean estimates\nwhich is usually just referred to as the ’standard error of the mean (SEM)\nnote that this is not the standard deviation of the original distribution\nimportantly, the SEM will go down as the sample size increases"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#calculating-the-standard-error-of-the-mean-sem",
    "href": "Lecture_Folder/Week4a.html#calculating-the-standard-error-of-the-mean-sem",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Calculating the Standard Error of the Mean (SEM)",
    "text": "Calculating the Standard Error of the Mean (SEM)\n\nThink conceptually - how will SEM change as sample size increases?\n\n\nset.seed(32)\ntrue_pop &lt;- rnorm(n=1000, mean=2, sd=5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.2646669\n\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 5))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.1299607\n\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=1000, lambda = 5)\nsamps_var &lt;- replicate(n = 50, sample(true_pop, size = 50))\nsamps_var_means &lt;- apply(samps_var, 2, mean)\nsem = sd(samps_var_means)/ sqrt(length(samps_var_means))\nprint(sem)\n\n[1] 0.04635888"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals",
    "href": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-1",
    "href": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-2",
    "href": "Lecture_Folder/Week4a.html#estimation-and-confidence-intervals-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Estimation and confidence intervals",
    "text": "Estimation and confidence intervals"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#confidence-intervals",
    "href": "Lecture_Folder/Week4a.html#confidence-intervals",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nA confidence interval is a range of values about a parameter estimate, such that we are X% certain that the true population parameter value lies within that interval.\nFor now, know that for a normally distributed sample, a confidence interval about the population mean can be calculated using the t.test() function in base R.\nThe 95% confidence interval is commonly reported in statistical analysis results, by convention, but other values are occasionally reported as well."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#coefficient-of-variation",
    "href": "Lecture_Folder/Week4a.html#coefficient-of-variation",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Coefficient of Variation",
    "text": "Coefficient of Variation\n\nTo make standard deviations comparable across populations with very different means, we can instead compare a standardized metric called the “coefficient of variation” (CV), which is simply the sample standard deviation divided by the sample mean (and usually expressed as a % by multiplying by 100)."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#bootstrapping",
    "href": "Lecture_Folder/Week4a.html#bootstrapping",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n-Unfortunately, most other kinds of estimates (anything not the mean) do not have this amazing property, but we can rely on another approach to calculate the standard error. - This involves generating your own sampling distribution for the estimate using the “bootstrap,” a method invented by Efron (1979). - We call the bootstrap, and other methods that do not rely on distributional assumptions of the variable itself, “nonparametric” approaches."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-etymology-of-the-term-bootstrap",
    "href": "Lecture_Folder/Week4a.html#the-etymology-of-the-term-bootstrap",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The etymology of the term ‘bootstrap’",
    "text": "The etymology of the term ‘bootstrap’"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-the-bootstrap-is-good",
    "href": "Lecture_Folder/Week4a.html#why-the-bootstrap-is-good",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why the bootstrap is good",
    "text": "Why the bootstrap is good\n\nCan be applied to almost any sample statistic\n\nThis includes means, proportions, correlations, regression\n\nWorks when there is no ready formula for a standard error\n\nFor example the median, trimmed mean, correlation, eigenvalue, etc.\n\nIs nonparametric, so doesn’t require normally-distributed data\nWorks for estimates based on complicated sampling procedures or calculations"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#easy-steps-for-bootstrapping-in-r",
    "href": "Lecture_Folder/Week4a.html#easy-steps-for-bootstrapping-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Easy steps for bootstrapping in R",
    "text": "Easy steps for bootstrapping in R\n\nTake a random sample (with replacement) from your sample data\nCalculate the estimate using the measurements in the bootstrap sample (step 1). This is the first bootstrap replicate estimate\nRepeat steps 1 and 2 a large number of times (1000 times is reasonable)\nCalculate the sample standard deviation of all the bootstrap replicate estimates obtained in step 3 (SSD = sd(sample)/sqrt(sample size))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#bootstrapping-1",
    "href": "Lecture_Folder/Week4a.html#bootstrapping-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\nThe resulting quantity is called the “bootstrap standard error”\nThe bootstrap can be applied to almost any sample statistic, including means, proportions, correlations, and regression parameters.\nIt works when there is no ready formula for a standard error, for example when estimating the median, trimmed mean, correlation, eigenvalue, etc.\nIt is nonparametric, so doesn’t require normally-distributed data, as mentioned.\nIt works well for parameter estimates that are based on complicated sampling procedures or calculations. For example, it is used to assess confidence in local relationships within phylogenetic trees."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#loops-in-r",
    "href": "Lecture_Folder/Week4a.html#loops-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Loops in R",
    "text": "Loops in R\n\nR is very good at performing repetitive tasks.\nIf we want a set of operations to be repeated several times we use what’s known as a loop.\nWhen you create a loop, R will execute the instructions in the loop a specified number of times or until a specified condition is met.\nThere are two common types of loop in R: the for loop and the while loop"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#for-loops",
    "href": "Lecture_Folder/Week4a.html#for-loops",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "For loops",
    "text": "For loops\n\nThe most commonly used loop structure when you want to repeat a task a defined number of times is the for loop. The most basic example of a for loop is:\nHow does this appear to be working?\n\n\n# Notice the sequence of parentheses and brackets used in this example\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#while-loops",
    "href": "Lecture_Folder/Week4a.html#while-loops",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "While loops",
    "text": "While loops\n\nAnother type of loop that you may use is the while loop.\nThe while loop is used when you want to keep looping until a specific logical condition is satisfied.\n\n\ni &lt;- 0\nwhile (i &lt;= 4) {\n  i &lt;- i + 1\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#if-and-else-statements",
    "href": "Lecture_Folder/Week4a.html#if-and-else-statements",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "If and Else Statements",
    "text": "If and Else Statements\n\nConditional statements are how you inject some logic into your code.\nThe most commonly used conditional statement is if.\n\nWhenever you see an if statement, read it as ‘If X is TRUE, then do a thing’.\n\nAnother statement is else, which extends the logic to ‘If X is TRUE, do a thing, or else do something different’."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#a-programming-joke-for-conditional-statements",
    "href": "Lecture_Folder/Week4a.html#a-programming-joke-for-conditional-statements",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "A programming joke for conditional statements",
    "text": "A programming joke for conditional statements\nA programmer’s partner says: ‘Please go to the store and buy a carton of milk and if they have eggs, get six.’\nThe programmer returned with 6 cartons of milk.\nWhen the partner sees this, and exclaims ‘Why the heck did you buy six cartons of milk?’\nThe programmer replied ‘They had eggs’\n\neggs &lt;- TRUE # Whether there were eggs in the store\n\n  if (eggs == TRUE) { # If there are eggs\n  n.milk &lt;- 6 # Get 6 cartons of milk\n    } else { # If there are not eggs\n  n.milk &lt;- 1 # Get 1 carton of milk\n  }"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude---simulate-a-population-and-sample-it",
    "href": "Lecture_Folder/Week4a.html#r-interlude---simulate-a-population-and-sample-it",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE - Simulate a population and sample it!",
    "text": "R INTERLUDE - Simulate a population and sample it!"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#simulations-to-compare-parameter-estimates",
    "href": "Lecture_Folder/Week4a.html#simulations-to-compare-parameter-estimates",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Simulations to compare parameter estimates",
    "text": "Simulations to compare parameter estimates\n\nLet’s use our distribution functions from last time to set up some data to play with\nLet’s imagine our data is made up of counts, with an average of 3 counts - which distribution would fit that data best?\nEx: number of hours per day spent doing homework by UO undergraduates\n\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=10000, lambda = 3)\nhist(true_pop, xlim = c(0,16))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#calculating-parameters",
    "href": "Lecture_Folder/Week4a.html#calculating-parameters",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Calculating parameters",
    "text": "Calculating parameters\n\nHow would we calculate the mean and range for this population?\n\n\nmean(true_pop)\n\n[1] 2.9817\n\nrange(true_pop)\n\n[1]  0 12\n\nmedian(true_pop)\n\n[1] 3\n\n\n\nhow about the variance and the standard deviation?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#sampling-exercise",
    "href": "Lecture_Folder/Week4a.html#sampling-exercise",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nSince we are working with simulated data, we can also afford to simulate our sampling!\nTry taking a sample from our true_pop dataset and change the sample size, then calculate the mean and range for your sample and see how it compares to the true values.\nHow many college students are you including in your survey?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#randomness-in-sampling",
    "href": "Lecture_Folder/Week4a.html#randomness-in-sampling",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Randomness in Sampling",
    "text": "Randomness in Sampling\n\nBecause of the randomness of sampling, you may get close to the true estimates even with a small sample size\nBut your results will change each time you take a new sample of the same size\nHow do we get a feel for how accurate each sample size is? Or which sample size is recommended?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#surveying-your-sampling",
    "href": "Lecture_Folder/Week4a.html#surveying-your-sampling",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\nStep 1 - take 50 samples of size 10 Step 2 - Calculate the mean from each sample Step 3 - Plot the distribution of sample mean estimates\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=10000, lambda = 3)\nsamps_var &lt;- replicate(50, sample(true_pop, 10))\nsamps_var_means &lt;- apply(samps_var, 2, mean)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#histograms",
    "href": "Lecture_Folder/Week4a.html#histograms",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Histograms",
    "text": "Histograms\n\n\n\nhist(true_pop)\n\n\n\n\n\n\n\n\n\n\nhist(samps_var_means)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#surveying-your-sampling-1",
    "href": "Lecture_Folder/Week4a.html#surveying-your-sampling-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Surveying your Sampling",
    "text": "Surveying your Sampling\n\nThis sampling variation is what we have to deal with, and account for, as empirical scientists.\nIf this had been a real-world scenario, we likely would be basing our estimate for the true mean on just a single sample mean.\nGetting close to the idea of power - does our experimental design have the power to detect the parameters we are interested in?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#challenge---bootstrapping-to-produce-a-confidence-interval",
    "href": "Lecture_Folder/Week4a.html#challenge---bootstrapping-to-produce-a-confidence-interval",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "CHALLENGE - Bootstrapping to produce a confidence interval",
    "text": "CHALLENGE - Bootstrapping to produce a confidence interval\n\nThe 2.5th and 97.5th percentiles of the bootstrap sampling distribution are a passable 95% confidence interval\nNote that no transformations or normality assumptions needed\nYou can use the quantile() function to calculate these\nYou can also use qnorm\nUse R to figure out the bootstrap distribution for other parameters (such as variance).\nTry to produce bootstrap distributions for the mean and variance of gene expresssion of one gene from the stickleback data set\nPlot the resulting distributions\nDetermine the value of the 2.5th and 97.5th percentiles"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-hypothesis",
    "href": "Lecture_Folder/Week4a.html#what-is-a-hypothesis",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\nA statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models\n\nThis is where statistical sampling distributions come into play"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-1",
    "href": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nWe can compare estimated parameters, while also including measures of uncertainty, using frequentist methods\nRequires statistical hypotheses: a statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-2",
    "href": "Lecture_Folder/Week4a.html#what-is-a-hypothesis-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a hypothesis?",
    "text": "What is a hypothesis?\n\nThis is where statistical sampling distributions come into play\n\nStatistical distributions are built upon sampling distributions\nWill tell us how “frequently” we expect to see a result as extreme as ours"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#hypothesis-tests",
    "href": "Lecture_Folder/Week4a.html#hypothesis-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height on average as Douglas fir trees"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#hypothesis-tests-1",
    "href": "Lecture_Folder/Week4a.html#hypothesis-tests-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions",
    "href": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions\n\nWhich scenario do you think will be easier to find a difference?\nWhat factor(s) will make our statistical tests better?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-1",
    "href": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nIn many cases we create a null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nSimilar to point estimates, we calculate an observed test statistic value for our data.\nThen see how probable it was by comparing against the null distribution.\nThe probability of seeing that value or greater is called the p-value of the statistic."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-2",
    "href": "Lecture_Folder/Week4a.html#statistical-sampling-distributions-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nAn example of a test statistic is the t-statistic.\nThe t-statistic is a standardized difference between two sample means\n\nt = 0 indicates no difference between population means\nt-distribution is Normal, with the center and peak at 0\n\nWe can evaluate the t-statistic for our sample data and see whether it falls far enough away from zero - then we reject the null hypothesis"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-1",
    "href": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-2",
    "href": "Lecture_Folder/Week4a.html#null-and-alternative-hypotheses-population-distributions-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#four-common-statistical-distributions",
    "href": "Lecture_Folder/Week4a.html#four-common-statistical-distributions",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\[\\huge t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere\n\n\n\n\n\n\n\n\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | under different degrees of freedom",
    "text": "The t-test and t sampling distribution | under different degrees of freedom"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-1",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\(H_0\\) : Null hypothesis : Ponderosa pine trees are the same height on average as Douglas fir trees\n\\[H_0 : \\mu_1 = \\mu_2\\]\n\\(H_A\\) : Alternative Hypothesis: Ponderosa pine trees are not the same height as Douglas fir trees\n\\[H_A : \\mu_1 \\neq \\mu_2\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-2",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\nwhere\n\n\n\n\n\n\n\n\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests",
    "href": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#a-tangent-on-degrees-of-freedom",
    "href": "Lecture_Folder/Week4a.html#a-tangent-on-degrees-of-freedom",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "A tangent on degrees of freedom",
    "text": "A tangent on degrees of freedom\n\nIn statistics, degrees of freedom refers to the number of values in a calculation that are free to vary.\nExample: you have a set of numbers, like 1, 2, 3, and 4. If you know the average (mean) of these numbers is 3, you can actually choose three of the numbers freely, but the fourth number will be determined by the other three. So in this case, you have three degrees of freedom.\nThis answer comes from ChatGPT!"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#degrees-of-freedom-exercise",
    "href": "Lecture_Folder/Week4a.html#degrees-of-freedom-exercise",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Degrees of freedom exercise",
    "text": "Degrees of freedom exercise\n\nTry out this concept in R\n\nRandomly sample from a list of numbers (1-10) 5 numbers\nCalculate the mean for that group of numbers\nIf you were to add a sixth number, what would it have to be for the mean to = 7?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "href": "Lecture_Folder/Week4a.html#on-a-scale-of-murica-to-10-how-many-degrees-of-freedom-do-you-have",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "On a scale of Murica to 10, how many degrees of freedom do you have?",
    "text": "On a scale of Murica to 10, how many degrees of freedom do you have?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#type-1-and-type-2-errors",
    "href": "Lecture_Folder/Week4a.html#type-1-and-type-2-errors",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing",
    "href": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\n\\(\\alpha\\) = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\n\\(\\beta\\) = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power",
    "href": "Lecture_Folder/Week4a.html#statistical-power",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "href": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-1",
    "href": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power-1",
    "href": "Lecture_Folder/Week4a.html#statistical-power-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#power-the-things-one-needs-to-know",
    "href": "Lecture_Folder/Week4a.html#power-the-things-one-needs-to-know",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Power | the things one needs to know",
    "text": "Power | the things one needs to know\n\\[ Power \\propto \\frac{(ES)(\\alpha)(\\sqrt n)}{\\sigma}\\]\n\nPower is proportional to the combination of these parameters\n\nES - effect size; how large is the change of interest?\n\\(\\alpha\\) - significance level (usually 0.05)\nn - sample size\n\\(\\sigma\\) - standard deviation among experimental units within the same group."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#power-what-we-usually-want-to-know",
    "href": "Lecture_Folder/Week4a.html#power-what-we-usually-want-to-know",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Power | what we usually want to know",
    "text": "Power | what we usually want to know"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#power-rough-calculation",
    "href": "Lecture_Folder/Week4a.html#power-rough-calculation",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Power | rough calculation",
    "text": "Power | rough calculation"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#what-is-a-power-analysis",
    "href": "Lecture_Folder/Week4a.html#what-is-a-power-analysis",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What is a power analysis?",
    "text": "What is a power analysis?\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power-2",
    "href": "Lecture_Folder/Week4a.html#statistical-power-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#statistical-power-3",
    "href": "Lecture_Folder/Week4a.html#statistical-power-3",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?\n\nSample size\nEffect size (difference between the groups)\nVariance (range of values for this trait/measure)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#a-priori-power-analyses",
    "href": "Lecture_Folder/Week4a.html#a-priori-power-analyses",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "A priori Power analyses",
    "text": "A priori Power analyses\n\nBefore we start an experiment, we are interested in what sample size we should collect\nWe can use simulations to test different sample sizes"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#an-example",
    "href": "Lecture_Folder/Week4a.html#an-example",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "An example",
    "text": "An example\n\nLet’s say we’re studying college students again, and we’re interested in seeing if there’s a difference in study hours between freshman and seniors\nHow many students should we sample?\n\nThis will depend on our predictions about the effect size of this measurement"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#steps-to-power-analysis",
    "href": "Lecture_Folder/Week4a.html#steps-to-power-analysis",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Steps to power analysis",
    "text": "Steps to power analysis\n\nSimulate the true distributions of our populations (decide on effect size, distribution type, and variance)\nDraw random samples of different sizes from those populations\nPerform our statistical test (t-test) on these samples\nRepeat 2 & 3 ~1000 times\nPlot our resulting p-values against sample size"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations",
    "href": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nWhat is the distribution type?\nWhat is the effect size: difference in means between populations?\nWhat is the variance?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-1",
    "href": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nsenior &lt;- rpois(5000, lambda = 10)\nfresh &lt;- rpois(5000, lambda = 12)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-2",
    "href": "Lecture_Folder/Week4a.html#step-1-simulating-our-true-populations-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample",
    "href": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample\n\nsample_s &lt;- sample(senior, size = 10, replace = FALSE)\nsample_f &lt;- sample(fresh, size = 10, replace = FALSE)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample-1",
    "href": "Lecture_Folder/Week4a.html#step-2-drawing-a-sample-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-3-statistical-test",
    "href": "Lecture_Folder/Week4a.html#step-3-statistical-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 3: statistical test",
    "text": "Step 3: statistical test\n\nt.test(sample_f, sample_s)\n\n\n    Welch Two Sample t-test\n\ndata:  sample_f and sample_s\nt = 1.1234, df = 16.683, p-value = 0.2772\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.497353  4.897353\nsample estimates:\nmean of x mean of y \n     12.0      10.3"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-setting-up-our-replicates",
    "href": "Lecture_Folder/Week4a.html#step-4-setting-up-our-replicates",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4: setting up our replicates",
    "text": "Step 4: setting up our replicates\n\nTake a look at the “samps_var” vectors, how are they arranged? How would we begin conducting t-tests using each replicate from the two populations?\n\n\n## sample size of 10\nsamps_var_s &lt;- replicate(n = 100, sample(senior, size = 10))\nsamps_var_f &lt;- replicate(n = 100, sample(fresh, size = 10))"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-testing-our-replicates",
    "href": "Lecture_Folder/Week4a.html#step-4-testing-our-replicates",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4: Testing our replicates",
    "text": "Step 4: Testing our replicates\n\n# setting up a \"test\" dataframe\ntests &lt;- data.frame(1:100)\ntests$SampleSize &lt;- rep(\"10\", 100)\n\nfor (i in 1:ncol(samps_var_f)){\n  tests$result[i] &lt;- t.test(samps_var_s[,i], samps_var_f[,i])$p.value\n}\ntable(tests$result &lt; 0.05)\n\n\nFALSE  TRUE \n   85    15"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-contd-changing-the-sample-size",
    "href": "Lecture_Folder/Week4a.html#step-4-contd-changing-the-sample-size",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4 contd: changing the sample size",
    "text": "Step 4 contd: changing the sample size"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#step-4-contd-multiple-sample-sizes",
    "href": "Lecture_Folder/Week4a.html#step-4-contd-multiple-sample-sizes",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Step 4 contd: multiple sample sizes",
    "text": "Step 4 contd: multiple sample sizes\n\nRequires a more complex for loop"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-complete-exercises-3.2-3.4",
    "href": "Lecture_Folder/Week4a.html#r-interlude-complete-exercises-3.2-3.4",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R Interlude | Complete Exercises 3.2-3.4",
    "text": "R Interlude | Complete Exercises 3.2-3.4"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-2",
    "href": "Lecture_Folder/Week4a.html#components-of-hypothesis-testing-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\nalpha = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\nbeta = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - beta). It depends on effect size, sample size, chosen alpha, and population standard deviation\nMultiple testing = performing the same or similar tests multiple times - need to correct"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-distributions-and-p-values",
    "href": "Lecture_Folder/Week4a.html#null-distributions-and-p-values",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "href": "Lecture_Folder/Week4a.html#why-do-we-use-alpha-0.5-as-a-cutoff-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-4",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-4",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\nTo calculate the t-statistic for two populations:\n\n\\[\\large t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere s is the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-one-tailed-test-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one-tailed test",
    "text": "The t-test and t sampling distribution | one-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "href": "Lecture_Folder/Week4a.html#the-t-test-and-t-sampling-distribution-two-tailed-test-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | two-tailed test",
    "text": "The t-test and t sampling distribution | two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests-1",
    "href": "Lecture_Folder/Week4a.html#assumptions-of-parameteric-t-tests-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nThis is an example of a parametric test"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-try-it-out",
    "href": "Lecture_Folder/Week4a.html#lets-try-it-out",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nUse the below code to set up two simulated populations:\n\n\nset.seed(518)\npop1 &lt;- sample(rnorm(n=10000, mean=2, sd=0.5), size = 100)\npop2 &lt;- sample(rnorm(n=10000, mean=5, sd=0.5), size = 100)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-try-it-out-1",
    "href": "Lecture_Folder/Week4a.html#lets-try-it-out-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "LEt’s try it out",
    "text": "LEt’s try it out"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#first-is-the-distributionspread-the-same",
    "href": "Lecture_Folder/Week4a.html#first-is-the-distributionspread-the-same",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "First, is the distribution/spread the same?",
    "text": "First, is the distribution/spread the same?\n\nUse the function var.test() in R\nHow do we interpret this?\n\n\nvar.test(pop1, pop2)\n\n\n    F test to compare two variances\n\ndata:  pop1 and pop2\nF = 0.8257, num df = 99, denom df = 99, p-value = 0.3423\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.5555635 1.2271791\nsample estimates:\nratio of variances \n         0.8256973"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#now-for-the-t-test",
    "href": "Lecture_Folder/Week4a.html#now-for-the-t-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Now for the t-test!",
    "text": "Now for the t-test!\n\nUse the function t.test() in R\nHow do we interpret this? How would you write this conclusion as a sentence?\n\n\nt.test(pop1, pop2)\n\n\n    Welch Two Sample t-test\n\ndata:  pop1 and pop2\nt = -41.396, df = 196.21, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.075616 -2.795896\nsample estimates:\nmean of x mean of y \n 2.035190  4.970946"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#mann-whitney-wilcoxon-tests",
    "href": "Lecture_Folder/Week4a.html#mann-whitney-wilcoxon-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Mann-Whitney-Wilcoxon Tests",
    "text": "Mann-Whitney-Wilcoxon Tests\n\nThe Mann-Whitney U (also called “Mann-Whitney-Wilcoxon) Test tests for distributional differences between the ranks of two samples.\nIn R the function wilcox.test() can be used to perform it, in much the same way the t.test() function is used."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-try-it-out-2",
    "href": "Lecture_Folder/Week4a.html#lets-try-it-out-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nset.seed(518)\npop1 &lt;- sample(rnorm(n=10000, mean=2, sd=0.5), size = 100)\npop2 &lt;- sample(rnorm(n=10000, mean=5, sd=1.5), size = 100)\nhist(pop2)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#test-the-variance",
    "href": "Lecture_Folder/Week4a.html#test-the-variance",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Test the variance",
    "text": "Test the variance\n\nUse the function we used before to see if the variance is the same or different between pop1 and pop2\nHow do we interpret this?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-mann-whit-u-test",
    "href": "Lecture_Folder/Week4a.html#the-mann-whit-u-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nUse the function wilcox.test() in R to compare pop1 and pop2\nHow do we interpret that result? How would you write it as a sentence for a paper?"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#the-mann-whit-u-test-1",
    "href": "Lecture_Folder/Week4a.html#the-mann-whit-u-test-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nwilcox.test(pop1, pop2)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  pop1 and pop2\nW = 440, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-1",
    "href": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values\n\nWe can also create a null statistical distribution that models the distribution of a test statistic under the null hypothesis\nTo create the null distribution we can use either randomization or resampling"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#creating-a-null-distribution-through-randomization",
    "href": "Lecture_Folder/Week4a.html#creating-a-null-distribution-through-randomization",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Creating a null distribution through randomization",
    "text": "Creating a null distribution through randomization\n\nCombine values from both populations into a single vector\nRandomly shuffle the vector using the sample() function\nCalculate a t statistic based on the first n1 and n2 observations as our “pseudo samples” from “populations” 1 and 2, respectively, and save the value\nRepeat steps 2 and 3 many times (e.g. 1000)\nCalculate the proportion of pseudo replicates in which t is ≥ to our original, observed value of t. This proportion is our estimated p-value for the test."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#lets-do-it---the-starting-populations",
    "href": "Lecture_Folder/Week4a.html#lets-do-it---the-starting-populations",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Let’s do it - the starting populations",
    "text": "Let’s do it - the starting populations\n\nset.seed(56)\npop_1 &lt;- rnorm(n=50, mean=20.1, sd=2)#simulate population 1 for this example\npop_2 &lt;- rnorm(n=50, mean=19.3, sd=2)#simulate population 2 for this example"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#calculate-the-t-test",
    "href": "Lecture_Folder/Week4a.html#calculate-the-t-test",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Calculate the t-test",
    "text": "Calculate the t-test\n\n# Store the t statistic calculated from our samples, using t.test()\nt_obs &lt;- t.test(x=pop_1, y=pop_2, alternative=\"greater\")$statistic"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "href": "Lecture_Folder/Week4a.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Combine the populations, sample from that, and calculate t-tests",
    "text": "Combine the populations, sample from that, and calculate t-tests\n\n# Combine both population vectors into one\npops_comb &lt;- c(pop_1, pop_2)\n\n# Randomly shuffle and calculate t statistic 1000 times\nt_rand &lt;- replicate(1000, {\n  pops_shuf &lt;- sample(pops_comb)\n  t.test(x=pops_shuf[1:50], y=pops_shuf[51:100], alternative=\"greater\")$statistic\n  })"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#plot-the-null-distribution",
    "href": "Lecture_Folder/Week4a.html#plot-the-null-distribution",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Plot the null distribution",
    "text": "Plot the null distribution\n\n# Plot the \"null distribution\" from the randomization-based t-values\nhist(t_rand)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-2",
    "href": "Lecture_Folder/Week4a.html#null-distributions-and-p-values-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#whats-our-result",
    "href": "Lecture_Folder/Week4a.html#whats-our-result",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "What’s our result?",
    "text": "What’s our result?\n\nHow do we interpret this?\n\n\n# Calculate the p-value for the test as the number of randomization t-values greater\n# than or equal to our actual t-value observed from the data\np &lt;- sum(t_rand&gt;=t_obs)/1000\n\np\n\n[1] 0.016"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r",
    "href": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nMake a dummy data set that contains one continuous and one categorical value (with two levels). Draw individuals of the two different factor levels from normal distributions with slightly different means. Take 100 obsv. per factor level.\nNow, perform a t-test to see if the two populations are statistically different from one another\n\n\nboxplot(continuous_variable~cat_variable, dataset name) \nt.test(continuous_variable~cat_variable, dataset name) \n\n\nRepeat steps 1 and 2 above but use different sample sizes (e.g. 10 , then 100, then 1000, then 10,000 obsv. per factor level)\nRepeat steps 1 and 2 above but now test between a categorical and continuous variable in the perchlorate data set (or any of your favorite data sets)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-parametric-t-test-in-r-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Parametric t-test in R",
    "text": "R INTERLUDE | Parametric t-test in R\n\nNow, apply the equations for the t-statistic above to your simulated sample to perform the same test, but using a resampling approach\n\nhint: go back to your Bootstrapping script\n\nUse this approach to calculate a distribution of random t statistics assuming the the null hypothesis of no difference is true.\nNow, compare your observed value to your created null distribution.\nWhat is the probability of that value occurring by chance under the null?\n\nThis is your p-value! (Assume you’re doing a one-tailed test)\nhint: Proportion of values in the null distribution equal to or larger than the observed t-value = p-value"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nRandomization test example 1\nData: The number of successful broods of pseudoscorpion females that were mated twice to either a single male (SM) or two different males (DM).\n\nSM: 4 0 3 1 2 3 4 2 4 2 0 2 0 1 2 6 0 2 3 3\nDM: 2 0 2 6 4 3 4 4 2 7 4 1 6 3 6 4\n\nObserved difference in the means between the two\n\n\\(\\bar{Y}_{SM}\\) − \\(\\bar{Y}_{DM}\\) = 2.2−3.625 = −1.425"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nSteps of the randomization test\nFirst, create a randomized data set in which the measurements are randomly reassigned (without replacement) to the two groups\n\nFor example, the following\nSM: 4 0 7 4 2 2 2 1 4 4 0 3 3 4 6 2 4 6 0 0\nDM: 2 2 3 3 2 3 3 4 1 2 1 4 6 6 2 0\n\nSecond, calculate the test statistic measuring the association between variables\n\ndifference between group means\nthis is the first bootstrap replicate\n\nRepeat steps 1 and 2 many times to produce many bootstrap replicates"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-2",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nBelow is the null distribution of the test statistic from 10,000 replications\n\nThis is produced by the randomized assignment of values to each group (SM or DM)\nThus this is the distribution we’d expect under the null hypothesis of no difference\n\nThe observed value from the data is –1.425\nThe area in red is the tail beyond this observed value and is therefore the bootstrap p-value"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-3",
    "href": "Lecture_Folder/Week4a.html#r-interlude-permutation-t-test-in-r-3",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Permutation t-test in R",
    "text": "R INTERLUDE | Permutation t-test in R\n\nOf these 10,000 randomizations, only 176 had a test statistic (difference between means) equal to or less than the observed value, –1.425.\nYou can use the simulated null distribution in the same way as t or F distribution in conventional tests.\nProportion of values in the null distribution equal or larger than the observed value of the test statistic is 176/10000 = 0.0176."
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power",
    "href": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nRead in the perchlorate data again\nPerform an ANOVA to test Strain on T4_Hormone_Level, but log-transform (base 10) the T4 variable\n\n\nperc &lt;- read.table('perchlorate_data.tsv', header=T, sep='\\t')\nx &lt;- perc$Strain\ny &lt;- log10(perc$T4_Hormone_Level)\n\nMyANOVA &lt;- aov(y ~ x)\nsummary (MyANOVA)\nboxplot(y ~ x)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-perform-a-one-way-anova-with-power-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Perform a one-way ANOVA with power",
    "text": "R INTERLUDE | Perform a one-way ANOVA with power\n\nConsider the parameters of this test related to power:\n\nThe per-group sample sizes\nThe standard deviation (use the higher within-group sd)\nThe effect size (|difference between means| / within-grp sd)\n\nFor more complex ANOVA power calculations (&gt;2 groups):\n\nThe total variance\nThe within-group variance (use the higher one)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "href": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\nBased on your results, calculate the power for your ANOVA.\n\n   pwr.t2n.test(n1=xxx, n2=xxx, d=xxx, sig.level=.05, power=NULL)\n\nCheck out the functions in the ‘pwr’ library (Unnecessary in this case, but could use ANOVA version):\n\n   pwr.anova.test(k=2, n=190, f=0.25, sig.level=.05, power=NULL)"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "href": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-1",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\neffect size approximations:\n\nf=0.1 (small)\nf=0.25 (medium)\nf=0.4 (large)\n\nsee http://www.statmethods.net/stats/power.html"
  },
  {
    "objectID": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "href": "Lecture_Folder/Week4a.html#r-interlude-post-hoc-and-a-priori-power-analyses-2",
    "title": "Week 4a - Statistics for Bioengineering",
    "section": "R INTERLUDE | post hoc and a priori power analyses",
    "text": "R INTERLUDE | post hoc and a priori power analyses\n\nLet’s say you have to repeat the experiment, but your IACUC wants you to get by by using fewer fish.\nYou want to be able to detect a minimum mean difference of 1.3 T4 units (about 0.114 on the log10 scale), at a power of 90%.\nFirst, divide 0.114 by std.dev. of transformed WK values (the higher std. dev. of the two groups) to get a conservative “d”.\nWhat kind of sample size for the WK group would you need???\n(Again use the pwr.t2n.test() function, but this time specify the WK sample size as the unknown parameter)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html",
    "href": "Lecture_Folder/Week4b.html",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(nycflights23)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#r-interlude---simulate-a-population-and-sample-it",
    "href": "Lecture_Folder/Week4b.html#r-interlude---simulate-a-population-and-sample-it",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "R INTERLUDE - Simulate a population and sample it!",
    "text": "R INTERLUDE - Simulate a population and sample it!"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#sampling-exercise",
    "href": "Lecture_Folder/Week4b.html#sampling-exercise",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Sampling Exercise",
    "text": "Sampling Exercise\n\nStep 1 - take 50 samples of\n\nsize 10\nsize 100\nsize 1000\n\nStep 2 - Calculate the range from each sample\nStep 3 - Calculate key statistics using summary\nStep 4 - Plot the distribution of sample mean estimates\nStep 5 - Calculate the 2.5% and 97.5% quantiles"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#different-sample-sizes",
    "href": "Lecture_Folder/Week4b.html#different-sample-sizes",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Different sample sizes",
    "text": "Different sample sizes\n\nSample size of 10\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=10000, lambda = 3)\nsamps_var_10 &lt;- replicate(50, sample(true_pop, 10))\nsamps_var_means_10 &lt;- apply(samps_var_10, 2, mean)\n\n\n\nSample size of 100\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=10000, lambda = 3)\nsamps_var_1000 &lt;- replicate(50, sample(true_pop, 100))\nsamps_var_means_100 &lt;- apply(samps_var_1000, 2, mean)\n\n\n\nSample size of 1000\n\nset.seed(32)\ntrue_pop &lt;- rpois(n=10000, lambda = 3)\nsamps_var_1000 &lt;- replicate(50, sample(true_pop, 1000))\nsamps_var_means_1000 &lt;- apply(samps_var_1000, 2, mean)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#statistics-for-original-distribution",
    "href": "Lecture_Folder/Week4b.html#statistics-for-original-distribution",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Statistics for original distribution",
    "text": "Statistics for original distribution\n\nrange(true_pop)\n\n[1]  0 12\n\nsummary(true_pop)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   2.000   3.000   2.982   4.000  12.000 \n\n\n\n\n\nhist(true_pop)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#section",
    "href": "Lecture_Folder/Week4b.html#section",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "",
    "text": "Sample size of 10\n\nrange(samps_var_means_10)\n\n[1] 1.9 4.0\n\nsummary(samps_var_means_10)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.9     2.6     2.9     2.9     3.3     4.0 \n\n\n\n\nSample size of 100\n\nrange(samps_var_means_100)\n\n[1] 2.66 3.26\n\nsummary(samps_var_means_100)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.660   2.835   2.950   2.967   3.070   3.260 \n\n\n\n\nSample size of 1000\n\nrange(samps_var_means_1000)\n\n[1] 2.886 3.072\n\nsummary(samps_var_means_1000)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  2.886   2.941   2.985   2.976   3.005   3.072"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#histograms",
    "href": "Lecture_Folder/Week4b.html#histograms",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Histograms",
    "text": "Histograms\n\n\n\nhist(true_pop)\n\n\n\n\n\n\n\n\n\n\nhist(samps_var_means_10, xlim =c(0,5))\n\n\n\n\n\n\n\n\n\n\nhist(samps_var_means_100, xlim =c(0,5))\n\n\n\n\n\n\n\n\n\n\nhist(samps_var_means_1000, xlim =c(0,5))"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#percentiles-and-quantiles",
    "href": "Lecture_Folder/Week4b.html#percentiles-and-quantiles",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Percentiles and quantiles",
    "text": "Percentiles and quantiles\n\nPercentile - an intuitive way of measuring a relative position in a data set\np-th percentile is a value that is greater than p% of the data\n50th percentile of a data set is the median\n25th percentile is the 1st quartile\n75th percentile is the 3rd quartile\nQuantiles divide a dataset into equal parts\nThe number of groups can be any integer, but is often 10\nAlso the basis of the p-value for test statistics"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#percentiles-and-quantiles-in-r",
    "href": "Lecture_Folder/Week4b.html#percentiles-and-quantiles-in-r",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Percentiles and quantiles in R",
    "text": "Percentiles and quantiles in R\n\ndata_RNAseq &lt;- read.table(\"Stickle_RNAseq.tsv\", header=TRUE, sep = \"\\t\")\nquantile(data_RNAseq$Gene20, probs = c(0.25, 0.5, 0.75))\n\n  25%   50%   75% \n 2.00  3.50 21.25 \n\n\n\n\n\ndata_RNAseq &lt;- read.table(\"Stickle_RNAseq.tsv\", header=TRUE, sep = \"\\t\")\nsummary(data_RNAseq$Gene20)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    2.00    3.50   13.11   21.25   44.00 \n\n\n\n\n\ndata_RNAseq &lt;- read.table(\"Stickle_RNAseq.tsv\", header=TRUE, sep = \"\\t\")\ndata_RNAseq$Gene20 |&gt;\nsummary()\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    2.00    3.50   13.11   21.25   44.00"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#challenge---bootstrapping-to-produce-a-confidence-interval",
    "href": "Lecture_Folder/Week4b.html#challenge---bootstrapping-to-produce-a-confidence-interval",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "CHALLENGE - Bootstrapping to produce a confidence interval",
    "text": "CHALLENGE - Bootstrapping to produce a confidence interval\n\nThe 2.5th and 97.5th percentiles of the bootstrap sampling distribution are a passable 95% confidence interval\nNote that no transformations or normality assumptions needed\nYou can use the quantile() function to calculate these\nYou can also use qnorm\nUse R to figure out the bootstrap distribution for other parameters (such as variance).\nTry to produce bootstrap distributions for the mean and variance of gene expresssion of one gene from the stickleback data set\nPlot the resulting distributions\nDetermine the value of the 2.5th and 97.5th percentiles"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#finding-the-cis-of-the-empirical-distribution",
    "href": "Lecture_Folder/Week4b.html#finding-the-cis-of-the-empirical-distribution",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Finding the CI’s of the empirical distribution",
    "text": "Finding the CI’s of the empirical distribution\n\nSample size of 10\n\nsamps_var_means_10 |&gt;\nquantile(probs = c(0.025, 0.975))\n\n  2.5%  97.5% \n1.9675 3.6775 \n\n\n\n\nSample size of 100\n\nsamps_var_means_100 |&gt;\nquantile(probs = c(0.025, 0.975))\n\n   2.5%   97.5% \n2.70225 3.24775 \n\n\n\n\nSample size of 1000\n\nsamps_var_means_1000 |&gt;\nquantile(probs = c(0.025, 0.975))\n\n    2.5%    97.5% \n2.892575 3.068750"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#what-is-a-hypothesis",
    "href": "Lecture_Folder/Week4b.html#what-is-a-hypothesis",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\nA statement of belief about the world\nNeed a critical test to\n\naccept or reject the hypothesis\ncompare the relative merits of different models\n\nThis is where statistical sampling distributions come into play\nStatistical sampling distributions are built upon sampling distributions of random variables"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#what-is-a-hypothesis-1",
    "href": "Lecture_Folder/Week4b.html#what-is-a-hypothesis-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "What is a hypothesis",
    "text": "What is a hypothesis\n\n\n\\(H_0\\) : Null hypothesis : The amino acid substitution does not change the catalytic rate of an enzyme\n\n\n\n\n\\(H_A\\) : Alternative Hypothesis: The amino acid substitution does change the catalytic rate of an enzyme\n\\(H_A\\) : Alternative Hypothesis: The amino acid substitution increases the catalytic rate of an enzyme\n\\(H_A\\) : Alternative Hypothesis: The amino acid substitution decreases the catalytic rate of an enzyme"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#hypothesis-tests",
    "href": "Lecture_Folder/Week4b.html#hypothesis-tests",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Hypothesis tests",
    "text": "Hypothesis tests\n\nWhat is the probability that we would reject a true null hypothesis?\nWhat is the probability that we would accept a false null hypothesis?\nHow do we decide when to reject a null hypothesis and support an alternative?\nWhat can we conclude if we fail to reject a null hypothesis?\nWhat parameter estimates of distributions are important to test hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#null-and-alternative-hypotheses-population-distributions",
    "href": "Lecture_Folder/Week4b.html#null-and-alternative-hypotheses-population-distributions",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses | population distributions",
    "text": "Null and alternative hypotheses | population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#null-and-alternative-hypotheses---population-distributions",
    "href": "Lecture_Folder/Week4b.html#null-and-alternative-hypotheses---population-distributions",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Null and alternative hypotheses - population distributions",
    "text": "Null and alternative hypotheses - population distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#type-1-and-type-2-errors",
    "href": "Lecture_Folder/Week4b.html#type-1-and-type-2-errors",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Type 1 and Type 2 errors",
    "text": "Type 1 and Type 2 errors"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#components-of-hypothesis-testing",
    "href": "Lecture_Folder/Week4b.html#components-of-hypothesis-testing",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Components of hypothesis testing",
    "text": "Components of hypothesis testing\n\np-value = the long run probability of rejecting a true null hypothesis\n\\(\\alpha\\) = critical value of p-value cutoff for experiments. The Type I error we are willing to tolerate.\n\\(\\beta\\) = cutoff for probability of accepting a false null hypothesis\nPower = the probability that a test will reject a false null hypothesis (1 - \\(\\beta\\)).\n\nIt depends on effect size, sample size, chosen alpha, and population standard deviation\nMakes sense - probability of rejecting a false null hypothesis\n\nMultiple testing = performing the same or similar tests multiple times - need to correct alpha value\nCan correct multiple testing using a tax (e.g. Bonferonni) or directly estimating a False Discovery Rate (FDR)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "href": "Lecture_Folder/Week4b.html#why-do-we-use-alpha-0.5-as-a-cutoff",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?",
    "text": "Why do we use \\(\\alpha = 0.5\\) as a cutoff?"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#statistical-sampling-distributions",
    "href": "Lecture_Folder/Week4b.html#statistical-sampling-distributions",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Statistical sampling distributions",
    "text": "Statistical sampling distributions\n\nStatistical tests provide a way to perform critical tests of hypotheses\nJust like raw data, statistics are random variables and depend on sampling distributions of the underlying data\nThe particular form of the statistical distribution depends on the test statistic and parameters such as the degrees of freedom that are determined by sample size.\nEssentially we get a distribution for statistics values too\nHow frequently do we see a statistics value as large/small as this one?"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#statistical-tests---parametric",
    "href": "Lecture_Folder/Week4b.html#statistical-tests---parametric",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Statistical tests - parametric",
    "text": "Statistical tests - parametric\n\nIn some cases we can perform parameteric statistical tests where we make assumptions about the distributions of the underlying variables\nMathematical proofs relate the observed test statistic to a theoretical probability distribution based upon the sample size\nThey are called parametric because we are estimating the parameter of an assumed distribution\nThe assumed distribution means that parametric tests often have assumptions"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#statistical-tests---non-parametric",
    "href": "Lecture_Folder/Week4b.html#statistical-tests---non-parametric",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Statistical tests - non-parametric",
    "text": "Statistical tests - non-parametric\n\nIn many other cases we create an empricial null statistical distribution that models the distribution of a test statistic under the null hypothesis.\nWe can use this for non-parametric statistical tests\nSimilar to point estimates, we calculate an observed test statistic value for our data.\nThen see how probable it was by comparing against the null distribution.\nThe probability of seeing that value or greater is called the p-value of the statistic.\nParametric and non-parametric tests function the same way, they really only differ by whether the null distribution is assumed or created empirically through resampling"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#four-common-statistical-distributions",
    "href": "Lecture_Folder/Week4b.html#four-common-statistical-distributions",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Four common statistical distributions",
    "text": "Four common statistical distributions"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#t-sampling-distribution",
    "href": "Lecture_Folder/Week4b.html#t-sampling-distribution",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "t sampling distribution",
    "text": "t sampling distribution\n\nOne of the oldest test statistic is the t-statistic.\nCompares\n\none group mean against a value (one sample t-test)\nor two group means against one another (two sample t-test)\n\nThe t-statistic is a standardized difference between two sample means\n\nt = 0 indicates no difference between population means\nt-distribution is ~ Normal, with the center and peak at 0\n\nWe can evaluate the t-statistic for our sample data and see whether it falls far enough away from zero\nIf our p-value falls below our critical value we reject the null hypothesis"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#section-1",
    "href": "Lecture_Folder/Week4b.html#section-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "",
    "text": "\\[\\large t = \\frac{(\\bar{y}_1-\\bar{y}_2)}{s_{\\bar{y}_1-\\bar{y}_2}} \\]\nwhere\n\n\n\n\n\n\n\n\n\nwhich is the calculation for the standard error of the mean difference"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "href": "Lecture_Folder/Week4b.html#the-t-test-and-t-sampling-distribution-under-different-degrees-of-freedom",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution under different degrees of freedom",
    "text": "The t-test and t sampling distribution under different degrees of freedom"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#the-t-test-and-t-sampling-distribution-one--and-two-tailed-test",
    "href": "Lecture_Folder/Week4b.html#the-t-test-and-t-sampling-distribution-one--and-two-tailed-test",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution | one- and two-tailed test",
    "text": "The t-test and t sampling distribution | one- and two-tailed test"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#the-t-test-and-t-sampling-distribution",
    "href": "Lecture_Folder/Week4b.html#the-t-test-and-t-sampling-distribution",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "The t-test and t sampling distribution",
    "text": "The t-test and t sampling distribution\n\\(H_0\\) : Null hypothesis : The microbiota treatment of stickleback fish does not change the level of expression of a particular gene\n\\[H_0 : \\mu_{conv} = \\mu_{gf}\\]\n\\(H_A\\) : Alternative hypothesis : The microbiota treatment of stickleback fish does change the level of expression of a particular gene\n\\[H_A : \\mu_{conv} \\neq \\mu_{gf}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#assumptions-of-parameteric-t-tests",
    "href": "Lecture_Folder/Week4b.html#assumptions-of-parameteric-t-tests",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Assumptions of parameteric t-tests",
    "text": "Assumptions of parameteric t-tests\n\n\nThe theoretical t-distributions for each degree of freedom were calculated for populations that are:\n\nnormally distributed\nhave equal variances (if comparing two means)\nobservations are independent (randomly drawn)\n\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#a-tangent-on-degrees-of-freedom",
    "href": "Lecture_Folder/Week4b.html#a-tangent-on-degrees-of-freedom",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "A tangent on degrees of freedom",
    "text": "A tangent on degrees of freedom\n\nIn statistics, degrees of freedom refers to the number of values in a calculation that are free to vary.\nExample: you have a set of numbers, like 1, 2, 3, and 4.\nIf you know the average (mean) of these numbers is 3, you can actually choose three of the numbers freely\nBut the fourth number will be determined by the other three.\nSo in this case, you have three degrees of freedom."
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#lets-try-it-out",
    "href": "Lecture_Folder/Week4b.html#lets-try-it-out",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nUse the below code to set up two simulated populations:\n\n\nset.seed(518)\npop1 &lt;- sample(rnorm(n=10000, mean=2, sd=0.5), size = 100)\npop2 &lt;- sample(rnorm(n=10000, mean=5, sd=0.5), size = 100)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#lets-try-it-out-1",
    "href": "Lecture_Folder/Week4b.html#lets-try-it-out-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\n\n\nhist(pop1, xlim = c(0, 10))\n\n\n\n\n\n\n\n\n\n\nhist(pop2, xlim = c(0,10))"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#now-for-the-t-test",
    "href": "Lecture_Folder/Week4b.html#now-for-the-t-test",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Now for the t-test!",
    "text": "Now for the t-test!\n\nUse the function t.test() in R\nHow do we interpret this? How would you write this conclusion as a sentence?\n\n\nt.test(pop1, pop2)\nt.test(data$continuous, data$categorical)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#now-for-the-t-test-1",
    "href": "Lecture_Folder/Week4b.html#now-for-the-t-test-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Now for the t-test!",
    "text": "Now for the t-test!\n\n\n\nt.test(pop1, pop2)\n\n\n    Welch Two Sample t-test\n\ndata:  pop1 and pop2\nt = -41.396, df = 196.21, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.075616 -2.795896\nsample estimates:\nmean of x mean of y \n 2.035190  4.970946 \n\n\n\n\nttest_output &lt;- t.test(pop1, pop2)\nprint(ttest_output)\n\n\n    Welch Two Sample t-test\n\ndata:  pop1 and pop2\nt = -41.396, df = 196.21, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.075616 -2.795896\nsample estimates:\nmean of x mean of y \n 2.035190  4.970946"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#r-interlude",
    "href": "Lecture_Folder/Week4b.html#r-interlude",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "R-interlude",
    "text": "R-interlude\n\ntry doing a two sample t-test on the stickleback microbiome RNA-seq data"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#nonparametric-tests-1",
    "href": "Lecture_Folder/Week4b.html#nonparametric-tests-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Nonparametric tests",
    "text": "Nonparametric tests\n\nWhat if your data does not meet the requirements of a parametric t-test?\nWhat do you do if the there is non-normality?\n\nnonparametric tests such as Mann-Whitney-Wilcoxon\nrandomization tests to create a null distribution"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#mann-whitney-wilcoxon-tests",
    "href": "Lecture_Folder/Week4b.html#mann-whitney-wilcoxon-tests",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Mann-Whitney-Wilcoxon Tests",
    "text": "Mann-Whitney-Wilcoxon Tests\n\nThe Mann-Whitney U (also called “Mann-Whitney-Wilcoxon) Test tests for distributional differences between the ranks of two samples.\nIn R the function wilcox.test() can be used to perform it, in much the same way the t.test() function is used."
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#lets-try-it-out-2",
    "href": "Lecture_Folder/Week4b.html#lets-try-it-out-2",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Let’s try it out",
    "text": "Let’s try it out\n\nset.seed(518)\npop1 &lt;- sample(rnorm(n=10000, mean=2, sd=0.5), size = 100)\npop2 &lt;- sample(rnorm(n=10000, mean=5, sd=1.5), size = 100)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#the-mann-whit-u-test",
    "href": "Lecture_Folder/Week4b.html#the-mann-whit-u-test",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nUse the function wilcox.test() in R to compare pop1 and pop2\nHow do we interpret that result?\nHow would you write it as a sentence for a paper?"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#the-mann-whit-u-test-1",
    "href": "Lecture_Folder/Week4b.html#the-mann-whit-u-test-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "The Mann Whit U Test",
    "text": "The Mann Whit U Test\n\nwilcox.test(pop1, pop2)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  pop1 and pop2\nW = 440, p-value &lt; 2.2e-16\nalternative hypothesis: true location shift is not equal to 0"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#null-distributions-and-p-values",
    "href": "Lecture_Folder/Week4b.html#null-distributions-and-p-values",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values\n\nWe can also create a null statistical distribution that models the distribution of a test statistic under the null hypothesis\nTo create the null distribution we can use either randomization or resampling"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#creating-a-null-distribution-through-randomization",
    "href": "Lecture_Folder/Week4b.html#creating-a-null-distribution-through-randomization",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Creating a null distribution through randomization",
    "text": "Creating a null distribution through randomization\n\nCombine values from both populations into a single vector\nRandomly shuffle the vector using the sample() function\nCalculate a t statistic based on the first n1 and n2 observations as our “pseudo samples” from “populations” 1 and 2, respectively, and save the value\nRepeat steps 2 and 3 many times (e.g. 1000)\nCalculate the proportion of pseudo replicates in which t is ≥ to our original, observed value of t. This proportion is our estimated p-value for the test."
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#lets-do-it---the-starting-populations",
    "href": "Lecture_Folder/Week4b.html#lets-do-it---the-starting-populations",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Let’s do it - the starting populations",
    "text": "Let’s do it - the starting populations\n\nset.seed(56)\npop_1 &lt;- rnorm(n=50, mean=20.1, sd=2)#simulate population 1 for this example\npop_2 &lt;- rnorm(n=50, mean=19.3, sd=2)#simulate population 2 for this example\n\n\nhist(pop_1)\n\n\n\n\n\n\n\nhist(pop_2)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#calculate-the-t-test",
    "href": "Lecture_Folder/Week4b.html#calculate-the-t-test",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Calculate the t-test",
    "text": "Calculate the t-test\n\n# Store the t statistic calculated from our samples, using t.test()\nt_obs &lt;- t.test(x=pop_1, y=pop_2, alternative=\"greater\")$statistic"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "href": "Lecture_Folder/Week4b.html#combine-the-populations-sample-from-that-and-calculate-t-tests",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Combine the populations, sample from that, and calculate t-tests",
    "text": "Combine the populations, sample from that, and calculate t-tests\n\n# Combine both population vectors into one\npops_comb &lt;- c(pop_1, pop_2)\n\n# Randomly shuffle and calculate t statistic 1000 times\nt_rand &lt;- replicate(1000, {\n  pops_shuf &lt;- sample(pops_comb)\n  t.test(x=pops_shuf[1:50], y=pops_shuf[51:100], alternative=\"greater\")$statistic\n  })"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#plot-the-null-distribution",
    "href": "Lecture_Folder/Week4b.html#plot-the-null-distribution",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Plot the null distribution",
    "text": "Plot the null distribution\n\n# Plot the \"null distribution\" from the randomization-based t-values\nhist(t_rand)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#null-distributions-and-p-values-1",
    "href": "Lecture_Folder/Week4b.html#null-distributions-and-p-values-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Null distributions and p-values",
    "text": "Null distributions and p-values"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#whats-our-result",
    "href": "Lecture_Folder/Week4b.html#whats-our-result",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "What’s our result?",
    "text": "What’s our result?\n\nHow do we interpret this?\n\n\n# Calculate the p-value for the test as the number of randomization t-values greater\n# than or equal to our actual t-value observed from the data\np &lt;- sum(t_rand&gt;=t_obs)/1000\n\np\n\n[1] 0.016"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#statistical-power-1",
    "href": "Lecture_Folder/Week4b.html#statistical-power-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nHelps us to interpret the failure to reject a null hypothesis\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?\n\nSample size\nEffect size (difference between the groups)\nVariance (range of values for this trait/measure)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#statistical-power-2",
    "href": "Lecture_Folder/Week4b.html#statistical-power-2",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Statistical power",
    "text": "Statistical power\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis\nMostly we shoot for a power of around 80%\nPower can be calculated post hoc or a priori"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#a-priori-power-analyses",
    "href": "Lecture_Folder/Week4b.html#a-priori-power-analyses",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "A priori Power analyses",
    "text": "A priori Power analyses\n\nBefore we start an experiment, we are interested in what sample size we should collect\nWe can use simulations to test different sample sizes\nLet’s say we’re studying college students again, and we’re interested in seeing if there’s a difference in study hours between freshman and seniors\nHow many students should we sample?\nThis will depend on our predictions about the effect size of this measurement"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#power-the-things-one-needs-to-know",
    "href": "Lecture_Folder/Week4b.html#power-the-things-one-needs-to-know",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Power | the things one needs to know",
    "text": "Power | the things one needs to know\n\\[ Power \\propto \\frac{(ES)(\\alpha)(\\sqrt n)}{\\sigma}\\]\n\nPower is proportional to the combination of these parameters\n\nES - effect size; how large is the change of interest?\n\\(\\alpha\\) - significance level (usually 0.05)\nn - sample size\n\\(\\sigma\\) - standard deviation among experimental units within the same group."
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#power-what-we-usually-want-to-know",
    "href": "Lecture_Folder/Week4b.html#power-what-we-usually-want-to-know",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Power | what we usually want to know",
    "text": "Power | what we usually want to know"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#power-rough-calculation",
    "href": "Lecture_Folder/Week4b.html#power-rough-calculation",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Power | rough calculation",
    "text": "Power | rough calculation"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#steps-to-power-analysis",
    "href": "Lecture_Folder/Week4b.html#steps-to-power-analysis",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Steps to power analysis",
    "text": "Steps to power analysis\n\nSimulate the true distributions of our populations (decide on effect size, distribution type, and variance)\nDraw random samples of different sizes from those populations\nPerform our statistical test (t-test) on these samples\nRepeat 2 & 3 ~1000 times\nPlot our resulting p-values against sample size"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-1-simulating-our-true-populations",
    "href": "Lecture_Folder/Week4b.html#step-1-simulating-our-true-populations",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nWhat is the distribution type?\nWhat is the effect size: difference in means between populations?\nWhat is the variance?"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-1-simulating-our-true-populations-1",
    "href": "Lecture_Folder/Week4b.html#step-1-simulating-our-true-populations-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nsenior &lt;- rpois(5000, lambda = 10)\nfresh &lt;- rpois(5000, lambda = 12)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-1-simulating-our-true-populations-2",
    "href": "Lecture_Folder/Week4b.html#step-1-simulating-our-true-populations-2",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 1: simulating our true populations",
    "text": "Step 1: simulating our true populations\n\nhist(senior)\n\n\n\n\n\n\n\nhist(fresh)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-2-drawing-a-sample",
    "href": "Lecture_Folder/Week4b.html#step-2-drawing-a-sample",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample\n\nsample_s &lt;- sample(senior, size = 10, replace = FALSE)\nsample_f &lt;- sample(fresh, size = 10, replace = FALSE)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-2-drawing-a-sample-1",
    "href": "Lecture_Folder/Week4b.html#step-2-drawing-a-sample-1",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 2: drawing a sample",
    "text": "Step 2: drawing a sample\n\nhist(sample_s)\n\n\n\n\n\n\n\nhist(sample_f)"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-3-statistical-test",
    "href": "Lecture_Folder/Week4b.html#step-3-statistical-test",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 3: statistical test",
    "text": "Step 3: statistical test\n\nt.test(sample_f, sample_s)\n\n\n    Welch Two Sample t-test\n\ndata:  sample_f and sample_s\nt = 0, df = 17.678, p-value = 1\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -4.002509  4.002509\nsample estimates:\nmean of x mean of y \n      9.9       9.9"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-4-setting-up-our-replicates",
    "href": "Lecture_Folder/Week4b.html#step-4-setting-up-our-replicates",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 4: setting up our replicates",
    "text": "Step 4: setting up our replicates\n\nTake a look at the “samps_var” vectors, how are they arranged? How would we begin conducting t-tests using each replicate from the two populations?\n\n\n## sample size of 10\nsamps_var_s &lt;- replicate(n = 100, sample(senior, size = 10))\nsamps_var_f &lt;- replicate(n = 100, sample(fresh, size = 10))"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-4-testing-our-replicates",
    "href": "Lecture_Folder/Week4b.html#step-4-testing-our-replicates",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 4: Testing our replicates",
    "text": "Step 4: Testing our replicates\n\n# setting up a \"test\" dataframe\ntests &lt;- data.frame(1:100)\ntests$SampleSize &lt;- rep(\"10\", 100)\n\nfor (i in 1:ncol(samps_var_f)){\n  tests$result[i] &lt;- t.test(samps_var_s[,i], samps_var_f[,i])$p.value\n}\ntable(tests$result &lt; 0.05)\n\n\nFALSE  TRUE \n   77    23"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-4-contd-changing-the-sample-size",
    "href": "Lecture_Folder/Week4b.html#step-4-contd-changing-the-sample-size",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 4 contd: changing the sample size",
    "text": "Step 4 contd: changing the sample size"
  },
  {
    "objectID": "Lecture_Folder/Week4b.html#step-4-contd-multiple-sample-sizes",
    "href": "Lecture_Folder/Week4b.html#step-4-contd-multiple-sample-sizes",
    "title": "Week 4b - Statistics for Bioengineering",
    "section": "Step 4 contd: multiple sample sizes",
    "text": "Step 4 contd: multiple sample sizes\n\nRequires a more complex for loop\n\n\nresults &lt;- data.frame()\n\n\n# using seq to set up the sample sizes\n\n\nfor (x in seq(10,100, by = 10)){\n  samps_var_s &lt;- replicate(n = 100, sample(senior, size = x))\n  samps_var_f &lt;- replicate(n = 100, sample(fresh, size = x))\n  \n  tests &lt;- data.frame(1:100)\n  tests$SampleSize &lt;- rep(x, 100)\n  for (i in 1:100){\n    tests$p.value[i] &lt;- t.test(samps_var_s[,i], samps_var_f[,i])$p.value\n  }\n  results &lt;- rbind(results, tests)\n}"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html",
    "href": "Lecture_Folder/Week5a.html",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(nycflights23)\ntheme_set(theme_minimal())"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#this-week",
    "href": "Lecture_Folder/Week5a.html#this-week",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nFinish Power\nStart linear models\nEugenics foundations of statistics"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#power",
    "href": "Lecture_Folder/Week5a.html#power",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Power",
    "text": "Power\n\nHelps us to interpret the failure to reject a null hypothesis\nWhat factors can affect the power of our experiment - our ability to avoid a Type 2 error?\n\nSample size\nEffect size (difference between the groups)\nVariance (range of values for this trait/measure)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#power-1",
    "href": "Lecture_Folder/Week5a.html#power-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Power",
    "text": "Power\n\nType 1 error - \\(\\alpha\\) - incorrectly rejecting a true null hypothesis\n\nThis is saying that there is an effect when there isn’t\n\nType 2 error - \\(\\beta\\) - incorrectly accepting a false null hypothesis\n\nThis is saying that there isn’t an effect when there is\n\nPower is the probability of rejecting a false null hypothesis and avoiding type II error\nMostly we shoot for a power of around 80%\nJust like \\(\\alpha\\), we want to calculate our power in advance"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#key-components-of-power",
    "href": "Lecture_Folder/Week5a.html#key-components-of-power",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Key components of power",
    "text": "Key components of power\n\nEffect Size (ES): The magnitude of the difference you expect to detect.\nSampling standard deviation (sd): a measure of variability within groups\nSample Size (n): The number of observations in the study.\nSignificance Level (\\(\\alpha\\)): The probability of committing a Type I error (rejecting the null hypothesis when it is true), typically set at 0.05.\nPower (1 - \\(\\beta\\)): The probability of correctly rejecting the null hypothesis, commonly set at 0.80 or 80%."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#effect-size-measured-as-cohens-d",
    "href": "Lecture_Folder/Week5a.html#effect-size-measured-as-cohens-d",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Effect size measured as Cohen’s D",
    "text": "Effect size measured as Cohen’s D\n\nCohen’s d is a statistical measure that quantifies the effect size between two group means, expressing the difference in standard deviation units.\nIt’s used to determine the magnitude of the difference between two groups in studies, like those using t-tests or ANOVA.\nCohen’s d is calculated by dividing the difference between the two group means by the pooled standard deviation."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#why-perform-power-analysis",
    "href": "Lecture_Folder/Week5a.html#why-perform-power-analysis",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Why Perform Power Analysis?",
    "text": "Why Perform Power Analysis?\nHere are the main reasons Why we Perform Power Analysis.\n\nDetermine Sample Size: To ensure your study has enough participants to detect the expected effect.\nAssess Test Feasibility: To understand if your study can achieve meaningful results with available resources.\nOptimize Resource Allocation: To avoid over- or under-sampling, ensuring efficient use of time and resources."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#power-2",
    "href": "Lecture_Folder/Week5a.html#power-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Power",
    "text": "Power"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#power---rough-calculation",
    "href": "Lecture_Folder/Week5a.html#power---rough-calculation",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Power - rough calculation",
    "text": "Power - rough calculation"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#parametric-power-in-r",
    "href": "Lecture_Folder/Week5a.html#parametric-power-in-r",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Parametric Power in R",
    "text": "Parametric Power in R\nR provides several packages for conducting power analysis, including pwr and statmod. We’ll explore examples using the pwr package.\n\nlibrary(pwr)\n\n# Parameters\neffect_size &lt;- 0.4 # The difference between null and alternative hypotheses\nsample_size &lt;- 50 # The number of observations in each group\nsd &lt;- 4 # The standard deviation\nalpha &lt;- 0.05 # The significance level\n\n\n# Calculate Type II Error\npwr_result &lt;-pwr.t.test(n = sample_size, \n                        d = effect_size / sd, \n                        sig.level = alpha,\n                        type = \"two.sample\",\n                        alternative = \"two.sided\")\n\ntype_II_error &lt;- 1 - pwr_result$power\npower &lt;- pwr_result$power\n\n\nprint(type_II_error)\n\n[1] 0.921476\n\nprint(power)\n\n[1] 0.07852399"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#calculate-sample-size-needed",
    "href": "Lecture_Folder/Week5a.html#calculate-sample-size-needed",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Calculate sample size needed",
    "text": "Calculate sample size needed\n\n# Parameters for two-sample t-test\neffect_size_t &lt;- 2.0  \nsd &lt;- 2\nd_calc &lt;- effect_size_t/sd # Moderate effect size (Cohen's d)\nalpha_t &lt;- 0.05       # Significance level\npower_t &lt;- 0.8        # Desired power\n\n# Calculate required sample size\nsample_size_t &lt;- pwr.t.test(d = d_calc, \n                            sig.level = alpha_t, \n                            power = power_t, \n                            type = \"two.sample\")$n\n\n# Output the result\ncat(\"Sample Size for Two-Sample t-Test:\", sample_size_t, \"\\n\")\n\nSample Size for Two-Sample t-Test: 16.71472"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#generate-power-curve-for-two-sample-t-test",
    "href": "Lecture_Folder/Week5a.html#generate-power-curve-for-two-sample-t-test",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Generate Power Curve for Two-Sample t-Test",
    "text": "Generate Power Curve for Two-Sample t-Test\nNow we will generate power curve for Two-Sample t-Test.\n\nsample_size_curve: Specifies the sample size per group (100 in this case).\neffect_sizes_curve: Defines a range of effect sizes (Cohen’s d) from 0.2 to 0.8 with a step of 0.1.\nNext calculates the power values for the power curve by iterating through the specified range of effect sizes and using the pwr.t.test function for each effect size to calculate power based on the given sample size, significance level, and type of test.\nFinally, plots the power curve using the calculated power values against the effect sizes, with appropriate labels for the axes and title for the plot. It visualizes how power varies with different effect sizes in the two-sample t-test scenario."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#generate-power-curve-for-two-sample-t-test-1",
    "href": "Lecture_Folder/Week5a.html#generate-power-curve-for-two-sample-t-test-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Generate Power Curve for Two-Sample t-Test",
    "text": "Generate Power Curve for Two-Sample t-Test\n\n# Parameters for power curve\nsample_size_curve &lt;- 100    # Sample size per group\neffect_sizes_curve &lt;- seq(0.2, 0.8, by = 0.1)  # Range of effect sizes\n\n# Calculate power values\npower_values_curve &lt;- sapply(effect_sizes_curve, function(d) pwr.t.test(d = d, \n                                                     n = sample_size_curve, \n                                                     sig.level = alpha_t, \n                                                     type = \"two.sample\")$power)\n\n\n# Plot power curve\nplot(effect_sizes_curve, power_values_curve, type = \"b\",\n     main = \"Power Curve for Two-Sample t-Test\",\n     xlab = \"Effect Size (Cohen's d)\",\n     ylab = \"Power\",\n     ylim = c(0, 1))"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#generate-a-sample-curve-for-two-sample-t-test",
    "href": "Lecture_Folder/Week5a.html#generate-a-sample-curve-for-two-sample-t-test",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Generate a Sample Curve for Two-Sample t-Test",
    "text": "Generate a Sample Curve for Two-Sample t-Test\n\neffect_size_t &lt;- 2.0  \nsd &lt; - 2.0\n\n[1] FALSE\n\nd_calc &lt;- effect_size_t/sd  # Moderate effect size (Cohen's d)\nalpha_t &lt;- 0.05             # Significance level\npower_t &lt;- 0.8              # Desired power\n\nsample_sizes_curve &lt;- seq(2, 200, by = 2)     # Sample size per group\neffect_sizes_curve &lt;- 0.4                     # Range of effect sizes\n\n# Calculate power values\npower_values_curve &lt;- sapply(effect_sizes_curve, function(d) pwr.t.test(d = d_calc, \n                                                     n = sample_sizes_curve, \n                                                     sig.level = alpha_t, \n                                                     type = \"two.sample\")$power)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#plot-power-curve",
    "href": "Lecture_Folder/Week5a.html#plot-power-curve",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Plot power curve",
    "text": "Plot power curve\n\nplot(sample_sizes_curve, power_values_curve, type = \"b\",\n     main = \"Sample sizes for Two-Sample t-Test\",\n     xlab = \"Sample size\",\n     ylab = \"Power\",\n     ylim = c(0, 1))"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#conduct-a-priori-power-analysis-for-one-way-anova",
    "href": "Lecture_Folder/Week5a.html#conduct-a-priori-power-analysis-for-one-way-anova",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Conduct A Priori Power Analysis for One-Way ANOVA",
    "text": "Conduct A Priori Power Analysis for One-Way ANOVA\nHere, we set the parameters for conducting a one-way ANOVA power analysis, similar to the t-test but with different effect size and significance level.\npwr.anova.test function to calculate the required sample size (sample_size_anova) for the one-way ANOVA based on the specified effect size, number of groups (k = 3), significance level, and desired power.\n\n# Parameters for one-way ANOVA\neffect_size_anova &lt;- 0.25  # Small effect size (Cohen's f)\nalpha_anova &lt;- 0.05        # Significance level\npower_anova &lt;- 0.8         # Desired power\n\n# Calculate required sample size\nsample_size_anova &lt;- pwr.anova.test(k = 3, f = effect_size_anova, \n                                    sig.level = alpha_anova, \n                                    power = power_anova)$n\n\n# Output the result\ncat(\"Sample Size for One-Way ANOVA:\", sample_size_anova, \"\\n\")\n\nSample Size for One-Way ANOVA: 52.3966"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#cohens-f",
    "href": "Lecture_Folder/Week5a.html#cohens-f",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Cohen’s f",
    "text": "Cohen’s f\n\nCohen’s f is an effect size statistic used in Analysis of Variance (ANOVA).\nIt measures the amount of variance in the dependent variable that is explained by the independent variable(s), or more generally, how much the group means differ from the grand mean.\nCohen’s f, along with other effect size measures, provides a standardized way to assess the magnitude of the effect observed in an ANOVA, going beyond simply determining statistical significance.\nCohen’s f is calculated as the square root of the variance due to the independent variable(s) divided by the total variance (or the variance within groups, depending on the specific type of ANOVA).\nCohen (1988) suggested the following interpretation for f:\n\nf = 0.10 is considered a small effect.\nf = 0.25 is considered a medium effect.\nf = 0.40 is considered a large effect."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation",
    "href": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "On your own - Bootstrap resampling power calculation",
    "text": "On your own - Bootstrap resampling power calculation\nStep 1: simulating our true populations\n\nWhat is the distribution type?\nWhat is the effect size: difference in means between populations?\nWhat is the variance?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-1",
    "href": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "On your own - Bootstrap resampling power calculation",
    "text": "On your own - Bootstrap resampling power calculation\nStep 1: simulating our true populations\n\nsenior &lt;- rpois(5000, lambda = 10)\nfresh &lt;- rpois(5000, lambda = 12)\n\n\nhist(senior)\n\n\n\n\n\n\n\nhist(fresh)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-2",
    "href": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "On your own - Bootstrap resampling power calculation",
    "text": "On your own - Bootstrap resampling power calculation\nStep 2: drawing a sample\n\nsample_s &lt;- sample(senior, size = 10, replace = FALSE)\nsample_f &lt;- sample(fresh, size = 10, replace = FALSE)\n\nStep 2: drawing a sample\n\nhist(sample_s)\n\n\n\n\n\n\n\nhist(sample_f)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-3",
    "href": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-3",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "On your own - Bootstrap resampling power calculation",
    "text": "On your own - Bootstrap resampling power calculation\nStep 3: statistical test\n\nt.test(sample_f, sample_s)\n\n\n    Welch Two Sample t-test\n\ndata:  sample_f and sample_s\nt = 5.2568, df = 16.488, p-value = 7.097e-05\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 4.064332 9.535668\nsample estimates:\nmean of x mean of y \n     14.5       7.7"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-4",
    "href": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-4",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "On your own - Bootstrap resampling power calculation",
    "text": "On your own - Bootstrap resampling power calculation\nStep 4: setting up our replicates\nTake a look at the “samps_var” vectors, how are they arranged? How would we begin conducting t-tests using each replicate from the two populations?\n\n## sample size of 10\nsamps_var_s &lt;- replicate(n = 100, sample(senior, size = 10))\nsamps_var_f &lt;- replicate(n = 100, sample(fresh, size = 10))"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-5",
    "href": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-5",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "On your own - Bootstrap resampling power calculation",
    "text": "On your own - Bootstrap resampling power calculation\nStep 4: Testing our replicates\n\n# setting up a \"test\" dataframe\ntests &lt;- data.frame(1:100)\ntests$SampleSize &lt;- rep(\"10\", 100)\n\nfor (i in 1:ncol(samps_var_f)){\n  tests$result[i] &lt;- t.test(samps_var_s[,i], samps_var_f[,i])$p.value\n}\ntable(tests$result &lt; 0.05)\n\n\nFALSE  TRUE \n   76    24"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-6",
    "href": "Lecture_Folder/Week5a.html#on-your-own---bootstrap-resampling-power-calculation-6",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "On your own - Bootstrap resampling power calculation",
    "text": "On your own - Bootstrap resampling power calculation\nRequires a more complex for loop\n\nresults &lt;- data.frame()\n\n# using seq to set up the sample sizes\n\nfor (x in seq(10,100, by = 10)){\n  samps_var_s &lt;- replicate(n = 100, sample(senior, size = x))\n  samps_var_f &lt;- replicate(n = 100, sample(fresh, size = x))\n  \n  tests &lt;- data.frame(1:100)\n  tests$SampleSize &lt;- rep(x, 100)\n  for (i in 1:100){\n    tests$p.value[i] &lt;- t.test(samps_var_s[,i], samps_var_f[,i])$p.value\n  }\n  results &lt;- rbind(results, tests)\n}"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#covariance",
    "href": "Lecture_Folder/Week5a.html#covariance",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Covariance",
    "text": "Covariance\n\nHow do we convey that 2 variables covary?\nCovariance statistic: multiplies each y and x deviation from its respective mean, sums that product across all observations, and divides by the total number of observations to yield an average\nPositive or negative covariance depending on the direction of the relationship, covariance of 0 if no relationship between the two"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#correlation",
    "href": "Lecture_Folder/Week5a.html#correlation",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Correlation",
    "text": "Correlation\n\nRemember when we said that the larger the mean, the greater the variance?\n\nExample: trying to compare mean body weight between elephants and mice\n\nThis also applies to covariance\nWe can calculate a correlation coefficient to standardize the covariance measure\n\nDividing the covariance y the standard deviations of x and y variables\nRanges from -1 to 1, with closer to 1 indicating a perfect linear relationship, and values close to 0 indicating no relationship"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#correlation-1",
    "href": "Lecture_Folder/Week5a.html#correlation-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#testing-for-correlation",
    "href": "Lecture_Folder/Week5a.html#testing-for-correlation",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Testing for Correlation",
    "text": "Testing for Correlation\n\nWe can calculate a t-statistic for our null hypothesis, and there’s a function in R for this!\n\ncor.test()\n\nWhat were the null and alternative hypotheses?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#testing-for-correlation---parametric",
    "href": "Lecture_Folder/Week5a.html#testing-for-correlation---parametric",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Testing for Correlation - Parametric",
    "text": "Testing for Correlation - Parametric\n\nR function cor.test()\nFormal hypothesis tests for correlation\n\nNull hypothesis is no correlation (CC = 0)\nAlternative hypothesis is some correlation (CC &gt; 0 or &lt; 0)\n\nRemember that parametric tests come with assumptions\n\nThe relationship being tested is assumed to be linear (as opposed to strongly curvilinear)\nThe probability distribution of the 2 variables is assumed to be normal"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#assumptions-of-parametric-correlation-tests",
    "href": "Lecture_Folder/Week5a.html#assumptions-of-parametric-correlation-tests",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Assumptions of Parametric Correlation Tests",
    "text": "Assumptions of Parametric Correlation Tests\n\nRemember that parametric tests come with assumptions\nThe relationship being tested is assumed to be linear (as opposed to strongly curvilinear)\nThe probability distribution of the 2 variables is assumed to be normal"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#nonparametric-correlation-tests",
    "href": "Lecture_Folder/Week5a.html#nonparametric-correlation-tests",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Nonparametric Correlation tests",
    "text": "Nonparametric Correlation tests\n\nAssociation between variables is monotonic (consistently increasing or decreasing)\nSpearman’s rank correlation test: good for small sample sizes (&lt; 30)\nKendall’s tau test: appropriate for larger sample sizes (&gt; 30)Testing for Correlation\nFormal hypothesis tests for correlation\n\nNull hypothesis is no correlation (CC = 0)\nAlternative hypothesis is some correlation (CC &gt; 0 or &lt; 0)\n\nWe can calculate a t-statistic for our null hypothesis, and there’s a function in R for this!\n\ncor.test()"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#nonparametric-correlation-tests-1",
    "href": "Lecture_Folder/Week5a.html#nonparametric-correlation-tests-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Nonparametric Correlation tests",
    "text": "Nonparametric Correlation tests\n\nAssociation between variables is monotonic (consistently increasing or decreasing)\nSpearman’s rank correlation test: good for small sample sizes (&lt; 30)\nKendall’s tau test: appropriate for larger sample sizes (&gt; 30)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#lets-try-it---correlation",
    "href": "Lecture_Folder/Week5a.html#lets-try-it---correlation",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Let’s try it - Correlation",
    "text": "Let’s try it - Correlation\n\nCheck out the help page for cor.test()"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#lets-try-it---correlation-1",
    "href": "Lecture_Folder/Week5a.html#lets-try-it---correlation-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Let’s try it - Correlation",
    "text": "Let’s try it - Correlation\n\nWork with the Drerio_development_complete.csv data set\nLoad it into R, and refamiliarize yourself with the contents\n\n\nfish &lt;- read.csv(file =\"Drerio_development_complete.csv\")"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#lets-try-it---correlation-2",
    "href": "Lecture_Folder/Week5a.html#lets-try-it---correlation-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Let’s try it - Correlation",
    "text": "Let’s try it - Correlation\n\nWhat variables might be correlated in this data set?\nTry creating a scatterplot with the different variables. Does anything appear to be correlated?\nPlot a histogram of the variables - do they appear to be normally distributed?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#lets-try-it---correlation-3",
    "href": "Lecture_Folder/Week5a.html#lets-try-it---correlation-3",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Let’s try it - Correlation",
    "text": "Let’s try it - Correlation\n\nplot(fish$Weight_mg, fish$Length_cm)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#lets-try-it---correlation-4",
    "href": "Lecture_Folder/Week5a.html#lets-try-it---correlation-4",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Let’s try it - Correlation",
    "text": "Let’s try it - Correlation"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#lets-try-it---correlation-5",
    "href": "Lecture_Folder/Week5a.html#lets-try-it---correlation-5",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Let’s try it - Correlation",
    "text": "Let’s try it - Correlation\n\nRun a correlation test\nWhich method should you use?\n\n\ncor.test()"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#lets-try-it---correlation-6",
    "href": "Lecture_Folder/Week5a.html#lets-try-it---correlation-6",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Let’s try it - Correlation",
    "text": "Let’s try it - Correlation\n\nRun a correlation test\n\n\ncor.test(fish$Weight_mg, fish$Length_cm, method = c(\"kendall\"))\n\n\n    Kendall's rank correlation tau\n\ndata:  fish$Weight_mg and fish$Length_cm\nz = 29.898, p-value &lt; 2.2e-16\nalternative hypothesis: true tau is not equal to 0\nsample estimates:\n      tau \n0.8161046"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#linear-regression",
    "href": "Lecture_Folder/Week5a.html#linear-regression",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nWe can model linear relationships\n\n\\[ y = B_0 + B_1 x + e \\]\ne represents the “error” (or “residual”) in the model, which accounts for “noise” or random errors in y unexplained by the effect of x\n\nFunction lm() in R"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#parent-offspring-regression",
    "href": "Lecture_Folder/Week5a.html#parent-offspring-regression",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Parent offspring regression",
    "text": "Parent offspring regression"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#bivariate-normality",
    "href": "Lecture_Folder/Week5a.html#bivariate-normality",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Bivariate normality",
    "text": "Bivariate normality"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#covariance-and-correlation",
    "href": "Lecture_Folder/Week5a.html#covariance-and-correlation",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Covariance and correlation",
    "text": "Covariance and correlation"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#anscombes-quartet",
    "href": "Lecture_Folder/Week5a.html#anscombes-quartet",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Anscombe’s Quartet",
    "text": "Anscombe’s Quartet"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#anscombes-quartet-1",
    "href": "Lecture_Folder/Week5a.html#anscombes-quartet-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Anscombe’s Quartet",
    "text": "Anscombe’s Quartet\n\nMean of x in each case 9 (exact)\nVariance of x in each case 11 (exact)\nMean of y in each case 7.50 (to 2 decimal places)\nVariance of y in each case 4.122 or 4.127 (to 3 decimal places)\nCorrelation between x and y in each case 0.816 (to 3 decimal places)\nLinear regression line in each case \\[ y = 3.00 + 0.50x\\]"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#a-linear-model-to-relate-two-variables",
    "href": "Lecture_Folder/Week5a.html#a-linear-model-to-relate-two-variables",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "A linear model to relate two variables",
    "text": "A linear model to relate two variables"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#many-approaches-are-linear-models",
    "href": "Lecture_Folder/Week5a.html#many-approaches-are-linear-models",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Many approaches are linear models",
    "text": "Many approaches are linear models\n\nIs flexible: Applicable to many different study designs\nProvides a common set of tools (lm in R for fixed effects)\nIncludes tools to estimate parameters:\n\n(e.g. sizes of effects, like the slope, or change in means)\n\nIs easier to work with, especially with multiple variables"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#many-approaches-are-linear-models-1",
    "href": "Lecture_Folder/Week5a.html#many-approaches-are-linear-models-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Many approaches are linear models",
    "text": "Many approaches are linear models\n\nLinear regression\nSingle factor ANOVA\nAnalysis of covariance\nMultiple regression\nMulti-factor ANOVA\nRepeated-measures ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#plethora-of-linear-models",
    "href": "Lecture_Folder/Week5a.html#plethora-of-linear-models",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Plethora of linear models",
    "text": "Plethora of linear models\n\nGeneral Linear Model (GLM) - two or more continuous variables\nGeneral Linear Mixed Model (GLMM) - a continuous response variable with a mix of continuous and categorical predictor variables\nGeneralized Linear Model - a GLMM that doesn’t assume normality of the response (we’ll get to this later)\nGeneralized Additive Model (GAM) - a model that doesn’t assume linearity (we won’t get to this later)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#linear-models",
    "href": "Lecture_Folder/Week5a.html#linear-models",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Linear models",
    "text": "Linear models\nAll an be written in the form\nresponse variable = intercept + (explanatory_variables) + random_error\nin the general form:\n\\[ Y=\\beta_0 +\\beta_1*X_1 + \\beta_2*X_2 +... + error\\]\nwhere \\(\\beta_0, \\beta_1, \\beta_2, ....\\) are the parameters of the linear model"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#linear-model-parameters",
    "href": "Lecture_Folder/Week5a.html#linear-model-parameters",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "linear model parameters",
    "text": "linear model parameters"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#linear-model-parameters-1",
    "href": "Lecture_Folder/Week5a.html#linear-model-parameters-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "linear model parameters",
    "text": "linear model parameters"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#linear-models-in-r",
    "href": "Lecture_Folder/Week5a.html#linear-models-in-r",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "linear models in R",
    "text": "linear models in R\nAll of these will include the intercept\n\nY~X\nY~1+X\nY~X+1\n\nAll of these will exclude the intercept\n\nY~-1+X\nY~X-1\n\nNeed to fit the model and then ‘read’ the output\n\ntrial_lm &lt;- lm(Y~X)\nsummary (trial_lm)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude",
    "href": "Lecture_Folder/Week5a.html#r-interlude",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE",
    "text": "R INTERLUDE\nWrite a script to read in the perchlorate data set. Now, add the code to perform a linear model of two continuous variables. Notice how the output of the linear model is specified to a new variable. Also note that the variables and dataset are placeholders\n\nmy_lm &lt;- lm(dataset$variable1 ~ dataset$variable2)\n\nNow look at a summary of the linear model\n\nsummary(my_lm)\nprint(my_lm)\n\nNow let’s produce a nice regression plot\n\nplot(dataset$variable1 ~ dataset$variable2, col = “blue”)\nabline(my_lm, col = “red”)\n\nNotice that you are adding the fitted line from your linear model Finally, remake this plot in GGPlot2"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-1",
    "href": "Lecture_Folder/Week5a.html#r-interlude-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE",
    "text": "R INTERLUDE\n\nPerchlorate_Data &lt;- read.table(\"perchlorate_data.tsv\", header=T)\nhead(Perchlorate_Data)\n\n  Strain Perchlorate_Level T4_Hormone_Level Follicle_Area Number_of_Follicles\n1     WK                 A         14.54394       704.939                   9\n2     WK                 A         26.95434       935.739                   9\n3     WK                 A         17.19650       399.945                   9\n4     WK                 A         24.01719       568.041                   9\n5     WK                 A         20.80560       661.448                  13\n6     WK                 A         14.15130       493.970                  13\n  Age_Category Testes_Area Testes_Stage\n1       Embryo   125119.90            0\n2       Embryo   537018.88            0\n3       Embryo   407869.97            0\n4       Embryo    39241.09            0\n5       Embryo     2286.20            0\n6       Embryo    27451.35            0\n\nx &lt;- Perchlorate_Data$T4_Hormone_Level\ny &lt;- Perchlorate_Data$Testes_Area\n\nperc_lm &lt;- lm(y ~ x)\nsummary (perc_lm)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-295380 -212504 -142136  214571  757801 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 245576.8    30930.4   7.940 2.21e-14 ***\nx              727.5      711.5   1.022    0.307    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 270600 on 388 degrees of freedom\nMultiple R-squared:  0.002687,  Adjusted R-squared:  0.0001169 \nF-statistic: 1.045 on 1 and 388 DF,  p-value: 0.3072\n\nplot(y ~ x, col = \"blue\")\nabline(perc_lm, col = \"red\")"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude---checking-the-output",
    "href": "Lecture_Folder/Week5a.html#r-interlude---checking-the-output",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE - Checking the output",
    "text": "R INTERLUDE - Checking the output"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#model-fitting-and-hypothesis-tests-in-regression",
    "href": "Lecture_Folder/Week5a.html#model-fitting-and-hypothesis-tests-in-regression",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Model fitting and hypothesis tests in regression",
    "text": "Model fitting and hypothesis tests in regression\n\\[H_0 : \\beta_0 = 0\\] \\[H_0 : \\beta_1 = 0\\]\nfull model - \\(y_i = \\beta_0 + \\beta_1*x_i + error_i\\)\nreduced model - \\(y_i = \\beta_0 + 0*x_i + error_i\\)\n\nfits a “reduced” model without slope term (H0)\nfits the “full” model with slope term added back\ncompares fit of full and reduced models using an F test"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#model-fitting-and-hypothesis-tests-in-regression-1",
    "href": "Lecture_Folder/Week5a.html#model-fitting-and-hypothesis-tests-in-regression-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Model fitting and hypothesis tests in regression",
    "text": "Model fitting and hypothesis tests in regression"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#hypothesis-tests-in-linear-regression",
    "href": "Lecture_Folder/Week5a.html#hypothesis-tests-in-linear-regression",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Hypothesis tests in linear regression",
    "text": "Hypothesis tests in linear regression\nEstimation of the variation that is explained by the model (SS_model)\nSS_model = SS_total(reduced model) - SS_residual(full model)\nThe variation that is unexplained by the model (SS_residual)\nSS_residual(full model)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#hypothesis-tests-in-linear-regression-1",
    "href": "Lecture_Folder/Week5a.html#hypothesis-tests-in-linear-regression-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Hypothesis tests in linear regression",
    "text": "Hypothesis tests in linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#hypothesis-tests-in-linear-regression-2",
    "href": "Lecture_Folder/Week5a.html#hypothesis-tests-in-linear-regression-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Hypothesis tests in linear regression",
    "text": "Hypothesis tests in linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r2-as-a-measure-of-model-fit",
    "href": "Lecture_Folder/Week5a.html#r2-as-a-measure-of-model-fit",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "\\(r^2\\) as a measure of model fit",
    "text": "\\(r^2\\) as a measure of model fit\n\\[r^2 = SS_{regression}/SS_{total} = 1 - (SS_{residual}/SS_{total})\\] or \\[r^2 = 1 - (SS_{residual(full)}/SS_{total(reduced)})\\] Which is the proportion of the variance in Y that is explained by X"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#relationship-of-correlation-and-regression",
    "href": "Lecture_Folder/Week5a.html#relationship-of-correlation-and-regression",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Relationship of correlation and regression",
    "text": "Relationship of correlation and regression\n\\[\\beta_{YX}=\\rho_{YX}*\\sigma_Y/\\sigma_X\\] \\[b_{YX} = r_{YX}*S_Y/S_X\\]"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#residual-analysis-did-we-meet-our-assumptions",
    "href": "Lecture_Folder/Week5a.html#residual-analysis-did-we-meet-our-assumptions",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Residual Analysis | did we meet our assumptions?",
    "text": "Residual Analysis | did we meet our assumptions?\n\nIndependent errors (residuals)\nEqual variance of residuals in all groups\nNormally-distributed residuals\nRobustness to departures from these assumptions is improved when sample size is large and design is balanced"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#residual-analysis-did-we-meet-our-assumptions-1",
    "href": "Lecture_Folder/Week5a.html#residual-analysis-did-we-meet-our-assumptions-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Residual Analysis | did we meet our assumptions?",
    "text": "Residual Analysis | did we meet our assumptions?\n\\[y_i = \\beta_0 + \\beta_1 * x_I + \\epsilon_i\\]"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#residual-analysis",
    "href": "Lecture_Folder/Week5a.html#residual-analysis",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Residual Analysis",
    "text": "Residual Analysis"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#residual-analysis-1",
    "href": "Lecture_Folder/Week5a.html#residual-analysis-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Residual Analysis",
    "text": "Residual Analysis"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#handling-violations-of-the-assumptions-of-linear-models",
    "href": "Lecture_Folder/Week5a.html#handling-violations-of-the-assumptions-of-linear-models",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Handling violations of the assumptions of linear models",
    "text": "Handling violations of the assumptions of linear models\n\nWhat if your residuals aren’t normal because of outliers?\nNonparametric methods exist, but these don’t provide parameter estimates with CIs.\nRobust regression (rlm)\nRandomization tests"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these",
    "href": "Lecture_Folder/Week5a.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Anscombe’s quartet again | what would residual plots look like for these?",
    "text": "Anscombe’s quartet again | what would residual plots look like for these?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these-1",
    "href": "Lecture_Folder/Week5a.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Anscombe’s quartet again | what would residual plots look like for these?",
    "text": "Anscombe’s quartet again | what would residual plots look like for these?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#residual-plots-spotting-assumption-violations",
    "href": "Lecture_Folder/Week5a.html#residual-plots-spotting-assumption-violations",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Residual Plots | Spotting assumption violations",
    "text": "Residual Plots | Spotting assumption violations"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#residuals-leverage-and-influence",
    "href": "Lecture_Folder/Week5a.html#residuals-leverage-and-influence",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Residuals | leverage and influence",
    "text": "Residuals | leverage and influence\n\n\n\n\n\n\n\n\n\n\n1 is an outlier for both Y and X\n2 is not an outlier for either Y or X but has a high residual\n3 is an outlier in just X - and thus a high residual - and therefore has high influence as measured by Cook’s D"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#residuals-leverage-and-influence-1",
    "href": "Lecture_Folder/Week5a.html#residuals-leverage-and-influence-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Residuals | leverage and influence",
    "text": "Residuals | leverage and influence\n\nLeverage - a measure of how much of an outlier each point is in x-space (on x-axis) and thus only applies to the predictor variable. (Values &gt; 2*(2/n) for simple regression are cause for concern)\nResiduals - As the residuals are the differences between the observed and predicted values along a vertical plane, they provide a measure of how much of an outlier each point is in y-space (on y-axis). The patterns of residuals against predicted y values (residual plot) are also useful diagnostic tools for investigating linearity and homogeneity of variance assumptions\nCook’s D statistic is a measure of the influence of each point on the fitted model (estimated slope) and incorporates both leverage and residuals. Values ≥ 1 (or even approaching 1) correspond to highly influential observations."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-residual-analyses",
    "href": "Lecture_Folder/Week5a.html#r-interlude-residual-analyses",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE | residual analyses",
    "text": "R INTERLUDE | residual analyses\nLet’s look at the zebrafish diet data.\n\nx &lt;- zfish_diet$Protein\ny &lt;- zfish_diet$Weight\n\nzfish_lm &lt;- lm(y ~ x)\nsummary (zfish_lm)\n\nplot(y ~ x, col = \"blue\")\nabline(zfish_lm, col = \"red\")\n\nhist(residuals(zfish_lm), breaks=30)\n\nplot (residuals(zfish_lm) ~ fitted.values(zfish_lm))\nplot (residuals(zfish_lm) ~ x)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-residual-analyses-1",
    "href": "Lecture_Folder/Week5a.html#r-interlude-residual-analyses-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE | residual analyses",
    "text": "R INTERLUDE | residual analyses\nOr apply the plot() function to the linear model object directly\n\nplot(zfish_lm)\n\nFigure out what these plots are telling you"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-2",
    "href": "Lecture_Folder/Week5a.html#r-interlude-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE",
    "text": "R INTERLUDE\nHow about using the influence.measures function???\n\ninfluence.measures(zfish_lm)\n\nDo we have any high leverage observations we need to worry about??? Now go back and try to recreate these graphs in GGPlot2"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-3",
    "href": "Lecture_Folder/Week5a.html#r-interlude-3",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE",
    "text": "R INTERLUDE"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#what-is-a-glm",
    "href": "Lecture_Folder/Week5a.html#what-is-a-glm",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "What is a GLM?",
    "text": "What is a GLM?\n\nGeneral Linear Model (GLM) - two or more continuous variables\n\nYou’ll notice that the function lm() in R can work with a GLM too (via PS6)\n\nGeneralized Linear Model - used to conduct linear regressions on non-continuous data, and non-normal data\nGeneral Linear Mixed Model (GLMM) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects (for more on this, see Peter Ralph’s Advanced Bio Stats class)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#how-do-we-factor-in-categorical-variables",
    "href": "Lecture_Folder/Week5a.html#how-do-we-factor-in-categorical-variables",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "How do we factor in categorical variables?",
    "text": "How do we factor in categorical variables?\n\nFor a single categorical predictor, we can include effects of each factor level:\n\n\\[ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e \\]\n\nEach factor level (ex: for Wolbachia: Yes or No) becomes it’s own “effector” that will change the value of y\nInstead of x being a continuous numerical value, for categorical data it will be either a 0 or 1"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#a-generalized-linear-model",
    "href": "Lecture_Folder/Week5a.html#a-generalized-linear-model",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "A Generalized Linear Model",
    "text": "A Generalized Linear Model\n\nCheck out the help page in RStudio for glm()\n\n\nglm(formula = y ~ x1 + x2, family = gaussian(link = \"identity\"))"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "href": "Lecture_Folder/Week5a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nSet up a glm() to test for the effect of Wolbachia infection on Recombinant Fraction"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "href": "Lecture_Folder/Week5a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nWhat do these components mean?\n\n\nmodel &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link=\"identity\"))\nsummary(model)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#interpreting-the-glm",
    "href": "Lecture_Folder/Week5a.html#interpreting-the-glm",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nWhy is our intercept significant?\n\nRemember that the null hypothesis is a model with an intercept and slope of 0\n\nHow would you interpret the “WolbachiaYes” coefficient, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#second-steps---adding-more-variables",
    "href": "Lecture_Folder/Week5a.html#second-steps---adding-more-variables",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nNow let’s add Food to our model - how does this change our model results?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#second-steps---adding-more-variables-1",
    "href": "Lecture_Folder/Week5a.html#second-steps---adding-more-variables-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nmodel2 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = \"identity\"))\nsummary(model2)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#interpreting-the-glm-1",
    "href": "Lecture_Folder/Week5a.html#interpreting-the-glm-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nHow would you interpret the Intercept and Food coefficients, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#interaction-effects-in-glms",
    "href": "Lecture_Folder/Week5a.html#interaction-effects-in-glms",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Interaction effects in GLMs",
    "text": "Interaction effects in GLMs\n\nYou can also model interactions between two categorical variables in glms\n\nWhat if variable x and variable z interact in non-additive ways?\n\nUse the notation x*z in the formula"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#third-steps---adding-interaction-effects",
    "href": "Lecture_Folder/Week5a.html#third-steps---adding-interaction-effects",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nLet’s finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model\nRun the model - what are the results?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#third-steps---adding-interaction-effects-1",
    "href": "Lecture_Folder/Week5a.html#third-steps---adding-interaction-effects-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nHow do we interpret these findings?\n\n\nmodel3 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = \"identity\"))\nsummary(model3)"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#how-do-we-know-which-model-to-use",
    "href": "Lecture_Folder/Week5a.html#how-do-we-know-which-model-to-use",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "How do we know which model to use?",
    "text": "How do we know which model to use?\n\nWant to be careful not to overfit your linear model (give too many variables)\nThe Akaike information criterion (AIC) is a metric for comparing different models to find the best fit\n\nNotice the AIC score in your output?\nFor more on this, take Advanced Bio Stats! Or do some reading on the internet."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-4",
    "href": "Lecture_Folder/Week5a.html#r-interlude-4",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE",
    "text": "R INTERLUDE"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#different-types-of-regression-model-1-and-model-2",
    "href": "Lecture_Folder/Week5a.html#different-types-of-regression-model-1-and-model-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Different Types of Regression | Model 1 and Model 2",
    "text": "Different Types of Regression | Model 1 and Model 2"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#different-types-of-regression-model-1-and-model-2-1",
    "href": "Lecture_Folder/Week5a.html#different-types-of-regression-model-1-and-model-2-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Different Types of Regression | Model 1 and Model 2",
    "text": "Different Types of Regression | Model 1 and Model 2"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#different-types-of-regression-model-1-and-model-2-2",
    "href": "Lecture_Folder/Week5a.html#different-types-of-regression-model-1-and-model-2-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Different Types of Regression | Model 1 and Model 2",
    "text": "Different Types of Regression | Model 1 and Model 2"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#fitting-more-complicated-models",
    "href": "Lecture_Folder/Week5a.html#fitting-more-complicated-models",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Fitting more complicated models",
    "text": "Fitting more complicated models"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#smoothers-and-local-regression",
    "href": "Lecture_Folder/Week5a.html#smoothers-and-local-regression",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Smoothers and local regression",
    "text": "Smoothers and local regression\n\nrunning medians (or less robust running means) generate predicted values that are the medians of the responses in the bands surrounding each observation.\nloess and lowesse (locally weighted scatterplot smoothing) - fit least squares regression lines to successive subsets of the observations weighted according to their distance from the target observation and thus depict changes in the trends throughout the data cloud.\nkernel smoothers - new smoothed y-values are computed as the weighted averages of points within a defined window (bandwidth) or neighbourhood of the original x-values. Hence the bandwidth depends on the scale of the x-axis. Weightings are determined by the type of kernel smoother specified, and for. Nevertheless, the larger the window, the greater the degree of smoothing.\nsplines - join together a series of polynomial fits that have been generated after the entire data cloud is split up into a number of smaller windows, the widths of which determine the smoothness of the resulting piecewise polynomial."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-model-i-and-ii-regression",
    "href": "Lecture_Folder/Week5a.html#r-interlude-model-i-and-ii-regression",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Model I and II regression",
    "text": "R INTERLUDE | Model I and II regression\n\nx &lt;- zfish$SL\ny &lt;- zfish$Weight\n\nsize_lm &lt;- lm(y~x)\nsummary(size_lm)\n\nplot(y~x, col = \"blue\")\nabline(size_lm, col = \"red\")\n\nNote that when we run the lm() function we use Model I regression. Is this appropriate?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-model-i-and-ii-regression-1",
    "href": "Lecture_Folder/Week5a.html#r-interlude-model-i-and-ii-regression-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Model I and II regression",
    "text": "R INTERLUDE | Model I and II regression\n\ninstall.packages(“lmodel2”)\nlibrary(lmodel2)\n\nsize_lm_ModII &lt;- lmodel2(y ~ x)\nsize_lm_ModII\n\nabline(a=0.1912797, b=0.1097880, lty=2)\n\nYou should have generated OLS, MA, and SMA regression models, and the last plots SMA line from parameter estimates"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#r-interlude-model-i-and-ii-regression-2",
    "href": "Lecture_Folder/Week5a.html#r-interlude-model-i-and-ii-regression-2",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Model I and II regression",
    "text": "R INTERLUDE | Model I and II regression\n\nSay you measured green fluorescent protein abundance in cell culture across several key, carefully controlled temperatures.\nYou ultimately want to know whether protein expression changes as a function of temperature in your experiment.\nRead in the gfp_temp.tsv data and perform a regression analysis.\nAddress the following questions\n\nWhich is X and which is Y?\nAre residual assumptions met?\nWhat model of regression should we use in this case and why?\nWhat is our decision regarding our null hypothesis of no relationship?"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#style-of-a-results-section",
    "href": "Lecture_Folder/Week5a.html#style-of-a-results-section",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Style of a results section",
    "text": "Style of a results section\n\nWrite the text of the Results section concisely and objectively.\nThe passive voice will likely dominate here, but use the active voice as much as possible.\nUse the past tense.\nAvoid repetitive paragraph structures. Do not interpret the data here."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#function-of-a-results-section",
    "href": "Lecture_Folder/Week5a.html#function-of-a-results-section",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Function of a results section",
    "text": "Function of a results section\n\nThe function is to objectively present your key results, without interpretation, in an orderly and logical sequence using both text and illustrative materials (Tables and Figures).\nThe results section always begins with text, reporting the key results and referring to figures and tables as you proceed.\nThe text of the Results section should be crafted to follow this sequence and highlight the evidence needed to answer the questions/hypotheses you investigated.\nImportant negative results should be reported, too. Authors usually write the text of the results section based upon the sequence of Tables and Figures."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#summaries-of-the-statistical-analyses",
    "href": "Lecture_Folder/Week5a.html#summaries-of-the-statistical-analyses",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Summaries of the statistical analyses",
    "text": "Summaries of the statistical analyses\nMay appear either in the text (usually parenthetically) or in the relevant Tables or Figures (in the legend or as footnotes to the Table or Figure). Each Table and Figure must be referenced in the text portion of the results, and you must tell the reader what the key result(s) is that each Table or Figure conveys.\n\nTables and Figures are assigned numbers separately and in the sequence that you will refer to them from the text.\n\nThe first Table you refer to is Table 1, the next Table 2 and so forth.\nSimilarly, the first Figure is Figure 1, the next Figure 2, etc.\n\nEach Table or Figure must include a brief description of the results being presented and other necessary information in a legend.\n\nTable legends go above the Table; tables are read from top to bottom.\nFigure legends go below the figure; figures are usually viewed from bottom to top.\n\nWhen referring to a Figure from the text, “Figure” is abbreviated as Fig.,e.g., (Fig. 1. Table is never abbreviated, e.g., Table 1."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#example",
    "href": "Lecture_Folder/Week5a.html#example",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Example",
    "text": "Example\nFor example, suppose you asked the question, “Is the average height of male students the same as female students in a pool of randomly selected Biology majors?” You would first collect height data from large random samples of male and female students. You would then calculate the descriptive statistics for those samples (mean, SD, n, range, etc) and plot these numbers. Suppose you found that male Biology majors are, on average, 12.5 cm taller than female majors; this is the answer to the question. Notice that the outcome of a statistical analysis is not a key result, but rather an analytical tool that helps us understand what is our key result."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#differences-directionality-and-magnitude",
    "href": "Lecture_Folder/Week5a.html#differences-directionality-and-magnitude",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Differences, directionality, and magnitude",
    "text": "Differences, directionality, and magnitude\n\nReport your results so as to provide as much information as possible to the reader about the nature of differences or relationships.\nFor example, if you are testing for differences among groups, and you find a significant difference, it is not sufficient to simply report that “groups A and B were significantly different”. How are they different? How much are they different?\nIt is much more informative to say something like, “Group A individuals were 23% larger than those in Group B”, or, “Group B pups gained weight at twice the rate of Group A pups.”\nReport the direction of differences (greater, larger, smaller, etc) and the magnitude of differences (% difference, how many times, etc.) whenever possible."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#statistical-results-in-text",
    "href": "Lecture_Folder/Week5a.html#statistical-results-in-text",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nStatistical test summaries (test name, p-value) are usually reported parenthetically in conjunction with the biological results they support. This parenthetical reference should include the statistical test used, the value, degrees of freedom and the level of significance.\nFor example, if you found that the mean height of male Biology majors was significantly larger than that of female Biology majors, you might report this result (in blue) and your statistical conclusion (shown in red) as follows:\n\n“Males (180.5 ± 5.1 cm; n=34) averaged 12.5 cm taller than females (168 ± 7.6 cm; n=34) in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001).”\n\nIf the summary statistics are shown in a figure, the sentence above need not report them specifically, but must include a reference to the figure where they may be seen:\n\n“Males averaged 12.5 cm taller than females in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001; Fig. 1).”"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#statistical-results-in-text-1",
    "href": "Lecture_Folder/Week5a.html#statistical-results-in-text-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nAlways enter the appropriate units when reporting data or summary statistics.\n\nfor an individual value you would write, “the mean length was 10 cm”, or, “the maximum time was 140 min.”\nWhen including a measure of variability, place the unit after the error value, e.g., “…was 10 ± 2.3 m”.\nLikewise place the unit after the last in a series of numbers all having the same unit. For example: “lengths of 5, 10, 15, and 20 m”, or “no differences were observed after 2, 4, 6, or 8 min. of incubation”."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#galton-as-the-father-of-eugenics",
    "href": "Lecture_Folder/Week5a.html#galton-as-the-father-of-eugenics",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\nFrancis Galton: Darwin’s half cousin\nStudied human variation and genetic inheritance\n\nHuman height, fingerprints, intelligence\nCorrelation, regression toward the mean, and “nature versus nurture”\nPioneered twin studies\n\n\n\n\n\nGalton"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#galton-as-the-father-of-eugenics-1",
    "href": "Lecture_Folder/Week5a.html#galton-as-the-father-of-eugenics-1",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\nBelieved that intelligence was hereditary based on surveying prominent academics in Europe\nUsed the ideas of correlation and regression towards the mean to argue that the upper class should breed amongst themselves to keep those “good genes” pure\nWanted to provide monetary incentives for “good” couples to marry and reproduce as a way to avoid the upper class being genetically muddied by the lower class"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "href": "Lecture_Folder/Week5a.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "A common sight at state fairs around the U.S. in the 1930s",
    "text": "A common sight at state fairs around the U.S. in the 1930s\n\nCompetitions for the “perfect family” to encourage public consciousness and support for eugenics"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#galton-with-charles-davenport-and-g.-stanley-hall",
    "href": "Lecture_Folder/Week5a.html#galton-with-charles-davenport-and-g.-stanley-hall",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Galton with Charles Davenport and G. Stanley Hall",
    "text": "Galton with Charles Davenport and G. Stanley Hall\n\nAmerican Eugenics Record Office (ERO) founded in Cold Springs Harbor"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#logo-of-the-us-eugenics-society",
    "href": "Lecture_Folder/Week5a.html#logo-of-the-us-eugenics-society",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Logo of the US eugenics society",
    "text": "Logo of the US eugenics society"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#eugenics-societies-in-america",
    "href": "Lecture_Folder/Week5a.html#eugenics-societies-in-america",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Eugenics societies in America",
    "text": "Eugenics societies in America\n\nAdvocated for state laws to ban interracial marriages and promote sterilization of “unfit” individuals (negative eugenics) - especially black, Latinx, and Native American women\n30 states passed laws to force mental institution patients to be sterilized\nBetween 1907 and 1963, over 64,000 individuals were forcibly sterilized under eugenic legislation in the United States"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#ra-fisher-and-eugenics-in-london",
    "href": "Lecture_Folder/Week5a.html#ra-fisher-and-eugenics-in-london",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics in London",
    "text": "RA Fisher and Eugenics in London\n\nDeveloper of Fishers exact test, analysis of variance (ANOVA), null hypothesis, p values, maximum likelihood, probability density functions\nFounding Chairman of the University of Cambridge Eugenics Society"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#ra-fisher-and-eugenics",
    "href": "Lecture_Folder/Week5a.html#ra-fisher-and-eugenics",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics",
    "text": "RA Fisher and Eugenics\n\n1/3rd of his work “The Genetical Theory of Natural Selection” discussed eugenics and his theory that the fall of civilizations was due to the fertility of their upper classes being diminished\nUsed these statistical methods to test data on human variation to prove biological differences between human races\nEugenics and racism were the primary motivators for many of these statistical tests that we use today"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#eugenics-has-a-direct-line-to-hitler-and-nazism",
    "href": "Lecture_Folder/Week5a.html#eugenics-has-a-direct-line-to-hitler-and-nazism",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Eugenics has a direct line to Hitler and Nazism",
    "text": "Eugenics has a direct line to Hitler and Nazism\n\nEugenics existed in America (and England) before it became popular in Germany.\nBy 1933, California had subjected more people to forceful sterilization than all other U.S. states combined.\nThe forced sterilization program engineered by the Nazis was partly inspired by California’s."
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#sterilizations-continue-in-america",
    "href": "Lecture_Folder/Week5a.html#sterilizations-continue-in-america",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Sterilizations continue in America",
    "text": "Sterilizations continue in America\n\nOur history books paint Nazi Germany as the primary evil of that time, while we try to cover up our significant role in eugenics\nIt wasn’t until 1978 that the US passed regulations on sterilization procedures\nCalifornia only passed a bill to outlaw sterilization of inmates in 2014\nCertain members of the genetic engineering community threaten to bring back eugenics ideas"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#so-what-do-we-do-from-here",
    "href": "Lecture_Folder/Week5a.html#so-what-do-we-do-from-here",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "So, what do we do from here?",
    "text": "So, what do we do from here?\n\nThe statistical methods that Galton, Fisher, and others developed are useful science tools\nImportant to use these tools for good - improving our planet, human health, and technology\nImportant to acknowledge and not forget the history of science - educate others to avoid repeating history"
  },
  {
    "objectID": "Lecture_Folder/Week5a.html#interested-in-learning-more",
    "href": "Lecture_Folder/Week5a.html#interested-in-learning-more",
    "title": "Week 5a - Statistics for Bioengineering",
    "section": "Interested in learning more?",
    "text": "Interested in learning more?\n\n\n\n\n\n\n\n\n\n\nSee also “The Gene” by Siddhartha Mukherjee"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html",
    "href": "Lecture_Folder/Week5b.html",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#a-linear-model-to-relate-two-variables",
    "href": "Lecture_Folder/Week5b.html#a-linear-model-to-relate-two-variables",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "A linear model to relate two variables",
    "text": "A linear model to relate two variables\n\\[ y_i = \\beta_0 + \\beta_1 x_1 + \\epsilon_i \\]"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#bivariate-normality",
    "href": "Lecture_Folder/Week5b.html#bivariate-normality",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Bivariate normality",
    "text": "Bivariate normality"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#what-is-a-linear-model",
    "href": "Lecture_Folder/Week5b.html#what-is-a-linear-model",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "What is a linear model?",
    "text": "What is a linear model?\nAll an be written in the form\nresponse_var = intercept + parameter*(explanatory_var) + error\n\n\n\n\\[ y_i = \\beta_0 + \\beta_1 x_1 + \\epsilon_i \\]\n\\[ y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n + \\epsilon_i \\]\n\\[ y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1x_2 + \\epsilon_i \\]\n\nFunctions in\n\nlm()\naov()\nglm()"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#many-approaches-are-linear-models",
    "href": "Lecture_Folder/Week5b.html#many-approaches-are-linear-models",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Many approaches are linear models",
    "text": "Many approaches are linear models\n\nLinear regression\nSingle factor ANOVA\nAnalysis of covariance\nMultiple regression\nMulti-factor ANOVA\nRepeated-measures ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#classes-of-linear-models",
    "href": "Lecture_Folder/Week5b.html#classes-of-linear-models",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Classes of linear models",
    "text": "Classes of linear models\n\nGeneral Linear Model (GLM) - two or more continuous variables\nGeneral Linear Mixed Model (GLMM) - a continuous response variable with a mix of continuous and categorical predictor variables\nGeneralized Linear Model - a GLMM that doesn’t assume normality of the response (we’ll get to this later)"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#linear-model-parameters",
    "href": "Lecture_Folder/Week5b.html#linear-model-parameters",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "linear model parameters",
    "text": "linear model parameters"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#what-is-a-non-linear-model",
    "href": "Lecture_Folder/Week5b.html#what-is-a-non-linear-model",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "What is a non-linear model?",
    "text": "What is a non-linear model?\n\nparametric non-linear model: assumes that the relationship between the dependent and independent variables can be modeled using a specfic mathematical function\n\nLogistic regression \\(log(\\frac{\\pi_i}{1-\\pi_1})=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +...+ \\beta_n x_n +\\epsilon\\)\nPolynomial regression \\(y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 +...+ \\beta_n x^n +\\epsilon\\)\nExponential regression \\(y = \\alpha^{\\beta x} + \\epsilon\\)\nPoisson regression \\(log(y) = \\beta_0 + \\beta_1 x + \\epsilon\\)\nPower regression \\(y = \\alpha x^\\beta + \\epsilon\\)\n\nnon-parameteric non-linear regression: doesn’t make this assumption, but instead uses machine learning algorhithms to larn the relationship\n\nKernel smoothing\nLocal polynomial regression\nNearest neighbor regression"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#simple-linear-regression-1",
    "href": "Lecture_Folder/Week5b.html#simple-linear-regression-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Simple Linear Regression",
    "text": "Simple Linear Regression\n\\[ y_i = B_0 + B_1 x_1 + e_i \\]\n\nRelate two continuous variables to one another\nOften use ordinary least squares (OLS) to fit a model\nThe estimates (\\(\\beta_0\\) and \\(\\beta_1\\)) are measured with normally distributed error\nParametric regression involves assumptions about the data\n\nneed to do a ‘residual analysis’ to check assumptions\nthere are ways to perform robust non-parametric linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#origin-of-the-term-regression",
    "href": "Lecture_Folder/Week5b.html#origin-of-the-term-regression",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Origin of the term regression?",
    "text": "Origin of the term regression?"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residuals",
    "href": "Lecture_Folder/Week5b.html#residuals",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Residuals",
    "text": "Residuals"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residuals-1",
    "href": "Lecture_Folder/Week5b.html#residuals-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Residuals",
    "text": "Residuals"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#hypothesis-tests-in-regression",
    "href": "Lecture_Folder/Week5b.html#hypothesis-tests-in-regression",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Hypothesis tests in regression",
    "text": "Hypothesis tests in regression\n\\[H_0 : \\beta_0 = 0\\] \\[H_A : \\beta_1 \\neq 0\\]\nreduced model (\\(H_0\\)) -\n\\[y_i = \\beta_0 + 0x_i + \\epsilon_i\\]\nfull model (\\(H_A\\)) -\n\\[y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i\\]\n\n\n\nfits a “reduced” model without slope term (H0)\nfits the “full” model with slope term added back\ncompares fit of full and reduced models using an F test statistic\ncompares the residual variance of the full vs. reduced models"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#hypothesis-tests-in-regression-1",
    "href": "Lecture_Folder/Week5b.html#hypothesis-tests-in-regression-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Hypothesis tests in regression",
    "text": "Hypothesis tests in regression"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#estimation-with-squared-errors",
    "href": "Lecture_Folder/Week5b.html#estimation-with-squared-errors",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Estimation with squared errors",
    "text": "Estimation with squared errors\n\nSum of Squares (\\(SS\\)) is the sum of the squared difference\nSum of Squares Total (\\(SS_{total}\\) or \\(SST\\)) is\n\nthe total variability in the data\nvariance in Y in simple linear regression\n\nSum of Squares Model (\\(SS_{model}\\) or \\(SSM\\)) is the variability explained by the model\nSum of Squares Error (\\(SS_{error}\\) or \\(SSE\\)) is the unexplained variability once the model is fit\n\n\\[SST = SSR + SSE\\]"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#r2-as-a-measure-of-model-fit",
    "href": "Lecture_Folder/Week5b.html#r2-as-a-measure-of-model-fit",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "\\(R^2\\) as a measure of model fit",
    "text": "\\(R^2\\) as a measure of model fit\n\\[R^2 = 1 - \\frac{SSE}{SST}\\] or\n\\[R^2 = \\frac{SSR}{SST}\\]\n\\(R^2\\) is the proportion of the variance in Y that is explained by X"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#hypothesis-tests-with-mean-squared-errors",
    "href": "Lecture_Folder/Week5b.html#hypothesis-tests-with-mean-squared-errors",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Hypothesis tests with mean squared errors",
    "text": "Hypothesis tests with mean squared errors\n\nMean square (\\(MS\\)) = divide the sum of squares by the degrees of freedom\n\\(MS\\) standardizes by the number of data points\n\\(MST\\), \\(MSM\\) and \\(MSE\\) are the mean squares total, model and error respectively\nWhat are the degrees of freedom for simple linear regression\n\nnumerator degrees of freedom: 1 (#variables - 1)\ndenominator degrees of freedom: n-2 (#observations - 2)"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#hypothesis-tests-in-linear-regression",
    "href": "Lecture_Folder/Week5b.html#hypothesis-tests-in-linear-regression",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Hypothesis tests in linear regression",
    "text": "Hypothesis tests in linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#hypothesis-tests-in-linear-regression-1",
    "href": "Lecture_Folder/Week5b.html#hypothesis-tests-in-linear-regression-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Hypothesis tests in linear regression",
    "text": "Hypothesis tests in linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#linear-models-in-r",
    "href": "Lecture_Folder/Week5b.html#linear-models-in-r",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "linear models in R",
    "text": "linear models in R\n\nIn general we need to fit the model and then ‘read’ the output\n\n\nmy_lm &lt;- lm(dataset$variable1 ~ dataset$variable2)\nsummary(my_lm)\n\n\nNow write a script to read in the zebrafish data set.\nNow, add the code to perform a linear model of two continuous variables (length and weight).\nNotice how the output of the linear model is specified to a new variable."
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#section",
    "href": "Lecture_Folder/Week5b.html#section",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "",
    "text": "Zebrafish_data &lt;- read.table(\"Drerio_development_complete.csv\", header=T, sep=\",\")\nhead(Zebrafish_data)\n\n  X.1 X Sample Condition    Sex Age_Days Pigmentation Group Weight_mg Length_cm\n1   1 1      1   Control Female        1           33     A  4.318525 0.9211093\n2   2 2      2   Control   Male        2           77     A  8.331734 1.8337986\n3   3 3      3   Control Female        3           15     A 15.795725 4.1445988\n4   4 4      4   Control   Male        4           39     A 16.351995 4.9857301\n5   5 5      5   Control Female        5           13     A 23.402953 6.5326226\n6   6 6      6   Control   Male        1           52     A  5.412950 0.9363841"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#section-1",
    "href": "Lecture_Folder/Week5b.html#section-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "",
    "text": "x &lt;- Zebrafish_data$Length_cm\ny &lt;- Zebrafish_data$Weight_mg\n\n\nzfish_lm &lt;- lm(y ~ x)\nsummary (zfish_lm)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1164 -1.1004  0.0976  0.9950  4.5447 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.42136    0.12820   18.89   &lt;2e-16 ***\nx            3.06303    0.03775   81.13   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.48 on 598 degrees of freedom\nMultiple R-squared:  0.9167,    Adjusted R-squared:  0.9166 \nF-statistic:  6582 on 1 and 598 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#making-a-plot-of-the-model-fit",
    "href": "Lecture_Folder/Week5b.html#making-a-plot-of-the-model-fit",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Making a plot of the model fit",
    "text": "Making a plot of the model fit\n\nplot(y ~ x, col = \"blue\")\nabline(zfish_lm, col = \"red\")"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#same-plot-in-ggplot2",
    "href": "Lecture_Folder/Week5b.html#same-plot-in-ggplot2",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Same plot in GGPlot2",
    "text": "Same plot in GGPlot2\n\nggplot(zfish_lm, aes(x = x, y = y)) +\n  geom_point(color = \"blue\", size = 2, alpha = 0.2) +                  \n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  labs(\n    title = \"Linear regression of zebrafish weight on standard length\",\n    x = \"zebrafish length in cm\",\n    y = \"zebrafish weight in gm\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#looking-at-the-model-object",
    "href": "Lecture_Folder/Week5b.html#looking-at-the-model-object",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Looking at the model object",
    "text": "Looking at the model object\n\nNames of variables in the model object\n\nnames(zfish_lm)\n\n [1] \"coefficients\"  \"residuals\"     \"effects\"       \"rank\"         \n [5] \"fitted.values\" \"assign\"        \"qr\"            \"df.residual\"  \n [9] \"xlevels\"       \"call\"          \"terms\"         \"model\"        \n\n\n\n\n\n\nPulling out estimates and confidence intervals\n\ncoef(zfish_lm)\n\n(Intercept)           x \n   2.421359    3.063034 \n\nconfint(zfish_lm)\n\n               2.5 %   97.5 %\n(Intercept) 2.169579 2.673139\nx           2.988886 3.137182\n\n\n\n\n\n\nFormatting the output in a nice table\n\nlibrary(gtsummary)\nlibrary(ggplot2)\ntbl_regression(zfish_lm)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\n\n\n\n\nx\n3.1\n3.0, 3.1\n&lt;0.001\n\n\n\nAbbreviation: CI = Confidence Interval"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#using-your-fitted-model-to-make-predictions",
    "href": "Lecture_Folder/Week5b.html#using-your-fitted-model-to-make-predictions",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Using your fitted model to make predictions",
    "text": "Using your fitted model to make predictions\n\npredict(zfish_lm, data.frame(x = c(0.2, 0.4, 0.8, 1)), interval=\"confidence\")\n\n       fit      lwr      upr\n1 3.033966 2.795162 3.272770\n2 3.646573 3.420517 3.872629\n3 4.871786 4.670369 5.073203\n4 5.484393 5.294756 5.674030"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#did-we-meet-our-assumptions",
    "href": "Lecture_Folder/Week5b.html#did-we-meet-our-assumptions",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Did we meet our assumptions?",
    "text": "Did we meet our assumptions?\n\nIndependent errors (residuals)\nEqual variance of residuals in all groups\nNormally-distributed residuals"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#handling-violations-of-the-assumptions-of-linear-models",
    "href": "Lecture_Folder/Week5b.html#handling-violations-of-the-assumptions-of-linear-models",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Handling violations of the assumptions of linear models",
    "text": "Handling violations of the assumptions of linear models\n\nWhat if your residuals aren’t normal because of outliers?\nNonparametric methods exist, but these don’t provide parameter estimates with CIs.\nRobust regression (rlm)\nRandomization tests"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these",
    "href": "Lecture_Folder/Week5b.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Anscombe’s quartet again | what would residual plots look like for these?",
    "text": "Anscombe’s quartet again | what would residual plots look like for these?"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these-1",
    "href": "Lecture_Folder/Week5b.html#anscombes-quartet-again-what-would-residual-plots-look-like-for-these-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Anscombe’s quartet again | what would residual plots look like for these?",
    "text": "Anscombe’s quartet again | what would residual plots look like for these?"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residual-plots-spotting-assumption-violations",
    "href": "Lecture_Folder/Week5b.html#residual-plots-spotting-assumption-violations",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Residual Plots | Spotting assumption violations",
    "text": "Residual Plots | Spotting assumption violations"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residuals-leverage-and-influence",
    "href": "Lecture_Folder/Week5b.html#residuals-leverage-and-influence",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Residuals | leverage and influence",
    "text": "Residuals | leverage and influence\n\n\n\n\n\n\n\n\n\n\n1 is an outlier for both Y and X\n2 is not an outlier for either Y or X but has a high residual\n3 is an outlier in just X - and thus a high residual - and therefore has high influence as measured by Cook’s D"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residuals-leverage-and-influence-1",
    "href": "Lecture_Folder/Week5b.html#residuals-leverage-and-influence-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Residuals | leverage and influence",
    "text": "Residuals | leverage and influence\n\nLeverage - a measure of how much of an outlier each point is in x-space (on x-axis) and thus only applies to the predictor variable. (Values &gt; 2*(2/n) for simple regression are cause for concern)\nResiduals - As the residuals are the differences between the observed and predicted values along a vertical plane, they provide a measure of how much of an outlier each point is in y-space (on y-axis). The patterns of residuals against predicted y values (residual plot) are also useful diagnostic tools for investigating linearity and homogeneity of variance assumptions\nCook’s D statistic is a measure of the influence of each point on the fitted model (estimated slope) and incorporates both leverage and residuals. Values ≥ 1 (or even approaching 1) correspond to highly influential observations."
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#r-interlude-residual-analyses",
    "href": "Lecture_Folder/Week5b.html#r-interlude-residual-analyses",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "R INTERLUDE | residual analyses",
    "text": "R INTERLUDE | residual analyses\nLet’s look at the residuals in the zebrafish data.\n\nhist(residuals(zfish_lm), breaks=30)"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residuals-vs.-original-x-variable",
    "href": "Lecture_Folder/Week5b.html#residuals-vs.-original-x-variable",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "residuals vs. original x variable",
    "text": "residuals vs. original x variable\n\nplot (residuals(zfish_lm) ~ x)"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residuals-vs.-predicted-fitted-values",
    "href": "Lecture_Folder/Week5b.html#residuals-vs.-predicted-fitted-values",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "residuals vs. predicted (fitted) values",
    "text": "residuals vs. predicted (fitted) values\n\nplot (residuals(zfish_lm) ~ fitted.values(zfish_lm))"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#residual-analyses",
    "href": "Lecture_Folder/Week5b.html#residual-analyses",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Residual analyses",
    "text": "Residual analyses\nOr apply the plot() function to the linear model object directly\n\nplot(zfish_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure out what these plots are telling you"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#or-you-can-use-this-nifty-little-package",
    "href": "Lecture_Folder/Week5b.html#or-you-can-use-this-nifty-little-package",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Or you can use this nifty little package",
    "text": "Or you can use this nifty little package\n\nlibrary(ggfortify)\nautoplot(zfish_lm, which = 1:6, ncol = 2, label.size = 3)"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#influence-measures",
    "href": "Lecture_Folder/Week5b.html#influence-measures",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Influence measures",
    "text": "Influence measures\n\nHow about using the influence.measures function???\n\n\ninfluence.measures(zfish_lm)\n\n\nDo we have any high leverage observations we need to worry about???"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#galton-as-the-father-of-eugenics",
    "href": "Lecture_Folder/Week5b.html#galton-as-the-father-of-eugenics",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\n\nFrancis Galton: Darwin’s half cousin\nStudied human variation and genetic inheritance\n\nHuman height, fingerprints, intelligence\nCorrelation, regression toward the mean, and “nature versus nurture”\nPioneered twin studies"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#galton-as-the-father-of-eugenics-1",
    "href": "Lecture_Folder/Week5b.html#galton-as-the-father-of-eugenics-1",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Galton as the Father of Eugenics",
    "text": "Galton as the Father of Eugenics\n\nBelieved that intelligence was hereditary based on surveying prominent academics in Europe\nUsed the ideas of correlation and regression towards the mean to argue that the upper class should breed amongst themselves to keep those “good genes” pure\nWanted to provide monetary incentives for “good” couples to marry and reproduce as a way to avoid the upper class being genetically muddied by the lower class"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "href": "Lecture_Folder/Week5b.html#a-common-sight-at-state-fairs-around-the-u.s.-in-the-1930s",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "A common sight at state fairs around the U.S. in the 1930s",
    "text": "A common sight at state fairs around the U.S. in the 1930s\n\nCompetitions for the “perfect family” to encourage public consciousness and support for eugenics"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#galton-charles-davenport-g.-stanley-hall",
    "href": "Lecture_Folder/Week5b.html#galton-charles-davenport-g.-stanley-hall",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Galton, Charles Davenport & G. Stanley Hall",
    "text": "Galton, Charles Davenport & G. Stanley Hall"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#logo-of-the-us-eugenics-society",
    "href": "Lecture_Folder/Week5b.html#logo-of-the-us-eugenics-society",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Logo of the US eugenics society",
    "text": "Logo of the US eugenics society\n\n\n\n\n\n\n\n\n\n\nAmerican Eugenics Record Office (ERO) founded in Cold Springs Harbor"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#eugenics-societies-in-america",
    "href": "Lecture_Folder/Week5b.html#eugenics-societies-in-america",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Eugenics societies in America",
    "text": "Eugenics societies in America\n\nAdvocated for state laws to ban interracial marriages and promote sterilization of “unfit” individuals (negative eugenics) - especially black, Latinx, and Native American women\n30 states passed laws to force mental institution patients to be sterilized\nBetween 1907 and 1963, over 64,000 individuals were forcibly sterilized under eugenic legislation in the United States"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#ra-fisher-and-eugenics-in-london",
    "href": "Lecture_Folder/Week5b.html#ra-fisher-and-eugenics-in-london",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics in London",
    "text": "RA Fisher and Eugenics in London\n\nDeveloper of Fishers exact test, analysis of variance (ANOVA), null hypothesis, p values, maximum likelihood, probability density functions\nFounding Chairman of the University of Cambridge Eugenics Society"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#ra-fisher-and-eugenics",
    "href": "Lecture_Folder/Week5b.html#ra-fisher-and-eugenics",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "RA Fisher and Eugenics",
    "text": "RA Fisher and Eugenics\n\n1/3rd of his work “The Genetical Theory of Natural Selection” discussed eugenics and his theory that the fall of civilizations was due to the fertility of their upper classes being diminished\nUsed these statistical methods to test data on human variation to prove biological differences between human races\nEugenics and racism were the primary motivators for many of these statistical tests that we use today"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#a-direct-line-to-hitler-and-nazism",
    "href": "Lecture_Folder/Week5b.html#a-direct-line-to-hitler-and-nazism",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "A direct line to Hitler and Nazism",
    "text": "A direct line to Hitler and Nazism\n\nEugenics existed in America (and England) before it became popular in Germany.\nBy 1933, California had subjected more people to forceful sterilization than all other U.S. states combined.\nThe forced sterilization program engineered by the Nazis was partly inspired by California’s."
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#sterilizations-continue-in-america",
    "href": "Lecture_Folder/Week5b.html#sterilizations-continue-in-america",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Sterilizations continue in America",
    "text": "Sterilizations continue in America\n\nOur history books paint Nazi Germany as the primary evil of that time, while we try to cover up our significant role in eugenics\nIt wasn’t until 1978 that the US passed regulations on sterilization procedures\nCalifornia only passed a bill to outlaw sterilization of inmates in 2014\nCertain members of the genetic engineering community threaten to bring back eugenics ideas\nOur current President repeats eugenics talking points"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#so-what-do-we-do-from-here",
    "href": "Lecture_Folder/Week5b.html#so-what-do-we-do-from-here",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "So, what do we do from here?",
    "text": "So, what do we do from here?\n\nThe statistical methods that Galton, Fisher, and others developed are useful science tools\nImportant to use these tools for good - improving our planet, human health, and technology\nImportant to acknowledge and not forget the history of science - educate others to avoid repeating history"
  },
  {
    "objectID": "Lecture_Folder/Week5b.html#interested-in-learning-more",
    "href": "Lecture_Folder/Week5b.html#interested-in-learning-more",
    "title": "Week 5b - Statistics for Bioengineering",
    "section": "Interested in learning more?",
    "text": "Interested in learning more?\n\n\n\n\n\n\n\n\n\n\nSee also\n\n“The Gene” by Siddhartha Mukherjee\n“Control” by Adam Rutherford"
  },
  {
    "objectID": "Homework_Folder/HW2_2025.html",
    "href": "Homework_Folder/HW2_2025.html",
    "title": "Linear Regression and ANOVA",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use a new data set of effects of IGF-1 on growth rate in mouse (igf.tsv), and a simplified stickleback microbiota/RNAseq data (RNAseq_microbiome.csv) set that you have been using in class. In addition, perform either a simple linear regression (2.1) or an ANOVA (2.2) on the dataset that you’ve identified for your term long project depending on the nature of your data.\nDue: Submit your work via Canvas by the end of the day (midnight) on Wednesday, May 14th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW2_2025.html#directions",
    "href": "Homework_Folder/HW2_2025.html#directions",
    "title": "BioE_Stats_2025_HW2 - Linear Regression and ANOVA",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use a new data set of effects of IGF-1 on growth rate in mouse (igf.tsv), and a simplified stickleback microbiota/RNAseq data (RNAseq_microbiome.csv) set that you have been using in class. In addition, perform either a simple linear regression (2.1) or an ANOVA (2.2) on the dataset that you’ve identified for your term long project depending on the nature of your data.\nDue: Submit your work via Canvas by the end of the day (midnight) on Wednesday, May 14th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW2_2025.html#problem-2.1-multiple-linear-regression-to-examine-the-effect-of-igf-1-on-the-early-growth-of-mice",
    "href": "Homework_Folder/HW2_2025.html#problem-2.1-multiple-linear-regression-to-examine-the-effect-of-igf-1-on-the-early-growth-of-mice",
    "title": "Linear Regression and ANOVA",
    "section": "Problem 2.1 : Multiple linear regression to examine the effect of IGF-1 on the early growth of mice",
    "text": "Problem 2.1 : Multiple linear regression to examine the effect of IGF-1 on the early growth of mice\nThe Study. Researchers are studying how levels of the hormone IGF-1 (insulin-like growth factor 1) affect early growth, and have measured IGF-1 levels along with length, weight, and a few maturity-related traits in 710 young mice. Your goal is to investigate how IGF-1 is related to differences in length after accounting for other factors.\nThe dataset (igf.tsv) can be found in the data folder on Canvas. This dataset has the following variables\n\nage (in weeks),\nsex\nigf (IGF-1 levels),\nmaturity (1-5, larger values are more sexually mature),\nweight (in g), and\nlength (body and tail, in cm).\n\nPerform the following steps:\n\nDescribe the data using your skills in exploratory data analysis. Which variables are categorical, which are continuous? Are they coded correctly in r, or do you need to coerce them to a different data type?\nFit two linear models, one with weight as the response and the other with length as a response, and both with igf as the predictor variable.\nSummarize the fitted model in terms of key statistics such as \\(R^2\\), F-value, degrees of freedom and p-values\nPerform a residual analysis to see if you have satisfied the assumptions of parametric linear regression, and identify outliers that might have a significant effect on the model\nProvide visualizations and summaries of what you find."
  },
  {
    "objectID": "Homework_Folder/HW2_2025.html#exercise-2.2-factorial-anova-examining-the-effects-of-microbiome-treatment-on-rna-expression-levels-in-the-guts-of-threespine-stickleback",
    "href": "Homework_Folder/HW2_2025.html#exercise-2.2-factorial-anova-examining-the-effects-of-microbiome-treatment-on-rna-expression-levels-in-the-guts-of-threespine-stickleback",
    "title": "Linear Regression and ANOVA",
    "section": "Exercise 2.2: Factorial ANOVA examining the effects of microbiome treatment on RNA expression levels in the guts of threespine stickleback",
    "text": "Exercise 2.2: Factorial ANOVA examining the effects of microbiome treatment on RNA expression levels in the guts of threespine stickleback\nLoad the RNAseq_microbiome.csv dataset which represents RNAseq data collected for three different genes (FGF3, Sox10 and SLC5) from the guts of threespine stickleback fish. In this experiment two different genotypes of stickleback (ocean and freshwater) were tested by subjecting each to two different microbiome treatments (conventional or mono-associated). Stickleback can be made germ free and then either exposed to the conventional microbiome or just one microbe. After exposure the guts were extracted, RNA isolated, and RNAseq data collected.\nThe dataset (igf.tsv) can be found in the data folder on Canvas. This dataset has the following variables:\n\nGenotype - whether the fish has an oceanic or freshwater genotype\nMicrobiota - whether the fish was germ free or conventionalized\nFGF3 - the level of gene expression of the signalling molecule Fibroblast Growth Factor 3\nSox10 - the level of gene expression of the transcription factor gene Sox10\nSLC5 - the level of gene expression of the small molecule transporter SLC5\n\nIs R correctly interpreting the class of your variables? It is always good to check this before doing anything.\n\nMake boxplots to graphically illustrate differences in gene expression distributions among genotype and microbiota treatment for each gene.\n\n\nUse the mutate function in dpylr to combine the two categorical variables into a new variable\nAny obvious patterns?\nWould you guess there is a difference among means?\nDoes it look like there may be an interaction?\n\n\nFit the factorial linear model\n\n\nUse the summary function to look at your results.\nIs there a statistically significant model?\nIs there a significant interaction between genotype and treatment?\n\n\nPerform a Tukey’s post-hoc means test across treatment groups\n\n\nPerform the test separately for each of the two levels for each categorical variable\nNow perform it on your new variable with four levels and rerun the Tukey’s test\nDo all groups differ from one another?"
  },
  {
    "objectID": "Homework_Folder/HW2_2025.html#problem-set-2---directions",
    "href": "Homework_Folder/HW2_2025.html#problem-set-2---directions",
    "title": "Linear Regression and ANOVA",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use a new data set of effects of IGF-1 on growth rate in mouse (igf.tsv), and a simplified stickleback microbiota/RNAseq data (RNAseq_microbiome.csv) set that you have been using in class. In addition, perform either a simple linear regression (2.1) or an ANOVA (2.2) on the dataset that you’ve identified for your term long project depending on the nature of your data.\nDue: Submit your work via Canvas by the end of the day (midnight) on Wednesday, May 14th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW1_2025.html#problem-set-1---directions",
    "href": "Homework_Folder/HW1_2025.html#problem-set-1---directions",
    "title": "EDA, t-test and Power Calculations",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use both the microbiota/RNAseq data set that you have been using in class, as well as the dataset that you’ve identified for your term long project. Try to accomplish a version of the tasks I lay out below on your own dataset, but you’re undoubtedly going to need to make some modifications and adjustments. In addition, you will be performing one set of power analyses using simulation on a hypothetical problem\nDue: Submit your work via Canvas by the end of the day (midnight) on Tuesday, April 29th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html",
    "href": "Lecture_Folder/Week6a.html",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#this-week",
    "href": "Lecture_Folder/Week6a.html#this-week",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nModel 1 and 2 regression\nMultiple linear regression\nAnalysis of Variance (ANOVA)\nKey principles of experimental design\nHow to report statistics in papers"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#general-linear-model---two-or-more-continuous-variables",
    "href": "Lecture_Folder/Week6a.html#general-linear-model---two-or-more-continuous-variables",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "General linear model - two or more continuous variables",
    "text": "General linear model - two or more continuous variables\n\\[ y_i = \\beta_0 + \\beta_1 x_1 + \\epsilon_i \\]\n\n\n\n\n\n\n\n\n\n\\[ y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n + \\epsilon_i \\]\n\\[ y_i = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1x_2 + \\epsilon_i \\]"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#generalized-linear-models---non-linear-in-the-coefficients",
    "href": "Lecture_Folder/Week6a.html#generalized-linear-models---non-linear-in-the-coefficients",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Generalized linear models - non-linear in the coefficients",
    "text": "Generalized linear models - non-linear in the coefficients\n\nPolynomial regression \\[y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 +...+ \\beta_n x^n +\\epsilon\\]\nLogistic regression \\[log(\\frac{\\pi_i}{1-\\pi_1})=\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 +...+ \\beta_n x_n +\\epsilon\\]\nPoisson regression \\[log(y) = \\beta_0 + \\beta_1 x + \\epsilon\\]\nExponential regression \\[y = \\alpha^{\\beta x} + \\epsilon\\]\nPower regression \\[y = \\alpha x^\\beta + \\epsilon\\]"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#hypothesis-tests-in-regression",
    "href": "Lecture_Folder/Week6a.html#hypothesis-tests-in-regression",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Hypothesis tests in regression",
    "text": "Hypothesis tests in regression\n\\[H_0 : \\beta_0 = 0\\] \\[H_A : \\beta_1 \\neq 0\\]\nreduced model (\\(H_0\\)) -\n\\[y_i = \\beta_0 + 0x_i + \\epsilon_i\\]\nfull model (\\(H_A\\)) -\n\\[y_i = \\beta_0 + \\beta_1x_i + \\epsilon_i\\]\n\n\n\nfits a “reduced” model without slope term (H0)\nfits the “full” model with slope term added back\ncompares fit of full and reduced models using an F test statistic\ncompares the residual variance of the full vs. reduced models"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression",
    "href": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Model I and II regression",
    "text": "R INTERLUDE | Model I and II regression\n\nFirst we fit a standard model I ordinary least squares\n\n\nzfish_data &lt;- read.table(\"Drerio_development_complete.csv\", header=T, sep=\",\")\n\nlength &lt;- zfish_data$Length_cm\nweight &lt;- zfish_data$Weight_mg\n\nsize_lm &lt;- lm(weight~length)\nsummary(size_lm)\n\n\nCall:\nlm(formula = weight ~ length)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.1164 -1.1004  0.0976  0.9950  4.5447 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.42136    0.12820   18.89   &lt;2e-16 ***\nlength       3.06303    0.03775   81.13   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.48 on 598 degrees of freedom\nMultiple R-squared:  0.9167,    Adjusted R-squared:  0.9166 \nF-statistic:  6582 on 1 and 598 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Model I and II regression",
    "text": "R INTERLUDE | Model I and II regression\n\nWe can fit the line\n\n\nlibrary(ggplot2)\n\nggplot(size_lm, aes(x = weight, y = length)) +\n  geom_point(color = \"blue\", size = 2, alpha = 0.2) +                  \n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  labs(\n    title = \"Linear regression of zebrafish weight on standard length\",\n    x = \"zebrafish length in cm\",\n    y = \"zebrafish weight in gm\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression-2",
    "href": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Model I and II regression",
    "text": "R INTERLUDE | Model I and II regression\n\nWe can fit a LOESS line\n\n\nlibrary(ggplot2)\n\nggplot(size_lm, aes(x = weight, y = length)) +\n  geom_point(color = \"blue\", size = 2, alpha = 0.2) +                  \n  geom_smooth(method = \"loess\", color = \"red\", se = TRUE) +\n  labs(\n    title = \"Linear regression of zebrafish weight on standard length\",\n    x = \"zebrafish length in cm\",\n    y = \"zebrafish weight in gm\"\n  ) +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#smoothers-and-local-regression",
    "href": "Lecture_Folder/Week6a.html#smoothers-and-local-regression",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Smoothers and local regression",
    "text": "Smoothers and local regression\n\nloess (locally estimated scatterplot smoothing) - fit least squares regression lines to successive subsets of the observations weighted according to their distance from the focal observation.\n\nkernel smoothers - new smoothed y-values are computed as the weighted averages of points within a defined window of the original x-values. Weightings are determined by the type of kernel smoother specified, the larger the window, the greater the degree of smoothing.\n\nsplines - joins together a series of polynomial fits that have been generated after the data is split up into a number of smaller windows."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression-3",
    "href": "Lecture_Folder/Week6a.html#r-interlude-model-i-and-ii-regression-3",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Model I and II regression",
    "text": "R INTERLUDE | Model I and II regression\n\nlibrary(lmodel2)\n\nsize_lm_ModII &lt;- lmodel2(weight ~ length)\n\nRMA was not requested: it will not be computed.\n\n\nNo permutation test will be performed\n\nsize_lm_ModII\n\n\nModel II regression\n\nCall: lmodel2(formula = weight ~ length)\n\nn = 600   r = 0.9574514   r-square = 0.9167132 \nParametric P-values:   2-tailed = 0    1-tailed = 0 \nAngle between the two OLS regression lines = 1.418965 degrees\n\nRegression results\n  Method Intercept    Slope Angle (degrees) P-perm (1-tailed)\n1    OLS  2.421359 3.063034        71.91950                NA\n2     MA  1.662671 3.316382        73.22019                NA\n3    SMA  2.013729 3.199153        72.64166                NA\n\nConfidence intervals\n  Method 2.5%-Intercept 97.5%-Intercept 2.5%-Slope 97.5%-Slope\n1    OLS       2.169579        2.673139   2.988886    3.137182\n2     MA       1.416796        1.897871   3.237842    3.398487\n3    SMA       1.789108        2.233204   3.125864    3.274161\n\nEigenvalues: 28.63954 0.1960763 \n\nH statistic used for computing C.I. of MA: 4.476936e-05 \n\n\n\nYou should also have generated OLS (Ordinary Least Squares), MA (Moving Average), and SMA (Standard Major Axis) regression models, and the last plots SMA line from parameter estimates"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude---on-your-own",
    "href": "Lecture_Folder/Week6a.html#r-interlude---on-your-own",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE - on your own",
    "text": "R INTERLUDE - on your own\n\nSay you measured green fluorescent protein abundance in cell culture across several key, carefully controlled temperatures.\nYou ultimately want to know whether protein expression changes as a function of temperature in your experiment.\nRead in the gfp_temp.tsv data and perform a regression analysis.\nAddress the following questions\n\nWhich is X and which is Y?\nAre residual assumptions met?\nWhat model of regression should we use in this case and why?\nWhat is our decision regarding our null hypothesis of no relationship?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multiple-linear-regression---goals",
    "href": "Lecture_Folder/Week6a.html#multiple-linear-regression---goals",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multiple Linear Regression - Goals",
    "text": "Multiple Linear Regression - Goals\n\nTo develop a better predictive model than is possible from models based on single independent variables.\nTo investigate the relative individual effects of each of the multiple independent variables above and beyond the effects of the other variables.\nThe individual effects of each of the predictor variables on the response variable can be depicted by single partial regression lines.\nThe slope of any single partial regression line (partial regression slope) thereby represents the rate of change or effect of that specific predictor variable (holding all the other predictor variables constant to their respective mean values) on the response variable."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multiple-linear-regression-additive-and-multiplicative-models-of-2-or-more-predictors",
    "href": "Lecture_Folder/Week6a.html#multiple-linear-regression-additive-and-multiplicative-models-of-2-or-more-predictors",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multiple Linear Regression | Additive and multiplicative models of 2 or more predictors",
    "text": "Multiple Linear Regression | Additive and multiplicative models of 2 or more predictors\nAdditive model \\[y_i = \\beta_0 + \\beta_1x_{1} + \\beta_2x_{2} + ... + \\beta_jx_{j} + \\epsilon_i\\]\n\n\nMultiplicative model (with two predictors) \\[y_i = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2 + \\epsilon_i\\]"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multiple-linear-regression-additive-and-multiplicative-models",
    "href": "Lecture_Folder/Week6a.html#multiple-linear-regression-additive-and-multiplicative-models",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multiple Linear Regression | Additive and multiplicative models",
    "text": "Multiple Linear Regression | Additive and multiplicative models"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multiple-linear-regression-assumptions",
    "href": "Lecture_Folder/Week6a.html#multiple-linear-regression-assumptions",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multiple linear regression assumptions",
    "text": "Multiple linear regression assumptions\n\n\nlinearity\nnormality\nhomogeneity of variance\nThe absence of strong multi-collinearity\n\na predictor variable must not be linearly predicted by - or correlated with - any combination of the other predictor variables."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#checking-for-multi-collinearity",
    "href": "Lecture_Folder/Week6a.html#checking-for-multi-collinearity",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "checking for multi-collinearity",
    "text": "checking for multi-collinearity\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nzfish_data &lt;- read.table(\"Drerio_development_complete.csv\", header=T, sep=\",\")\n\nlength &lt;- zfish_data$Length_cm\nweight &lt;- zfish_data$Weight_mg\nage &lt;- zfish_data$Age_Days\npigment &lt;- zfish_data$Pigmentation\n\n\nscatterplotMatrix(~length+pigment+age, diag=\"boxplot\")\n\nWarning in applyDefaults(diagonal, defaults = list(method = \"adaptiveDensity\"),\n: unnamed diag arguments, will be ignored"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-multiple-regression-with-2-predictor-variables",
    "href": "Lecture_Folder/Week6a.html#r-interlude-multiple-regression-with-2-predictor-variables",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | multiple regression with 2 predictor variables",
    "text": "R INTERLUDE | multiple regression with 2 predictor variables\n\nRead in the RNAseq_lipid.tsv and examine the continuous variables.\nWe are interested in whether Gene01 and/or Gene02 expression levels influence lipid content.\nFirst plot \\(Y\\) vs \\(Gene01\\), \\(Y\\) vs \\(Gene02\\), then set up and test a multiplicative model.\nWhat are the parameter estimates of interest in this case?\nWhat are the outcomes from our hypothesis tests?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-multiple-regression-with-2-predictor-variables-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-multiple-regression-with-2-predictor-variables-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | multiple regression with 2 predictor variables",
    "text": "R INTERLUDE | multiple regression with 2 predictor variables\n\nRNAseq_Data &lt;- read.table(\"RNAseq_lipid.tsv\", header=T, sep=\"\\t\")\n\ny &lt;- RNAseq_Data$Lipid_Conc\ng1 &lt;- RNAseq_Data$Gene01\ng2 &lt;- RNAseq_Data$Gene02\ng3 &lt;- RNAseq_Data$Gene03\ng4 &lt;- RNAseq_Data$Gene04\n\nMult_lm &lt;- lm(y ~ g1*g2)\nsummary(Mult_lm)\n\n\nCall:\nlm(formula = y ~ g1 * g2)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.52111 -0.16333 -0.00931  0.21515  0.54255 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.2965521  0.3461603   9.523 5.40e-08 ***\ng1           0.0558232  0.0040117  13.915 2.34e-10 ***\ng2          -0.0082765  0.0290978  -0.284    0.780    \ng1:g2        0.0001702  0.0003199   0.532    0.602    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2997 on 16 degrees of freedom\nMultiple R-squared:  0.9846,    Adjusted R-squared:  0.9817 \nF-statistic: 341.3 on 3 and 16 DF,  p-value: 1.042e-14"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-multiple-regression-with-2-predictor-variables-2",
    "href": "Lecture_Folder/Week6a.html#r-interlude-multiple-regression-with-2-predictor-variables-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | multiple regression with 2 predictor variables",
    "text": "R INTERLUDE | multiple regression with 2 predictor variables\n\nNow get rid of the interaction term, and set up a purely additive model\nDid any of our estimates change? Why?\nDid the degrees of freedom change? Why?\n\n\nAdd_lm &lt;- lm(y ~ g1+g2)\nsummary(Add_lm)\n\n\nAlso try different combinations of genes\nFinally, see if you can make a partial regression plot of just one predictor and the response variable"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial",
    "href": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | adding a polynomial",
    "text": "R INTERLUDE | adding a polynomial\n\nPoly_lm_1 &lt;- lm(y ~ poly(g1, 1))\nsummary(Poly_lm_1)\n\n\nCall:\nlm(formula = y ~ poly(g1, 1))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.50579 -0.18804 -0.03178  0.20893  0.54981 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  7.47450    0.06402  116.75   &lt;2e-16 ***\npoly(g1, 1)  9.58694    0.28631   33.48   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2863 on 18 degrees of freedom\nMultiple R-squared:  0.9842,    Adjusted R-squared:  0.9833 \nF-statistic:  1121 on 1 and 18 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | adding a polynomial",
    "text": "R INTERLUDE | adding a polynomial\n\nPoly_lm_2 &lt;- lm(y ~ poly(g1, 2))\nsummary(Poly_lm_2)\n\n\nCall:\nlm(formula = y ~ poly(g1, 2))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.48903 -0.19681 -0.01246  0.18486  0.54854 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   7.47450    0.06575 113.681   &lt;2e-16 ***\npoly(g1, 2)1  9.58694    0.29404  32.604   &lt;2e-16 ***\npoly(g1, 2)2  0.07566    0.29404   0.257      0.8    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.294 on 17 degrees of freedom\nMultiple R-squared:  0.9843,    Adjusted R-squared:  0.9824 \nF-statistic: 531.5 on 2 and 17 DF,  p-value: 4.725e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial-2",
    "href": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | adding a polynomial",
    "text": "R INTERLUDE | adding a polynomial\n\nPoly_lm_3 &lt;- lm(y ~ poly(g1, 3))\nsummary(Poly_lm_3)\n\n\nCall:\nlm(formula = y ~ poly(g1, 3))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5201 -0.1758 -0.0155  0.1628  0.5170 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   7.47450    0.06720 111.233  &lt; 2e-16 ***\npoly(g1, 3)1  9.58694    0.30051  31.902 6.51e-16 ***\npoly(g1, 3)2  0.07566    0.30051   0.252    0.804    \npoly(g1, 3)3  0.15773    0.30051   0.525    0.607    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3005 on 16 degrees of freedom\nMultiple R-squared:  0.9845,    Adjusted R-squared:  0.9816 \nF-statistic: 339.4 on 3 and 16 DF,  p-value: 1.089e-14"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial-3",
    "href": "Lecture_Folder/Week6a.html#r-interlude-adding-a-polynomial-3",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | adding a polynomial",
    "text": "R INTERLUDE | adding a polynomial\n\nPoly_lm_10 &lt;- lm(y ~ poly(g1, 10))\nsummary(Poly_lm_10)\n\n\nCall:\nlm(formula = y ~ poly(g1, 10))\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.33720 -0.10156  0.00083  0.11606  0.30332 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     7.474500   0.053607 139.431 2.55e-16 ***\npoly(g1, 10)1   9.586936   0.239738  39.989 1.90e-11 ***\npoly(g1, 10)2   0.075656   0.239738   0.316   0.7595    \npoly(g1, 10)3   0.157731   0.239738   0.658   0.5271    \npoly(g1, 10)4  -0.065839   0.239738  -0.275   0.7898    \npoly(g1, 10)5   0.652130   0.239738   2.720   0.0236 *  \npoly(g1, 10)6   0.167389   0.239738   0.698   0.5027    \npoly(g1, 10)7  -0.349566   0.239738  -1.458   0.1788    \npoly(g1, 10)8  -0.007755   0.239738  -0.032   0.9749    \npoly(g1, 10)9   0.036730   0.239738   0.153   0.8816    \npoly(g1, 10)10 -0.588592   0.239738  -2.455   0.0364 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2397 on 9 degrees of freedom\nMultiple R-squared:  0.9945,    Adjusted R-squared:  0.9883 \nF-statistic: 161.6 on 10 and 9 DF,  p-value: 6.533e-09"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#model-selection",
    "href": "Lecture_Folder/Week6a.html#model-selection",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Model selection",
    "text": "Model selection"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#model-selection-the-problems",
    "href": "Lecture_Folder/Week6a.html#model-selection-the-problems",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Model selection | the problems",
    "text": "Model selection | the problems\n\nHow to decide the complexity of polynomial: straight line regression, quadratic, cubic, ….\nWhich variables to keep/ discard when building a multiple regression model?\nSelecting from candidate models representing different biological processes."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#model-selection-a-beetle-example",
    "href": "Lecture_Folder/Week6a.html#model-selection-a-beetle-example",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Model selection | a beetle example",
    "text": "Model selection | a beetle example"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#start-with-linear-regression",
    "href": "Lecture_Folder/Week6a.html#start-with-linear-regression",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Start with linear regression",
    "text": "Start with linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#quadratic-2nd-degree-polynomial",
    "href": "Lecture_Folder/Week6a.html#quadratic-2nd-degree-polynomial",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Quadratic (2nd degree) polynomial?",
    "text": "Quadratic (2nd degree) polynomial?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#quadratic-3rd-degree-polynomial",
    "href": "Lecture_Folder/Week6a.html#quadratic-3rd-degree-polynomial",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Quadratic (3rd degree) polynomial?",
    "text": "Quadratic (3rd degree) polynomial?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#a-polynomial-of-degree-5",
    "href": "Lecture_Folder/Week6a.html#a-polynomial-of-degree-5",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "A polynomial of degree 5?",
    "text": "A polynomial of degree 5?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#a-polynomial-of-degree-10",
    "href": "Lecture_Folder/Week6a.html#a-polynomial-of-degree-10",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "A polynomial of degree 10?",
    "text": "A polynomial of degree 10?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#the-problem-with-this-approach",
    "href": "Lecture_Folder/Week6a.html#the-problem-with-this-approach",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "The problem with this approach",
    "text": "The problem with this approach\n\nThe log likelihood of the model increases with the number of parameters\nSo does \\(r^2\\)\nIsn’t this good - the best fit to the data?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#the-problem-with-this-approach-1",
    "href": "Lecture_Folder/Week6a.html#the-problem-with-this-approach-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "The problem with this approach",
    "text": "The problem with this approach\n\nDoes it violate a principle of parsimony\nFit no more parameters than is necessary.\nIf two or more models fit the data almost equally well, prefer the simpler model.\n\n\n“models should be pared down until they are minimal and adequate”\n\nCrawley 2007, p325"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#lets-consider-our-objectives",
    "href": "Lecture_Folder/Week6a.html#lets-consider-our-objectives",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Let’s consider our objectives",
    "text": "Let’s consider our objectives\n\nModel should predicts well\nApproximates true relationship between the variables\nBe able to evaluate a wider array of models. Not only or more “reduced” models.\nBut an overfitted model may not predict well in the future!"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#a-polynomial-of-degree-10-1",
    "href": "Lecture_Folder/Week6a.html#a-polynomial-of-degree-10-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "A polynomial of degree 10?",
    "text": "A polynomial of degree 10?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#how-do-we-accomplish-these-goals",
    "href": "Lecture_Folder/Week6a.html#how-do-we-accomplish-these-goals",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "How do we accomplish these goals?",
    "text": "How do we accomplish these goals?\nHow to accomplish these goals To answer this, we need\n\nA criterion to compare models:\n\nMallow’s Cp\nAIC (Akaike’s Information Criterion)\nBIC (Bayesian Information Criterion)\n\nA strategy for searching the candidate models"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#how-do-we-accomplish-these-goals-1",
    "href": "Lecture_Folder/Week6a.html#how-do-we-accomplish-these-goals-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "How do we accomplish these goals?",
    "text": "How do we accomplish these goals?\n\nHow to decide the complexity of polynomial: straight line regression, quadratic, cubic, ….\nWhich variables to keep/ discard when building a multiple regression model?\nSelecting from candidate models representing different biological processes."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#section-3",
    "href": "Lecture_Folder/Week6a.html#section-3",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "",
    "text": "MSresiduals- represents the mean amount of variation unexplained by the model, and therefore the lowest value indicates the best fit.\nAdjusted \\(r^2\\) - (the proportion of mean amount of variation in response variable explained by the model) is calculated as adj. r2 which is adjusted for both sample size and the number of terms. Larger values indicate better fit.\nMallow’s Cp - is an index resulting from the comparison of the specific model to a model that contain all the possible terms. Models with the lowest value and/or values closest to their respective p (the number of model terms, including the y-intercept) indicate best fit.\nAkaike Information Criteria (AIC) - there are several different versions of AIC, each of which adds a different constant designed to penalize according to the number of parameters and sample size to a likelihood function to produce a relative measure of the information content of a model. Smaller values indicate more parsimonious models. As a rule of thumb, if the difference between two AIC values (delta AIC) is greater than 2, the lower AIC is a significant improvement in parsimony.\nSchwarz or Bayesian Information Criteria (BIC or SIC) - is outwardly similar to AIC. The constant added to the likelihood function penalizes models with more predictor terms more heavily (and thus select more simple models) than AIC. It is for this reason that BIC is favored by many researchers."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#mallows-cp",
    "href": "Lecture_Folder/Week6a.html#mallows-cp",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Mallow’s Cp",
    "text": "Mallow’s Cp\n\nFrequently used in multiple regression\nTest case: “all subsets regression”\nStrategy: Test all possible models and selection the one with the smallest Cp\nleaps package in R. Smart search among a potentially huge number of models\nTypically we are modeling observational data. Experimental data often allows smart use of variables\nInvestigating all possible subsets of variables = only intelligent decision is choice of variables …."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#mallows-cp-1",
    "href": "Lecture_Folder/Week6a.html#mallows-cp-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Mallow’s Cp",
    "text": "Mallow’s Cp"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#mallows-cp-2",
    "href": "Lecture_Folder/Week6a.html#mallows-cp-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Mallow’s Cp",
    "text": "Mallow’s Cp\nFor prediction: All models with Cp &lt; p predict about equally well. Don’t get carried away with a “best”.\nFor explanation: If numerous equally well fitting models fit the data, it is difficult to deduce which predictor “explains” the response.\nGeneral caveat: “regression is not causation”. Experiment needed to get to causal explanation."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude---model-fitting-of-multiple-linear-regression-example",
    "href": "Lecture_Folder/Week6a.html#r-interlude---model-fitting-of-multiple-linear-regression-example",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE - model fitting of multiple linear regression example",
    "text": "R INTERLUDE - model fitting of multiple linear regression example\n\nxxx\nxxx\nxxx"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-1",
    "href": "Lecture_Folder/Week6a.html#anova-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA",
    "text": "ANOVA\n\nStands for ANalysis of VAriance\nCore statistical procedure in biology\nDeveloped by R.A. Fisher in the early 20th Century\nThe core idea is to ask how much variation exists within vs. among groups\nANOVAs are linear models that have categorical predictor and continuous response variables\nThe categorical predictors are often called factors, and can have two or more levels (important to specify in R)\nEach factor will have a hypothesis test\nThe levels of each factor may also need to be tested"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#an-example---irises-1",
    "href": "Lecture_Folder/Week6a.html#an-example---irises-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "An Example - Irises",
    "text": "An Example - Irises\n\nWe have data from the R package iris\n3 Different species: Iris versicolor, Iris setosa, and Iris virginica"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#an-example---irises-2",
    "href": "Lecture_Folder/Week6a.html#an-example---irises-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "An Example - Irises",
    "text": "An Example - Irises\n\nstripchart(iris$Sepal.Length ~ iris$Species, vertical=T, method=\"jitter\",\n           ylab=\"sepal length\", xlab=\"species\", pch=19, cex=0.5)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anovas-and-hypotheses",
    "href": "Lecture_Folder/Week6a.html#anovas-and-hypotheses",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVAs and Hypotheses",
    "text": "ANOVAs and Hypotheses\n\nAs with any statistical test, we will be testing the probability of accepting or rejecting our null hypothesis, compared to an alternative hypothesis\nWhat are the null and alternative hypotheses for our example?\n\n\\[H_0: \\mu(\\text{versicolor_length\"}) = \\mu(\\text{setosa_length}) = \\mu(\\text{virginica_length})\\]\n\\[H_A: \\mu(\\text{versicolor_length\"}) \\neq \\mu(\\text{setosa_length}) \\neq \\mu(\\text{virginica_length})\\]\n\nNOTE: the alternative hypothesis is that at least one group is different"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-2",
    "href": "Lecture_Folder/Week6a.html#anova-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA",
    "text": "ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-conceptually-similar-to-regression",
    "href": "Lecture_Folder/Week6a.html#anova-conceptually-similar-to-regression",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Conceptually similar to regression",
    "text": "ANOVA | Conceptually similar to regression"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-statistical-results-table",
    "href": "Lecture_Folder/Week6a.html#anova-statistical-results-table",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Statistical results table",
    "text": "ANOVA | Statistical results table"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-f-ratio-calculation",
    "href": "Lecture_Folder/Week6a.html#anova-f-ratio-calculation",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | F-ratio calculation",
    "text": "ANOVA | F-ratio calculation"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-f-ratio-calculation-1",
    "href": "Lecture_Folder/Week6a.html#anova-f-ratio-calculation-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | F-ratio calculation",
    "text": "ANOVA | F-ratio calculation"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#assumptions-of-anova",
    "href": "Lecture_Folder/Week6a.html#assumptions-of-anova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Assumptions of ANOVA",
    "text": "Assumptions of ANOVA\n\nThe response variable (y) is approximately normal in all groups (factor levels)\n\nDeviation from normality O.K. if sample sizes and variances across groups are equal\n\nVariances equal across groups\nObservations within a group are independent\n\nrandomly sampled\nno structuring"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#lets-practice-with-irises",
    "href": "Lecture_Folder/Week6a.html#lets-practice-with-irises",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Let’s practice with irises",
    "text": "Let’s practice with irises\n\nFirst steps, what are the null and alternative hypotheses for our test? (Already done!)\nNext, do our data meet or violate the assumptions of ANOVA tests?\nThen, we can set up our ANOVA\nWhat tests should you run (functions, graphing, etc.) in RStudio to evaluate if the data is O.K. to use in an ANOVA test?\n\nPlot the data for each group as a histogram - is it normally distributed?\nRun variance tests between the groups - do they have equal variance?\nIs our data randomly sampled? Assume yes."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#lets-practice-with-irises-1",
    "href": "Lecture_Folder/Week6a.html#lets-practice-with-irises-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Let’s practice with irises",
    "text": "Let’s practice with irises\n\nset &lt;- subset(iris, Species ==\"setosa\")\nvers &lt;- subset(iris, Species ==\"versicolor\")\nvir &lt;- subset(iris, Species==\"virginica\")\nhist(set$Sepal.Length, main = \"I. setosa\")\n\n\n\n\n\n\n\nhist(vers$Sepal.Length, main = \"I. versicolor\")\n\n\n\n\n\n\n\nhist(vir$Sepal.Length, main=\"I. virginica\")"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#lets-practice-with-irises-2",
    "href": "Lecture_Folder/Week6a.html#lets-practice-with-irises-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Let’s practice with irises",
    "text": "Let’s practice with irises\n\nHow do we interpret these findings?\n\n\niris_aov &lt;- aov(Sepal.Length ~ Species, iris)\nanova(iris_aov)\n\nAnalysis of Variance Table\n\nResponse: Sepal.Length\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nSpecies     2 63.212  31.606  119.26 &lt; 2.2e-16 ***\nResiduals 147 38.956   0.265                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-results",
    "href": "Lecture_Folder/Week6a.html#anova-results",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA results",
    "text": "ANOVA results\n\nSpecies is significantly associated with differences in sepal length!\nThe Mean Square (MS) of our factor (species) explains more of the variance in the response variable (sepal length) than the residuals (random or unmeasured variables)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nonparametric-tests-similar-to-anova",
    "href": "Lecture_Folder/Week6a.html#nonparametric-tests-similar-to-anova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nonparametric tests similar to ANOVA",
    "text": "Nonparametric tests similar to ANOVA\n\nThe Kruskal-Wallis test is robust to non-normality and group variance differences\nCheck out the help page for kruskal.test() and run a model on iris sepal length"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nonparametric-tests-similar-to-anova-1",
    "href": "Lecture_Folder/Week6a.html#nonparametric-tests-similar-to-anova-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nonparametric tests similar to ANOVA",
    "text": "Nonparametric tests similar to ANOVA\n\nAlso a significant difference between species\n\n\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-and-linear-models-1",
    "href": "Lecture_Folder/Week6a.html#anova-and-linear-models-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Anova and linear models",
    "text": "Anova and linear models\n\n\n\nCall:\nlm(formula = iris$Sepal.Length ~ iris$Species)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              5.0060     0.0728  68.762  &lt; 2e-16 ***\niris$Speciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\niris$Speciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#post-hoc-comparisons-1",
    "href": "Lecture_Folder/Week6a.html#post-hoc-comparisons-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Post Hoc Comparisons",
    "text": "Post Hoc Comparisons\n\nSo now you’ve got a significant result that says your groups are different from one another!\nBut how are they different? 2 groups could be the same and 1 is different, or all 3 could be different from each other!"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#post-hoc-comparisons-2",
    "href": "Lecture_Folder/Week6a.html#post-hoc-comparisons-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Post Hoc comparisons",
    "text": "Post Hoc comparisons\n\nThere are several ways to compare groups after an ANOVA\nOne of the most common ways is by Tukey’s tests (Tukey’s range test, Tukey’s honestly significant difference (HSD) test)\nThe function TukeyHSD() in R"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#lets-practice---irises",
    "href": "Lecture_Folder/Week6a.html#lets-practice---irises",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Let’s practice - Irises",
    "text": "Let’s practice - Irises\n\nThe function TukeyHSD() in R\nRun post-hoc analyses on your anova model using TukeyHSD function\n\nCheck out the help page to figure out how to run\n\nHow do you interpret the results?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#lets-practice---irises-1",
    "href": "Lecture_Folder/Week6a.html#lets-practice---irises-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Let’s practice - Irises",
    "text": "Let’s practice - Irises\n\niris_aov &lt;- aov(Sepal.Length ~ Species, iris)\nTukeyHSD(iris_aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sepal.Length ~ Species, data = iris)\n\n$Species\n                      diff       lwr       upr p adj\nversicolor-setosa    0.930 0.6862273 1.1737727     0\nvirginica-setosa     1.582 1.3382273 1.8257727     0\nvirginica-versicolor 0.652 0.4082273 0.8957727     0"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#lets-practice---using-the-categorical-predictor-variables-in-the-zebrafish-data-set",
    "href": "Lecture_Folder/Week6a.html#lets-practice---using-the-categorical-predictor-variables-in-the-zebrafish-data-set",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Let’s practice - using the categorical predictor variables in the zebrafish data set",
    "text": "Let’s practice - using the categorical predictor variables in the zebrafish data set\n\nRead in the data as before\nPick one or two categorical predictor variables to include\nMake sure that R sees them as type factor\nSet up the model and evaluate the overall fit\nDo a post-hoc means test with Tukey’s HSD"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#what-is-a-glm",
    "href": "Lecture_Folder/Week6a.html#what-is-a-glm",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "What is a GLM?",
    "text": "What is a GLM?\n\nGeneral Linear Model (GLM) - two or more continuous variables\nGeneralized Linear Model - used to conduct linear regressions on non-continuous data, and non-normal data\nGeneral Linear Mixed Model (GLMM) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects (for more on this, see Peter Ralph’s Advanced Bio Stats class)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#how-do-we-factor-in-categorical-variables",
    "href": "Lecture_Folder/Week6a.html#how-do-we-factor-in-categorical-variables",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "How do we factor in categorical variables?",
    "text": "How do we factor in categorical variables?\n\nFor a single categorical predictor, we can include effects of each factor level:\n\n\\[ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e \\]\n\nEach factor level (ex: for Wolbachia: Yes or No) becomes it’s own “effector” that will change the value of y\nInstead of x being a continuous numerical value, for categorical data it will be either a 0 or 1"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#a-generalized-linear-model",
    "href": "Lecture_Folder/Week6a.html#a-generalized-linear-model",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "A Generalized Linear Model",
    "text": "A Generalized Linear Model\n\nCheck out the help page in RStudio for glm()"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "href": "Lecture_Folder/Week6a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nSet up a glm() to test for the effect of Wolbachia infection on Recombinant Fraction"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "href": "Lecture_Folder/Week6a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nWhat do these components mean?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#interpreting-the-glm",
    "href": "Lecture_Folder/Week6a.html#interpreting-the-glm",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nWhy is our intercept significant?\n\nRemember that the null hypothesis is a model with an intercept and slope of 0\n\nHow would you interpret the “WolbachiaYes” coefficient, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#second-steps---adding-more-variables",
    "href": "Lecture_Folder/Week6a.html#second-steps---adding-more-variables",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nNow let’s add Food to our model - how does this change our model results?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#second-steps---adding-more-variables-1",
    "href": "Lecture_Folder/Week6a.html#second-steps---adding-more-variables-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#interpreting-the-glm-1",
    "href": "Lecture_Folder/Week6a.html#interpreting-the-glm-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nHow would you interpret the Intercept and Food coefficients, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#interaction-effects-in-glms",
    "href": "Lecture_Folder/Week6a.html#interaction-effects-in-glms",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Interaction effects in GLMs",
    "text": "Interaction effects in GLMs\n\nYou can also model interactions between two categorical variables in glms\n\nWhat if variable x and variable z interact in non-additive ways?\n\nUse the notation x*z in the formula"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#third-steps---adding-interaction-effects",
    "href": "Lecture_Folder/Week6a.html#third-steps---adding-interaction-effects",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nLet’s finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model\nRun the model - what are the results?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#third-steps---adding-interaction-effects-1",
    "href": "Lecture_Folder/Week6a.html#third-steps---adding-interaction-effects-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nHow do we interpret these findings?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#how-do-we-know-which-model-to-use",
    "href": "Lecture_Folder/Week6a.html#how-do-we-know-which-model-to-use",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "How do we know which model to use?",
    "text": "How do we know which model to use?\n\nWant to be careful not to overfit your linear model (give too many variables)\nThe Akaike information criterion (AIC) is a metric for comparing different models to find the best fit\n\nNotice the AIC score in your output?\nFor more on this, take Advanced Bio Stats! Or do some reading on the internet."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multiple-linear-regression---goals-1",
    "href": "Lecture_Folder/Week6a.html#multiple-linear-regression---goals-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multiple Linear Regression - Goals",
    "text": "Multiple Linear Regression - Goals\n\nTo develop a better predictive model than is possible from models based on single independent variables.\nTo investigate the relative individual effects of each of the multiple independent variables above and beyond the effects of the other variables.\nThe individual effects of each of the predictor variables on the response variable can be depicted by single partial regression lines.\nThe slope of any single partial regression line (partial regression slope) thereby represents the rate of change or effect of that specific predictor variable (holding all the other predictor variables constant to their respective mean values) on the response variable."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-one-way-anova",
    "href": "Lecture_Folder/Week6a.html#r-interlude-one-way-anova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | One way ANOVA",
    "text": "R INTERLUDE | One way ANOVA\n\nAgain, use the RNAseq_lip.tsv data again.\nLet’s test for an effect of Population on Gene01 expression levels\nFirst, let’s look at how the data are distributed\n\n\nRNAseq_Data &lt;- read.table('RNAseq_lip.tsv', header=T, sep='\\t')\ng1 &lt;- RNAseq_Data$Gene01\nPop &lt;- RNAseq_Data$Population\nboxplot(g1~Pop, col=c(\"blue\",\"green\"))\n\nOr, to plot all points:\n\nstripchart(g1~Pop, vertical=T, pch=19, col=c(\"blue\",\"green\"), \n           at=c(1.25,1.75), method=\"jitter\", jitter=0.05)\nPop_Anova &lt;- aov(g1 ~ Pop)\nsummary(Pop_Anova)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-one-way-anova-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-one-way-anova-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | One way ANOVA",
    "text": "R INTERLUDE | One way ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-one-or-more-predictor-variables",
    "href": "Lecture_Folder/Week6a.html#anova-one-or-more-predictor-variables",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | One or more predictor variables",
    "text": "ANOVA | One or more predictor variables\n\nOne-way ANOVAs just have a single factor\nMulti-factor ANOVAs\n\nFactorial - two or more factors and their interactions\nNested - the levels of one factor are contained within another level\nThe models can be quite complex\n\nANOVAs use an F-statistic to test factors in a model\n\nRatio of two variances (numerator and denominator)\nThe numerator and denominator d.f. need to be included (e.g. \\(F_{1, 34} = 29.43\\))\n\nDetermining the appropriate test ratios for complex ANOVAs takes some work"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-assumptions",
    "href": "Lecture_Folder/Week6a.html#anova-assumptions",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Assumptions",
    "text": "ANOVA | Assumptions\n\nNormally distributed groups\n\nrobust to non-normality if equal variances and sample sizes\n\nEqual variances across groups\n\nokay if largest-to-smallest variance ratio &lt; 3:1\nproblematic if there is a mean-variance relationship among groups\n\nObservations in a group are independent\n\nrandomly selected\ndon’t confound group with another factor"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-fixed-effects-of-factors",
    "href": "Lecture_Folder/Week6a.html#anova-fixed-effects-of-factors",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Fixed effects of factors",
    "text": "ANOVA | Fixed effects of factors\n\nGroups are predetermined, of direct interest, repeatable.\nFor example:\n\nmedical treatments in a clinical trial\npredetermined doses of a toxin\nage groups in a population\nhabitat, season, etc.\n\nAny conclusions reached in the study about differences among groups can be applied only to the groups included in the study.\nThe results cannot be generalized to other treatments, habitats, etc. not included in the study."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-random-effects-of-factors",
    "href": "Lecture_Folder/Week6a.html#anova-random-effects-of-factors",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors\n\nMeasurements that come in groups. A group can be:\n\na family made up of siblings\na subject measured repeatedly\na transect of quadrats in a sampling survey\na block of an experiment done at a given time\n\nGroups are assumed to be randomly sampled from a population of groups.\nTherefore, conclusions reached about groups can be generalized to the population of groups.\nWith random effects, the variance among groups is the main quantity of interest, not the specific group attributes."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-random-effects-of-factors-1",
    "href": "Lecture_Folder/Week6a.html#anova-random-effects-of-factors-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors\n\nBelow are cases where you are likely to treat factors as random effects\nWhenever your sampling design is nested\n\nquadrats within transects\ntransects within woodlots\nwoodlots within districts\n\nWhenever you divide up plots and apply separate treatments to subplots\nWhenever your replicates are grouped spatially or temporally\n\nin blocks\nin batches\n\nWhenever you take measurements on related individuals\nWhenever you measure subjects or other sampling units repeatedly"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-random-effects-of-factors-2",
    "href": "Lecture_Folder/Week6a.html#anova-random-effects-of-factors-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-random-effects---test-your-understanding",
    "href": "Lecture_Folder/Week6a.html#anova-random-effects---test-your-understanding",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Random effects - test your understanding",
    "text": "ANOVA | Random effects - test your understanding\n\nFactor is sex (Male vs. Female)\nFactor is fish tank (10 tanks in an experiment)\nFactor is family (measure multiple sibs per family)\nFactor is temperature (10 arbitrary temps over natural range)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#anova-caution-about-fixed-vs.-random-effects",
    "href": "Lecture_Folder/Week6a.html#anova-caution-about-fixed-vs.-random-effects",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANOVA | Caution about fixed vs. random effects",
    "text": "ANOVA | Caution about fixed vs. random effects\n\nUsing fixed vs. random effects changes the way that statistical tests are performed in ANOVA\nMost statistical packages assume that all factors are fixed unless you instruct it otherwise\nDesignating factors as random takes extra work and probably a read of the manual\nIn R, lm assumes that all effects are fixed\nFor random effects, use lme instead (part of the nlme package)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#means-for-greater-than-two-factor-levels",
    "href": "Lecture_Folder/Week6a.html#means-for-greater-than-two-factor-levels",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Means for greater than two factor levels?",
    "text": "Means for greater than two factor levels?\n\nThe F-ratio test for a single-factor ANOVA tests for any difference among groups.\nIf we want to understand specific differences, we need further “contrasts”.\nUnplanned comparisons (post hoc):\n\nMultiple comparisons carried out after the results are obtained.\nUsed to find where the differences lie (which means differ from which other means)\nComparisons require protection for inflated Type 1 error rates:\n\nTukey tests: compare all pairs of means and control for multiple comparisons\nScheffé contrasts: compare all combinations of means\n\n\nPlanned comparisons (a priori):\n\nComparisons between group means that were decided when the experiment was designed (not after the data were in)\nMust be few in number to avoid inflating Type 1 error rates"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#planned-a-priori-contrasts",
    "href": "Lecture_Folder/Week6a.html#planned-a-priori-contrasts",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts\n\nA well planned experiment often dictates which comparison of means are of most interest, whereas other comparisons are of no interest.\nBy restricting the comparisons to just the ones of interest, researchers can mitigate the multiple testing problem associated with post-hoc tests.\nSome statisticians argue that, in fact, planned comparisons allow researchers to avoid adjusting p-values all together because each test is therefore unique.\nContrasts can also allow more complicated tests of the relationships among means.\nCoding a priori contrasts in R is quite easy and just depends upon writing the right series of coefficient contrasts."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#planned-a-priori-contrasts-1",
    "href": "Lecture_Folder/Week6a.html#planned-a-priori-contrasts-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#understand-the-coefficients-table",
    "href": "Lecture_Folder/Week6a.html#understand-the-coefficients-table",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Understand the coefficients table",
    "text": "Understand the coefficients table"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-planned-contrasts",
    "href": "Lecture_Folder/Week6a.html#r-interlude-planned-contrasts",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Planned contrasts",
    "text": "R INTERLUDE | Planned contrasts\n\nTake the RNAseq data you’ve examined before and create a new four level genotype by combining genotype and microbiota treatment into a single variable\nThink about how to do this using dplyr functions.\n\n\nRNAseq_Data &lt;- read.table(\"RNAseq.tsv\", header=T, sep='')\n\nx &lt;- RNAseq_Data$categorical_var\ny &lt;- RNAseq_Data$continuous_var1\nz &lt;- RNAseq_Data$continuous_var2\n\n\nSet up the a priori contrasts specifically testing one group mean against another\nThese are just examples - you should figure out the logic of the contrasts\n\n\ncontrasts(x) &lt;- cbind(c(0, 1, 0, -1), c(2, -1, 0, -1), c(-1, -1, 3, -1))\n\n\nConfirm that the contrasts are orthogonal\n\n\nround(crossprod(contrasts(x)), 2)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-planned-contrasts-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-planned-contrasts-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Planned contrasts",
    "text": "R INTERLUDE | Planned contrasts\n\nDefine the contrast labels\n\n\nrnaseq_data_list &lt;- list(x = list(‘xxx vs. xxx’ = 1, ‘xxx vs. xxx’ = 2, ‘xxx vs. xxx’ = 3))\n\n\nThen fit the fixed effect model\n\n\nRNAseq_aov_fixed &lt;- aov(y ~ x)\nplot(RNAseq_aov_fixed)\nboxplot(y ~ x)\nsummary(RNAseq_aov_fixed, split = rnaseq_data_list)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-unplanned-contrasts",
    "href": "Lecture_Folder/Week6a.html#r-interlude-unplanned-contrasts",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Unplanned contrasts",
    "text": "R INTERLUDE | Unplanned contrasts\n\nRemember that this is when you had no hypotheses of differences in means in advance\nRead in the perchlorate data from Week 3\nLet’s assess the effects of the 4 perchlorate levels on T4\nWhich perchlorate levels differ in their effect on T4?\n\n\nperc &lt;- read.table('perchlorate_data.tsv', header=T, sep='\\t')\n\nx &lt;- perc$Perchlorate_Level\ny &lt;- log10(perc$T4_Hormone_Level)\n\nMyANOVA &lt;- aov(y ~ x)\nsummary (MyANOVA)\nboxplot(y ~ x)\n\ninstall.packages(\"multcomp\")\nlibrary(multcomp)\n\nsummary(glht(MyANOVA, linfct = mcp(x = \"Tukey\")))"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multifactor-anova-1",
    "href": "Lecture_Folder/Week6a.html#multifactor-anova-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nNested ANOVA or nested design\n\nfactors might be hierarchical - in other words nested - within one another\nThe sources of variance are therefore hierarchical too\n\nThe factorial ANOVA design is the most common experimental design used to investigate more than one treatment variable\n\nIn a factorial design every combination of treatments from two (or more) treatment variables is investigated.\nThe main purpose of a factorial design is to evaluate possible interactions between variables.\nAn interaction between two explanatory variables means that the effect of one variable on the response depends on the state of a second variable."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "href": "Lecture_Folder/Week6a.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA | Key difference between nested and factorial designs",
    "text": "Multifactor ANOVA | Key difference between nested and factorial designs\n\nNested designs are hierarchical\n\noften contain sub-replicates that are random, uncontrolled, nuisance effects\nbut the nested factors can be of interest too\n\nFactorial designs are\n\nall pairwise combinations,\nand often involve all combinations of factor levels\nwhen each factor is fixed interactions can be assessed\n\nCompletely nested designs therefore have no interaction terms, whereas factorial designs do\nMixed models can have a combination of fixed and random factors that are more complicated"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nested-anova-walking-stick-example",
    "href": "Lecture_Folder/Week6a.html#nested-anova-walking-stick-example",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\n\nExample 1: Study of “repeatability” (simple nested design)\nThe walking stick, Timema cristinae, is a wingless herbivorous insect on plants in chaparral habitats of California.\nNosil and Crespi (2006) measured individuals using digital photographs.\nTo evaluate measurement repeatability they took two separate photographs of each specimen.\nAfter measuring traits on one set of photographs, they repeated the measurements on the second set."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nested-anova-walking-stick-example-1",
    "href": "Lecture_Folder/Week6a.html#nested-anova-walking-stick-example-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\nEach pair of dots represents the two measurements"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nested-anova-walking-stick-example-2",
    "href": "Lecture_Folder/Week6a.html#nested-anova-walking-stick-example-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nested-anova-anova-table-of-results",
    "href": "Lecture_Folder/Week6a.html#nested-anova-anova-table-of-results",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nested ANOVA | ANOVA Table of Results",
    "text": "Nested ANOVA | ANOVA Table of Results"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nesting-logic",
    "href": "Lecture_Folder/Week6a.html#nesting-logic",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nesting Logic",
    "text": "Nesting Logic"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nesting-equations",
    "href": "Lecture_Folder/Week6a.html#nesting-equations",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nesting equations",
    "text": "Nesting equations"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nesting-hypothesis-tests",
    "href": "Lecture_Folder/Week6a.html#nesting-hypothesis-tests",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nesting hypothesis tests",
    "text": "Nesting hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nesting-ms-calculations",
    "href": "Lecture_Folder/Week6a.html#nesting-ms-calculations",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nesting MS calculations",
    "text": "Nesting MS calculations"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#nested-anova-table-of-results",
    "href": "Lecture_Folder/Week6a.html#nested-anova-table-of-results",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Nested ANOVA table of results",
    "text": "Nested ANOVA table of results"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-nested-anova",
    "href": "Lecture_Folder/Week6a.html#r-interlude-nested-anova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-nested-anova-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-nested-anova-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nandrew_data &lt;- read.table('andrew.tsv', header=T, sep=‘\\t')\nhead(andrew_data)\n\n\nThere are four variables: ‘TREAT’, ‘PATCH’, ‘QUAD’ and ‘ALGAE’\nThe main effect factor is TREAT\nMake a simplified factor called TREAT2, in which 0% and 33% are a level called “low” and 66% and 100% are “high”\n\n\nandrew_data$TREAT2 &lt;- factor(c(rep(“low”,40),rep(“high”,40))\n\n\nThe nested factor is PATCH - also need to turn this into a factor\n\n\nandrew_data$PATCH &lt;- factor(andrew_data$PATCH)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-nested-anova-2",
    "href": "Lecture_Folder/Week6a.html#r-interlude-nested-anova-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nIn this case, our response variable is ALGAE\nLook at the distribution of ALGAE for the two levels of TREAT2 using boxplots based on the patch means, which are the replicates in this case.\n\n\nandrew.agg &lt;- with(andrew_data, aggregate(data.frame(ALGAE), \n                  by = list(TREAT2=TREAT2, PATCH=PATCH), mean)\n\nlibrary(nlme)\nandrew.agg &lt;- gsummary(andrew_data, groups=andrew_data$PATCH)\n\nboxplot(ALGAE ~ TREAT2, andrew.agg)\n\n\nEvaluate assumptions based on the boxplots\nIs the design balanced (equal numbers of sub-replicates per PATCH)?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-nested-anova-3",
    "href": "Lecture_Folder/Week6a.html#r-interlude-nested-anova-3",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nRun the nested ANOVA:\n\n\nnested.aov &lt;- aov(ALGAE ~ TREAT2 + Error(PATCH), data=andrew_data)\nsummary(nested.aov)\n\n\nDo we detect an effect of TREAT2 (high vs low sea urchin density)?\nEstimate variance components to assess relative contributions of the random factors\n\n\nlibrary(nlme)\nVarCorr(lme(ALGAE ~ 1, random = ~1 | TREAT2/PATCH, andrew_data))\n\n\nCalculate the % of variation due to between-treatment differences vs. due to among patches within treatment differences.\nSee pg. 302 in Logan if you need help.\nWhat do these variance component estimates tell us???"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multifactor-anova-2",
    "href": "Lecture_Folder/Week6a.html#multifactor-anova-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nFor example, Relyae (2003) looked at how a moderate dose (1.6mg/L) of a commonly used pesticide, carbaryl (Sevin), affected bullfrog tadpole survival.\nIn particular, the experiment asked how the effect of carbaryl depended on whether a native predator, the red-spotted newt, was also present.\nThe newt was caged and could cause no direct harm, but it emitted visual and chemical cues to other tadpoles\nThe experiment was carried out in 10-L tubs (experimental units), each containing 10 tadpoles.\nThe four combinations of pesticide treatment (carbaryl vs. water only) and predator treatment (present or absent) were randomly assigned to tubs.\nThe results showed that survival was high except when pesticide was applied together with the predator.\nThus, the two treatments, predation and pesticide, seem to have interacted."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#multifactor-anova-3",
    "href": "Lecture_Folder/Week6a.html#multifactor-anova-3",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#two-factor-factorial-designs",
    "href": "Lecture_Folder/Week6a.html#two-factor-factorial-designs",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Two Factor Factorial Designs",
    "text": "Two Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#three-factor-factorial-designs",
    "href": "Lecture_Folder/Week6a.html#three-factor-factorial-designs",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Three Factor Factorial Designs",
    "text": "Three Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#factorial-designs-number-of-replicates",
    "href": "Lecture_Folder/Week6a.html#factorial-designs-number-of-replicates",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Factorial Designs | Number of Replicates",
    "text": "Factorial Designs | Number of Replicates"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#model-1-factorial-anova-both-main-effects-fixed",
    "href": "Lecture_Folder/Week6a.html#model-1-factorial-anova-both-main-effects-fixed",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Model 1 factorial ANOVA | both main effects fixed",
    "text": "Model 1 factorial ANOVA | both main effects fixed"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#model-2-factorial-anova-both-main-effects-fixed",
    "href": "Lecture_Folder/Week6a.html#model-2-factorial-anova-both-main-effects-fixed",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Model 2 factorial ANOVA | both main effects fixed",
    "text": "Model 2 factorial ANOVA | both main effects fixed"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#model-2-factorial-anova-both-main-effects-random",
    "href": "Lecture_Folder/Week6a.html#model-2-factorial-anova-both-main-effects-random",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Model 2 factorial ANOVA | both main effects random",
    "text": "Model 2 factorial ANOVA | both main effects random"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#the-mean-squares-for-a-factorial-model",
    "href": "Lecture_Folder/Week6a.html#the-mean-squares-for-a-factorial-model",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "The mean squares for a factorial model",
    "text": "The mean squares for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#the-f-ratios-for-a-factorial-model",
    "href": "Lecture_Folder/Week6a.html#the-f-ratios-for-a-factorial-model",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "The F-ratios for a factorial model",
    "text": "The F-ratios for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#interpretation-significant-main-and-interaction-effects",
    "href": "Lecture_Folder/Week6a.html#interpretation-significant-main-and-interaction-effects",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Interpretation | significant main and interaction effects",
    "text": "Interpretation | significant main and interaction effects"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#interaction-plots",
    "href": "Lecture_Folder/Week6a.html#interaction-plots",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Interaction plots",
    "text": "Interaction plots"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "href": "Lecture_Folder/Week6a.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\n\ncontinuous response variable and two main effect categorical variables\n\n\ngene &lt;- rnadata$Gene80\nmicrobiota &lt;- rnadata$Microbiota\ngenotype &lt;- rnadata$Genotype\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#fit-the-factorial-linear-model-two-different-ways-to-do-the-same-thing",
    "href": "Lecture_Folder/Week6a.html#fit-the-factorial-linear-model-two-different-ways-to-do-the-same-thing",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Fit the factorial linear model | two different ways to do the same thing",
    "text": "Fit the factorial linear model | two different ways to do the same thing\n\nrna_aov &lt;- aov(gene ~ microbiota + genotype + microbiota:genotype)\nrna_aov &lt;- aov(gene ~ microbiota*genotype)\n\n\nExamine the fitted model diagnostics and the ANOVA results table\n\n\nplot(rna_aov)\nsummary(rna_aov)\nanova(rna_aov)\n\n\nWhat are the general results of our hypothesis tests?\nIf there is an interaction, can we understand it by looking at the boxplots?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-2-by-3-fixed-effect-factorial-anova",
    "href": "Lecture_Folder/Week6a.html#r-interlude-2-by-3-fixed-effect-factorial-anova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-3 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-3 fixed effect factorial ANOVA\n\nTry the following code to produce an interaction plot for the response variable cell count.\nIn this case there are 2 genotypes and 3 treatment levels.\nDownload the IntPlot_data file and IntPlot_Example.R\nGo through the R script, get a feel for what it’s doing, and try to produce and interpret the interaction plot."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "href": "Lecture_Folder/Week6a.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Means tests | factor level combinations in multi-factor ANOVA",
    "text": "Means tests | factor level combinations in multi-factor ANOVA\n\nThe F-ratio test for a single-factor ANOVA tests for any difference among groups.\nIf we want to understand specific differences, we need further “contrasts”.\nUnplanned comparisons (post hoc)\nPlanned comparisons (a priori)\nNow we need to make ‘pseudo-factors’ that combine our levels of interest"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#planned-a-priori-contrasts-2",
    "href": "Lecture_Folder/Week6a.html#planned-a-priori-contrasts-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "href": "Lecture_Folder/Week6a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\ncontinuous response and two main effect variables\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\ngene &lt;- rnadata$Gene80\nmicrobiota &lt;- rnadata$Microbiota\ngenotype &lt;- rnadata$Genotype\n\nmake new “pseudo factor,” combining genotype and microbiota\n\ngxm &lt;- interaction(genotype,microbiota)\nlevels(gxm)\nboxplot(gene ~ gxm)\n\nspecify the following 2 contrasts\n\ncontrasts(gxm) &lt;- cbind(c(2, -1, 0, -1), c(-1, -1, 3, -1))"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\nFit the factorial linear model\n\nrna_aov &lt;- aov(gene ~ gxm)\n\nExamine the ANOVA table, using supplied contrasts. Figure out the appropriate titles to give them.\n\nsummary(rna_aov, split = list(gxm = list('xxx'=1,'xxx'=2)))\n\nWhat does the contrast summary tell you about the nature of the interaction?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#attributes-of-mixed-effects-models",
    "href": "Lecture_Folder/Week6a.html#attributes-of-mixed-effects-models",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Attributes of mixed effects models",
    "text": "Attributes of mixed effects models\n\nLinear models that include both fixed and random effects.\nThe model is split into fixed and random parts:\n\nFixed effects influence mean of the response variable Y.\nRandom effects influence the variance of Y.\n\nThere is a different error variance for each level of grouping.\nEstimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.\nP-values for fixed effects are conservative when design unbalanced.\nImplemented in the nlme & lme4 packages in R."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#assumptions-of-mixed-effects-models",
    "href": "Lecture_Folder/Week6a.html#assumptions-of-mixed-effects-models",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Assumptions of mixed-effects models",
    "text": "Assumptions of mixed-effects models\n\nVariation within groups follows a normal distribution with equal variance among groups.\nGroups are randomly sampled from “population” of groups.\nGroup means follow a normal distribution.\nMeasurements within groups are independent."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "href": "Lecture_Folder/Week6a.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects",
    "text": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#general-r-syntax-for-two-factor-factorial-designs",
    "href": "Lecture_Folder/Week6a.html#general-r-syntax-for-two-factor-factorial-designs",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "General R syntax for two factor factorial designs",
    "text": "General R syntax for two factor factorial designs"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "href": "Lecture_Folder/Week6a.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Variance components with 2 random factors using LME4",
    "text": "R INTERLUDE | Variance components with 2 random factors using LME4\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\nvariables excluding first 5 and last 5 observations\n\ngene &lt;- rnadata$Gene80[6:75] \nmicrobiota &lt;- rnadata$Microbiota[6:75]\ngenotype &lt;- rnadata$Genotype[6:75]\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)\n\nEstimate the variance components using Restricted Maximum Likelihood (REML)\n\nlibrary(lme4)\nlmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))\n\nBased on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#brain-body-size-neaderthals-as-compared-to-humans",
    "href": "Lecture_Folder/Week6a.html#brain-body-size-neaderthals-as-compared-to-humans",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "href": "Lecture_Folder/Week6a.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "href": "Lecture_Folder/Week6a.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova",
    "href": "Lecture_Folder/Week6a.html#ancova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA",
    "text": "ANCOVA\n\nAnalysis of covariance - mixture of regression and ANOVA\nResponse is still a normally distributed continuous variable\nOne or more continuous predictor variables (covariates)\nSometimes the covariates are of biological interest\nMost often we want to remove unexplained variance\nIn this way they are similar to a blocking variable in ANOVA\nOperationally, ANCOVA is regular ANOVA in which the group and overall means are replaced by group and overall relationships"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-adjusting-for-the-covariate",
    "href": "Lecture_Folder/Week6a.html#ancova-adjusting-for-the-covariate",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-adjusting-for-the-covariate-1",
    "href": "Lecture_Folder/Week6a.html#ancova-adjusting-for-the-covariate-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-linear-model-with-two-covariates",
    "href": "Lecture_Folder/Week6a.html#ancova-linear-model-with-two-covariates",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Linear model with two covariates",
    "text": "ANCOVA | Linear model with two covariates"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-factor-and-covariate-hypothesis-tests",
    "href": "Lecture_Folder/Week6a.html#ancova-factor-and-covariate-hypothesis-tests",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Factor and covariate hypothesis tests",
    "text": "ANCOVA | Factor and covariate hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-f-ratio-tests",
    "href": "Lecture_Folder/Week6a.html#ancova-f-ratio-tests",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | F ratio tests",
    "text": "ANCOVA | F ratio tests"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-assumptions",
    "href": "Lecture_Folder/Week6a.html#ancova-assumptions",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Assumptions",
    "text": "ANCOVA | Assumptions\n\nThe residuals are normally distributed\nThe residuals show homoscedasticity of variance\nThe residuals are independent of one another\nThe relationship between the response variable and each covariate is linear\nHomogeneity of slopes among the groups\nSimilar covariate ranges among the groups"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-heterogeneous-slopes",
    "href": "Lecture_Folder/Week6a.html#ancova-heterogeneous-slopes",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-heterogeneous-slopes-1",
    "href": "Lecture_Folder/Week6a.html#ancova-heterogeneous-slopes-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes\n\nProblem - adjusting to a mean is difficult or impossible if the slopes are different\nIn essence, the samples for the groups come from two different populations\nA test for homogeneity of slopes can be performed\nThe assumption is tested by looking for a significant interaction term between the categorical response variables and the covariate(s)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#ancova-non-overlapping-range-of-the-covariate",
    "href": "Lecture_Folder/Week6a.html#ancova-non-overlapping-range-of-the-covariate",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "ANCOVA | Non-overlapping range of the covariate",
    "text": "ANCOVA | Non-overlapping range of the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-ancova",
    "href": "Lecture_Folder/Week6a.html#r-interlude-ancova",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nImpacts of sexual activity on male fruitfly longevity\nData from Partridge and Faraquhar (1981)\nLongevity of male measured in response to access to\n\nno females\none virgin\neight virgins\none mated\neight mated\n\nThe male fruit flies also varied in size\nThe males were assigned randomly to each of the treatment levels, and then measured thorax length as a covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-ancova-1",
    "href": "Lecture_Folder/Week6a.html#r-interlude-ancova-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nlongevity_data &lt;- read.table('longevity.csv', header=T, sep=',')\nhead(longevity_data)\n\nVariables\n\nlong &lt;- longevity_data$LONGEVITY\ntreat &lt;- longevity_data$TREATMENT\nthorax &lt;- longevity_data$THORAX\n\n\ncheck to see if the covariate should be included\n\n\nboxplot(long ~ treat)\nplot(long ~ thorax)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-ancova-2",
    "href": "Lecture_Folder/Week6a.html#r-interlude-ancova-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nassess assumptions of normality and homogeneity of variance\n\n\nplot(aov(long ~ thorax + treat ), which = 1)\n\n\n†ry it again with a transformed response variable\n\n\nplot(aov(log10(long) ~ thorax + treat ), which = 1)\n\n\nvisually assess linearity, homogenetiy of slopes and covariate range equality\n\n\nlibrary(lattice)\nprint(xyplot(log10(long) ~ thorax | treat, type = c(\"r\", \"p\")))"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#r-interlude-ancova-3",
    "href": "Lecture_Folder/Week6a.html#r-interlude-ancova-3",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nformally test homogenetiy of slopes by testing the interaction term\n\n\nanova(aov(log10(long) ~ thorax*treat))\n\n\nformally test covariate range disparity by modeling the effect of the treatments on the covariate\n\n\nanova(aov(thorax ~ treat))\n\n\nFINALLY, set up contrasts, fit the additive model and visualize the results (pg. 459 and 460 of your Logan book)\nSummarize the trends in a nice plot (pg. 461 of your Logan book)"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#what-is-an-experimental-study",
    "href": "Lecture_Folder/Week6a.html#what-is-an-experimental-study",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "What is an experimental study?",
    "text": "What is an experimental study?\n\nIn an experimental study the researcher assigns treatments to units\nIn an observational study nature does the assigning of treatments to units\nThe crucial advantage of experiments derives from the random assignment of treatments to units\nRandom assignment, or randomization, minimizes the influence of confounding variables"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#mount-everest-example",
    "href": "Lecture_Folder/Week6a.html#mount-everest-example",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\nSurvival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.\nWhy?"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#mount-everest-example-1",
    "href": "Lecture_Folder/Week6a.html#mount-everest-example-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\n\nOne possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).\nThe other is that the two variables are associated because other variables affect both supplemental oxygen and survival.\nUse of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.\nVariables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called confounding variables\nThey are correlated with the variable of interest, and therefore preventing a decision about cause and effect.\nWith random assignment, no confounding variables will be associated with treatment except by chance."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#clinical-trials",
    "href": "Lecture_Folder/Week6a.html#clinical-trials",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Clinical Trials",
    "text": "Clinical Trials\n\nThe gold standard of experimental designs is the clinical trial\nExperimental design in all areas of biology have been informed by procedures used in clinical trials\nA clinical trial is an experimental study in which two or more treatments are assigned to human subjects\nThe design of clinical trials has been refined because the cost of making a mistake with human subjects is so high\nExperiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#example-of-a-clinical-trial",
    "href": "Lecture_Folder/Week6a.html#example-of-a-clinical-trial",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial\n\nTransmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa\nThe spermicide nonoxynol-9 had shown in vitro activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).\nThey tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.\nData were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.\nTwo gel treatments were assigned randomly to women at each clinic.\nOne gel contained nonoxynol-9 and the other a placebo.\nNeither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#example-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week6a.html#example-of-a-clinical-trial-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#design-components-of-a-clinical-trial",
    "href": "Lecture_Folder/Week6a.html#design-components-of-a-clinical-trial",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\nThe goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.\n\nTo reduce bias, the experiment included:\n\nSimultaneous control group: study included both the treatment of interest and a control group (the women receiving the placebo).\nRandomization: treatments were randomly assigned to women at each clinic.\nBlinding: neither the subjects nor the clinicians knew which women were assigned which treatment."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#design-components-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week6a.html#design-components-of-a-clinical-trial-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\n\nTo reduce the effects of sampling error, the experiment included:\n\nReplication: study was carried out on multiple independent subjects.\nBalance: number of women was nearly equal in the two groups at every clinic.\nBlocking: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”)."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#simultaneous-control-group",
    "href": "Lecture_Folder/Week6a.html#simultaneous-control-group",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Simultaneous control group",
    "text": "Simultaneous control group\n\nIn clinical trials either a placebo or the currently accepted treatment should be provided.\nIn experiments requiring intrusive methods to administer treatment, such as\n\ninjections\nsurgery\nrestraint\nconfinement\n\nthe control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#simultaneous-control-group-1",
    "href": "Lecture_Folder/Week6a.html#simultaneous-control-group-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Simultaneous control group",
    "text": "Simultaneous control group\n\nThe “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.\nIn field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.\nIdeally, the same disturbance should be applied to the control plots."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#randomization",
    "href": "Lecture_Folder/Week6a.html#randomization",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nThe researcher should randomize assignment of treatments to units or subjects\nChance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control\nA completely randomized design is one in which treatments are assigned to all units by randomization"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#randomization-1",
    "href": "Lecture_Folder/Week6a.html#randomization-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nRandomization breaks the association between possible confounding variables and the explanatory variable\nRandomization doesn’t eliminate the variation contributed by confounding variables, only their correlation with treatment\nRandomization ensures that variation from confounding variables is similar between the different treatment groups."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#randomization-2",
    "href": "Lecture_Folder/Week6a.html#randomization-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nRandomization should be carried out using a random process:\n\nList all n subjects, one per row, in a computer spreadsheet.\nUse the computer to give each individual a random number.\nAssign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.\n\nOther ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.\n“Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blinding",
    "href": "Lecture_Folder/Week6a.html#blinding",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nBlinding is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.\nBlinding prevents subjects and researchers from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.\nFor example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding (Ernst and White 1998)."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blinding-1",
    "href": "Lecture_Folder/Week6a.html#blinding-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nIn a single-blind experiment, the subjects are unaware of the treatment that they have been assigned.\nTreatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.\nBlinding can also be a concern in non-human studies where animals respond to stimuli"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blinding-2",
    "href": "Lecture_Folder/Week6a.html#blinding-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nIn a double-blind experiment the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments\n\nResearchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome\nMany response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias\nResearchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blinding-3",
    "href": "Lecture_Folder/Week6a.html#blinding-3",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nReviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).\nExperiments on non–human subjects are also prone to bias from lack of blinding."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blinding-4",
    "href": "Lecture_Folder/Week6a.html#blinding-4",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nBebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.\nBlinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order)."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#replication",
    "href": "Lecture_Folder/Week6a.html#replication",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nThe goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables\nOne way to reduce noise is to make the experimental conditions constant\nIn field experiments, however, highly constant experimental conditions might not be feasible nor desirable\nBy limiting the conditions of an experiment, we also limit the generality of the results\nAnother way to make treatment effects stand out is to include extreme treatments and to replicate the data."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#replication-1",
    "href": "Lecture_Folder/Week6a.html#replication-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nReplication is the assignment of each treatment to multiple, independent experimental units.\nWithout replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.\nStudies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.\nLarger samples mean more information, and more information means better estimates and more powerful tests."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#replication-2",
    "href": "Lecture_Folder/Week6a.html#replication-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nReplication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.\nThe figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#pseudoreplication",
    "href": "Lecture_Folder/Week6a.html#pseudoreplication",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Pseudoreplication",
    "text": "Pseudoreplication"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#balance",
    "href": "Lecture_Folder/Week6a.html#balance",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Balance",
    "text": "Balance\n\nA study design is balanced if all treatments have the same sample size.\nConversely, a design is unbalanced if there are unequal sample sizes between treatments.\nBalance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.\nTo appreciate this, look again at the equation for the standard error of the difference between two treatment means."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#balance-1",
    "href": "Lecture_Folder/Week6a.html#balance-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Balance",
    "text": "Balance\n\nFor a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.\nBalance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blocking",
    "href": "Lecture_Folder/Week6a.html#blocking",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blocking",
    "text": "Blocking\n\nBlocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.\nBlocking essentially repeats the same, completely randomized experiment multiple times, once for each block.\nDifferences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks is discarded."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blocking-paired-designs",
    "href": "Lecture_Folder/Week6a.html#blocking-paired-designs",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs\n\nFor example, consider the design choices for a two-treatment experiment to investigate the effect of clear cutting on salamander density.\nIn the completely randomized (“two-sample”) design we take a random sample of forest plots from the population and then randomly assign each plot to either the clear-cut treatment or the no clear-cut treatment.\nIn the paired design we take a random sample of forest plots and clear-cut a randomly chosen half of each plot, leaving the other half untouched."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blocking-paired-designs-1",
    "href": "Lecture_Folder/Week6a.html#blocking-paired-designs-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs\n\nIn the paired design, measurements on adjacent plot-halves are not independent. This is because they are likely to be similar in soil, water, sunlight, and other conditions that affect the number of salamanders.\nAs a result, we must analyze paired data differently than when every plot is independent of all the others, as in the case of the two-sample design.\nPaired design is usually more powerful than completely randomized design because it controls for a lot of the extraneous variation between plots or sampling units that sometimes obscures the effects we are looking for."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blocking-paired-designs-2",
    "href": "Lecture_Folder/Week6a.html#blocking-paired-designs-2",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#blocking-randomized-complete-block-design",
    "href": "Lecture_Folder/Week6a.html#blocking-randomized-complete-block-design",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Blocking | Randomized complete block design",
    "text": "Blocking | Randomized complete block design\n\nRCB design is analogous to the paired design, but may have more than two treatments. Each treatment is applied once to every block.\nAs in the paired design, treatment effects in a randomized block design are measured by differences between treatments exclusively within blocks.\nBy accounting for some sources of sampling variation blocking can make differences between treatments stand out.\nBlocking is worthwhile if units within blocks are relatively homogeneous, apart from treatment effects, and units belonging to different blocks vary because of environmental or other differences."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#what-if-you-cant-do-experiments",
    "href": "Lecture_Folder/Week6a.html#what-if-you-cant-do-experiments",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "What if you can’t do experiments?",
    "text": "What if you can’t do experiments?\n\nExperimental studies are not always feasible, in which case we must fall back upon observational studies.\nThe best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.\nRandomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.\nTwo strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates)."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#style-of-a-results-section",
    "href": "Lecture_Folder/Week6a.html#style-of-a-results-section",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Style of a results section",
    "text": "Style of a results section\n\nWrite the text of the Results section concisely and objectively.\nThe passive voice will likely dominate here, but use the active voice as much as possible.\nUse the past tense.\nAvoid repetitive paragraph structures. Do not interpret the data here."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#function-of-a-results-section",
    "href": "Lecture_Folder/Week6a.html#function-of-a-results-section",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Function of a results section",
    "text": "Function of a results section\n\nThe function is to objectively present your key results, without interpretation, in an orderly and logical sequence using both text and illustrative materials (Tables and Figures).\nThe results section always begins with text, reporting the key results and referring to figures and tables as you proceed.\nThe text of the Results section should be crafted to follow this sequence and highlight the evidence needed to answer the questions/hypotheses you investigated.\nImportant negative results should be reported, too. Authors usually write the text of the results section based upon the sequence of Tables and Figures."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#summaries-of-the-statistical-analyses",
    "href": "Lecture_Folder/Week6a.html#summaries-of-the-statistical-analyses",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Summaries of the statistical analyses",
    "text": "Summaries of the statistical analyses\nMay appear either in the text (usually parenthetically) or in the relevant Tables or Figures (in the legend or as footnotes to the Table or Figure). Each Table and Figure must be referenced in the text portion of the results, and you must tell the reader what the key result(s) is that each Table or Figure conveys.\n\nTables and Figures are assigned numbers separately and in the sequence that you will refer to them from the text.\n\nThe first Table you refer to is Table 1, the next Table 2 and so forth.\nSimilarly, the first Figure is Figure 1, the next Figure 2, etc.\n\nEach Table or Figure must include a brief description of the results being presented and other necessary information in a legend.\n\nTable legends go above the Table; tables are read from top to bottom.\nFigure legends go below the figure; figures are usually viewed from bottom to top.\n\nWhen referring to a Figure from the text, “Figure” is abbreviated as Fig.,e.g., (Fig. 1. Table is never abbreviated, e.g., Table 1."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#example",
    "href": "Lecture_Folder/Week6a.html#example",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Example",
    "text": "Example\nFor example, suppose you asked the question, “Is the average height of male students the same as female students in a pool of randomly selected Biology majors?” You would first collect height data from large random samples of male and female students. You would then calculate the descriptive statistics for those samples (mean, SD, n, range, etc) and plot these numbers. Suppose you found that male Biology majors are, on average, 12.5 cm taller than female majors; this is the answer to the question. Notice that the outcome of a statistical analysis is not a key result, but rather an analytical tool that helps us understand what is our key result."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#differences-directionality-and-magnitude",
    "href": "Lecture_Folder/Week6a.html#differences-directionality-and-magnitude",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Differences, directionality, and magnitude",
    "text": "Differences, directionality, and magnitude\n\nReport your results so as to provide as much information as possible to the reader about the nature of differences or relationships.\nFor example, if you are testing for differences among groups, and you find a significant difference, it is not sufficient to simply report that “groups A and B were significantly different”. How are they different? How much are they different?\nIt is much more informative to say something like, “Group A individuals were 23% larger than those in Group B”, or, “Group B pups gained weight at twice the rate of Group A pups.”\nReport the direction of differences (greater, larger, smaller, etc) and the magnitude of differences (% difference, how many times, etc.) whenever possible."
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#statistical-results-in-text",
    "href": "Lecture_Folder/Week6a.html#statistical-results-in-text",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nStatistical test summaries (test name, p-value) are usually reported parenthetically in conjunction with the biological results they support. This parenthetical reference should include the statistical test used, the value, degrees of freedom and the level of significance.\nFor example, if you found that the mean height of male Biology majors was significantly larger than that of female Biology majors, you might report this result (in blue) and your statistical conclusion (shown in red) as follows:\n\n“Males (180.5 ± 5.1 cm; n=34) averaged 12.5 cm taller than females (168 ± 7.6 cm; n=34) in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001).”\n\nIf the summary statistics are shown in a figure, the sentence above need not report them specifically, but must include a reference to the figure where they may be seen:\n\n“Males averaged 12.5 cm taller than females in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001; Fig. 1).”"
  },
  {
    "objectID": "Lecture_Folder/Week6a.html#statistical-results-in-text-1",
    "href": "Lecture_Folder/Week6a.html#statistical-results-in-text-1",
    "title": "Week 6a - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nAlways enter the appropriate units when reporting data or summary statistics.\n\nfor an individual value you would write, “the mean length was 10 cm”, or, “the maximum time was 140 min.”\nWhen including a measure of variability, place the unit after the error value, e.g., “…was 10 ± 2.3 m”.\nLikewise place the unit after the last in a series of numbers all having the same unit. For example: “lengths of 5, 10, 15, and 20 m”, or “no differences were observed after 2, 4, 6, or 8 min. of incubation”."
  },
  {
    "objectID": "Lecture_Folder/Week1b.html",
    "href": "Lecture_Folder/Week1b.html",
    "title": "Week 1b - Statistics for Bioengineering",
    "section": "",
    "text": "Intro to Unix and the command line\nScripting\nR & RStudio\nMarkdown\n\nOn Tuesday\n\nGit and GitHub\nExploratory Data Analysis (EDA)\n\n\n\n\n\nIt is incredibly fast and powerful, particularly for repeated actions\nIt allows you to do thousands of ‘clicks’ with single commands\nAbility to analyze large datasets that Excel and other GUIs can’t handle well\nAccess to thousands of free programs made for and by scientists\nThe commands work almost identically across platforms\nAbility to use computer clusters like Talapas\n\n\n\n\n\n\n\ncoding generally involves computer languages that use compilers\n\nC^{++}, Fortran, etc\n\nscripting generally involves computer languages that are interpreted on the fly\n\nPython, R, Julia, etc.\n\ncoding - faster but less flexible; scripting - flexible but slower\nThe distinction between the two has become somewhat fuzzy and most modern analytical pipelines contain a combination of both\n\n\n\n\n\n\n\nWe almost never know the world perfectly, but still want to draw conclusions or make decisions\nWe need to estimate underlying parameters from samples of data\nSometimes we need to test hypotheses using data\nOther times we need to more succinctly summarize and/or visualize large amounts of data\nThere are well known mathematical rules that help us\nStatistics can be done by hand, but computers let us do most of the mathematics quickly\n\n\n\n\n\n\n\nWe want to turn data into conclusions about the world\n\npoint estimates and confidence intervals\nexperimental design\nhypothesis testing\ndata reduction of highly dimensional data\n\nWe need a firm understanding of probability, sampling and distributions"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html",
    "href": "Lecture_Folder/Week6b.html",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#this-week",
    "href": "Lecture_Folder/Week6b.html#this-week",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nModel 1 and 2 regression\nMultiple linear regression\nAnalysis of Variance (ANOVA)\nKey principles of experimental design\nHow to report statistics in papers"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#multiple-linear-regression-additive-and-multiplicative-models-of-2-or-more-predictors",
    "href": "Lecture_Folder/Week6b.html#multiple-linear-regression-additive-and-multiplicative-models-of-2-or-more-predictors",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Multiple Linear Regression | Additive and multiplicative models of 2 or more predictors",
    "text": "Multiple Linear Regression | Additive and multiplicative models of 2 or more predictors\nAdditive model \\[y_i = \\beta_0 + \\beta_1x_{1} + \\beta_2x_{2} + ... + \\beta_jx_{j} + \\epsilon_i\\]\n\n\nMultiplicative model (with two predictors) \\[y_i = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2 + \\epsilon_i\\]"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#multiple-linear-regression-additive-and-multiplicative-models",
    "href": "Lecture_Folder/Week6b.html#multiple-linear-regression-additive-and-multiplicative-models",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Multiple Linear Regression | Additive and multiplicative models",
    "text": "Multiple Linear Regression | Additive and multiplicative models"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#model-selection",
    "href": "Lecture_Folder/Week6b.html#model-selection",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Model selection",
    "text": "Model selection"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#model-selection-the-problems",
    "href": "Lecture_Folder/Week6b.html#model-selection-the-problems",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Model selection | the problems",
    "text": "Model selection | the problems\n\nHow to decide the complexity of polynomial: straight line regression, quadratic, cubic, ….\nWhich variables to keep/ discard when building a multiple regression model?\nSelecting from candidate models representing different biological processes."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#model-selection-a-beetle-example",
    "href": "Lecture_Folder/Week6b.html#model-selection-a-beetle-example",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Model selection | a beetle example",
    "text": "Model selection | a beetle example"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#start-with-linear-regression",
    "href": "Lecture_Folder/Week6b.html#start-with-linear-regression",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Start with linear regression",
    "text": "Start with linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#quadratic-2nd-degree-polynomial",
    "href": "Lecture_Folder/Week6b.html#quadratic-2nd-degree-polynomial",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Quadratic (2nd degree) polynomial?",
    "text": "Quadratic (2nd degree) polynomial?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#a-polynomial-of-degree-10",
    "href": "Lecture_Folder/Week6b.html#a-polynomial-of-degree-10",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "A polynomial of degree 10?",
    "text": "A polynomial of degree 10?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#the-problem-with-this-approach",
    "href": "Lecture_Folder/Week6b.html#the-problem-with-this-approach",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "The problem with this approach",
    "text": "The problem with this approach\n\nThe log likelihood of the model increases with the number of parameters\nSo does \\(r^2\\)\nIsn’t this good - the best fit to the data?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#the-problem-with-this-approach-1",
    "href": "Lecture_Folder/Week6b.html#the-problem-with-this-approach-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "The problem with this approach",
    "text": "The problem with this approach\n\n“models should be pared down until they are minimal and adequate”\n\nCrawley 2007, p325\n\n\n\n\nParsimony - fit no more parameters than is necessary.\nIf two or more models fit the data almost equally well, prefer the simpler model."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#lets-consider-our-goals",
    "href": "Lecture_Folder/Week6b.html#lets-consider-our-goals",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Let’s consider our goals",
    "text": "Let’s consider our goals\n\nModel should predicts well\nApproximates true relationship between the variables\nBe able to evaluate a wider array of models.\nAn overfitted model may not predict well in the future!"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#how-do-we-accomplish-these-goals",
    "href": "Lecture_Folder/Week6b.html#how-do-we-accomplish-these-goals",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "How do we accomplish these goals?",
    "text": "How do we accomplish these goals?\nHow to accomplish these goals To answer this, we need\n\nA criterion to compare models:\n\nAdjusted \\(R^2\\)\nMallow’s Cp\nAIC (Akaike’s Information Criterion)\nBIC (Bayesian Information Criterion)\n\nA strategy for searching the candidate models\n\nForwards\nBackwards\nAll combinations"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#how-do-we-accomplish-these-goals-1",
    "href": "Lecture_Folder/Week6b.html#how-do-we-accomplish-these-goals-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "How do we accomplish these goals?",
    "text": "How do we accomplish these goals?\n\nAdjusted \\(R^2\\)\n\nthe proportion of mean amount of variation in response variable explained by the model\nis adjusted for both sample size and the number of terms.\nLarger values indicate better fit.\n\nMallow’s Cp -\n\nis an index resulting from the comparison of the specific model to a model that contain all the possible terms.\nModels with the lowest value and/or values closest to their respective p (the number of model terms, including the y-intercept) indicate best fit.\nFrequently used in multiple regression\nStrategy: Test all possible models and selection the one with the smallest Cp\nCp ~ P - the model is considered to be a good fit\nCp &gt; P - the model might be missing important factors\nCp &lt; P - the model might be overfitting too many parameters\nleaps package in R does a smart search among models"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#how-do-we-accomplish-these-goals-2",
    "href": "Lecture_Folder/Week6b.html#how-do-we-accomplish-these-goals-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "How do we accomplish these goals?",
    "text": "How do we accomplish these goals?\n\nAkaike Information Criteria (AIC)\n\nThere are several different versions of AIC\nEach version adds a different constant designed to penalize according to the number of parameters and sample size to a likelihood function to produce a relative measure of the information content of a model.\nSignificantly smaller values indicate more parsimonious models.\nAs a rule of thumb, if the difference between two AIC values (delta AIC) is greater than 2, the lower AIC is a significant improvement in parsimony.\n\nBayesian or Schwarz Information Criteria (BIC or SIC)\n\nBIC is outwardly similar to AIC.\nLike AIC, the model with the lowest BIC is typically selected\nThe constant added to the likelihood function penalizes models with more predictor terms more heavily (and thus select more simple models) than AIC.\nIt is for this reason that BIC is favored by many researchers."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude---model-fitting",
    "href": "Lecture_Folder/Week6b.html#r-interlude---model-fitting",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE - model fitting",
    "text": "R INTERLUDE - model fitting\n\nThe MASS library is used for stepAIC and stepBIC\nThe leaps library is used for Mallow's Cp\n\n\nlibrary(MASS)       # for stepAIC\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nlibrary(leaps)      # for regsubsets (Mallow's Cp)\nlibrary(car)        # for vif (optional: multicollinearity)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\nbiomarker_data &lt;- read.table(\"biomarkers.tsv\", header=T, sep=\"\\t\")\n\nfull_model &lt;- lm(biomarker_data$marker1 ~ marker2 + marker3 + marker4 + marker5 + marker6, data = biomarker_data)\nsummary(full_model)\n\n\nCall:\nlm(formula = biomarker_data$marker1 ~ marker2 + marker3 + marker4 + \n    marker5 + marker6, data = biomarker_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-25.0998  -6.2578   0.9321   6.5981  24.5741 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 337.886384  38.716208   8.727 1.19e-15 ***\nmarker2       0.011402   0.014156   0.805   0.4215    \nmarker3       0.965065   0.028644  33.691  &lt; 2e-16 ***\nmarker4      -0.066742   0.034039  -1.961   0.0513 .  \nmarker5       0.008825   0.014098   0.626   0.5321    \nmarker6      -0.008459   0.061264  -0.138   0.8903    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.805 on 194 degrees of freedom\nMultiple R-squared:  0.9737,    Adjusted R-squared:  0.973 \nF-statistic:  1435 on 5 and 194 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#aic-based-stepwise-selection",
    "href": "Lecture_Folder/Week6b.html#aic-based-stepwise-selection",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "AIC-based stepwise selection",
    "text": "AIC-based stepwise selection\n\n### AIC-based stepwise selection ###\n# Stepwise selection using AIC (both directions)\nstep_aic &lt;- stepAIC(full_model, direction = \"both\", trace = FALSE)\nsummary(step_aic)\n\n\nCall:\nlm(formula = biomarker_data$marker1 ~ marker3 + marker4, data = biomarker_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.2069  -5.9493   0.9458   6.4603  24.1383 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 344.29166   36.44220   9.448   &lt;2e-16 ***\nmarker3       0.97655    0.02055  47.521   &lt;2e-16 ***\nmarker4      -0.06788    0.03363  -2.019   0.0449 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.756 on 197 degrees of freedom\nMultiple R-squared:  0.9735,    Adjusted R-squared:  0.9733 \nF-statistic:  3623 on 2 and 197 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#bic-based-stepwise-selection",
    "href": "Lecture_Folder/Week6b.html#bic-based-stepwise-selection",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "BIC-based stepwise selection",
    "text": "BIC-based stepwise selection\n\n### BIC-based stepwise selection ###\n# BIC is calculated as: -2*logLik + log(n)*k\nn &lt;- nrow(biomarker_data)\n#step_bic &lt;- stepAIC(full_model, direction = \"both\", trace = FALSE)\nstep_bic &lt;- stepAIC(full_model, direction = \"both\", k = log(n), trace = FALSE)\nsummary(step_bic)\n\n\nCall:\nlm(formula = biomarker_data$marker1 ~ marker3, data = biomarker_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-25.681  -6.947   1.079   6.938  23.419 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 271.15909    3.95699   68.53   &lt;2e-16 ***\nmarker3       1.01041    0.01196   84.45   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.832 on 198 degrees of freedom\nMultiple R-squared:  0.973, Adjusted R-squared:  0.9729 \nF-statistic:  7132 on 1 and 198 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#mallows-cp-using-all-subsets-regression",
    "href": "Lecture_Folder/Week6b.html#mallows-cp-using-all-subsets-regression",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Mallow’s Cp using all subsets regression",
    "text": "Mallow’s Cp using all subsets regression\n\n### Mallow's Cp using all subsets regression ###\n# Use leaps to compute Mallow's Cp\nleaps_result &lt;- regsubsets(biomarker_data$marker1 ~ ., data = biomarker_data, nvmax = ncol(biomarker_data) - 1)\nleaps_summary &lt;- summary(leaps_result)\n\n# Extract Mallow's Cp values\ncp_values &lt;- leaps_summary$cp\n\n# Find model with minimum Cp\nmin_cp_index &lt;- which.min(cp_values)\nbest_model_vars &lt;- names(coef(leaps_result, min_cp_index))[-1]  # exclude intercept\n\n# Fit model using variables from best Cp\ncp_formula &lt;- as.formula(paste(\"biomarker_data$marker1 ~\", paste(best_model_vars, collapse = \" + \")))\ncp_model &lt;- lm(cp_formula, data = biomarker_data)\nsummary(cp_model)\n\n\nCall:\nlm(formula = cp_formula, data = biomarker_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.2069  -5.9493   0.9458   6.4603  24.1383 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 344.29166   36.44220   9.448   &lt;2e-16 ***\nmarker3       0.97655    0.02055  47.521   &lt;2e-16 ***\nmarker4      -0.06788    0.03363  -2.019   0.0449 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9.756 on 197 degrees of freedom\nMultiple R-squared:  0.9735,    Adjusted R-squared:  0.9733 \nF-statistic:  3623 on 2 and 197 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#comparing-the-models",
    "href": "Lecture_Folder/Week6b.html#comparing-the-models",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Comparing the models",
    "text": "Comparing the models\n\n\n\n--- AIC Model ---\n\n\nbiomarker_data$marker1 ~ marker3 + marker4\n\n\nAIC: 1483.712 \n\n\n--- BIC Model ---\n\n\nbiomarker_data$marker1 ~ marker3\n\n\nBIC: 1495.701 \n\n\n--- Mallow's Cp Model ---\n\n\nbiomarker_data$marker1 ~ marker3 + marker4\n\n\nCp: -0.4337318"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova",
    "href": "Lecture_Folder/Week6b.html#anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA",
    "text": "ANOVA\n\nStands for ANalysis of VAriance\nCore statistical procedure in biology\nDeveloped by R.A. Fisher in the early 20th Century\nThe core idea is to ask how much variation exists within vs. among groups\nANOVAs are linear models that have categorical predictor and continuous response variables\nThe categorical predictors are often called factors, and can have two or more levels (important to specify in R)\nEach factor will have a hypothesis test\nThe levels of each factor may also need to be tested (means tests)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#an-example---irises-1",
    "href": "Lecture_Folder/Week6b.html#an-example---irises-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "An Example - Irises",
    "text": "An Example - Irises\n\nWe have data built into base R\n3 Different species: Iris versicolor, Iris setosa, and Iris virginica\nLength of sepal as a continuous variable\nQuestion - do the species differ in the length of sepals?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#an-example---irises-2",
    "href": "Lecture_Folder/Week6b.html#an-example---irises-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "An Example - Irises",
    "text": "An Example - Irises\n\nstripchart(iris$Sepal.Length ~ iris$Species, vertical=T, method=\"jitter\",\n           ylab=\"sepal length\", xlab=\"species\", pch=19, cex=0.5)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anovas-and-hypotheses",
    "href": "Lecture_Folder/Week6b.html#anovas-and-hypotheses",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVAs and Hypotheses",
    "text": "ANOVAs and Hypotheses\n\nAs with any statistical test, we will be testing the probability of accepting or rejecting our null hypothesis, compared to an alternative hypothesis\nWhat are the null and alternative hypotheses for our example?\n\n\\[ H_0: \\mu(\\text{versicolor_length\"}) = \\mu(\\text{setosa_length}) = \\mu(\\text{virginica_length})  \\]\n\n\\[ H_a: \\mu(\\text{versicolor_length\"}) \\neq \\mu(\\text{setosa_length}) \\neq \\mu(\\text{virginica_length}) \\]\n\nNOTE: the alternative hypothesis is that at least one group is different"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-similar-to-regression",
    "href": "Lecture_Folder/Week6b.html#anova-similar-to-regression",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | similar to regression",
    "text": "ANOVA | similar to regression"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-1",
    "href": "Lecture_Folder/Week6b.html#anova-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA",
    "text": "ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-statistical-results-table",
    "href": "Lecture_Folder/Week6b.html#anova-statistical-results-table",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Statistical results table",
    "text": "ANOVA | Statistical results table"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-f-ratio-calculation",
    "href": "Lecture_Folder/Week6b.html#anova-f-ratio-calculation",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | F-ratio calculation",
    "text": "ANOVA | F-ratio calculation"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-f-ratio-calculation-1",
    "href": "Lecture_Folder/Week6b.html#anova-f-ratio-calculation-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | F-ratio calculation",
    "text": "ANOVA | F-ratio calculation"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#assumptions-of-anova",
    "href": "Lecture_Folder/Week6b.html#assumptions-of-anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Assumptions of ANOVA",
    "text": "Assumptions of ANOVA\n\nThe response variable (y) is approximately normal in all groups (factor levels)\n\nDeviation from normality O.K. if sample sizes and variances across groups are equal\n\nVariances equal across groups\nObservations within a group are independent\n\nrandomly sampled\nno structuring"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#lets-practice-with-irises",
    "href": "Lecture_Folder/Week6b.html#lets-practice-with-irises",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Let’s practice with irises",
    "text": "Let’s practice with irises\n\nFirst steps, what are the null and alternative hypotheses for our test? (Already done!)\nNext, do our data meet or violate the assumptions of ANOVA tests?\nThen, we can set up our ANOVA\nWhat tests should you run (functions, graphing, etc.) in RStudio to evaluate if the data is O.K. to use in an ANOVA test?\n\nPlot the data for each group as a histogram - is it normally distributed?\nRun variance tests between the groups - do they have equal variance?\nIs our data randomly sampled? Assume yes."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#lets-practice-with-irises-1",
    "href": "Lecture_Folder/Week6b.html#lets-practice-with-irises-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Let’s practice with irises",
    "text": "Let’s practice with irises\n\nset &lt;- subset(iris, Species ==\"setosa\")\nvers &lt;- subset(iris, Species ==\"versicolor\")\nvir &lt;- subset(iris, Species==\"virginica\")\nhist(set$Sepal.Length, main = \"I. setosa\")\n\n\n\n\n\n\n\nhist(vers$Sepal.Length, main = \"I. versicolor\")\n\n\n\n\n\n\n\nhist(vir$Sepal.Length, main=\"I. virginica\")"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#lets-practice-with-irises-2",
    "href": "Lecture_Folder/Week6b.html#lets-practice-with-irises-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Let’s practice with irises",
    "text": "Let’s practice with irises\n\niris_aov &lt;- aov(Sepal.Length ~ Species, iris)\nanova(iris_aov)\n\nAnalysis of Variance Table\n\nResponse: Sepal.Length\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nSpecies     2 63.212  31.606  119.26 &lt; 2.2e-16 ***\nResiduals 147 38.956   0.265                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nHow do we interpret these findings?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-results",
    "href": "Lecture_Folder/Week6b.html#anova-results",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA results",
    "text": "ANOVA results\n\nSpecies is significantly associated with differences in sepal length!\nThe Mean Square (MS) of our factor (species) explains more of the variance in the response variable (sepal length) than the residuals (random or unmeasured variables)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nonparametric-tests-similar-to-anova",
    "href": "Lecture_Folder/Week6b.html#nonparametric-tests-similar-to-anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nonparametric tests similar to ANOVA",
    "text": "Nonparametric tests similar to ANOVA\n\nThe Kruskal-Wallis test is robust to non-normality and group variance differences\nCheck out the help page for kruskal.test() and run a model on iris sepal length"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nonparametric-tests-similar-to-anova-1",
    "href": "Lecture_Folder/Week6b.html#nonparametric-tests-similar-to-anova-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nonparametric tests similar to ANOVA",
    "text": "Nonparametric tests similar to ANOVA\n\nAlso a significant difference between species\n\n\nkruskal.test(Sepal.Length ~ Species, iris)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-and-linear-models-1",
    "href": "Lecture_Folder/Week6b.html#anova-and-linear-models-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA and linear models",
    "text": "ANOVA and linear models\n\nsummary(lm(iris$Sepal.Length ~ iris$Species))\n\n\nCall:\nlm(formula = iris$Sepal.Length ~ iris$Species)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              5.0060     0.0728  68.762  &lt; 2e-16 ***\niris$Speciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\niris$Speciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#on-your-own",
    "href": "Lecture_Folder/Week6b.html#on-your-own",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "On your own",
    "text": "On your own\n\nset up an analysis using the biomarker data\nUse the diagnosis categorical variable as the predictor for one of the markers\nNote that you’ll likely need to coerce the varible to be as.factor"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#post-hoc-comparisons",
    "href": "Lecture_Folder/Week6b.html#post-hoc-comparisons",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Post Hoc Comparisons",
    "text": "Post Hoc Comparisons\n\nSo now you’ve got a significant result that says your groups are different from one another!\nBut how are they different? 2 groups could be the same and 1 is different, or all 3 could be different from each other!\nThere are several ways to compare groups after an ANOVA\nOne of the most common ways is by Tukey’s tests (Tukey’s range test, Tukey’s honestly significant difference (HSD) test)\nThe function TukeyHSD() in R"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#lets-practice---using-the-categorical-predictor-variables-in-the-stickleback-data-set",
    "href": "Lecture_Folder/Week6b.html#lets-practice---using-the-categorical-predictor-variables-in-the-stickleback-data-set",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Let’s practice - using the categorical predictor variables in the stickleback data set",
    "text": "Let’s practice - using the categorical predictor variables in the stickleback data set\n\nRead in the data as before\nPick one or two categorical predictor variables to include\nMake sure that R sees them as type factor\nSet up the model and evaluate the overall fit\nDo a post-hoc means test with Tukey’s HSD"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#fitting-the-model",
    "href": "Lecture_Folder/Week6b.html#fitting-the-model",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Fitting the model",
    "text": "Fitting the model\n\nstickle_micro &lt;-read.table(\"Stickle_RNAseq.tsv\", header=T, sep=\"\\t\")\n  \nstickle_micro_anova &lt;- aov(Gene42 ~ Geno.Micro, stickle_micro)\nanova(stickle_micro_anova)\n\nAnalysis of Variance Table\n\nResponse: Gene42\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nGeno.Micro  3 120764   40255  25.328 1.837e-11 ***\nResiduals  76 120789    1589                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#tukeys-posthoc",
    "href": "Lecture_Folder/Week6b.html#tukeys-posthoc",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Tukey’s posthoc",
    "text": "Tukey’s posthoc\n\nTukeyHSD(stickle_micro_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Gene42 ~ Geno.Micro, data = stickle_micro)\n\n$Geno.Micro\n              diff        lwr        upr     p adj\nconvB-convA   50.5   17.38429  83.615711 0.0008090\nmonoA-convA  -29.1  -62.21571   4.015711 0.1051497\nmonoB-convA  -53.9  -87.01571 -20.784289 0.0003145\nmonoA-convB  -79.6 -112.71571 -46.484289 0.0000001\nmonoB-convB -104.4 -137.51571 -71.284289 0.0000000\nmonoB-monoA  -24.8  -57.91571   8.315711 0.2095350"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#plot-of-the-different-levels",
    "href": "Lecture_Folder/Week6b.html#plot-of-the-different-levels",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Plot of the different levels",
    "text": "Plot of the different levels\n\nlibrary(ggplot2)\nggplot(stickle_micro, aes(x = Geno.Micro, y = Gene42)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\") +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", shape = 20, size = 3, color = \"red\") +\n  labs(\n    title = \"Box Plot by Category\",\n    x = \"Category\",\n    y = \"Value\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#on-your-own---irises-and-biomarker-data",
    "href": "Lecture_Folder/Week6b.html#on-your-own---irises-and-biomarker-data",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "On your own - Irises and Biomarker Data",
    "text": "On your own - Irises and Biomarker Data\n\nThe function TukeyHSD() in R\nRun post-hoc analyses on your anova model using TukeyHSD function\n\nCheck out the help page to figure out how to run\n\nHow do you interpret the results?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#lets-practice---irises-and-biomarker-data",
    "href": "Lecture_Folder/Week6b.html#lets-practice---irises-and-biomarker-data",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Let’s practice - Irises and Biomarker Data",
    "text": "Let’s practice - Irises and Biomarker Data\n\niris_aov &lt;- aov(Sepal.Length ~ Species, iris)\nTukeyHSD(iris_aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sepal.Length ~ Species, data = iris)\n\n$Species\n                      diff       lwr       upr p adj\nversicolor-setosa    0.930 0.6862273 1.1737727     0\nvirginica-setosa     1.582 1.3382273 1.8257727     0\nvirginica-versicolor 0.652 0.4082273 0.8957727     0"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#what-is-a-glmm",
    "href": "Lecture_Folder/Week6b.html#what-is-a-glmm",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "What is a GLMM?",
    "text": "What is a GLMM?\n\nGeneral Linear Mixed Model (GLMM) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects (for more on this, see Peter Ralph’s Advanced Bio Stats class)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#how-do-we-factor-in-categorical-variables",
    "href": "Lecture_Folder/Week6b.html#how-do-we-factor-in-categorical-variables",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "How do we factor in categorical variables?",
    "text": "How do we factor in categorical variables?\n\nFor a single categorical predictor, we can include effects of each factor level:\n\n\\[ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e \\]\n\nEach factor level (ex: for Wolbachia: Yes or No) becomes it’s own “effector” that will change the value of y\nInstead of x being a continuous numerical value, for categorical data it will be either a 0 or 1"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#a-generalized-linear-model",
    "href": "Lecture_Folder/Week6b.html#a-generalized-linear-model",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "A Generalized Linear Model",
    "text": "A Generalized Linear Model\n\nCheck out the help page in RStudio for glm()\n\n\nglm(formula = y ~ x1 + x2, family = gaussian(link = \"identity\"))"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "href": "Lecture_Folder/Week6b.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nSet up a glm() to test for the effect of Wolbachia infection on Recombinant Fraction"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "href": "Lecture_Folder/Week6b.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nWhat do these components mean?\n\n\nmodel &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link=\"identity\"))\nsummary(model)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#interpreting-the-glm",
    "href": "Lecture_Folder/Week6b.html#interpreting-the-glm",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nWhy is our intercept significant?\n\nRemember that the null hypothesis is a model with an intercept and slope of 0\n\nHow would you interpret the “WolbachiaYes” coefficient, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#second-steps---adding-more-variables",
    "href": "Lecture_Folder/Week6b.html#second-steps---adding-more-variables",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nNow let’s add Food to our model - how does this change our model results?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#second-steps---adding-more-variables-1",
    "href": "Lecture_Folder/Week6b.html#second-steps---adding-more-variables-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nmodel2 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = \"identity\"))\nsummary(model2)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#interpreting-the-glm-1",
    "href": "Lecture_Folder/Week6b.html#interpreting-the-glm-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nHow would you interpret the Intercept and Food coefficients, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#interaction-effects-in-glms",
    "href": "Lecture_Folder/Week6b.html#interaction-effects-in-glms",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Interaction effects in GLMs",
    "text": "Interaction effects in GLMs\n\nYou can also model interactions between two categorical variables in glms\n\nWhat if variable x and variable z interact in non-additive ways?\n\nUse the notation x*z in the formula"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#third-steps---adding-interaction-effects",
    "href": "Lecture_Folder/Week6b.html#third-steps---adding-interaction-effects",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nLet’s finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model\nRun the model - what are the results?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#third-steps---adding-interaction-effects-1",
    "href": "Lecture_Folder/Week6b.html#third-steps---adding-interaction-effects-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nHow do we interpret these findings?\n\n\nmodel3 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = \"identity\"))\nsummary(model3)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#how-do-we-know-which-model-to-use",
    "href": "Lecture_Folder/Week6b.html#how-do-we-know-which-model-to-use",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "How do we know which model to use?",
    "text": "How do we know which model to use?\n\nWant to be careful not to overfit your linear model (give too many variables)\nThe Akaike information criterion (AIC) is a metric for comparing different models to find the best fit\n\nNotice the AIC score in your output?\nFor more on this, take Advanced Bio Stats! Or do some reading on the internet."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#multiple-linear-regression---goals",
    "href": "Lecture_Folder/Week6b.html#multiple-linear-regression---goals",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Multiple Linear Regression - Goals",
    "text": "Multiple Linear Regression - Goals\n\nTo develop a better predictive model than is possible from models based on single independent variables.\nTo investigate the relative individual effects of each of the multiple independent variables above and beyond the effects of the other variables.\nThe individual effects of each of the predictor variables on the response variable can be depicted by single partial regression lines.\nThe slope of any single partial regression line (partial regression slope) thereby represents the rate of change or effect of that specific predictor variable (holding all the other predictor variables constant to their respective mean values) on the response variable."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-one-way-anova",
    "href": "Lecture_Folder/Week6b.html#r-interlude-one-way-anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | One way ANOVA",
    "text": "R INTERLUDE | One way ANOVA\n\nAgain, use the RNAseq_lip.tsv data again.\nLet’s test for an effect of Population on Gene01 expression levels\nFirst, let’s look at how the data are distributed\n\n\nRNAseq_Data &lt;- read.table('RNAseq_lip.tsv', header=T, sep='\\t')\ng1 &lt;- RNAseq_Data$Gene01\nPop &lt;- RNAseq_Data$Population\nboxplot(g1~Pop, col=c(\"blue\",\"green\"))\n\nOr, to plot all points:\n\nstripchart(g1~Pop, vertical=T, pch=19, col=c(\"blue\",\"green\"), \n           at=c(1.25,1.75), method=\"jitter\", jitter=0.05)\nPop_Anova &lt;- aov(g1 ~ Pop)\nsummary(Pop_Anova)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-one-way-anova-1",
    "href": "Lecture_Folder/Week6b.html#r-interlude-one-way-anova-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | One way ANOVA",
    "text": "R INTERLUDE | One way ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-one-or-more-predictor-variables",
    "href": "Lecture_Folder/Week6b.html#anova-one-or-more-predictor-variables",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | One or more predictor variables",
    "text": "ANOVA | One or more predictor variables\n\nOne-way ANOVAs just have a single factor\nMulti-factor ANOVAs\n\nFactorial - two or more factors and their interactions\nNested - the levels of one factor are contained within another level\nThe models can be quite complex\n\nANOVAs use an F-statistic to test factors in a model\n\nRatio of two variances (numerator and denominator)\nThe numerator and denominator d.f. need to be included (e.g. \\(F_{1, 34} = 29.43\\))\n\nDetermining the appropriate test ratios for complex ANOVAs takes some work"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-assumptions",
    "href": "Lecture_Folder/Week6b.html#anova-assumptions",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Assumptions",
    "text": "ANOVA | Assumptions\n\nNormally distributed groups\n\nrobust to non-normality if equal variances and sample sizes\n\nEqual variances across groups\n\nokay if largest-to-smallest variance ratio &lt; 3:1\nproblematic if there is a mean-variance relationship among groups\n\nObservations in a group are independent\n\nrandomly selected\ndon’t confound group with another factor"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-fixed-effects-of-factors",
    "href": "Lecture_Folder/Week6b.html#anova-fixed-effects-of-factors",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Fixed effects of factors",
    "text": "ANOVA | Fixed effects of factors\n\nGroups are predetermined, of direct interest, repeatable.\nFor example:\n\nmedical treatments in a clinical trial\npredetermined doses of a toxin\nage groups in a population\nhabitat, season, etc.\n\nAny conclusions reached in the study about differences among groups can be applied only to the groups included in the study.\nThe results cannot be generalized to other treatments, habitats, etc. not included in the study."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-random-effects-of-factors",
    "href": "Lecture_Folder/Week6b.html#anova-random-effects-of-factors",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors\n\nMeasurements that come in groups. A group can be:\n\na family made up of siblings\na subject measured repeatedly\na transect of quadrats in a sampling survey\na block of an experiment done at a given time\n\nGroups are assumed to be randomly sampled from a population of groups.\nTherefore, conclusions reached about groups can be generalized to the population of groups.\nWith random effects, the variance among groups is the main quantity of interest, not the specific group attributes."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-random-effects-of-factors-1",
    "href": "Lecture_Folder/Week6b.html#anova-random-effects-of-factors-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors\n\nBelow are cases where you are likely to treat factors as random effects\nWhenever your sampling design is nested\n\nquadrats within transects\ntransects within woodlots\nwoodlots within districts\n\nWhenever you divide up plots and apply separate treatments to subplots\nWhenever your replicates are grouped spatially or temporally\n\nin blocks\nin batches\n\nWhenever you take measurements on related individuals\nWhenever you measure subjects or other sampling units repeatedly"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-random-effects-of-factors-2",
    "href": "Lecture_Folder/Week6b.html#anova-random-effects-of-factors-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-random-effects---test-your-understanding",
    "href": "Lecture_Folder/Week6b.html#anova-random-effects---test-your-understanding",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Random effects - test your understanding",
    "text": "ANOVA | Random effects - test your understanding\n\nFactor is sex (Male vs. Female)\nFactor is fish tank (10 tanks in an experiment)\nFactor is family (measure multiple sibs per family)\nFactor is temperature (10 arbitrary temps over natural range)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#anova-caution-about-fixed-vs.-random-effects",
    "href": "Lecture_Folder/Week6b.html#anova-caution-about-fixed-vs.-random-effects",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANOVA | Caution about fixed vs. random effects",
    "text": "ANOVA | Caution about fixed vs. random effects\n\nUsing fixed vs. random effects changes the way that statistical tests are performed in ANOVA\nMost statistical packages assume that all factors are fixed unless you instruct it otherwise\nDesignating factors as random takes extra work and probably a read of the manual\nIn R, lm assumes that all effects are fixed\nFor random effects, use lme instead (part of the nlme package)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#means-for-greater-than-two-factor-levels",
    "href": "Lecture_Folder/Week6b.html#means-for-greater-than-two-factor-levels",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Means for greater than two factor levels?",
    "text": "Means for greater than two factor levels?\n\nThe F-ratio test for a single-factor ANOVA tests for any difference among groups.\nIf we want to understand specific differences, we need further “contrasts”.\nUnplanned comparisons (post hoc):\n\nMultiple comparisons carried out after the results are obtained.\nUsed to find where the differences lie (which means differ from which other means)\nComparisons require protection for inflated Type 1 error rates:\n\nTukey tests: compare all pairs of means and control for multiple comparisons\nScheffé contrasts: compare all combinations of means\n\n\nPlanned comparisons (a priori):\n\nComparisons between group means that were decided when the experiment was designed (not after the data were in)\nMust be few in number to avoid inflating Type 1 error rates"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#planned-a-priori-contrasts",
    "href": "Lecture_Folder/Week6b.html#planned-a-priori-contrasts",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts\n\nA well planned experiment often dictates which comparison of means are of most interest, whereas other comparisons are of no interest.\nBy restricting the comparisons to just the ones of interest, researchers can mitigate the multiple testing problem associated with post-hoc tests.\nSome statisticians argue that, in fact, planned comparisons allow researchers to avoid adjusting p-values all together because each test is therefore unique.\nContrasts can also allow more complicated tests of the relationships among means.\nCoding a priori contrasts in R is quite easy and just depends upon writing the right series of coefficient contrasts."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#planned-a-priori-contrasts-1",
    "href": "Lecture_Folder/Week6b.html#planned-a-priori-contrasts-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#understand-the-coefficients-table",
    "href": "Lecture_Folder/Week6b.html#understand-the-coefficients-table",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Understand the coefficients table",
    "text": "Understand the coefficients table"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-planned-contrasts",
    "href": "Lecture_Folder/Week6b.html#r-interlude-planned-contrasts",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Planned contrasts",
    "text": "R INTERLUDE | Planned contrasts\n\nTake the RNAseq data you’ve examined before and create a new four level genotype by combining genotype and microbiota treatment into a single variable\nThink about how to do this using dplyr functions.\n\n\nRNAseq_Data &lt;- read.table(\"RNAseq.tsv\", header=T, sep='')\n\nx &lt;- RNAseq_Data$categorical_var\ny &lt;- RNAseq_Data$continuous_var1\nz &lt;- RNAseq_Data$continuous_var2\n\n\nSet up the a priori contrasts specifically testing one group mean against another\nThese are just examples - you should figure out the logic of the contrasts\n\n\ncontrasts(x) &lt;- cbind(c(0, 1, 0, -1), c(2, -1, 0, -1), c(-1, -1, 3, -1))\n\n\nConfirm that the contrasts are orthogonal\n\n\nround(crossprod(contrasts(x)), 2)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-planned-contrasts-1",
    "href": "Lecture_Folder/Week6b.html#r-interlude-planned-contrasts-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Planned contrasts",
    "text": "R INTERLUDE | Planned contrasts\n\nDefine the contrast labels\n\n\nrnaseq_data_list &lt;- list(x = list(‘xxx vs. xxx’ = 1, ‘xxx vs. xxx’ = 2, ‘xxx vs. xxx’ = 3))\n\n\nThen fit the fixed effect model\n\n\nRNAseq_aov_fixed &lt;- aov(y ~ x)\nplot(RNAseq_aov_fixed)\nboxplot(y ~ x)\nsummary(RNAseq_aov_fixed, split = rnaseq_data_list)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-unplanned-contrasts",
    "href": "Lecture_Folder/Week6b.html#r-interlude-unplanned-contrasts",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Unplanned contrasts",
    "text": "R INTERLUDE | Unplanned contrasts\n\nRemember that this is when you had no hypotheses of differences in means in advance\nRead in the perchlorate data from Week 3\nLet’s assess the effects of the 4 perchlorate levels on T4\nWhich perchlorate levels differ in their effect on T4?\n\n\nperc &lt;- read.table('perchlorate_data.tsv', header=T, sep='\\t')\n\nx &lt;- perc$Perchlorate_Level\ny &lt;- log10(perc$T4_Hormone_Level)\n\nMyANOVA &lt;- aov(y ~ x)\nsummary (MyANOVA)\nboxplot(y ~ x)\n\ninstall.packages(\"multcomp\")\nlibrary(multcomp)\n\nsummary(glht(MyANOVA, linfct = mcp(x = \"Tukey\")))"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#multifactor-anova-1",
    "href": "Lecture_Folder/Week6b.html#multifactor-anova-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nNested ANOVA or nested design\n\nfactors might be hierarchical - in other words nested - within one another\nThe sources of variance are therefore hierarchical too\n\nThe factorial ANOVA design is the most common experimental design used to investigate more than one treatment variable\n\nIn a factorial design every combination of treatments from two (or more) treatment variables is investigated.\nThe main purpose of a factorial design is to evaluate possible interactions between variables.\nAn interaction between two explanatory variables means that the effect of one variable on the response depends on the state of a second variable."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "href": "Lecture_Folder/Week6b.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA | Key difference between nested and factorial designs",
    "text": "Multifactor ANOVA | Key difference between nested and factorial designs\n\nNested designs are hierarchical\n\noften contain sub-replicates that are random, uncontrolled, nuisance effects\nbut the nested factors can be of interest too\n\nFactorial designs are\n\nall pairwise combinations,\nand often involve all combinations of factor levels\nwhen each factor is fixed interactions can be assessed\n\nCompletely nested designs therefore have no interaction terms, whereas factorial designs do\nMixed models can have a combination of fixed and random factors that are more complicated"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nested-anova-walking-stick-example",
    "href": "Lecture_Folder/Week6b.html#nested-anova-walking-stick-example",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\n\nExample 1: Study of “repeatability” (simple nested design)\nThe walking stick, Timema cristinae, is a wingless herbivorous insect on plants in chaparral habitats of California.\nNosil and Crespi (2006) measured individuals using digital photographs.\nTo evaluate measurement repeatability they took two separate photographs of each specimen.\nAfter measuring traits on one set of photographs, they repeated the measurements on the second set."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nested-anova-walking-stick-example-1",
    "href": "Lecture_Folder/Week6b.html#nested-anova-walking-stick-example-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\nEach pair of dots represents the two measurements"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nested-anova-walking-stick-example-2",
    "href": "Lecture_Folder/Week6b.html#nested-anova-walking-stick-example-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nested-anova-anova-table-of-results",
    "href": "Lecture_Folder/Week6b.html#nested-anova-anova-table-of-results",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nested ANOVA | ANOVA Table of Results",
    "text": "Nested ANOVA | ANOVA Table of Results"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nesting-logic",
    "href": "Lecture_Folder/Week6b.html#nesting-logic",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nesting Logic",
    "text": "Nesting Logic"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nesting-equations",
    "href": "Lecture_Folder/Week6b.html#nesting-equations",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nesting equations",
    "text": "Nesting equations"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nesting-hypothesis-tests",
    "href": "Lecture_Folder/Week6b.html#nesting-hypothesis-tests",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nesting hypothesis tests",
    "text": "Nesting hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nesting-ms-calculations",
    "href": "Lecture_Folder/Week6b.html#nesting-ms-calculations",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nesting MS calculations",
    "text": "Nesting MS calculations"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#nested-anova-table-of-results",
    "href": "Lecture_Folder/Week6b.html#nested-anova-table-of-results",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Nested ANOVA table of results",
    "text": "Nested ANOVA table of results"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-nested-anova",
    "href": "Lecture_Folder/Week6b.html#r-interlude-nested-anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-nested-anova-1",
    "href": "Lecture_Folder/Week6b.html#r-interlude-nested-anova-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nandrew_data &lt;- read.table('andrew.tsv', header=T, sep=‘\\t')\nhead(andrew_data)\n\n\nThere are four variables: ‘TREAT’, ‘PATCH’, ‘QUAD’ and ‘ALGAE’\nThe main effect factor is TREAT\nMake a simplified factor called TREAT2, in which 0% and 33% are a level called “low” and 66% and 100% are “high”\n\n\nandrew_data$TREAT2 &lt;- factor(c(rep(“low”,40),rep(“high”,40))\n\n\nThe nested factor is PATCH - also need to turn this into a factor\n\n\nandrew_data$PATCH &lt;- factor(andrew_data$PATCH)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-nested-anova-2",
    "href": "Lecture_Folder/Week6b.html#r-interlude-nested-anova-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nIn this case, our response variable is ALGAE\nLook at the distribution of ALGAE for the two levels of TREAT2 using boxplots based on the patch means, which are the replicates in this case.\n\n\nandrew.agg &lt;- with(andrew_data, aggregate(data.frame(ALGAE), \n                  by = list(TREAT2=TREAT2, PATCH=PATCH), mean)\n\nlibrary(nlme)\nandrew.agg &lt;- gsummary(andrew_data, groups=andrew_data$PATCH)\n\nboxplot(ALGAE ~ TREAT2, andrew.agg)\n\n\nEvaluate assumptions based on the boxplots\nIs the design balanced (equal numbers of sub-replicates per PATCH)?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-nested-anova-3",
    "href": "Lecture_Folder/Week6b.html#r-interlude-nested-anova-3",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nRun the nested ANOVA:\n\n\nnested.aov &lt;- aov(ALGAE ~ TREAT2 + Error(PATCH), data=andrew_data)\nsummary(nested.aov)\n\n\nDo we detect an effect of TREAT2 (high vs low sea urchin density)?\nEstimate variance components to assess relative contributions of the random factors\n\n\nlibrary(nlme)\nVarCorr(lme(ALGAE ~ 1, random = ~1 | TREAT2/PATCH, andrew_data))\n\n\nCalculate the % of variation due to between-treatment differences vs. due to among patches within treatment differences.\nSee pg. 302 in Logan if you need help.\nWhat do these variance component estimates tell us???"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#multifactor-anova-2",
    "href": "Lecture_Folder/Week6b.html#multifactor-anova-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nFor example, Relyae (2003) looked at how a moderate dose (1.6mg/L) of a commonly used pesticide, carbaryl (Sevin), affected bullfrog tadpole survival.\nIn particular, the experiment asked how the effect of carbaryl depended on whether a native predator, the red-spotted newt, was also present.\nThe newt was caged and could cause no direct harm, but it emitted visual and chemical cues to other tadpoles\nThe experiment was carried out in 10-L tubs (experimental units), each containing 10 tadpoles.\nThe four combinations of pesticide treatment (carbaryl vs. water only) and predator treatment (present or absent) were randomly assigned to tubs.\nThe results showed that survival was high except when pesticide was applied together with the predator.\nThus, the two treatments, predation and pesticide, seem to have interacted."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#multifactor-anova-3",
    "href": "Lecture_Folder/Week6b.html#multifactor-anova-3",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#two-factor-factorial-designs",
    "href": "Lecture_Folder/Week6b.html#two-factor-factorial-designs",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Two Factor Factorial Designs",
    "text": "Two Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#three-factor-factorial-designs",
    "href": "Lecture_Folder/Week6b.html#three-factor-factorial-designs",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Three Factor Factorial Designs",
    "text": "Three Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#factorial-designs-number-of-replicates",
    "href": "Lecture_Folder/Week6b.html#factorial-designs-number-of-replicates",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Factorial Designs | Number of Replicates",
    "text": "Factorial Designs | Number of Replicates"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#model-1-factorial-anova-both-main-effects-fixed",
    "href": "Lecture_Folder/Week6b.html#model-1-factorial-anova-both-main-effects-fixed",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Model 1 factorial ANOVA | both main effects fixed",
    "text": "Model 1 factorial ANOVA | both main effects fixed"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#model-2-factorial-anova-both-main-effects-fixed",
    "href": "Lecture_Folder/Week6b.html#model-2-factorial-anova-both-main-effects-fixed",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Model 2 factorial ANOVA | both main effects fixed",
    "text": "Model 2 factorial ANOVA | both main effects fixed"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#model-2-factorial-anova-both-main-effects-random",
    "href": "Lecture_Folder/Week6b.html#model-2-factorial-anova-both-main-effects-random",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Model 2 factorial ANOVA | both main effects random",
    "text": "Model 2 factorial ANOVA | both main effects random"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#the-mean-squares-for-a-factorial-model",
    "href": "Lecture_Folder/Week6b.html#the-mean-squares-for-a-factorial-model",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "The mean squares for a factorial model",
    "text": "The mean squares for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#the-f-ratios-for-a-factorial-model",
    "href": "Lecture_Folder/Week6b.html#the-f-ratios-for-a-factorial-model",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "The F-ratios for a factorial model",
    "text": "The F-ratios for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#interpretation-significant-main-and-interaction-effects",
    "href": "Lecture_Folder/Week6b.html#interpretation-significant-main-and-interaction-effects",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Interpretation | significant main and interaction effects",
    "text": "Interpretation | significant main and interaction effects"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#interaction-plots",
    "href": "Lecture_Folder/Week6b.html#interaction-plots",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Interaction plots",
    "text": "Interaction plots"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "href": "Lecture_Folder/Week6b.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\n\ncontinuous response variable and two main effect categorical variables\n\n\ngene &lt;- rnadata$Gene80\nmicrobiota &lt;- rnadata$Microbiota\ngenotype &lt;- rnadata$Genotype\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#fit-the-factorial-linear-model-two-different-ways-to-do-the-same-thing",
    "href": "Lecture_Folder/Week6b.html#fit-the-factorial-linear-model-two-different-ways-to-do-the-same-thing",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Fit the factorial linear model | two different ways to do the same thing",
    "text": "Fit the factorial linear model | two different ways to do the same thing\n\nrna_aov &lt;- aov(gene ~ microbiota + genotype + microbiota:genotype)\nrna_aov &lt;- aov(gene ~ microbiota*genotype)\n\n\nExamine the fitted model diagnostics and the ANOVA results table\n\n\nplot(rna_aov)\nsummary(rna_aov)\nanova(rna_aov)\n\n\nWhat are the general results of our hypothesis tests?\nIf there is an interaction, can we understand it by looking at the boxplots?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-2-by-3-fixed-effect-factorial-anova",
    "href": "Lecture_Folder/Week6b.html#r-interlude-2-by-3-fixed-effect-factorial-anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-3 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-3 fixed effect factorial ANOVA\n\nTry the following code to produce an interaction plot for the response variable cell count.\nIn this case there are 2 genotypes and 3 treatment levels.\nDownload the IntPlot_data file and IntPlot_Example.R\nGo through the R script, get a feel for what it’s doing, and try to produce and interpret the interaction plot."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "href": "Lecture_Folder/Week6b.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Means tests | factor level combinations in multi-factor ANOVA",
    "text": "Means tests | factor level combinations in multi-factor ANOVA\n\nThe F-ratio test for a single-factor ANOVA tests for any difference among groups.\nIf we want to understand specific differences, we need further “contrasts”.\nUnplanned comparisons (post hoc)\nPlanned comparisons (a priori)\nNow we need to make ‘pseudo-factors’ that combine our levels of interest"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#planned-a-priori-contrasts-2",
    "href": "Lecture_Folder/Week6b.html#planned-a-priori-contrasts-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "href": "Lecture_Folder/Week6b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\ncontinuous response and two main effect variables\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\ngene &lt;- rnadata$Gene80\nmicrobiota &lt;- rnadata$Microbiota\ngenotype &lt;- rnadata$Genotype\n\nmake new “pseudo factor,” combining genotype and microbiota\n\ngxm &lt;- interaction(genotype,microbiota)\nlevels(gxm)\nboxplot(gene ~ gxm)\n\nspecify the following 2 contrasts\n\ncontrasts(gxm) &lt;- cbind(c(2, -1, 0, -1), c(-1, -1, 3, -1))"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "href": "Lecture_Folder/Week6b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\nFit the factorial linear model\n\nrna_aov &lt;- aov(gene ~ gxm)\n\nExamine the ANOVA table, using supplied contrasts. Figure out the appropriate titles to give them.\n\nsummary(rna_aov, split = list(gxm = list('xxx'=1,'xxx'=2)))\n\nWhat does the contrast summary tell you about the nature of the interaction?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#attributes-of-mixed-effects-models",
    "href": "Lecture_Folder/Week6b.html#attributes-of-mixed-effects-models",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Attributes of mixed effects models",
    "text": "Attributes of mixed effects models\n\nLinear models that include both fixed and random effects.\nThe model is split into fixed and random parts:\n\nFixed effects influence mean of the response variable Y.\nRandom effects influence the variance of Y.\n\nThere is a different error variance for each level of grouping.\nEstimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.\nP-values for fixed effects are conservative when design unbalanced.\nImplemented in the nlme & lme4 packages in R."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#assumptions-of-mixed-effects-models",
    "href": "Lecture_Folder/Week6b.html#assumptions-of-mixed-effects-models",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Assumptions of mixed-effects models",
    "text": "Assumptions of mixed-effects models\n\nVariation within groups follows a normal distribution with equal variance among groups.\nGroups are randomly sampled from “population” of groups.\nGroup means follow a normal distribution.\nMeasurements within groups are independent."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "href": "Lecture_Folder/Week6b.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects",
    "text": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#general-r-syntax-for-two-factor-factorial-designs",
    "href": "Lecture_Folder/Week6b.html#general-r-syntax-for-two-factor-factorial-designs",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "General R syntax for two factor factorial designs",
    "text": "General R syntax for two factor factorial designs"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "href": "Lecture_Folder/Week6b.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Variance components with 2 random factors using LME4",
    "text": "R INTERLUDE | Variance components with 2 random factors using LME4\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\nvariables excluding first 5 and last 5 observations\n\ngene &lt;- rnadata$Gene80[6:75] \nmicrobiota &lt;- rnadata$Microbiota[6:75]\ngenotype &lt;- rnadata$Genotype[6:75]\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)\n\nEstimate the variance components using Restricted Maximum Likelihood (REML)\n\nlibrary(lme4)\nlmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))\n\nBased on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#brain-body-size-neaderthals-as-compared-to-humans",
    "href": "Lecture_Folder/Week6b.html#brain-body-size-neaderthals-as-compared-to-humans",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "href": "Lecture_Folder/Week6b.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "href": "Lecture_Folder/Week6b.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova",
    "href": "Lecture_Folder/Week6b.html#ancova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA",
    "text": "ANCOVA\n\nAnalysis of covariance - mixture of regression and ANOVA\nResponse is still a normally distributed continuous variable\nOne or more continuous predictor variables (covariates)\nSometimes the covariates are of biological interest\nMost often we want to remove unexplained variance\nIn this way they are similar to a blocking variable in ANOVA\nOperationally, ANCOVA is regular ANOVA in which the group and overall means are replaced by group and overall relationships"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-adjusting-for-the-covariate",
    "href": "Lecture_Folder/Week6b.html#ancova-adjusting-for-the-covariate",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-adjusting-for-the-covariate-1",
    "href": "Lecture_Folder/Week6b.html#ancova-adjusting-for-the-covariate-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-linear-model-with-two-covariates",
    "href": "Lecture_Folder/Week6b.html#ancova-linear-model-with-two-covariates",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Linear model with two covariates",
    "text": "ANCOVA | Linear model with two covariates"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-factor-and-covariate-hypothesis-tests",
    "href": "Lecture_Folder/Week6b.html#ancova-factor-and-covariate-hypothesis-tests",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Factor and covariate hypothesis tests",
    "text": "ANCOVA | Factor and covariate hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-f-ratio-tests",
    "href": "Lecture_Folder/Week6b.html#ancova-f-ratio-tests",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | F ratio tests",
    "text": "ANCOVA | F ratio tests"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-assumptions",
    "href": "Lecture_Folder/Week6b.html#ancova-assumptions",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Assumptions",
    "text": "ANCOVA | Assumptions\n\nThe residuals are normally distributed\nThe residuals show homoscedasticity of variance\nThe residuals are independent of one another\nThe relationship between the response variable and each covariate is linear\nHomogeneity of slopes among the groups\nSimilar covariate ranges among the groups"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-heterogeneous-slopes",
    "href": "Lecture_Folder/Week6b.html#ancova-heterogeneous-slopes",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-heterogeneous-slopes-1",
    "href": "Lecture_Folder/Week6b.html#ancova-heterogeneous-slopes-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes\n\nProblem - adjusting to a mean is difficult or impossible if the slopes are different\nIn essence, the samples for the groups come from two different populations\nA test for homogeneity of slopes can be performed\nThe assumption is tested by looking for a significant interaction term between the categorical response variables and the covariate(s)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#ancova-non-overlapping-range-of-the-covariate",
    "href": "Lecture_Folder/Week6b.html#ancova-non-overlapping-range-of-the-covariate",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "ANCOVA | Non-overlapping range of the covariate",
    "text": "ANCOVA | Non-overlapping range of the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-ancova",
    "href": "Lecture_Folder/Week6b.html#r-interlude-ancova",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nImpacts of sexual activity on male fruitfly longevity\nData from Partridge and Faraquhar (1981)\nLongevity of male measured in response to access to\n\nno females\none virgin\neight virgins\none mated\neight mated\n\nThe male fruit flies also varied in size\nThe males were assigned randomly to each of the treatment levels, and then measured thorax length as a covariate"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-ancova-1",
    "href": "Lecture_Folder/Week6b.html#r-interlude-ancova-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nlongevity_data &lt;- read.table('longevity.csv', header=T, sep=',')\nhead(longevity_data)\n\nVariables\n\nlong &lt;- longevity_data$LONGEVITY\ntreat &lt;- longevity_data$TREATMENT\nthorax &lt;- longevity_data$THORAX\n\n\ncheck to see if the covariate should be included\n\n\nboxplot(long ~ treat)\nplot(long ~ thorax)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-ancova-2",
    "href": "Lecture_Folder/Week6b.html#r-interlude-ancova-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nassess assumptions of normality and homogeneity of variance\n\n\nplot(aov(long ~ thorax + treat ), which = 1)\n\n\n†ry it again with a transformed response variable\n\n\nplot(aov(log10(long) ~ thorax + treat ), which = 1)\n\n\nvisually assess linearity, homogenetiy of slopes and covariate range equality\n\n\nlibrary(lattice)\nprint(xyplot(log10(long) ~ thorax | treat, type = c(\"r\", \"p\")))"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#r-interlude-ancova-3",
    "href": "Lecture_Folder/Week6b.html#r-interlude-ancova-3",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nformally test homogenetiy of slopes by testing the interaction term\n\n\nanova(aov(log10(long) ~ thorax*treat))\n\n\nformally test covariate range disparity by modeling the effect of the treatments on the covariate\n\n\nanova(aov(thorax ~ treat))\n\n\nFINALLY, set up contrasts, fit the additive model and visualize the results (pg. 459 and 460 of your Logan book)\nSummarize the trends in a nice plot (pg. 461 of your Logan book)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#what-is-an-experimental-study",
    "href": "Lecture_Folder/Week6b.html#what-is-an-experimental-study",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "What is an experimental study?",
    "text": "What is an experimental study?\n\nIn an experimental study the researcher assigns treatments to units\nIn an observational study nature does the assigning of treatments to units\nThe crucial advantage of experiments derives from the random assignment of treatments to units\nRandom assignment, or randomization, minimizes the influence of confounding variables\nCan infer cause and effect more easily"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#key-components-of-a-good-experiment",
    "href": "Lecture_Folder/Week6b.html#key-components-of-a-good-experiment",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Key components of a good experiment",
    "text": "Key components of a good experiment\nAn experiment is when two or more treatment groups are assigned to research units - randomization - research units are assigne at random to tratment groups in one of several ways. In particular neither the researcher or the unit should decide who gets the treatment - control - different treatemnt groups are as identical as posible, ecept for the specfic treatment they receive. A lack of controls can lead to confounding variables. Note the placebo effect. - replication - repeated to be able to estimate sampling variation. Different types of random sampling depending upon the nature of the experiment - blinding - single or better yet double blind - neither the subject nor the"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#mount-everest-example",
    "href": "Lecture_Folder/Week6b.html#mount-everest-example",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\nSurvival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.\nWhy?"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#mount-everest-example-1",
    "href": "Lecture_Folder/Week6b.html#mount-everest-example-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\n\nOne possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).\nThe other is that the two variables are associated because other variables affect both supplemental oxygen and survival.\nUse of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.\nVariables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called confounding variables\nThey are correlated with the variable of interest, and therefore preventing a decision about cause and effect.\nWith random assignment, no confounding variables will be associated with treatment except by chance."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#clinical-trials",
    "href": "Lecture_Folder/Week6b.html#clinical-trials",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Clinical Trials",
    "text": "Clinical Trials\n\nThe gold standard of experimental designs is the clinical trial\nExperimental design in all areas of biology have been informed by procedures used in clinical trials\nA clinical trial is an experimental study in which two or more treatments are assigned to human subjects\nThe design of clinical trials has been refined because the cost of making a mistake with human subjects is so high\nExperiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#example-of-a-clinical-trial",
    "href": "Lecture_Folder/Week6b.html#example-of-a-clinical-trial",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial\n\nTransmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa\nThe spermicide nonoxynol-9 had shown in vitro activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).\nThey tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.\nData were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.\nTwo gel treatments were assigned randomly to women at each clinic.\nOne gel contained nonoxynol-9 and the other a placebo.\nNeither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#example-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week6b.html#example-of-a-clinical-trial-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#design-components-of-a-clinical-trial",
    "href": "Lecture_Folder/Week6b.html#design-components-of-a-clinical-trial",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\nThe goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.\n\nTo reduce bias, the experiment included:\n\nSimultaneous control group: study included both the treatment of interest and a control group (the women receiving the placebo).\nRandomization: treatments were randomly assigned to women at each clinic.\nBlinding: neither the subjects nor the clinicians knew which women were assigned which treatment."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#design-components-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week6b.html#design-components-of-a-clinical-trial-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\n\nTo reduce the effects of sampling error, the experiment included:\n\nReplication: study was carried out on multiple independent subjects.\nBalance: number of women was nearly equal in the two groups at every clinic.\nBlocking: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”)."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#simultaneous-control-group",
    "href": "Lecture_Folder/Week6b.html#simultaneous-control-group",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Simultaneous control group",
    "text": "Simultaneous control group\n\nIn clinical trials either a placebo or the currently accepted treatment should be provided.\nIn experiments requiring intrusive methods to administer treatment, such as\n\ninjections\nsurgery\nrestraint\nconfinement\n\nthe control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#simultaneous-control-group-1",
    "href": "Lecture_Folder/Week6b.html#simultaneous-control-group-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Simultaneous control group",
    "text": "Simultaneous control group\n\nThe “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.\nIn field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.\nIdeally, the same disturbance should be applied to the control plots."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#randomization",
    "href": "Lecture_Folder/Week6b.html#randomization",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nThe researcher should randomize assignment of treatments to units or subjects\nChance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control\nA completely randomized design is one in which treatments are assigned to all units by randomization"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#randomization-1",
    "href": "Lecture_Folder/Week6b.html#randomization-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nRandomization breaks the association between possible confounding variables and the explanatory variable\nRandomization doesn’t eliminate the variation contributed by confounding variables, only their correlation with treatment\nRandomization ensures that variation from confounding variables is similar between the different treatment groups."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#randomization-2",
    "href": "Lecture_Folder/Week6b.html#randomization-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nRandomization should be carried out using a random process:\n\nList all n subjects, one per row, in a computer spreadsheet.\nUse the computer to give each individual a random number.\nAssign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.\n\nOther ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.\n“Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#randomization-types",
    "href": "Lecture_Folder/Week6b.html#randomization-types",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Randomization Types",
    "text": "Randomization Types\n\nCompletely randomized design - all subjects are placed to treatment or control with equal probability\nRandomized block - first broken into gropus (e.g. age or gender) then assigend to tratment groups at random\nMathced pair design - sujects are paired by similarity before being randoly assigned to treatment groups"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#sampling-approaches",
    "href": "Lecture_Folder/Week6b.html#sampling-approaches",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Sampling approaches",
    "text": "Sampling approaches\n\nsimple random sample - every sample has equal probability of being chosen\nstratified sample - divvided into groups then a simple random sample are taken from each\ncluster sample - divided into similar gropu, usually naturally occure, a simple random samples of clusters is then taken and very member of the cluster is included in the sample\nmultistage sampling - combines the above. First clusters are random sampled. Second random samples are take from each. Then process is repeated\nsystematic sample - members of a sample are chosen in a pre-determiend ways. e.g Choose everyth 20th person coming into a store"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#bias-in-experiments",
    "href": "Lecture_Folder/Week6b.html#bias-in-experiments",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Bias in experiments",
    "text": "Bias in experiments\n\nlack of control\nlac of blinidng\nlack of reandomiztaion"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#bias-in-surveys",
    "href": "Lecture_Folder/Week6b.html#bias-in-surveys",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Bias in surveys",
    "text": "Bias in surveys\n\nsamplign bias - not all members of the ppulation or cluster are equally likely\nnon-response bias - xxx\nasymmetric questions - xxx\nsocial desirability bias - xxx"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#statistical-sampling",
    "href": "Lecture_Folder/Week6b.html#statistical-sampling",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Statistical sampling",
    "text": "Statistical sampling\n\ncensuse - collect ifnormation from a completel population of interest\nsampling bad ways\n\nanecdotal evidence\nconveience sample - easily acessible (say students in a class\nRandom sample - a random process is used, and the point is to avoid bias\n\n\n)"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blinding",
    "href": "Lecture_Folder/Week6b.html#blinding",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nBlinding is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.\nBlinding prevents subjects and researchers from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.\nFor example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding (Ernst and White 1998)."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blinding-1",
    "href": "Lecture_Folder/Week6b.html#blinding-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nIn a single-blind experiment, the subjects are unaware of the treatment that they have been assigned.\nTreatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.\nBlinding can also be a concern in non-human studies where animals respond to stimuli"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blinding-2",
    "href": "Lecture_Folder/Week6b.html#blinding-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nIn a double-blind experiment the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments\n\nResearchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome\nMany response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias\nResearchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blinding-3",
    "href": "Lecture_Folder/Week6b.html#blinding-3",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nReviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).\nExperiments on non–human subjects are also prone to bias from lack of blinding."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blinding-4",
    "href": "Lecture_Folder/Week6b.html#blinding-4",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nBebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.\nBlinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order)."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#replication",
    "href": "Lecture_Folder/Week6b.html#replication",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nThe goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables\nOne way to reduce noise is to make the experimental conditions constant\nIn field experiments, however, highly constant experimental conditions might not be feasible nor desirable\nBy limiting the conditions of an experiment, we also limit the generality of the results\nAnother way to make treatment effects stand out is to include extreme treatments and to replicate the data."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#replication-1",
    "href": "Lecture_Folder/Week6b.html#replication-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nReplication is the assignment of each treatment to multiple, independent experimental units.\nWithout replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.\nStudies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.\nLarger samples mean more information, and more information means better estimates and more powerful tests."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#replication-2",
    "href": "Lecture_Folder/Week6b.html#replication-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nReplication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.\nThe figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#pseudoreplication",
    "href": "Lecture_Folder/Week6b.html#pseudoreplication",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Pseudoreplication",
    "text": "Pseudoreplication"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#balance",
    "href": "Lecture_Folder/Week6b.html#balance",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Balance",
    "text": "Balance\n\nA study design is balanced if all treatments have the same sample size.\nConversely, a design is unbalanced if there are unequal sample sizes between treatments.\nBalance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.\nTo appreciate this, look again at the equation for the standard error of the difference between two treatment means."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#balance-1",
    "href": "Lecture_Folder/Week6b.html#balance-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Balance",
    "text": "Balance\n\nFor a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.\nBalance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blocking",
    "href": "Lecture_Folder/Week6b.html#blocking",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blocking",
    "text": "Blocking\n\nBlocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.\nBlocking essentially repeats the same, completely randomized experiment multiple times, once for each block.\nDifferences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks is discarded."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blocking-paired-designs",
    "href": "Lecture_Folder/Week6b.html#blocking-paired-designs",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs\n\nFor example, consider the design choices for a two-treatment experiment to investigate the effect of clear cutting on salamander density.\nIn the completely randomized (“two-sample”) design we take a random sample of forest plots from the population and then randomly assign each plot to either the clear-cut treatment or the no clear-cut treatment.\nIn the paired design we take a random sample of forest plots and clear-cut a randomly chosen half of each plot, leaving the other half untouched."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blocking-paired-designs-1",
    "href": "Lecture_Folder/Week6b.html#blocking-paired-designs-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs\n\nIn the paired design, measurements on adjacent plot-halves are not independent. This is because they are likely to be similar in soil, water, sunlight, and other conditions that affect the number of salamanders.\nAs a result, we must analyze paired data differently than when every plot is independent of all the others, as in the case of the two-sample design.\nPaired design is usually more powerful than completely randomized design because it controls for a lot of the extraneous variation between plots or sampling units that sometimes obscures the effects we are looking for."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blocking-paired-designs-2",
    "href": "Lecture_Folder/Week6b.html#blocking-paired-designs-2",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#blocking-randomized-complete-block-design",
    "href": "Lecture_Folder/Week6b.html#blocking-randomized-complete-block-design",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Blocking | Randomized complete block design",
    "text": "Blocking | Randomized complete block design\n\nRCB design is analogous to the paired design, but may have more than two treatments. Each treatment is applied once to every block.\nAs in the paired design, treatment effects in a randomized block design are measured by differences between treatments exclusively within blocks.\nBy accounting for some sources of sampling variation blocking can make differences between treatments stand out.\nBlocking is worthwhile if units within blocks are relatively homogeneous, apart from treatment effects, and units belonging to different blocks vary because of environmental or other differences."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#what-if-you-cant-do-experiments",
    "href": "Lecture_Folder/Week6b.html#what-if-you-cant-do-experiments",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "What if you can’t do experiments?",
    "text": "What if you can’t do experiments?\n\nExperimental studies are not always feasible, in which case we must fall back upon observational studies.\nThe best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.\nRandomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.\nTwo strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates)."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#style-of-a-results-section",
    "href": "Lecture_Folder/Week6b.html#style-of-a-results-section",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Style of a results section",
    "text": "Style of a results section\n\nWrite the text of the Results section concisely and objectively.\nThe passive voice will likely dominate here, but use the active voice as much as possible.\nUse the past tense.\nAvoid repetitive paragraph structures. Do not interpret the data here."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#function-of-a-results-section",
    "href": "Lecture_Folder/Week6b.html#function-of-a-results-section",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Function of a results section",
    "text": "Function of a results section\n\nThe function is to objectively present your key results, without interpretation, in an orderly and logical sequence using both text and illustrative materials (Tables and Figures).\nThe results section always begins with text, reporting the key results and referring to figures and tables as you proceed.\nThe text of the Results section should be crafted to follow this sequence and highlight the evidence needed to answer the questions/hypotheses you investigated.\nImportant negative results should be reported, too. Authors usually write the text of the results section based upon the sequence of Tables and Figures."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#summaries-of-the-statistical-analyses",
    "href": "Lecture_Folder/Week6b.html#summaries-of-the-statistical-analyses",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Summaries of the statistical analyses",
    "text": "Summaries of the statistical analyses\nMay appear either in the text (usually parenthetically) or in the relevant Tables or Figures (in the legend or as footnotes to the Table or Figure). Each Table and Figure must be referenced in the text portion of the results, and you must tell the reader what the key result(s) is that each Table or Figure conveys.\n\nTables and Figures are assigned numbers separately and in the sequence that you will refer to them from the text.\n\nThe first Table you refer to is Table 1, the next Table 2 and so forth.\nSimilarly, the first Figure is Figure 1, the next Figure 2, etc.\n\nEach Table or Figure must include a brief description of the results being presented and other necessary information in a legend.\n\nTable legends go above the Table; tables are read from top to bottom.\nFigure legends go below the figure; figures are usually viewed from bottom to top.\n\nWhen referring to a Figure from the text, “Figure” is abbreviated as Fig.,e.g., (Fig. 1. Table is never abbreviated, e.g., Table 1."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#example",
    "href": "Lecture_Folder/Week6b.html#example",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Example",
    "text": "Example\nFor example, suppose you asked the question, “Is the average height of male students the same as female students in a pool of randomly selected Biology majors?” You would first collect height data from large random samples of male and female students. You would then calculate the descriptive statistics for those samples (mean, SD, n, range, etc) and plot these numbers. Suppose you found that male Biology majors are, on average, 12.5 cm taller than female majors; this is the answer to the question. Notice that the outcome of a statistical analysis is not a key result, but rather an analytical tool that helps us understand what is our key result."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#differences-directionality-and-magnitude",
    "href": "Lecture_Folder/Week6b.html#differences-directionality-and-magnitude",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Differences, directionality, and magnitude",
    "text": "Differences, directionality, and magnitude\n\nReport your results so as to provide as much information as possible to the reader about the nature of differences or relationships.\nFor example, if you are testing for differences among groups, and you find a significant difference, it is not sufficient to simply report that “groups A and B were significantly different”. How are they different? How much are they different?\nIt is much more informative to say something like, “Group A individuals were 23% larger than those in Group B”, or, “Group B pups gained weight at twice the rate of Group A pups.”\nReport the direction of differences (greater, larger, smaller, etc) and the magnitude of differences (% difference, how many times, etc.) whenever possible."
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#statistical-results-in-text",
    "href": "Lecture_Folder/Week6b.html#statistical-results-in-text",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nStatistical test summaries (test name, p-value) are usually reported parenthetically in conjunction with the biological results they support. This parenthetical reference should include the statistical test used, the value, degrees of freedom and the level of significance.\nFor example, if you found that the mean height of male Biology majors was significantly larger than that of female Biology majors, you might report this result (in blue) and your statistical conclusion (shown in red) as follows:\n\n“Males (180.5 ± 5.1 cm; n=34) averaged 12.5 cm taller than females (168 ± 7.6 cm; n=34) in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001).”\n\nIf the summary statistics are shown in a figure, the sentence above need not report them specifically, but must include a reference to the figure where they may be seen:\n\n“Males averaged 12.5 cm taller than females in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001; Fig. 1).”"
  },
  {
    "objectID": "Lecture_Folder/Week6b.html#statistical-results-in-text-1",
    "href": "Lecture_Folder/Week6b.html#statistical-results-in-text-1",
    "title": "Week 6b - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nAlways enter the appropriate units when reporting data or summary statistics.\n\nfor an individual value you would write, “the mean length was 10 cm”, or, “the maximum time was 140 min.”\nWhen including a measure of variability, place the unit after the error value, e.g., “…was 10 ± 2.3 m”.\nLikewise place the unit after the last in a series of numbers all having the same unit. For example: “lengths of 5, 10, 15, and 20 m”, or “no differences were observed after 2, 4, 6, or 8 min. of incubation”."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html",
    "href": "Lecture_Folder/Week7a.html",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#this-week",
    "href": "Lecture_Folder/Week7a.html#this-week",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nFinish One Factor Analysis of Variance (ANOVA)\n\npost-hoc means comparisons\na priori means tests\nfixed vs. random effects in ANOVA\n\nHow to report statistics in papers\nMultifactor ANOVA\n\nFactorial\nNested\n\nKey principles of experimental design\nGeneralized Linear Mixed Models (GLMMs)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#an-example---irises",
    "href": "Lecture_Folder/Week7a.html#an-example---irises",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "An Example - Irises",
    "text": "An Example - Irises\n\nstripchart(iris$Sepal.Length ~ iris$Species, vertical=T, method=\"jitter\",\n           ylab=\"sepal length\", xlab=\"species\", pch=19, cex=0.5)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anovas-and-hypotheses",
    "href": "Lecture_Folder/Week7a.html#anovas-and-hypotheses",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVAs and Hypotheses",
    "text": "ANOVAs and Hypotheses\n\\[ H_0: \\mu(\\text{versicolor_length\"}) = \\mu(\\text{setosa_length}) = \\mu(\\text{virginica_length})  \\]\n\n\\[ H_a: \\mu(\\text{versicolor_length\"}) \\neq \\mu(\\text{setosa_length}) \\neq \\mu(\\text{virginica_length}) \\]"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-similar-to-regression",
    "href": "Lecture_Folder/Week7a.html#anova-similar-to-regression",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | similar to regression",
    "text": "ANOVA | similar to regression"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova",
    "href": "Lecture_Folder/Week7a.html#anova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA",
    "text": "ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#assumptions-of-anova",
    "href": "Lecture_Folder/Week7a.html#assumptions-of-anova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Assumptions of ANOVA",
    "text": "Assumptions of ANOVA\n\nThe response variable (y) is approximately normal in all groups (factor levels)\n\nDeviation from normality O.K. if sample sizes and variances across groups are approximately equal\nMost statisticians think that this is within a factor of 2 or 3\n\nVariances equal across groups\nObservations within a group are independent\n\nrandomly sampled\nno structuring of the sampling (but we’ll handle this later)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#differences-in-iris-sepal-length",
    "href": "Lecture_Folder/Week7a.html#differences-in-iris-sepal-length",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Differences in Iris sepal length",
    "text": "Differences in Iris sepal length\n\niris_aov &lt;- aov(Sepal.Length ~ Species, iris)\nanova(iris_aov)\n\nAnalysis of Variance Table\n\nResponse: Sepal.Length\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nSpecies     2 63.212  31.606  119.26 &lt; 2.2e-16 ***\nResiduals 147 38.956   0.265                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWould report this as\n\n\\[F_{2, 147} = 119.26; p &lt;2.2*10^{-16}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#means-estimates-using-lm",
    "href": "Lecture_Folder/Week7a.html#means-estimates-using-lm",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Means estimates using lm",
    "text": "Means estimates using lm\n\nsummary(lm(iris$Sepal.Length ~ iris$Species))\n\n\nCall:\nlm(formula = iris$Sepal.Length ~ iris$Species)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              5.0060     0.0728  68.762  &lt; 2e-16 ***\niris$Speciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\niris$Speciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#means-for-greater-than-two-factor-levels",
    "href": "Lecture_Folder/Week7a.html#means-for-greater-than-two-factor-levels",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Means for greater than two factor levels?",
    "text": "Means for greater than two factor levels?\n\nThe F-ratio test for a single-factor ANOVA tests for any difference among groups.\nIf we want to understand specific differences, we need further “contrasts”.\nUnplanned comparisons (post hoc):\n\nMultiple comparisons carried out after the results are obtained.\nUsed to find which means differ from which other means\nComparisons require protection for inflated Type 1 error rates:\n\nPlanned comparisons (a priori):\n\nComparisons between group means that were decided when the experiment was designed (not after the data were in)\nMust be few in number to avoid inflating Type 1 error rates"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#post-hoc-comparisons",
    "href": "Lecture_Folder/Week7a.html#post-hoc-comparisons",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Post Hoc Comparisons",
    "text": "Post Hoc Comparisons\n\nSay you start your experiment with no idea of how groups would differ.\nSo now you’ve got a significant result that says your groups are different from one another!\nBut how are they different?\n\n2 groups could be the same and 1 is different,\nor all 3 could be different from each other!\n\nThere are several ways to compare groups after an ANOVA\nOne of the most common ways is by Tukey’s tests\n\nTukey’s honestly significant difference (HSD) test (all pairs)\nScheffé contrasts (all combinations of means)\n\nThe function TukeyHSD() in R"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#irises",
    "href": "Lecture_Folder/Week7a.html#irises",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Irises",
    "text": "Irises\n\niris_aov &lt;- aov(Sepal.Length ~ Species, iris)\nTukeyHSD(iris_aov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Sepal.Length ~ Species, data = iris)\n\n$Species\n                      diff       lwr       upr p adj\nversicolor-setosa    0.930 0.6862273 1.1737727     0\nvirginica-setosa     1.582 1.3382273 1.8257727     0\nvirginica-versicolor 0.652 0.4082273 0.8957727     0"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#irises-1",
    "href": "Lecture_Folder/Week7a.html#irises-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Irises",
    "text": "Irises"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#irises-2",
    "href": "Lecture_Folder/Week7a.html#irises-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Irises",
    "text": "Irises\n\nlibrary(ggplot2)\nggplot(iris, aes(x = Species, y = Sepal.Length)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\") +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  stat_summary(fun = mean, geom = \"point\", shape = 20, size = 3, color = \"red\") +\n  labs(\n    title = \"Box Plot by Category\",\n    x = \"Species\",\n    y = \"Sepal Length\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#biomarker-data",
    "href": "Lecture_Folder/Week7a.html#biomarker-data",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Biomarker Data",
    "text": "Biomarker Data\n\nbiomarker_data &lt;-read.table(\"biomarkers.tsv\", header=T, sep=\"\\t\")\nbiomarker_anova &lt;- aov(marker5 ~ diagnosis, biomarker_data)\nanova(biomarker_anova)\n\nAnalysis of Variance Table\n\nResponse: marker5\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \ndiagnosis   2  34600 17299.8  7.4487 0.0007613 ***\nResiduals 197 457536  2322.5                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#biomarker-data-1",
    "href": "Lecture_Folder/Week7a.html#biomarker-data-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Biomarker Data",
    "text": "Biomarker Data\n\nbiomarker_data &lt;-read.table(\"biomarkers.tsv\", header=T, sep=\"\\t\")\nbiomarker_anova &lt;- aov(marker5 ~ diagnosis, biomarker_data)\nTukeyHSD(biomarker_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = marker5 ~ diagnosis, data = biomarker_data)\n\n$diagnosis\n                       diff        lwr      upr     p adj\nsarcoma1-benign    7.063072 -12.783009 26.90915 0.6783433\nsarcoma2-benign   31.775344  12.192171 51.35852 0.0005000\nsarcoma2-sarcoma1 24.712272   1.945757 47.47879 0.0297665"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#biomarker-data-2",
    "href": "Lecture_Folder/Week7a.html#biomarker-data-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Biomarker Data",
    "text": "Biomarker Data"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#biomarker-data-3",
    "href": "Lecture_Folder/Week7a.html#biomarker-data-3",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Biomarker Data",
    "text": "Biomarker Data\n\nbiomarker_data &lt;-read.table(\"biomarkers.tsv\", header=T, sep=\"\\t\")\nbiomarker_anova &lt;- aov(marker5 ~ diagnosis, biomarker_data)\nsummary(lm(marker5 ~ diagnosis, biomarker_data))\n\n\nCall:\nlm(formula = marker5 ~ diagnosis, data = biomarker_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-130.946  -27.899   -0.907   31.973  141.049 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        417.618      4.819  86.656  &lt; 2e-16 ***\ndiagnosissarcoma1    7.063      8.404   0.840 0.401668    \ndiagnosissarcoma2   31.775      8.292   3.832 0.000171 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 48.19 on 197 degrees of freedom\nMultiple R-squared:  0.0703,    Adjusted R-squared:  0.06087 \nF-statistic: 7.449 on 2 and 197 DF,  p-value: 0.0007613"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#lets-practice---using-the-categorical-predictor-variables-in-the-stickleback-data-set",
    "href": "Lecture_Folder/Week7a.html#lets-practice---using-the-categorical-predictor-variables-in-the-stickleback-data-set",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Let’s practice - using the categorical predictor variables in the stickleback data set",
    "text": "Let’s practice - using the categorical predictor variables in the stickleback data set\n\nRead in the data as before\nPick one categorical predictor variable to include\nMake sure that R sees them as type factor\nSet up the model and evaluate the overall fit\nDo a post-hoc means test with Tukey’s HSD"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#fitting-the-model",
    "href": "Lecture_Folder/Week7a.html#fitting-the-model",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Fitting the model",
    "text": "Fitting the model\n\nstickle_micro &lt;-read.table(\"Stickle_RNAseq.tsv\", header=T, sep=\"\\t\")\n  \nstickle_micro_anova &lt;- aov(Gene42 ~ Geno.Micro, stickle_micro)\nanova(stickle_micro_anova)\n\nAnalysis of Variance Table\n\nResponse: Gene42\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nGeno.Micro  3 120764   40255  25.328 1.837e-11 ***\nResiduals  76 120789    1589                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#tukeys-posthoc",
    "href": "Lecture_Folder/Week7a.html#tukeys-posthoc",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Tukey’s posthoc",
    "text": "Tukey’s posthoc\n\nTukeyHSD(stickle_micro_anova)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Gene42 ~ Geno.Micro, data = stickle_micro)\n\n$Geno.Micro\n              diff        lwr        upr     p adj\nconvB-convA   50.5   17.38429  83.615711 0.0008090\nmonoA-convA  -29.1  -62.21571   4.015711 0.1051497\nmonoB-convA  -53.9  -87.01571 -20.784289 0.0003145\nmonoA-convB  -79.6 -112.71571 -46.484289 0.0000001\nmonoB-convB -104.4 -137.51571 -71.284289 0.0000000\nmonoB-monoA  -24.8  -57.91571   8.315711 0.2095350"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#plot-of-the-different-levels",
    "href": "Lecture_Folder/Week7a.html#plot-of-the-different-levels",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Plot of the different levels",
    "text": "Plot of the different levels"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#planned-a-priori-contrasts-1",
    "href": "Lecture_Folder/Week7a.html#planned-a-priori-contrasts-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts\n\nA well planned experiment often dictates which comparison of means are of most interest, whereas other comparisons are of no interest.\nBy restricting the comparisons to just those of interest, researchers can mitigate the multiple testing problem associated with post-hoc tests.\nSome statisticians argue that, in fact, planned comparisons allow researchers to avoid adjusting p-values all together because each test is therefore unique.\nContrasts can also allow more complicated tests of the relationships among means.\nCoding a priori contrasts in R is quite easy and just depends upon writing the right series of coefficient contrasts."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#planned-a-priori-contrasts-2",
    "href": "Lecture_Folder/Week7a.html#planned-a-priori-contrasts-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts\n\n\n\n\n\n\n\n\n\n\nNull Hypothesis\nGroup_1\nGroup_2\nGroup_3\nGroup_4\n\n\n\n\n\\(\\mu_1 =\\mu_2\\)\n1\n-1\n0\n0\n\n\n\\(\\mu_1 =\\mu_3\\)\n1\n0\n-1\n0\n\n\n\\(\\mu_3 =\\mu_4\\)\n0\n0\n-1\n1\n\n\n\\(\\frac{(\\mu_1+\\mu_2)}{2} = \\mu_3\\)\n0.5\n0.5\n-1\n0"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-planned-contrasts",
    "href": "Lecture_Folder/Week7a.html#r-interlude-planned-contrasts",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Planned contrasts",
    "text": "R INTERLUDE | Planned contrasts\n\nRNAseq_Data &lt;- read.table(\"Stickle_RNAseq.tsv\", header=T, sep='')\n\nRNAseq_Data$Geno.Micro &lt;- factor(RNAseq_Data$Geno.Micro)\n\ncontrast_matrix &lt;- matrix(c(\n  -1, 1, 0, 0,\n  -1, 0, 1, 0\n), ncol = 2)\n\ncolnames(contrast_matrix) &lt;- c(\"level1_vs_level2\", \"level1_vs_level3\")\nrownames(contrast_matrix) &lt;- levels(RNAseq_Data$Geno.Micro)\n\ncontrasts(RNAseq_Data$Geno.Micro) &lt;- contrast_matrix\n\nRNA_model &lt;- aov(Gene10 ~ Geno.Micro, data = RNAseq_Data)\nsummary.lm(RNA_model)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-planned-contrasts-1",
    "href": "Lecture_Folder/Week7a.html#r-interlude-planned-contrasts-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Planned contrasts",
    "text": "R INTERLUDE | Planned contrasts\n\n\n\nCall:\naov(formula = Gene10 ~ Geno.Micro, data = RNAseq_Data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-72.00 -17.62   1.15  16.44  58.00 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                 121.037      2.682  45.128  &lt; 2e-16 ***\nGeno.Microlevel1_vs_level2   19.317      4.380   4.410 3.35e-05 ***\nGeno.Microlevel1_vs_level3    3.217      4.380   0.734    0.465    \nGeno.Micro                   -8.126      5.364  -1.515    0.134    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.99 on 76 degrees of freedom\nMultiple R-squared:  0.3045,    Adjusted R-squared:  0.277 \nF-statistic: 11.09 on 3 and 76 DF,  p-value: 4.063e-06"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-fixed-effects-of-factors",
    "href": "Lecture_Folder/Week7a.html#anova-fixed-effects-of-factors",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | Fixed effects of factors",
    "text": "ANOVA | Fixed effects of factors\n\nGroups are predetermined, of direct interest, repeatable.\nFor example:\n\nmedical treatments in a clinical trial\npredetermined doses of a toxin\nage groups in a population\nhabitat, season, etc.\n\nAny conclusions reached in the study about differences among groups can be applied only to the groups included in the study.\nThe results cannot be generalized to other treatments, habitats, etc. not included in the study."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-random-effects-of-factors",
    "href": "Lecture_Folder/Week7a.html#anova-random-effects-of-factors",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors\n\nMeasurements that come in groups. A group can be:\n\na family made up of siblings\na subject measured repeatedly\na transect of quadrats in a sampling survey\na block of an experiment done at a given time\n\nGroups are assumed to be randomly sampled from a population of groups.\nTherefore, conclusions reached about groups can be generalized to the population of groups.\nWith random effects, the variance among groups is the main quantity of interest, not the specific group attributes."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-random-effects-of-factors-1",
    "href": "Lecture_Folder/Week7a.html#anova-random-effects-of-factors-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors\n\nWhenever your sampling design is nested\nWhenever you divide up plots and apply separate treatments to subplots\nWhenever your replicates are grouped spatially or temporally\n\nin blocks\nin batches\n\nWhenever you take measurements on related individuals\nWhenever you measure subjects or other sampling units repeatedly"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-random-effects-of-factors-2",
    "href": "Lecture_Folder/Week7a.html#anova-random-effects-of-factors-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | Random effects of factors",
    "text": "ANOVA | Random effects of factors\n\\[ H_0: \\sigma^2_\\alpha=0\\] \\[ H_A: \\sigma^2_\\alpha \\neq 0\\]"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-caution-about-fixed-vs.-random-effects",
    "href": "Lecture_Folder/Week7a.html#anova-caution-about-fixed-vs.-random-effects",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | Caution about fixed vs. random effects",
    "text": "ANOVA | Caution about fixed vs. random effects\n\nUsing fixed vs. random effects changes the way that statistical tests are performed in ANOVA\nMost statistical packages assume that all factors are fixed unless you instruct it otherwise\nDesignating factors as random takes extra work and probably a read of the manual\nIn R, lm assumes that all effects are fixed\nFor random effects, use lme instead (part of the nlme package)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-r-interlude",
    "href": "Lecture_Folder/Week7a.html#anova-r-interlude",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | R interlude",
    "text": "ANOVA | R interlude\n\nSet up an analysis of the stickleback data but with the factor as a random effect\n\n\nlibrary(nlme)\nRNAseq_Data &lt;- read.table(\"Stickle_RNAseq.tsv\", header=T, sep='')\n\nRNAseq_Data$Geno.Micro &lt;- factor(RNAseq_Data$Geno.Micro)\n\nmicro_model_random_effect &lt;- lme(fixed = Gene202 ~ 1,\n                                 random = ~1 | Geno.Micro,\n                                 data = stickle_micro)\n\nsummary(micro_model_random_effect)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#style-of-a-results-section",
    "href": "Lecture_Folder/Week7a.html#style-of-a-results-section",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Style of a results section",
    "text": "Style of a results section\n\nWrite the text of the Results section concisely and objectively.\nThe passive voice will likely dominate here, but use the active voice as much as possible.\nUse the past tense.\nAvoid repetitive paragraph structures.\nDo not interpret the data here."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#function-of-a-results-section",
    "href": "Lecture_Folder/Week7a.html#function-of-a-results-section",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Function of a results section",
    "text": "Function of a results section\n\nThe function is to objectively present your key results, without interpretation, in an orderly and logical sequence using both text and illustrative materials (Tables and Figures).\nThe results section always begins with text, reporting the key results and referring to figures and tables as you proceed.\nThe text of the Results section should be crafted to follow this sequence and highlight the evidence needed to answer the questions/hypotheses you investigated.\nImportant negative results should be reported, too.\nAuthors usually write the text of the results section based upon the sequence of Tables and Figures."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#summaries-of-the-statistical-analyses",
    "href": "Lecture_Folder/Week7a.html#summaries-of-the-statistical-analyses",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Summaries of the statistical analyses",
    "text": "Summaries of the statistical analyses\n\nMay appear either in the text (usually parenthetically) or in the relevant Tables or Figures (in the legend or as footnotes to the Table or Figure).\nEach Table and Figure must be referenced in the text portion of the results, and you must tell the reader what the key result(s) is that each Table or Figure conveys.\nTables and Figures are assigned numbers separately and in the sequence that you will refer to them from the text.\n\nThe first Table you refer to is Table 1, the next Table 2 and so forth.\nSimilarly, the first Figure is Figure 1, the next Figure 2, etc.\n\nEach Table or Figure must include a brief description of the results being presented and other necessary information in a legend.\n\nTable legends go above the Table; tables are read from top to bottom.\nFigure legends go below the figure; figures are usually viewed from bottom to top.\n\nWhen referring to a Figure from the text, “Figure” is abbreviated as Fig.,e.g., (Fig. 1. Table is never abbreviated, e.g., Table 1."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#example",
    "href": "Lecture_Folder/Week7a.html#example",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Example",
    "text": "Example\n\nFor example, suppose you asked the question, “Is the average height of male students the same as female students in a pool of randomly selected Biology majors?”\nYou would first collect height data from large random samples of male and female students.\nYou would then calculate the descriptive statistics for those samples (mean, SD, n, range, etc) and plot these numbers.\nSuppose you found that male Biology majors are, on average, 12.5 cm taller than female majors; this is the answer to the question.\nNotice that the outcome of a statistical analysis itself is not a key result, but rather an analytical tool that helps us understand what is our key result."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#differences-directionality-and-magnitude",
    "href": "Lecture_Folder/Week7a.html#differences-directionality-and-magnitude",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Differences, directionality, and magnitude",
    "text": "Differences, directionality, and magnitude\n\nReport your results so as to provide as much information as possible to the reader about the nature of differences or relationships.\nFor example, if you are testing for differences among groups, and you find a significant difference, it is not sufficient to simply report that “groups A and B were significantly different”. How are they different? How much are they different?\nIt is much more informative to say something like, “Group A individuals were 23% larger than those in Group B”, or, “Group B pups gained weight at twice the rate of Group A pups.”\nReport the direction of differences (greater, larger, smaller, etc) and the magnitude of differences (% difference, how many times, etc.) whenever possible."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#statistical-results-in-text",
    "href": "Lecture_Folder/Week7a.html#statistical-results-in-text",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nStatistical test summaries (test name, p-value) are usually reported parenthetically in conjunction with the biological results they support. This parenthetical reference should include the statistical test used, the value, degrees of freedom and the level of significance.\nFor example, if you found that the mean height of male Biology majors was significantly larger than that of female Biology majors, you might report this result (in blue) and your statistical conclusion (shown in red) as follows:\n\n“Males (180.5 ± 5.1 cm; n=34) averaged 12.5 cm taller than females (168 ± 7.6 cm; n=34) in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001).”\n\nIf the summary statistics are shown in a figure, the sentence above need not report them specifically, but must include a reference to the figure where they may be seen:\n\n“Males averaged 12.5 cm taller than females in the pool of Biology majors (two-sample t-test, t = 5.78, 33 d.f., p &lt; 0.001; Fig. 1).”"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#statistical-results-in-text-1",
    "href": "Lecture_Folder/Week7a.html#statistical-results-in-text-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Statistical results in text",
    "text": "Statistical results in text\n\nAlways enter the appropriate units when reporting data or summary statistics.\n\nfor an individual value you would write, “the mean length was 10 cm”, or, “the maximum time was 140 min.”\nWhen including a measure of variability, place the unit after the error value, e.g., “…was 10 ± 2.3 m”.\nLikewise place the unit after the last in a series of numbers all having the same unit. For example: “lengths of 5, 10, 15, and 20 m”, or “no differences were observed after 2, 4, 6, or 8 min. of incubation”."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#multifactor-anova-1",
    "href": "Lecture_Folder/Week7a.html#multifactor-anova-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nNested ANOVA or nested design\n\nfactors might be hierarchical - in other words nested - within one another\nThe sources of variance are therefore hierarchical too\n\nThe factorial ANOVA design is the most common experimental design used to investigate more than one treatment variable\n\nIn a factorial design every combination of treatments from two (or more) treatment variables is investigated.\nThe main purpose of a factorial design is to evaluate possible interactions between variables.\nAn interaction between two explanatory variables means that the effect of one variable on the response depends on the state of a second variable."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "href": "Lecture_Folder/Week7a.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA | Key difference between nested and factorial designs",
    "text": "Multifactor ANOVA | Key difference between nested and factorial designs\n\nNested designs are hierarchical\n\noften contain sub-replicates that are random, uncontrolled, nuisance effects\nbut the nested factors can be of interest too\n\nFactorial designs are\n\nall pairwise combinations,\nand often involve all combinations of factor levels\nwhen each factor is fixed interactions can be assessed\n\nCompletely nested designs therefore have no interaction terms, whereas factorial designs do\nMixed models can have a combination of fixed and random factors that are more complicated"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#multifactor-anova-2",
    "href": "Lecture_Folder/Week7a.html#multifactor-anova-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nFor example, Relyae (2003) looked at how a moderate dose (1.6mg/L) of a commonly used pesticide, carbaryl (Sevin), affected bullfrog tadpole survival.\nIn particular, the experiment asked how the effect of carbaryl depended on whether a native predator, the red-spotted newt, was also present.\nThe newt was caged and could cause no direct harm, but it emitted visual and chemical cues to other tadpoles\nThe experiment was carried out in 10-L tubs (experimental units), each containing 10 tadpoles.\nThe four combinations of pesticide treatment (carbaryl vs. water only) and predator treatment (present or absent) were randomly assigned to tubs.\nThe results showed that survival was high except when pesticide was applied together with the predator.\nThus, the two treatments, predation and pesticide, seem to have interacted."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#multifactor-anova-3",
    "href": "Lecture_Folder/Week7a.html#multifactor-anova-3",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#two-factor-factorial-designs",
    "href": "Lecture_Folder/Week7a.html#two-factor-factorial-designs",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Two Factor Factorial Designs",
    "text": "Two Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#three-factor-factorial-designs",
    "href": "Lecture_Folder/Week7a.html#three-factor-factorial-designs",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Three Factor Factorial Designs",
    "text": "Three Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#factorial-designs-number-of-replicates",
    "href": "Lecture_Folder/Week7a.html#factorial-designs-number-of-replicates",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Factorial Designs | Number of Replicates",
    "text": "Factorial Designs | Number of Replicates"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#model-1-factorial-anova-both-main-effects-fixed",
    "href": "Lecture_Folder/Week7a.html#model-1-factorial-anova-both-main-effects-fixed",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Model 1 factorial ANOVA | both main effects fixed",
    "text": "Model 1 factorial ANOVA | both main effects fixed"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#model-2-factorial-anova-both-main-effects-fixed",
    "href": "Lecture_Folder/Week7a.html#model-2-factorial-anova-both-main-effects-fixed",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Model 2 factorial ANOVA | both main effects fixed",
    "text": "Model 2 factorial ANOVA | both main effects fixed"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#model-2-factorial-anova-both-main-effects-random",
    "href": "Lecture_Folder/Week7a.html#model-2-factorial-anova-both-main-effects-random",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Model 2 factorial ANOVA | both main effects random",
    "text": "Model 2 factorial ANOVA | both main effects random"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#the-mean-squares-for-a-factorial-model",
    "href": "Lecture_Folder/Week7a.html#the-mean-squares-for-a-factorial-model",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "The mean squares for a factorial model",
    "text": "The mean squares for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#the-f-ratios-for-a-factorial-model",
    "href": "Lecture_Folder/Week7a.html#the-f-ratios-for-a-factorial-model",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "The F-ratios for a factorial model",
    "text": "The F-ratios for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#interpretation-significant-main-and-interaction-effects",
    "href": "Lecture_Folder/Week7a.html#interpretation-significant-main-and-interaction-effects",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Interpretation | significant main and interaction effects",
    "text": "Interpretation | significant main and interaction effects"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#interaction-plots",
    "href": "Lecture_Folder/Week7a.html#interaction-plots",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Interaction plots",
    "text": "Interaction plots"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "href": "Lecture_Folder/Week7a.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\n\ncontinuous response variable and two main effect categorical variables\n\n\ngene &lt;- rnadata$Gene80\nmicrobiota &lt;- rnadata$Microbiota\ngenotype &lt;- rnadata$Genotype\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#fit-the-factorial-linear-model-two-different-ways-to-do-the-same-thing",
    "href": "Lecture_Folder/Week7a.html#fit-the-factorial-linear-model-two-different-ways-to-do-the-same-thing",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Fit the factorial linear model | two different ways to do the same thing",
    "text": "Fit the factorial linear model | two different ways to do the same thing\n\nrna_aov &lt;- aov(gene ~ microbiota + genotype + microbiota:genotype)\nrna_aov &lt;- aov(gene ~ microbiota*genotype)\n\n\nExamine the fitted model diagnostics and the ANOVA results table\n\n\nplot(rna_aov)\nsummary(rna_aov)\nanova(rna_aov)\n\n\nWhat are the general results of our hypothesis tests?\nIf there is an interaction, can we understand it by looking at the boxplots?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-2-by-3-fixed-effect-factorial-anova",
    "href": "Lecture_Folder/Week7a.html#r-interlude-2-by-3-fixed-effect-factorial-anova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-3 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-3 fixed effect factorial ANOVA\n\nTry the following code to produce an interaction plot for the response variable cell count.\nIn this case there are 2 genotypes and 3 treatment levels.\nDownload the IntPlot_data file and IntPlot_Example.R\nGo through the R script, get a feel for what it’s doing, and try to produce and interpret the interaction plot."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "href": "Lecture_Folder/Week7a.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Means tests | factor level combinations in multi-factor ANOVA",
    "text": "Means tests | factor level combinations in multi-factor ANOVA\n\nThe F-ratio test for a single-factor ANOVA tests for any difference among groups.\nIf we want to understand specific differences, we need further “contrasts”.\nUnplanned comparisons (post hoc)\nPlanned comparisons (a priori)\nNow we need to make ‘pseudo-factors’ that combine our levels of interest"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#planned-a-priori-contrasts-3",
    "href": "Lecture_Folder/Week7a.html#planned-a-priori-contrasts-3",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "href": "Lecture_Folder/Week7a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\ncontinuous response and two main effect variables\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\ngene &lt;- rnadata$Gene80\nmicrobiota &lt;- rnadata$Microbiota\ngenotype &lt;- rnadata$Genotype\n\nmake new “pseudo factor,” combining genotype and microbiota\n\ngxm &lt;- interaction(genotype,microbiota)\nlevels(gxm)\nboxplot(gene ~ gxm)\n\nspecify the following 2 contrasts\n\ncontrasts(gxm) &lt;- cbind(c(2, -1, 0, -1), c(-1, -1, 3, -1))"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "href": "Lecture_Folder/Week7a.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\nFit the factorial linear model\n\nrna_aov &lt;- aov(gene ~ gxm)\n\nExamine the ANOVA table, using supplied contrasts. Figure out the appropriate titles to give them.\n\nsummary(rna_aov, split = list(gxm = list('xxx'=1,'xxx'=2)))\n\nWhat does the contrast summary tell you about the nature of the interaction?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nested-anova-walking-stick-example",
    "href": "Lecture_Folder/Week7a.html#nested-anova-walking-stick-example",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\n\nExample 1: Study of “repeatability” (simple nested design)\nThe walking stick, Timema cristinae, is a wingless herbivorous insect on plants in chaparral habitats of California.\nNosil and Crespi (2006) measured individuals using digital photographs.\nTo evaluate measurement repeatability they took two separate photographs of each specimen.\nAfter measuring traits on one set of photographs, they repeated the measurements on the second set."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nested-anova-walking-stick-example-1",
    "href": "Lecture_Folder/Week7a.html#nested-anova-walking-stick-example-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\nEach pair of dots represents the two measurements"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nested-anova-walking-stick-example-2",
    "href": "Lecture_Folder/Week7a.html#nested-anova-walking-stick-example-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nested-anova-anova-table-of-results",
    "href": "Lecture_Folder/Week7a.html#nested-anova-anova-table-of-results",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nested ANOVA | ANOVA Table of Results",
    "text": "Nested ANOVA | ANOVA Table of Results"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nesting-logic",
    "href": "Lecture_Folder/Week7a.html#nesting-logic",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nesting Logic",
    "text": "Nesting Logic"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nesting-equations",
    "href": "Lecture_Folder/Week7a.html#nesting-equations",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nesting equations",
    "text": "Nesting equations"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nesting-hypothesis-tests",
    "href": "Lecture_Folder/Week7a.html#nesting-hypothesis-tests",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nesting hypothesis tests",
    "text": "Nesting hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nesting-ms-calculations",
    "href": "Lecture_Folder/Week7a.html#nesting-ms-calculations",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nesting MS calculations",
    "text": "Nesting MS calculations"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#nested-anova-table-of-results",
    "href": "Lecture_Folder/Week7a.html#nested-anova-table-of-results",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Nested ANOVA table of results",
    "text": "Nested ANOVA table of results"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-nested-anova",
    "href": "Lecture_Folder/Week7a.html#r-interlude-nested-anova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-nested-anova-1",
    "href": "Lecture_Folder/Week7a.html#r-interlude-nested-anova-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nandrew_data &lt;- read.table('andrew.tsv', header=T, sep=‘\\t')\nhead(andrew_data)\n\n\nThere are four variables: ‘TREAT’, ‘PATCH’, ‘QUAD’ and ‘ALGAE’\nThe main effect factor is TREAT\nMake a simplified factor called TREAT2, in which 0% and 33% are a level called “low” and 66% and 100% are “high”\n\n\nandrew_data$TREAT2 &lt;- factor(c(rep(“low”,40),rep(“high”,40))\n\n\nThe nested factor is PATCH - also need to turn this into a factor\n\n\nandrew_data$PATCH &lt;- factor(andrew_data$PATCH)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-nested-anova-2",
    "href": "Lecture_Folder/Week7a.html#r-interlude-nested-anova-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nIn this case, our response variable is ALGAE\nLook at the distribution of ALGAE for the two levels of TREAT2 using boxplots based on the patch means, which are the replicates in this case.\n\n\nandrew.agg &lt;- with(andrew_data, aggregate(data.frame(ALGAE), \n                  by = list(TREAT2=TREAT2, PATCH=PATCH), mean)\n\nlibrary(nlme)\nandrew.agg &lt;- gsummary(andrew_data, groups=andrew_data$PATCH)\n\nboxplot(ALGAE ~ TREAT2, andrew.agg)\n\n\nEvaluate assumptions based on the boxplots\nIs the design balanced (equal numbers of sub-replicates per PATCH)?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-nested-anova-3",
    "href": "Lecture_Folder/Week7a.html#r-interlude-nested-anova-3",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nRun the nested ANOVA:\n\n\nnested.aov &lt;- aov(ALGAE ~ TREAT2 + Error(PATCH), data=andrew_data)\nsummary(nested.aov)\n\n\nDo we detect an effect of TREAT2 (high vs low sea urchin density)?\nEstimate variance components to assess relative contributions of the random factors\n\n\nlibrary(nlme)\nVarCorr(lme(ALGAE ~ 1, random = ~1 | TREAT2/PATCH, andrew_data))\n\n\nCalculate the % of variation due to between-treatment differences vs. due to among patches within treatment differences.\nSee pg. 302 in Logan if you need help.\nWhat do these variance component estimates tell us???"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#what-is-an-experimental-study",
    "href": "Lecture_Folder/Week7a.html#what-is-an-experimental-study",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "What is an experimental study?",
    "text": "What is an experimental study?\n\nIn an experimental study the researcher assigns treatments to units\nIn an observational study nature does the assigning of treatments to units\nThe crucial advantage of experiments derives from the random assignment of treatments to units\nRandom assignment, or randomization, minimizes the influence of confounding variables\nCan infer cause and effect more easily"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#key-components-of-a-good-experiment",
    "href": "Lecture_Folder/Week7a.html#key-components-of-a-good-experiment",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Key components of a good experiment",
    "text": "Key components of a good experiment\n\nAn experiment is when two or more treatment groups are assigned to research units\nrandomization - research units are assigne at random to tratment groups in one of several ways. In particular neither the researcher or the unit should decide who gets the treatment\ncontrol - different treatemnt groups are as identical as posible, ecept for the specfic treatment they receive. A lack of controls can lead to confounding variables. Note the placebo effect.\nreplication - repeated to be able to estimate sampling variation. Different types of random sampling depending upon the nature of the experiment\nblinding - single or better yet double blind - neither the subject nor the"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#mount-everest-example",
    "href": "Lecture_Folder/Week7a.html#mount-everest-example",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\nSurvival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.\nWhy?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#mount-everest-example-1",
    "href": "Lecture_Folder/Week7a.html#mount-everest-example-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\n\nOne possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).\nThe other is that the two variables are associated because other variables affect both supplemental oxygen and survival.\nUse of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.\nVariables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called confounding variables\nThey are correlated with the variable of interest, and therefore preventing a decision about cause and effect.\nWith random assignment, no confounding variables will be associated with treatment except by chance."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#clinical-trials",
    "href": "Lecture_Folder/Week7a.html#clinical-trials",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Clinical Trials",
    "text": "Clinical Trials\n\nThe gold standard of experimental designs is the clinical trial\nExperimental design in all areas of biology have been informed by procedures used in clinical trials\nA clinical trial is an experimental study in which two or more treatments are assigned to human subjects\nThe design of clinical trials has been refined because the cost of making a mistake with human subjects is so high\nExperiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#example-of-a-clinical-trial",
    "href": "Lecture_Folder/Week7a.html#example-of-a-clinical-trial",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial\n\nTransmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa\nThe spermicide nonoxynol-9 had shown in vitro activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).\nThey tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.\nData were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.\nTwo gel treatments were assigned randomly to women at each clinic.\nOne gel contained nonoxynol-9 and the other a placebo.\nNeither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#example-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week7a.html#example-of-a-clinical-trial-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#design-components-of-a-clinical-trial",
    "href": "Lecture_Folder/Week7a.html#design-components-of-a-clinical-trial",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\nThe goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.\n\nTo reduce bias, the experiment included:\n\nSimultaneous control group: study included both the treatment of interest and a control group (the women receiving the placebo).\nRandomization: treatments were randomly assigned to women at each clinic.\nBlinding: neither the subjects nor the clinicians knew which women were assigned which treatment."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#design-components-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week7a.html#design-components-of-a-clinical-trial-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\n\nTo reduce the effects of sampling error, the experiment included:\n\nReplication: study was carried out on multiple independent subjects.\nBalance: number of women was nearly equal in the two groups at every clinic.\nBlocking: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”)."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#simultaneous-control-group",
    "href": "Lecture_Folder/Week7a.html#simultaneous-control-group",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Simultaneous control group",
    "text": "Simultaneous control group\n\nIn clinical trials either a placebo or the currently accepted treatment should be provided.\nIn experiments requiring intrusive methods to administer treatment, such as\n\ninjections\nsurgery\nrestraint\nconfinement\n\nthe control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#simultaneous-control-group-1",
    "href": "Lecture_Folder/Week7a.html#simultaneous-control-group-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Simultaneous control group",
    "text": "Simultaneous control group\n\nThe “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.\nIn field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.\nIdeally, the same disturbance should be applied to the control plots."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#randomization",
    "href": "Lecture_Folder/Week7a.html#randomization",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nThe researcher should randomize assignment of treatments to units or subjects\nChance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control\nA completely randomized design is one in which treatments are assigned to all units by randomization"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#randomization-1",
    "href": "Lecture_Folder/Week7a.html#randomization-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nRandomization breaks the association between possible confounding variables and the explanatory variable\nRandomization doesn’t eliminate the variation contributed by confounding variables, only their correlation with treatment\nRandomization ensures that variation from confounding variables is similar between the different treatment groups."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#randomization-2",
    "href": "Lecture_Folder/Week7a.html#randomization-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Randomization",
    "text": "Randomization\n\nRandomization should be carried out using a random process:\n\nList all n subjects, one per row, in a computer spreadsheet.\nUse the computer to give each individual a random number.\nAssign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.\n\nOther ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.\n“Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#randomization-types",
    "href": "Lecture_Folder/Week7a.html#randomization-types",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Randomization Types",
    "text": "Randomization Types\n\nCompletely randomized design - all subjects are placed to treatment or control with equal probability\nRandomized block - first broken into gropus (e.g. age or gender) then assigend to tratment groups at random\nMathced pair design - sujects are paired by similarity before being randoly assigned to treatment groups"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#sampling-approaches",
    "href": "Lecture_Folder/Week7a.html#sampling-approaches",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Sampling approaches",
    "text": "Sampling approaches\n\nsimple random sample - every sample has equal probability of being chosen\nstratified sample - divvided into groups then a simple random sample are taken from each\ncluster sample - divided into similar gropu, usually naturally occure, a simple random samples of clusters is then taken and very member of the cluster is included in the sample\nmultistage sampling - combines the above. First clusters are random sampled. Second random samples are take from each. Then process is repeated\nsystematic sample - members of a sample are chosen in a pre-determiend ways. e.g Choose everyth 20th person coming into a store"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#bias-in-experiments",
    "href": "Lecture_Folder/Week7a.html#bias-in-experiments",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Bias in experiments",
    "text": "Bias in experiments\n\nlack of control\nlac of blinidng\nlack of reandomiztaion"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#bias-in-surveys",
    "href": "Lecture_Folder/Week7a.html#bias-in-surveys",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Bias in surveys",
    "text": "Bias in surveys\n\nsamplign bias - not all members of the ppulation or cluster are equally likely\nnon-response bias - xxx\nasymmetric questions - xxx\nsocial desirability bias - xxx"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#statistical-sampling",
    "href": "Lecture_Folder/Week7a.html#statistical-sampling",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Statistical sampling",
    "text": "Statistical sampling\n\ncensuse - collect ifnormation from a completel population of interest\nsampling bad ways\n\nanecdotal evidence\nconveience sample - easily acessible (say students in a class\nRandom sample - a random process is used, and the point is to avoid bias\n\n\n)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blinding",
    "href": "Lecture_Folder/Week7a.html#blinding",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nBlinding is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.\nBlinding prevents subjects and researchers from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.\nFor example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding (Ernst and White 1998)."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blinding-1",
    "href": "Lecture_Folder/Week7a.html#blinding-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nIn a single-blind experiment, the subjects are unaware of the treatment that they have been assigned.\nTreatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.\nBlinding can also be a concern in non-human studies where animals respond to stimuli"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blinding-2",
    "href": "Lecture_Folder/Week7a.html#blinding-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nIn a double-blind experiment the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments\n\nResearchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome\nMany response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias\nResearchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blinding-3",
    "href": "Lecture_Folder/Week7a.html#blinding-3",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nReviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).\nExperiments on non–human subjects are also prone to bias from lack of blinding."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blinding-4",
    "href": "Lecture_Folder/Week7a.html#blinding-4",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blinding",
    "text": "Blinding\n\nBebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.\nBlinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order)."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#replication",
    "href": "Lecture_Folder/Week7a.html#replication",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nThe goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables\nOne way to reduce noise is to make the experimental conditions constant\nIn field experiments, however, highly constant experimental conditions might not be feasible nor desirable\nBy limiting the conditions of an experiment, we also limit the generality of the results\nAnother way to make treatment effects stand out is to include extreme treatments and to replicate the data."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#replication-1",
    "href": "Lecture_Folder/Week7a.html#replication-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nReplication is the assignment of each treatment to multiple, independent experimental units.\nWithout replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.\nStudies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.\nLarger samples mean more information, and more information means better estimates and more powerful tests."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#replication-2",
    "href": "Lecture_Folder/Week7a.html#replication-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Replication",
    "text": "Replication\n\nReplication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.\nThe figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#pseudoreplication",
    "href": "Lecture_Folder/Week7a.html#pseudoreplication",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Pseudoreplication",
    "text": "Pseudoreplication"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#balance",
    "href": "Lecture_Folder/Week7a.html#balance",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Balance",
    "text": "Balance\n\nA study design is balanced if all treatments have the same sample size.\nConversely, a design is unbalanced if there are unequal sample sizes between treatments.\nBalance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.\nTo appreciate this, look again at the equation for the standard error of the difference between two treatment means."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#balance-1",
    "href": "Lecture_Folder/Week7a.html#balance-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Balance",
    "text": "Balance\n\nFor a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.\nBalance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blocking",
    "href": "Lecture_Folder/Week7a.html#blocking",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blocking",
    "text": "Blocking\n\nBlocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.\nBlocking essentially repeats the same, completely randomized experiment multiple times, once for each block.\nDifferences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks is discarded."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blocking-paired-designs",
    "href": "Lecture_Folder/Week7a.html#blocking-paired-designs",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs\n\nFor example, consider the design choices for a two-treatment experiment to investigate the effect of clear cutting on salamander density.\nIn the completely randomized (“two-sample”) design we take a random sample of forest plots from the population and then randomly assign each plot to either the clear-cut treatment or the no clear-cut treatment.\nIn the paired design we take a random sample of forest plots and clear-cut a randomly chosen half of each plot, leaving the other half untouched."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blocking-paired-designs-1",
    "href": "Lecture_Folder/Week7a.html#blocking-paired-designs-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs\n\nIn the paired design, measurements on adjacent plot-halves are not independent. This is because they are likely to be similar in soil, water, sunlight, and other conditions that affect the number of salamanders.\nAs a result, we must analyze paired data differently than when every plot is independent of all the others, as in the case of the two-sample design.\nPaired design is usually more powerful than completely randomized design because it controls for a lot of the extraneous variation between plots or sampling units that sometimes obscures the effects we are looking for."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blocking-paired-designs-2",
    "href": "Lecture_Folder/Week7a.html#blocking-paired-designs-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blocking | Paired designs",
    "text": "Blocking | Paired designs"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#blocking-randomized-complete-block-design",
    "href": "Lecture_Folder/Week7a.html#blocking-randomized-complete-block-design",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Blocking | Randomized complete block design",
    "text": "Blocking | Randomized complete block design\n\nRCB design is analogous to the paired design, but may have more than two treatments. Each treatment is applied once to every block.\nAs in the paired design, treatment effects in a randomized block design are measured by differences between treatments exclusively within blocks.\nBy accounting for some sources of sampling variation blocking can make differences between treatments stand out.\nBlocking is worthwhile if units within blocks are relatively homogeneous, apart from treatment effects, and units belonging to different blocks vary because of environmental or other differences."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#what-if-you-cant-do-experiments",
    "href": "Lecture_Folder/Week7a.html#what-if-you-cant-do-experiments",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "What if you can’t do experiments?",
    "text": "What if you can’t do experiments?\n\nExperimental studies are not always feasible, in which case we must fall back upon observational studies.\nThe best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.\nRandomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.\nTwo strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates)."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#what-is-a-glmm",
    "href": "Lecture_Folder/Week7a.html#what-is-a-glmm",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "What is a GLMM?",
    "text": "What is a GLMM?\n\nGeneral Linear Mixed Model (GLMM) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#how-do-we-factor-in-categorical-variables",
    "href": "Lecture_Folder/Week7a.html#how-do-we-factor-in-categorical-variables",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "How do we factor in categorical variables?",
    "text": "How do we factor in categorical variables?\n\nFor a single categorical predictor, we can include effects of each factor level:\n\n\\[ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e \\]\n\nEach factor level (ex: for Wolbachia: Yes or No) becomes it’s own “effector” that will change the value of y\nInstead of x being a continuous numerical value, for categorical data it will be either a 0 or 1"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#a-generalized-linear-model",
    "href": "Lecture_Folder/Week7a.html#a-generalized-linear-model",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "A Generalized Linear Model",
    "text": "A Generalized Linear Model\n\nCheck out the help page in RStudio for glm()\n\n\nglm(formula = y ~ x1 + x2, family = gaussian(link = \"identity\"))"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "href": "Lecture_Folder/Week7a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nSet up a glm() to test for the effect of Wolbachia infection on Recombinant Fraction"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "href": "Lecture_Folder/Week7a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nWhat do these components mean?\n\n\nfly &lt;- read.table(\"Mostoufi2022_Recombination_Edit.csv\", header=T, sep=',')\nmodel &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link=\"identity\"))\nsummary(model)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.348054   0.005845  59.545   &lt;2e-16 ***\nfly$WolbachiaYes 0.021664   0.008474   2.557   0.0112 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00406577)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91480  on 225  degrees of freedom\nAIC: -601.48\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#interpreting-the-glm",
    "href": "Lecture_Folder/Week7a.html#interpreting-the-glm",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nWhy is our intercept significant?\n\nRemember that the null hypothesis is a model with an intercept and slope of 0\n\nHow would you interpret the “WolbachiaYes” coefficient, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#second-steps---adding-more-variables",
    "href": "Lecture_Folder/Week7a.html#second-steps---adding-more-variables",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nNow let’s add Food to our model - how does this change our model results?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#second-steps---adding-more-variables-1",
    "href": "Lecture_Folder/Week7a.html#second-steps---adding-more-variables-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nmodel2 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = \"identity\"))\nsummary(model2)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, \n    family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.344691   0.008121  42.445   &lt;2e-16 ***\nfly$WolbachiaYes 0.021731   0.008504   2.555   0.0113 *  \nfly$FoodSucrose  0.002933   0.010481   0.280   0.7799    \nfly$FoodYeast    0.007366   0.010128   0.727   0.4678    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00409246)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91262  on 223  degrees of freedom\nAIC: -598.02\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#interpreting-the-glm-1",
    "href": "Lecture_Folder/Week7a.html#interpreting-the-glm-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nHow would you interpret the Intercept and Food coefficients, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#interaction-effects-in-glms",
    "href": "Lecture_Folder/Week7a.html#interaction-effects-in-glms",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Interaction effects in GLMs",
    "text": "Interaction effects in GLMs\n\nYou can also model interactions between two categorical variables in glms\n\nWhat if variable x and variable z interact in non-additive ways?\n\nUse the notation x*z in the formula"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#third-steps---adding-interaction-effects",
    "href": "Lecture_Folder/Week7a.html#third-steps---adding-interaction-effects",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nLet’s finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model\nRun the model - what are the results?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#third-steps---adding-interaction-effects-1",
    "href": "Lecture_Folder/Week7a.html#third-steps---adding-interaction-effects-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nHow do we interpret these findings?\n\n\nmodel3 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = \"identity\"))\nsummary(model3)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + \n    fly$Wolbachia * fly$Food, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       0.344520   0.009760  35.298   &lt;2e-16 ***\nfly$WolbachiaYes                  0.022080   0.013970   1.581    0.115    \nfly$FoodSucrose                   0.010286   0.014458   0.711    0.478    \nfly$FoodYeast                     0.001256   0.014059   0.089    0.929    \nfly$WolbachiaYes:fly$FoodSucrose -0.015873   0.021002  -0.756    0.451    \nfly$WolbachiaYes:fly$FoodYeast    0.012910   0.020282   0.637    0.525    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.004096248)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.90527  on 221  degrees of freedom\nAIC: -595.86\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#how-do-we-know-which-model-to-use",
    "href": "Lecture_Folder/Week7a.html#how-do-we-know-which-model-to-use",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "How do we know which model to use?",
    "text": "How do we know which model to use?\n\nWant to be careful not to overfit your linear model (give too many variables)\nThe Akaike information criterion (AIC) is a metric for comparing different models to find the best fit\n\nNotice the AIC score in your output?\nFor more on this, take Advanced Bio Stats! Or do some reading on the internet."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#attributes-of-mixed-effects-models",
    "href": "Lecture_Folder/Week7a.html#attributes-of-mixed-effects-models",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Attributes of mixed effects models",
    "text": "Attributes of mixed effects models\n\nLinear models that include both fixed and random effects.\nThe model is split into fixed and random parts:\n\nFixed effects influence mean of the response variable Y.\nRandom effects influence the variance of Y.\n\nThere is a different error variance for each level of grouping.\nEstimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.\nP-values for fixed effects are conservative when design unbalanced.\nImplemented in the nlme & lme4 packages in R."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#assumptions-of-mixed-effects-models",
    "href": "Lecture_Folder/Week7a.html#assumptions-of-mixed-effects-models",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Assumptions of mixed-effects models",
    "text": "Assumptions of mixed-effects models\n\nVariation within groups follows a normal distribution with equal variance among groups.\nGroups are randomly sampled from “population” of groups.\nGroup means follow a normal distribution.\nMeasurements within groups are independent."
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "href": "Lecture_Folder/Week7a.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects",
    "text": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#general-r-syntax-for-two-factor-factorial-designs",
    "href": "Lecture_Folder/Week7a.html#general-r-syntax-for-two-factor-factorial-designs",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "General R syntax for two factor factorial designs",
    "text": "General R syntax for two factor factorial designs"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "href": "Lecture_Folder/Week7a.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Variance components with 2 random factors using LME4",
    "text": "R INTERLUDE | Variance components with 2 random factors using LME4\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\nvariables excluding first 5 and last 5 observations\n\ngene &lt;- rnadata$Gene80[6:75] \nmicrobiota &lt;- rnadata$Microbiota[6:75]\ngenotype &lt;- rnadata$Genotype[6:75]\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)\n\nEstimate the variance components using Restricted Maximum Likelihood (REML)\n\nlibrary(lme4)\nlmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))\n\nBased on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#brain-body-size-neaderthals-as-compared-to-humans",
    "href": "Lecture_Folder/Week7a.html#brain-body-size-neaderthals-as-compared-to-humans",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "href": "Lecture_Folder/Week7a.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "href": "Lecture_Folder/Week7a.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova",
    "href": "Lecture_Folder/Week7a.html#ancova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA",
    "text": "ANCOVA\n\nAnalysis of covariance - mixture of regression and ANOVA\nResponse is still a normally distributed continuous variable\nOne or more continuous predictor variables (covariates)\nSometimes the covariates are of biological interest\nMost often we want to remove unexplained variance\nIn this way they are similar to a blocking variable in ANOVA\nOperationally, ANCOVA is regular ANOVA in which the group and overall means are replaced by group and overall relationships"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-adjusting-for-the-covariate",
    "href": "Lecture_Folder/Week7a.html#ancova-adjusting-for-the-covariate",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-adjusting-for-the-covariate-1",
    "href": "Lecture_Folder/Week7a.html#ancova-adjusting-for-the-covariate-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-linear-model-with-two-covariates",
    "href": "Lecture_Folder/Week7a.html#ancova-linear-model-with-two-covariates",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Linear model with two covariates",
    "text": "ANCOVA | Linear model with two covariates"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-factor-and-covariate-hypothesis-tests",
    "href": "Lecture_Folder/Week7a.html#ancova-factor-and-covariate-hypothesis-tests",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Factor and covariate hypothesis tests",
    "text": "ANCOVA | Factor and covariate hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-f-ratio-tests",
    "href": "Lecture_Folder/Week7a.html#ancova-f-ratio-tests",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | F ratio tests",
    "text": "ANCOVA | F ratio tests"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-assumptions",
    "href": "Lecture_Folder/Week7a.html#ancova-assumptions",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Assumptions",
    "text": "ANCOVA | Assumptions\n\nThe residuals are normally distributed\nThe residuals show homoscedasticity of variance\nThe residuals are independent of one another\nThe relationship between the response variable and each covariate is linear\nHomogeneity of slopes among the groups\nSimilar covariate ranges among the groups"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-heterogeneous-slopes",
    "href": "Lecture_Folder/Week7a.html#ancova-heterogeneous-slopes",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-heterogeneous-slopes-1",
    "href": "Lecture_Folder/Week7a.html#ancova-heterogeneous-slopes-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes\n\nProblem - adjusting to a mean is difficult or impossible if the slopes are different\nIn essence, the samples for the groups come from two different populations\nA test for homogeneity of slopes can be performed\nThe assumption is tested by looking for a significant interaction term between the categorical response variables and the covariate(s)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#ancova-non-overlapping-range-of-the-covariate",
    "href": "Lecture_Folder/Week7a.html#ancova-non-overlapping-range-of-the-covariate",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANCOVA | Non-overlapping range of the covariate",
    "text": "ANCOVA | Non-overlapping range of the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-ancova",
    "href": "Lecture_Folder/Week7a.html#r-interlude-ancova",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nImpacts of sexual activity on male fruitfly longevity\nData from Partridge and Faraquhar (1981)\nLongevity of male measured in response to access to\n\nno females\none virgin\neight virgins\none mated\neight mated\n\nThe male fruit flies also varied in size\nThe males were assigned randomly to each of the treatment levels, and then measured thorax length as a covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-ancova-1",
    "href": "Lecture_Folder/Week7a.html#r-interlude-ancova-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nlongevity_data &lt;- read.table('longevity.csv', header=T, sep=',')\nhead(longevity_data)\n\nVariables\n\nlong &lt;- longevity_data$LONGEVITY\ntreat &lt;- longevity_data$TREATMENT\nthorax &lt;- longevity_data$THORAX\n\n\ncheck to see if the covariate should be included\n\n\nboxplot(long ~ treat)\nplot(long ~ thorax)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-ancova-2",
    "href": "Lecture_Folder/Week7a.html#r-interlude-ancova-2",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nassess assumptions of normality and homogeneity of variance\n\n\nplot(aov(long ~ thorax + treat ), which = 1)\n\n\n†ry it again with a transformed response variable\n\n\nplot(aov(log10(long) ~ thorax + treat ), which = 1)\n\n\nvisually assess linearity, homogenetiy of slopes and covariate range equality\n\n\nlibrary(lattice)\nprint(xyplot(log10(long) ~ thorax | treat, type = c(\"r\", \"p\")))"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#r-interlude-ancova-3",
    "href": "Lecture_Folder/Week7a.html#r-interlude-ancova-3",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nformally test homogenetiy of slopes by testing the interaction term\n\n\nanova(aov(log10(long) ~ thorax*treat))\n\n\nformally test covariate range disparity by modeling the effect of the treatments on the covariate\n\n\nanova(aov(thorax ~ treat))\n\n\nFINALLY, set up contrasts, fit the additive model and visualize the results (pg. 459 and 460 of your Logan book)\nSummarize the trends in a nice plot (pg. 461 of your Logan book)"
  },
  {
    "objectID": "Lecture_Folder/Week7a.html#anova-r-interlude-1",
    "href": "Lecture_Folder/Week7a.html#anova-r-interlude-1",
    "title": "Week 7a - Statistics for Bioengineering",
    "section": "ANOVA | R interlude",
    "text": "ANOVA | R interlude\n\n\n\nAttaching package: 'nlme'\n\n\nThe following object is masked from 'package:dplyr':\n\n    collapse\n\n\nLinear mixed-effects model fit by REML\n  Data: stickle_micro \n       AIC      BIC    logLik\n  1108.535 1115.644 -551.2677\n\nRandom effects:\n Formula: ~1 | Geno.Micro\n        (Intercept) Residual\nStdDev:    272.6901  237.105\n\nFixed effects:  Gene202 ~ 1 \n               Value Std.Error DF  t-value p-value\n(Intercept) 257.2125  138.8982 76 1.851806  0.0679\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.69680500 -0.24080838 -0.06883669  0.22398290  3.62528785 \n\nNumber of Observations: 80\nNumber of Groups: 4"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html",
    "href": "Lecture_Folder/Week7b.html",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#this-week",
    "href": "Lecture_Folder/Week7b.html#this-week",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nMultifactor ANOVA\n\nFactorial\nNested\n\nKey principles of experimental design\nGeneralized Linear Mixed Models (GLMMs)"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#multifactor-anova-1",
    "href": "Lecture_Folder/Week7b.html#multifactor-anova-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nThe factorial ANOVA design is the most common experimental design used to investigate more than one treatment variable\n\nIn a factorial design every combination of treatments from two (or more) treatment variables is investigated.\nThe main purpose of a factorial design is to evaluate possible interactions between variables.\nAn interaction between two explanatory variables means that the effect of one variable on the response depends on the state of a second variable.\n\nNested ANOVA or nested design\n\nfactors might be hierarchical - in other words nested - within one another\nThe sources of variance are therefore hierarchical too\nA common situation is where sampling of observations occurs within groups"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "href": "Lecture_Folder/Week7b.html#multifactor-anova-key-difference-between-nested-and-factorial-designs",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA | Key difference between nested and factorial designs",
    "text": "Multifactor ANOVA | Key difference between nested and factorial designs\n\nFactorial designs are\n\nall pairwise combinations,\nand often involve all combinations of factor levels\nwhen each factor is fixed interactions can be assessed\n\nNested designs are hierarchical\n\noften contain sub-replicates that are random, uncontrolled, nuisance effects\nbut the nested factors can be of interest too\n\nCompletely nested designs therefore have no interaction terms, whereas factorial designs do\nMixed models can have a combination of fixed and random factors that are more complicated"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#multifactor-anova-2",
    "href": "Lecture_Folder/Week7b.html#multifactor-anova-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA\n\nRelyae (2003) looked at how a moderate dose (1.6mg/L) of a commonly used pesticide, carbaryl (Sevin), affected bullfrog tadpole survival.\nIn particular, the experiment asked how the effect of carbaryl depended on whether a native predator, the red-spotted newt, was also present.\nThe experiment was carried out in 10-L tubs (experimental units), each containing 10 tadpoles.\nThe four combinations of pesticide treatment (carbaryl vs. water only) and predator treatment (present or absent) were randomly assigned to tubs.\nThe results showed that survival was high except when pesticide was applied together with the predator.\nThus, the two treatments, predation and pesticide, seem to have interacted."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#multifactor-anova-3",
    "href": "Lecture_Folder/Week7b.html#multifactor-anova-3",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Multifactor ANOVA",
    "text": "Multifactor ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#two-factor-factorial-designs",
    "href": "Lecture_Folder/Week7b.html#two-factor-factorial-designs",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Two Factor Factorial Designs",
    "text": "Two Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#three-factor-factorial-designs",
    "href": "Lecture_Folder/Week7b.html#three-factor-factorial-designs",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Three Factor Factorial Designs",
    "text": "Three Factor Factorial Designs"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#factorial-anova-both-main-effects-fixed",
    "href": "Lecture_Folder/Week7b.html#factorial-anova-both-main-effects-fixed",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Factorial ANOVA | both main effects fixed",
    "text": "Factorial ANOVA | both main effects fixed"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#factorial-designs-number-of-replicates",
    "href": "Lecture_Folder/Week7b.html#factorial-designs-number-of-replicates",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Factorial Designs | Number of Replicates",
    "text": "Factorial Designs | Number of Replicates"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#factorial-anova-both-main-effects-random",
    "href": "Lecture_Folder/Week7b.html#factorial-anova-both-main-effects-random",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Factorial ANOVA | both main effects random",
    "text": "Factorial ANOVA | both main effects random"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#the-mean-squares-for-a-factorial-model",
    "href": "Lecture_Folder/Week7b.html#the-mean-squares-for-a-factorial-model",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "The mean squares for a factorial model",
    "text": "The mean squares for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#the-f-ratios-for-a-factorial-model",
    "href": "Lecture_Folder/Week7b.html#the-f-ratios-for-a-factorial-model",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "The F-ratios for a factorial model",
    "text": "The F-ratios for a factorial model"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#interpretation-significant-main-and-interaction-effects",
    "href": "Lecture_Folder/Week7b.html#interpretation-significant-main-and-interaction-effects",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Interpretation | significant main and interaction effects",
    "text": "Interpretation | significant main and interaction effects"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#interaction-plots",
    "href": "Lecture_Folder/Week7b.html#interaction-plots",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Interaction plots",
    "text": "Interaction plots"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "href": "Lecture_Folder/Week7b.html#r-interlude-2-by-2-fixed-effect-factorial-anova",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA\n\nrna_data &lt;-read.table(\"Stickle_RNAseq.tsv\", header=T, sep=\"\\t\")\nhead(rna_data)\n\n  Individual Genotype   Microbiota Geno.Micro Gene1 Gene2 Gene3 Gene4 Gene5\n1        AC1        A conventional      convA    16    15    71   153     2\n2        AC2        A conventional      convA     7     6    72   123     1\n3        AC3        A conventional      convA     9     8    22   178     0\n4        AC4        A conventional      convA     8    18    15   128     2\n5        AC5        A conventional      convA    11    19    51   210     1\n6        AC6        A conventional      convA    19    20    31   148     2\n  Gene6 Gene7 Gene8 Gene9 Gene10 Gene11 Gene12 Gene13 Gene14 Gene15 Gene16\n1    11     9    11   540    104    866   1004     39     31      1     88\n2     4    11    17   374     84    837    908     38     29     20    100\n3    17    13    24   410    119    883   1261     31    105      3      5\n4    14    11    25   434     63    844    900     33      1     17    116\n5     9    11    15   390     84    843   1358     26    116      3     59\n6    14    13    18   541     95    815   1401     34     80     10     70\n  Gene17 Gene18 Gene19 Gene20 Gene21 Gene22 Gene23 Gene24 Gene25 Gene26 Gene27\n1     85   1429     16     21    166      8      4      5    136    178      2\n2     51   1564     17     10    177     10      9      9    102    173     12\n3     25   1656     16     37    179      3     16      8    203    221     13\n4    102   1587     17     23    174     16     11      6    190    170     11\n5     53   1471     17     21    177      4     17      7    201    162      8\n6     40   1517     16     23    173     12     10      9    116    210      5\n  Gene28 Gene29 Gene30 Gene31 Gene32 Gene33 Gene34 Gene35 Gene36 Gene37 Gene38\n1      5      4    825    172    196   1887     17     34    111    139     11\n2      1      4    836    204    137   1800     11     44    255    120      7\n3      1      9    661    341     48   2401     23     18      7    120      0\n4      3      4    905    193    202   2782     17     26     15    145      9\n5      3      5    931    220    261   2200     17      2    225    114     18\n6      2     10    686    221     58   2285     15     53     54    107     10\n  Gene39 Gene40 Gene41 Gene42 Gene43 Gene44 Gene45 Gene46 Gene47 Gene48 Gene49\n1     21      4     95    294    133      8      8    143      8    112     15\n2     12      5     78    303    116      9      2    322     11     95     14\n3      5      9     96    401    188      7     14      9     17      8     16\n4     28      5     86    344    146      7      9    176     13    135     16\n5     17     10     86    337    159      8      2    123     13    142     16\n6     16      6    100    277    109      8      3    369      7    114     15\n  Gene50 Gene51 Gene52 Gene53 Gene54 Gene55 Gene56 Gene57 Gene58 Gene59 Gene60\n1     23      2    141      4     15      9    303    112      4      2      9\n2      8      0    154      5     27      9    633    219      6      3      8\n3     23      2    167      8      1     14      0      2     72     49      8\n4      7      3    156      4      6     16    726     85    110     23      9\n5     23      2    144      6     22     14     34    346     23     62      9\n6     19      3    132      7      1      6    189    125      8     19      9\n  Gene61 Gene62 Gene63 Gene64 Gene65 Gene66 Gene67 Gene68 Gene69 Gene70 Gene71\n1      9      8     23  12310      3    225    287      1    211    675     20\n2     11     12     38  10732      4    175    285      0    178    469     23\n3     25     17     31   7924      2    115    283      1    216    328     63\n4     36     16     23  10259      3    112    287      1    174     88     18\n5      5     11     23   9190      5    288    286      1    173    429     36\n6      7     18     39  10743      3    146    282      0    203    331     26\n  Gene72 Gene73 Gene74 Gene75 Gene76 Gene77 Gene78 Gene79 Gene80 Gene81 Gene82\n1     35     13   8781      9     85      0      0      4     74    268    119\n2     59     16   8585      9     81      0      2      2    106    149    133\n3      1     13  11252      5    118      0      1      7    302     89    151\n4     75     12   7089      4     87      0      1      4     98    115    126\n5     49     12  10185      8     89      0      0      2    311    234    105\n6     40     13   8259      8     85      0      2      4    110    217    134\n  Gene83 Gene84 Gene85 Gene86 Gene87 Gene88 Gene89 Gene90 Gene91 Gene92 Gene93\n1     56      1    275    118    157   1126    248     15    155     66     28\n2     49      0    326    115    160   1100    250     24    147    118     34\n3     37      3    247    105    221    801    195      1    151     11     37\n4     42      0    233    110    169    918    245      4    148    135     31\n5     47      1    330    114    193    732    253     16    148     22     32\n6     40      1    191    112    179   1000    222     20    149      7     32\n  Gene94 Gene95 Gene96 Gene97 Gene98 Gene99 Gene100 Gene101 Gene102 Gene103\n1     50    224    131    276     12    108     937      17       1     148\n2     52    270    139    237     16     98     974      18       9     130\n3     90    162    142    463      0    147    1202       0       2     186\n4     81    166    138    266      7    105    1048       9       9     164\n5     27    314    131    316      2    145     982       7       2     154\n6     72    195    134    353     18    125     729      23       5     142\n  Gene104 Gene105 Gene106 Gene107 Gene108 Gene109 Gene110 Gene111 Gene112\n1     385       3      49      17      15      16      77      46      37\n2     269      14      95      11      10      17      55      26      20\n3     188       9       3      29      21       8      23      10       0\n4     364       9      46      35      12      19      49      31      35\n5     176       4      72      28      11      15       2      30       9\n6     427      29      62      15      20      10      16      60      25\n  Gene113 Gene114 Gene115 Gene116 Gene117 Gene118 Gene119 Gene120 Gene121\n1       1      21       8       1     853      37     240     776       4\n2       2      20      14       2     746      43     211     724       2\n3       1       8       6       1     247      60     294     185       2\n4       1      25       8       2     568      55     236     465       2\n5       0       9       6       2     511      53     222     675       4\n6       2       9      13       1    1066      45     316    1085       2\n  Gene122 Gene123 Gene124 Gene125 Gene126 Gene127 Gene128 Gene129 Gene130\n1       3      24     303      40      89     142     141    1582     557\n2       2      24     444      24      69     100     132    1511     609\n3       3      76     145      41     120     203     255    1885     163\n4       3      14     338      26     125     181     202    1744     612\n5       3      77     515      19      81     201     218    2121     266\n6       3      15     313      40      39      83       2    1527     481\n  Gene131 Gene132 Gene133 Gene134 Gene135 Gene136 Gene137 Gene138 Gene139\n1     351      55    1016      50     243      20     104     158       5\n2     322      41    1441      45     250      15      88     206       6\n3     507      84     907      94      47      22      62     315       5\n4     366     100    1162      74     194      19      47     353       5\n5     474      37    1432      96     274      22     105     110       6\n6     353      69    1520      10     281      21      54     169       4\n  Gene140 Gene141 Gene142 Gene143 Gene144 Gene145 Gene146 Gene147 Gene148\n1       1     252      22      40     104       8      26     404     634\n2       4     254      18     118      88       3      31     407     808\n3       0     397      88       0      26       1      25     389     769\n4       1     491      26      20     114       1      29     398     722\n5       1     361      42      23      76       7      30     396     733\n6       1     423       1      15     127       2      33     397     810\n  Gene149 Gene150 Gene151 Gene152 Gene153 Gene154 Gene155 Gene156 Gene157\n1      40      13       8      35     622      36      30      65     220\n2      20      17       4      78     531      41      26      41     193\n3      22      31       3       0     469      84       5      79     207\n4      36      28       4      17     374      14      31      55     224\n5      10      18       8       4     510     116      32      40     205\n6      31      25       1      90     425       6      22      43     190\n  Gene158 Gene159 Gene160 Gene161 Gene162 Gene163 Gene164 Gene165 Gene166\n1       9     517      61      21     102     205      35     159     420\n2      10     413      81      16      81     202      28     210     216\n3       3     555      54      38     130     341      19     204      38\n4       7     570      83       3     109     258      36     183     216\n5       7     518      58      12      63     273      29     212     324\n6       3     504      44      19     100     375      21     179     183\n  Gene167 Gene168 Gene169 Gene170 Gene171 Gene172 Gene173 Gene174 Gene175\n1     103     915       1     331       2     239     891    1823     489\n2      83     854       0     269       0     236     750    1707     465\n3      95    1084       3     369       0      87     318     581     677\n4      95    1111       1     432       0      72    1042     150     608\n5      83     938       1     354       0     318    1102    3281     585\n6      82     960       1     335       0     156     810     448     505\n  Gene176 Gene177 Gene178 Gene179 Gene180 Gene181 Gene182 Gene183 Gene184\n1      44     138      94      28      71     148     276     597       2\n2      99     180      98      27      80     108     349     581       5\n3       2     272      27       7       3     172     302     603       5\n4      78     195     123      10      56     113     324     590       6\n5      95     234      75      31      91     123     267     584       4\n6      61     170      84      11      37     205     261     605       3\n  Gene185 Gene186 Gene187 Gene188 Gene189 Gene190 Gene191 Gene192 Gene193\n1      32     157     111      90      15     186      76    3133      16\n2      46     161      84      96      14     216      86    2941      28\n3       6      81     162     107       1     892     526    3985      11\n4      20     126      15     103       4      41     189    4552      20\n5      58     155     185      94      12     248     635    3488      26\n6      56      94      93      90      15    1013     310    3643      14\n  Gene194 Gene195 Gene196 Gene197 Gene198 Gene199 Gene200 Gene201 Gene202\n1     110     869      27      58     196      17    1431      74      58\n2     114     820      48      45     194      17    1332      65      85\n3     308     928       5      19     219      13    3909      82      56\n4     234     820      13      47     206      18    3193      76      62\n5     370     884      33      28     193      14    3491      82      67\n6     182     793       3      35     205      16    2670      73      72\n  Gene203 Gene204 Gene205 Gene206 Gene207 Gene208 Gene209 Gene210 Gene211\n1       5      23       8       2      13     175       3    1054       4\n2       9      23       2       1      12     154       1    1041       4\n3       2       6       1       0      14     211       0      86      23\n4       0      12       5       0      13     196       0     580      12\n5       2      20       4       0      13     203       0     555       5\n6       3      17       3       2      13     184       0    1069       3\n  Gene212 Gene213 Gene214 Gene215 Gene216 Gene217 Gene218 Gene219 Gene220\n1    2226       2      83      53     160      15       3     250       8\n2    1952       6      27      82     139      19       5     239       9\n3     519       3      54      13     231      30      14     252       8\n4    1592       4      43      16     138      22       5     251       9\n5    1248       8      96      59     132      34       2     249       9\n6    1422       5      64      91     294      30       9     245       8\n  Gene221 Gene222 Gene223 Gene224 Gene225 Gene226 Gene227 Gene228 Gene229\n1     319    1678     293    3756     162      35     151     201      38\n2     303    1447     230    2859     161      20      77     188      37\n3     310    1430      73    3078     186      58      16     221       2\n4     326    1542     262    3511     172      26      20     225      79\n5     309    1665     204    3014     188       8     149     186      31\n6     314    1467     276    2215     183      56     243     219      22\n  Gene230 Gene231 Gene232 Gene233 Gene234 Gene235 Gene236 Gene237 Gene238\n1      40     578    1770     247      74     141     105     239      58\n2      21     553    1616     256     101      88      82     220     117\n3       3     696     438     225      59       3     148     130       9\n4      32     637    1553     236      77       3     141     108      64\n5       4     489    1830     246      82     165     118     104     118\n6       8     697    1401     256      47     152     139     302      52\n  Gene239 Gene240 Gene241 Gene242 Gene243 Gene244 Gene245 Gene246 Gene247\n1     335     116       4      63     364      31      67    8266       2\n2     308      96       4      59     326      74      51    8664       8\n3     470     208      23      95     412       3      41    8327      13\n4     329     213      11      71     343      56      34    8332      13\n5     380     122       4      71     402      34      66    8552       5\n6     334      86      12      84     330      18      62    8886      12\n  Gene248 Gene249 Gene250 Gene251 Gene252 Gene253 Gene254 Gene255 Gene256\n1      39      51      13      78       2     144      93      17     627\n2      48      47      24      84       6     194     106      20     611\n3       8      56      19      59       3     434     176      84     853\n4      29      50      22      87       4     279     152       6     615\n5      67      53      31      62       5     132     123      32     779\n6      25      50      11      85       2     135     203      32     825\n  Gene257 Gene258 Gene259 Gene260 Gene261 Gene262 Gene263 Gene264 Gene265\n1      30      14     419     102     675      46     120      23      21\n2      38      17     523     113     607     111     101       8      20\n3       7       2     757      94     399       1       7      60      13\n4      55       5     609     103     502      57     143       3      19\n5      26       3     280      81     463     130      19      41       5\n6       7       7     746      96     534      44      48       7      15\n  Gene266 Gene267 Gene268 Gene269 Gene270 Gene271 Gene272 Gene273 Gene274\n1      16       1      62     709       3     141      11     108      69\n2       9       2      54     661       2     163      17     100     110\n3       5       1      52     601      22     152       6      98      30\n4       7       1      69     646       7     130       8     105      58\n5       2       1      69     589      16     151      11      97     167\n6      15       2      57     694       8     144      15     102      67\n  Gene275 Gene276 Gene277 Gene278 Gene279 Gene280 Gene281 Gene282 Gene283\n1     110     216      26      39       5    2571      69     377    4921\n2      98     243      27      44       4    2889      69     448    4836\n3     113      72      14      60       1     485     116     495    4370\n4     115     193      33      32       2    3963     100     479    4641\n5     122     205      16      54       2    1215     121     455    4476\n6     102      96      20      47       0    2046      47     411    4622\n  Gene284 Gene285 Gene286 Gene287 Gene288 Gene289 Gene290 Gene291 Gene292\n1      24     237      71    2764     125     307    1344     437     429\n2      19     230      71    2742      94     303    1254     844     601\n3      24     262      96    2906     155     388    1477     143     114\n4      25     244      57    2606     115     427    1324    1076     522\n5      22     254      75    2844      84     311    1404     312      88\n6      22     263      98    2831     135     249    1524     576     150\n  Gene293 Gene294 Gene295 Gene296 Gene297 Gene298 Gene299 Gene300 Gene301\n1      55     157       5      24      16     594       8      55       2\n2      64     194      10      22      22     498      18      44       3\n3      52     264       6      30      51     785      17       1       2\n4      52     280       5      26      14     679      13      37       2\n5      56      91      10      26      28     680      11      18       1\n6      63     171       5      27       7     845      16       4       2\n  Gene302 Gene303 Gene304 Gene305 Gene306 Gene307 Gene308 Gene309 Gene310\n1    7380      72       5      49      16      18     167      39     131\n2    6331      90       8      43      36      11     183      36     121\n3    6978     114      13      46      27      17     208       9      33\n4    6661      89      11      52      19      22     211       6      59\n5    6519     105      10      48      29      13     153      27      74\n6    6528      87      14      53      15      17     164      50      92\n  Gene311 Gene312 Gene313 Gene314 Gene315 Gene316 Gene317 Gene318 Gene319\n1     655      63     115      11     140     282    1225     109       6\n2     296      67      97       8     139     236    1157     114       3\n3      55     180     121      19     121     338     273      91       5\n4     365      74     114       5     143     291     907     103       8\n5     586       5     139       9     135     363    1182     116       3\n6     759     123     119      20     135     280     334      93       5\n  Gene320 Gene321 Gene322 Gene323 Gene324 Gene325 Gene326 Gene327 Gene328\n1     330      57      33      43     306      86      22       4      28\n2     316      68      29      59     572      69      22       4      25\n3     330      81      30     134     124     164      21       6      33\n4     326      66      31      86     123      64      21       4      31\n5     331      53      30      50     107     121      22       2      33\n6     332      43      32      71     483     110      21       2      33\n  Gene329 Gene330 Gene331 Gene332 Gene333 Gene334 Gene335 Gene336 Gene337\n1     307      33       8     278      58       9       7      22      14\n2     404      24      11     227      56       9      15      36      14\n3     488      43      10     406      56       1      15       8       2\n4     357      20      13     264      55      10       9      32      13\n5     241      18       8     444      56       9      10      18       4\n6     402      42      10     513      57       8      16      19      17\n  Gene338 Gene339 Gene340 Gene341 Gene342 Gene343 Gene344 Gene345 Gene346\n1      12      88       7      45    1896      35       9      19    1042\n2      14     103      14      70    1717      27      21      19    2227\n3       6      70       6       9    1578      11      31       8     137\n4      11     127       4      48    1925      27      20      12    2354\n5       9      70       8      21    1684      22      20      19    3050\n6       7      88      11       8    1859      17      21      24    1112\n  Gene347 Gene348 Gene349 Gene350 Gene351 Gene352 Gene353 Gene354 Gene355\n1      30      77     159     164      53     122      36      18      66\n2      21     114     147     160      42     132      51      22      58\n3      42      25     216     236      46     152      42       6      87\n4      13      67     148     223      47     128      57       6      88\n5      19      41     125     211      54     125      34      29      56\n6      38      81     178     250      44     128      34      17      81\n  Gene356 Gene357 Gene358 Gene359 Gene360 Gene361 Gene362 Gene363 Gene364\n1      14     267       9     168       2       9      18       0     120\n2      22     243       5     382       2       1      21       0     101\n3       3     259       9       0      10       6      51       0      45\n4      20     258       8      84       3       6      39       0     185\n5      10     257       6     325       3       4      27       0      15\n6       8     248       5     234       5       3      41       0      64\n  Gene365 Gene366 Gene367 Gene368 Gene369 Gene370 Gene371 Gene372 Gene373\n1     790      51      98       6    1179     198    2562     346     296\n2     747      67      94      12    1324     424    2635     295     306\n3     857     259     313       1    2478       3    2814     361     313\n4     765     173     190      15    1594      62    2559     334     308\n5     845       2      28       1    2649     178    2586     371     292\n6     801     351     276       8    1781     301    2571     339     317\n  Gene374 Gene375 Gene376 Gene377 Gene378 Gene379 Gene380 Gene381 Gene382\n1     612      13     166      21      61      26      27    1155     978\n2     613      14     319      22      85      11      39     960     911\n3     160      19      10      27      65      32      13    1108     908\n4     313      16     282      21      85       2      24    1127     990\n5     434      16      77      18      79      17      30    1001     955\n6      93       8      57      21      61      38      27     916     938\n  Gene383 Gene384 Gene385 Gene386 Gene387 Gene388 Gene389 Gene390 Gene391\n1     124       3     267     245      77     128      98     272     282\n2     127       1     255     245      68     135      98     512     562\n3     144      37     495      52      80      24      96      97      66\n4     136      22     152     189      79      85      95     334     643\n5     121       1     306     184      73     115      97     334     515\n6     117       4     427     325      76     111      97      18      18\n  Gene392 Gene393 Gene394 Gene395 Gene396 Gene397 Gene398 Gene399 Gene400\n1     208     157     592       5     241      57    1146      13    1720\n2     362     233     547      34     442     101    2001      24    2700\n3      43      24     692       1      56       7     286      13    1043\n4     217     239     599       6     661      98    2298      21    2418\n5     120     328     606      13      44      86    1498      16     800\n6     126     170     713       9     394      57    1005      20     681\n  Gene401 Gene402 Gene403 Gene404 Gene405 Gene406 Gene407 Gene408 Gene409\n1    3289     841      44     102     137      51      78    2416     139\n2    4943    1245      47     111     152      56      67    2398     139\n3    1670     543      79     112     172      64      94    2285     276\n4    3322    1161      61     106     151      54      87    2204     134\n5    5556     606      41     113     144      48      73    2347     177\n6    5801    1017      39     103     178      54      60    2375      41\n  Gene410 Gene411 Gene412 Gene413 Gene414 Gene415 Gene416 Gene417 Gene418\n1     228     312      14    1683      97      54      24    1101    1568\n2     205     315      22    1224    1211      30      28    1015    1556\n3     192     383      25     908     107       5      13     324     369\n4     207     401      15    1666     481       5      19    1127     903\n5     217     345      19    1569     181      38      27     855     700\n6     198     278      26    1486      71      63      22    1733     882\n  Gene419 Gene420 Gene421 Gene422 Gene423 Gene424 Gene425 Gene426 Gene427\n1      19      36      50     787     657      69       3     826      58\n2      26      45      39     756     676      79       1     493      52\n3      14       5      41     210     826     126       1     231      94\n4      19      23      31      87     740      48       4     277      89\n5      22      60      43    1166     801     113       4     656      73\n6      15      31      39     470     793      98       2     570      59\n  Gene428 Gene429 Gene430 Gene431 Gene432 Gene433 Gene434 Gene435 Gene436\n1      18     464     135       9     105      59      11      15     174\n2      17     431     143      16     142      57      24      23     175\n3      23     435     192      10      99     110       0       9     293\n4      18     456     234       5     147      11      12      12      88\n5      17     443     139      17     109       1      20      19     175\n6      25     439     179       4     125      73       8      14     224\n  Gene437 Gene438 Gene439 Gene440 Gene441 Gene442 Gene443 Gene444 Gene445\n1      32      89      47      22      50     164     136       1     435\n2      30      79      34      19      44     113     124       0     533\n3      40       5       8      38      47      45     155       0     476\n4      27      98      31      15      45     110     130       1     513\n5      36      60      32      19      45     120     135       1     513\n6      31      26      33      39      45     186     163       0     392\n  Gene446 Gene447 Gene448 Gene449 Gene450 Gene451 Gene452 Gene453 Gene454\n1      27     130    1719     370      26      42       1      19      46\n2      33     141     858     325      26      54       1      10      41\n3      99     177     344     145       6       1       0      21      27\n4      72     179     501     146      23      13       0      12      38\n5      35     174     992     342      29      18       0      10      17\n6      29     180    1274     233      16      60       0      21      31\n  Gene455 Gene456 Gene457 Gene458 Gene459 Gene460 Gene461 Gene462 Gene463\n1       2       1      54      22     112     472     660      32      17\n2       0       2      39      11     110     411     618      50      20\n3      35      16      23      13     114     315     843      83      57\n4       7      12      47      21     110     486     748      79      49\n5       1      21      18      16     112     419     668      34      32\n6      14      19      16      16     112     451     712      67      32\n  Gene464 Gene465 Gene466 Gene467 Gene468 Gene469 Gene470 Gene471 Gene472\n1      42     104     937     162     116     605      34      14      66\n2      21      62     481     135     106     590      32      12      42\n3      55       9     321     239       3     564      23       2      11\n4      35       1     581     229      63     599      40      15      45\n5      60      34     579     177     117     575      29      12      78\n6      28     127     457     243     203     588      26       7      57\n  Gene473 Gene474 Gene475 Gene476 Gene477 Gene478 Gene479 Gene480 Gene481\n1      32    1073     138    1258     163      20       6      53     762\n2      35     970     171    1193     199      11       9      56     740\n3       7     209     178    2135     131       9      17     128     231\n4       3     287     172     982     106      17       5     153     238\n5      26     611     194    1686     104       3      11       4      76\n6      14     577     167    1685     197      20      10     137     560\n  Gene482 Gene483 Gene484 Gene485 Gene486 Gene487 Gene488 Gene489 Gene490\n1     992    1082      15     423      69     730      58     218    1675\n2     902     926      12     203      87     838      78     224    1728\n3     201     212       2      32     326     710      66     277    1808\n4    1061     678       8       1      72     825      69     280    1812\n5     826    1473      18     334       8     794      82     282    1788\n6      59    1122       7     198     420     643      68     262    1818\n  Gene491 Gene492 Gene493 Gene494 Gene495 Gene496 Gene497 Gene498 Gene499\n1     535    1937     166       3    2405     275    2008    1681      65\n2     549    1528     177       3    2262     273    1959    1654      70\n3     494    3667     237       7      67       6     534     439       5\n4     532    3312     223       3    2556     196    1169     374      14\n5     507    2511     171       2    1933     250    1330     922      29\n6     478    1160     208       3    1158       1    2213      18      14\n  Gene500 Gene501 Gene502 Gene503 Gene504 Gene505 Gene506 Gene507 Gene508\n1       4       1      20     205      23     176      47      14      22\n2       6      10      31     180      12     380      92      45      32\n3       7       5      38       7      18      11       5     123     148\n4       8       8      38      22      15     131      59      50      56\n5       6       4      21      90      25     312       4      71      83\n6       3       1      31     274      28     240       4      25      86\n  Gene509 Gene510 Gene511 Gene512 Gene513 Gene514 Gene515 Gene516 Gene517\n1      24     137     143     455      23       7       1       5     499\n2      53     147     113     406      31       4       9      12     505\n3     313     197     242     401       0      11       1      10    1154\n4      58      80      80     481       4       9       2       6     472\n5     154     198     141     415      31       9       3       7     742\n6     332     143     127     385       5      11       8      10     661\n  Gene518 Gene519 Gene520 Gene521 Gene522 Gene523 Gene524 Gene525 Gene526\n1     112    1030    2644       8      76      33       2      55    3567\n2     109     838    2676       9      67      51       2      36    2726\n3      73     226    2727      11      21      62       2      37    1033\n4      76    1538    2696       9      42      41       2      37    2523\n5      99     996    2667      11      26      45       2      46    1669\n6     130     298    2706       6      49      48       2      60    4378\n  Gene527 Gene528 Gene529 Gene530 Gene531 Gene532 Gene533 Gene534 Gene535\n1     292     312     290      64       0      57     574     144      56\n2     310     323     275      41       8      67     488     140      85\n3     300     283     381      90      10     131     967      37     113\n4     293     283     339     117      11     111     492      82      95\n5     311     317     299      16       1      92     431     117      56\n6     301     337     189      16      11       5     682     128      51\n  Gene536 Gene537 Gene538 Gene539 Gene540 Gene541 Gene542 Gene543 Gene544\n1     231      84     101    1252      43       2    1026      89      62\n2     219      63     120    1278      47       8     734      56      80\n3      59      23     106    1260      23      17     633      51     111\n4     348      26     106    1270      34       6     760      78      97\n5      73      76     113    1261      45       5    1030      46      42\n6     197     128     107    1260      45       9     643      57     109\n  Gene545 Gene546 Gene547 Gene548 Gene549 Gene550 Gene551 Gene552 Gene553\n1     175     324      82      27      53      53      17       6     313\n2     179     285      50      33      58      29      19       3     415\n3     170     394     355      16      48      51       6      47     305\n4     175     384     133      26      47      48       6      11     311\n5     175     246     288      23      58      55       9      19     324\n6     177     295     218      20      51      32      18      32     323\n  Gene554 Gene555 Gene556 Gene557 Gene558 Gene559 Gene560 Gene561 Gene562\n1       7     655      17     299      19     207      15      96      13\n2      17     606      19     263      19     153       9     114      25\n3      59     744      27     388      21     217      11      88       7\n4      20     716      27     185      18     221      11      81      28\n5       9     792      24     316      19     190      14      84      11\n6      52     751      17     299      20     210       9     110       0\n  Gene563 Gene564 Gene565 Gene566 Gene567 Gene568 Gene569 Gene570 Gene571\n1      33     158      51      28      17       1       5      19      23\n2      36     141      52      25       1       1       5      20      17\n3      68     183      73      49      13       1       2      22     152\n4      54     162      59      22       9       1       4      20      60\n5      45     186      48      14       1       1       6      19     165\n6      62     201      66      34      13       1       4      21      40\n  Gene572 Gene573 Gene574 Gene575 Gene576 Gene577 Gene578 Gene579 Gene580\n1      52       0      42     189     252      55     639      41      52\n2      88       2      63     189     239      77     668      48      41\n3     142      10       5     150     296      98     228      48      14\n4     185       5      42     163     272      66     609      45      22\n5      48       1       9     168     297      80     409      52      14\n6     112       2      48     205     299      83     458      47      41\n  Gene581 Gene582 Gene583 Gene584 Gene585 Gene586 Gene587 Gene588 Gene589\n1     310       9     332    1458     173      45      55     147     129\n2     308       8     164    1879     325      55      46     147     116\n3      95      10      96    1285       2      82       0       0     155\n4     298       8     428    1606     280      76      48      46     147\n5     247       9     101    1082     109      47      65     111     150\n6      79       8     305    1487     343      54      71      37     133\n  Gene590 Gene591 Gene592 Gene593 Gene594 Gene595 Gene596 Gene597 Gene598\n1      30       0       0       2       1      14      22      11       1\n2     770       4       2       2       2      22      14      24       6\n3      24       1       0       1       0      22      17      13       1\n4     593       4       1       1       1      24      22      32       7\n5     244       5       1       2       2      17      17      21       0\n6     544       3       0       1       1      21      21      21       2\n  Gene599 Gene600\n1      24      69\n2      82      88\n3      25      70\n4      37      87\n5       4      66\n6      25      80"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-2-by-2-fixed-effect-factorial-anova-1",
    "href": "Lecture_Folder/Week7b.html#r-interlude-2-by-2-fixed-effect-factorial-anova-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA",
    "text": "R INTERLUDE | 2-by-2 fixed effect factorial ANOVA\n\ncontinuous response variable and two main effect categorical variables\n\n\ngene &lt;- rna_data$Gene100\nmicrobiota &lt;- rna_data$Microbiota\ngenotype &lt;- rna_data$Genotype\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#by-2-fixed-effect-boxplots",
    "href": "Lecture_Folder/Week7b.html#by-2-fixed-effect-boxplots",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2-by-2 fixed effect boxplots",
    "text": "2-by-2 fixed effect boxplots"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#by-2-fixed-effect-boxplots-1",
    "href": "Lecture_Folder/Week7b.html#by-2-fixed-effect-boxplots-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2-by-2 fixed effect boxplots",
    "text": "2-by-2 fixed effect boxplots"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#by-2-fixed-effect-boxplots-2",
    "href": "Lecture_Folder/Week7b.html#by-2-fixed-effect-boxplots-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2-by-2 fixed effect boxplots",
    "text": "2-by-2 fixed effect boxplots"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing",
    "href": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Fit the factorial linear model | different ways to do the same thing",
    "text": "Fit the factorial linear model | different ways to do the same thing\n\nrna_aov &lt;- aov(gene ~ microbiota + genotype + microbiota:genotype)\nrna_aov &lt;- aov(gene ~ microbiota*genotype)\nrna_lm &lt;- lm(gene ~ microbiota + genotype + microbiota:genotype)\nrna_lm &lt;- lm(gene ~ microbiota*genotype)\n\n\nExamine the fitted model diagnostics and the ANOVA results table"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing-1",
    "href": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Fit the factorial linear model | different ways to do the same thing",
    "text": "Fit the factorial linear model | different ways to do the same thing\n\nplot(rna_aov)\nsummary(rna_aov)\nanova(rna_aov)\n\nplot(rna_lm)\nsummary(rna_alm)\nanova(rna_alm)"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing-2",
    "href": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Fit the factorial linear model | different ways to do the same thing",
    "text": "Fit the factorial linear model | different ways to do the same thing\n\nanova(rna_aov)\n\nAnalysis of Variance Table\n\nResponse: gene\n                    Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nmicrobiota           1  243763  243763  6.8179   0.01087 *  \ngenotype             1    4234    4234  0.1184   0.73170    \nmicrobiota:genotype  1 1452066 1452066 40.6133 1.299e-08 ***\nResiduals           76 2717264   35753                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nanova(rna_lm)\n\nAnalysis of Variance Table\n\nResponse: gene\n                    Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nmicrobiota           1  243763  243763  6.8179   0.01087 *  \ngenotype             1    4234    4234  0.1184   0.73170    \nmicrobiota:genotype  1 1452066 1452066 40.6133 1.299e-08 ***\nResiduals           76 2717264   35753                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing-3",
    "href": "Lecture_Folder/Week7b.html#fit-the-factorial-linear-model-different-ways-to-do-the-same-thing-3",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Fit the factorial linear model | different ways to do the same thing",
    "text": "Fit the factorial linear model | different ways to do the same thing\n\nsummary(rna_aov)\n\n                    Df  Sum Sq Mean Sq F value  Pr(&gt;F)    \nmicrobiota           1  243763  243763   6.818  0.0109 *  \ngenotype             1    4234    4234   0.118  0.7317    \nmicrobiota:genotype  1 1452066 1452066  40.613 1.3e-08 ***\nResiduals           76 2717264   35753                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(rna_lm)\n\n\nCall:\nlm(formula = gene ~ microbiota * genotype)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-336.00 -131.85   19.52  144.00  507.00 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)               1004.95      42.28  23.768  &lt; 2e-16 ***\nmicrobiotamono             159.05      59.79   2.660  0.00953 ** \ngenotypeB                  254.90      59.79   4.263 5.73e-05 ***\nmicrobiotamono:genotypeB  -538.90      84.56  -6.373 1.30e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 189.1 on 76 degrees of freedom\nMultiple R-squared:  0.3849,    Adjusted R-squared:  0.3606 \nF-statistic: 15.85 on 3 and 76 DF,  p-value: 4.254e-08"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#interaction-plots-1",
    "href": "Lecture_Folder/Week7b.html#interaction-plots-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Interaction Plots",
    "text": "Interaction Plots\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nsummary_df &lt;- rna_data |&gt;\n  group_by(Genotype, Microbiota) |&gt;\n  summarise(mean_response = mean(Gene100), .groups = \"drop\")\n\nsummary_df &lt;- rna_data |&gt;\n  group_by(Genotype, Microbiota) |&gt;\n  summarise(mean_response = mean(Gene100),\n            se = sd(Gene100) / sqrt(n()), .groups = \"drop\")\n\n# ggplot interaction plot\nggplot(summary_df, aes(x = Genotype, y = mean_response, group = Microbiota, color = Microbiota)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = mean_response - se, ymax = mean_response + se), width = 0.2) +\n  labs(title = \"Interaction Plot with SE\",\n       x = \"Genotype\",\n       y = \"Mean Expression of Gene100\",\n       color = \"Microbiota\") +\n  theme_minimal()"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#interaction-plots-2",
    "href": "Lecture_Folder/Week7b.html#interaction-plots-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Interaction Plots",
    "text": "Interaction Plots\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "href": "Lecture_Folder/Week7b.html#means-tests-factor-level-combinations-in-multi-factor-anova",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Means tests | factor level combinations in multi-factor ANOVA",
    "text": "Means tests | factor level combinations in multi-factor ANOVA\n\nThe F-ratio test for a single-factor ANOVA tests for any difference among groups.\nIf we want to understand specific differences, we need further “contrasts”.\nUnplanned comparisons (post hoc)\nPlanned comparisons (a priori)\nNow we need to make ‘pseudo-factors’ that combine our levels of interest"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#planned-a-priori-contrasts",
    "href": "Lecture_Folder/Week7b.html#planned-a-priori-contrasts",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Planned (a priori) contrasts",
    "text": "Planned (a priori) contrasts"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "href": "Lecture_Folder/Week7b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\ncontinuous response and two main effect variables\n\nrna_data &lt;-read.table(\"Stickle_RNAseq.tsv\", header=T, sep=\"\\t\")\ngene &lt;- rna_data$Gene80\nmicrobiota &lt;- rna_data$Microbiota\ngenotype &lt;- rna_data$Genotype\n\nmake new “pseudo factor,” combining genotype and microbiota\n\ngxm &lt;- interaction(genotype,microbiota)\nlevels(gxm)\n\n[1] \"A.conventional\" \"B.conventional\" \"A.mono\"         \"B.mono\"        \n\nboxplot(gene ~ gxm)\n\n\n\n\n\n\n\n\nspecify the following 2 contrasts\n\ncontrasts(gxm) &lt;- cbind(c(2, -1, 0, -1), c(-1, -1, 3, -1))"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "href": "Lecture_Folder/Week7b.html#r-interlude-2x2-fixed-effects-factorial-anova-contrasts-interaction-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction",
    "text": "R INTERLUDE | 2x2 Fixed-Effects Factorial ANOVA contrasts & interaction\nFit the factorial linear model\n\nrna_aov &lt;- aov(gene ~ gxm)\n\nExamine the ANOVA table, using supplied contrasts. Figure out the appropriate titles to give them.\n\nsummary(rna_aov, split = list(gxm = list('xxx'=1,'xxx'=2)))\n\nWhat does the contrast summary tell you about the nature of the interaction?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nested-anova-walking-stick-example",
    "href": "Lecture_Folder/Week7b.html#nested-anova-walking-stick-example",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\n\nExample 1: Study of “repeatability” (simple nested design)\nThe walking stick, Timema cristinae, is a wingless herbivorous insect on plants in chaparral habitats of California.\nNosil and Crespi (2006) measured individuals using digital photographs.\nTo evaluate measurement repeatability they took two separate photographs of each specimen.\nAfter measuring traits on one set of photographs, they repeated the measurements on the second set."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nested-anova-walking-stick-example-1",
    "href": "Lecture_Folder/Week7b.html#nested-anova-walking-stick-example-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example\nEach pair of dots represents the two measurements"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nested-anova-walking-stick-example-2",
    "href": "Lecture_Folder/Week7b.html#nested-anova-walking-stick-example-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nested ANOVA | Walking stick example",
    "text": "Nested ANOVA | Walking stick example"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nested-anova-anova-table-of-results",
    "href": "Lecture_Folder/Week7b.html#nested-anova-anova-table-of-results",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nested ANOVA | ANOVA Table of Results",
    "text": "Nested ANOVA | ANOVA Table of Results"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nesting-logic",
    "href": "Lecture_Folder/Week7b.html#nesting-logic",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nesting Logic",
    "text": "Nesting Logic"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nesting-equations",
    "href": "Lecture_Folder/Week7b.html#nesting-equations",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nesting equations",
    "text": "Nesting equations"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nesting-hypothesis-tests",
    "href": "Lecture_Folder/Week7b.html#nesting-hypothesis-tests",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nesting hypothesis tests",
    "text": "Nesting hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nesting-ms-calculations",
    "href": "Lecture_Folder/Week7b.html#nesting-ms-calculations",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nesting MS calculations",
    "text": "Nesting MS calculations"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#nested-anova-table-of-results",
    "href": "Lecture_Folder/Week7b.html#nested-anova-table-of-results",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Nested ANOVA table of results",
    "text": "Nested ANOVA table of results"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-nested-anova",
    "href": "Lecture_Folder/Week7b.html#r-interlude-nested-anova",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-nested-anova-1",
    "href": "Lecture_Folder/Week7b.html#r-interlude-nested-anova-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nandrew_data &lt;- read.table('andrew.tsv', header=T, sep=‘\\t')\nhead(andrew_data)\n\n\nThere are four variables: ‘TREAT’, ‘PATCH’, ‘QUAD’ and ‘ALGAE’\nThe main effect factor is TREAT\nMake a simplified factor called TREAT2, in which 0% and 33% are a level called “low” and 66% and 100% are “high”\n\n\nandrew_data$TREAT2 &lt;- factor(c(rep(“low”,40),rep(“high”,40))\n\n\nThe nested factor is PATCH - also need to turn this into a factor\n\n\nandrew_data$PATCH &lt;- factor(andrew_data$PATCH)"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-nested-anova-2",
    "href": "Lecture_Folder/Week7b.html#r-interlude-nested-anova-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nIn this case, our response variable is ALGAE\nLook at the distribution of ALGAE for the two levels of TREAT2 using boxplots based on the patch means, which are the replicates in this case.\n\n\nandrew.agg &lt;- with(andrew_data, aggregate(data.frame(ALGAE), \n                  by = list(TREAT2=TREAT2, PATCH=PATCH), mean)\n\nlibrary(nlme)\nandrew.agg &lt;- gsummary(andrew_data, groups=andrew_data$PATCH)\n\nboxplot(ALGAE ~ TREAT2, andrew.agg)\n\n\nEvaluate assumptions based on the boxplots\nIs the design balanced (equal numbers of sub-replicates per PATCH)?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-nested-anova-3",
    "href": "Lecture_Folder/Week7b.html#r-interlude-nested-anova-3",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Nested ANOVA",
    "text": "R INTERLUDE | Nested ANOVA\n\nRun the nested ANOVA:\n\n\nnested.aov &lt;- aov(ALGAE ~ TREAT2 + Error(PATCH), data=andrew_data)\nsummary(nested.aov)\n\n\nDo we detect an effect of TREAT2 (high vs low sea urchin density)?\nEstimate variance components to assess relative contributions of the random factors\n\n\nlibrary(nlme)\nVarCorr(lme(ALGAE ~ 1, random = ~1 | TREAT2/PATCH, andrew_data))\n\n\nCalculate the % of variation due to between-treatment differences vs. due to among patches within treatment differences.\nWhat do these variance component estimates tell us???"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#what-is-an-experimental-study",
    "href": "Lecture_Folder/Week7b.html#what-is-an-experimental-study",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "What is an experimental study?",
    "text": "What is an experimental study?\n\nIn an experimental study the researcher assigns treatments to units\nIn an observational study nature does the assigning of treatments to units\nThe crucial advantage of experiments derives from the random assignment of treatments to units\nRandomization minimizes the influence of confounding variables\nCan infer cause and effect more easily"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#mount-everest-example",
    "href": "Lecture_Folder/Week7b.html#mount-everest-example",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\nSurvival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.\nWhy?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#mount-everest-example-1",
    "href": "Lecture_Folder/Week7b.html#mount-everest-example-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\n\nOne possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).\nThe other is that the two variables are associated because other variables affect both supplemental oxygen and survival.\nUse of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.\nVariables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called confounding variables\nThey are correlated with the variable of interest, and therefore preventing a decision about cause and effect.\nWith random assignment, no confounding variables will be associated with treatment except by chance."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#clinical-trials",
    "href": "Lecture_Folder/Week7b.html#clinical-trials",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Clinical Trials",
    "text": "Clinical Trials\n\nThe gold standard of experimental designs is the clinical trial\nExperimental design in all areas of biology have been informed by procedures used in clinical trials\nA clinical trial is an experimental study in which two or more treatments are assigned to human subjects\nThe design of clinical trials has been refined because the cost of making a mistake with human subjects is so high\nExperiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#example-of-a-clinical-trial",
    "href": "Lecture_Folder/Week7b.html#example-of-a-clinical-trial",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial\n\nTransmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa\nThe spermicide nonoxynol-9 had shown in vitro activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).\nThey tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.\nData were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.\nTwo gel treatments were assigned randomly to women at each clinic.\nOne gel contained nonoxynol-9 and the other a placebo.\nNeither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#example-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week7b.html#example-of-a-clinical-trial-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#design-components-of-a-clinical-trial",
    "href": "Lecture_Folder/Week7b.html#design-components-of-a-clinical-trial",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\nThe goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.\n\nTo reduce bias, the experiment included:\n\nSimultaneous control group: study included both the treatment of interest and a control group (the women receiving the placebo).\nRandomization: treatments were randomly assigned to women at each clinic.\nBlinding: neither the subjects nor the clinicians knew which women were assigned which treatment."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#design-components-of-a-clinical-trial-1",
    "href": "Lecture_Folder/Week7b.html#design-components-of-a-clinical-trial-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\n\nTo reduce the effects of sampling error, the experiment included:\n\nReplication: study was carried out on multiple independent subjects.\nBalance: number of women was nearly equal in the two groups at every clinic.\nBlocking: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”)."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#simultaneous-control-group",
    "href": "Lecture_Folder/Week7b.html#simultaneous-control-group",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "1. Simultaneous control group",
    "text": "1. Simultaneous control group\n\nIn clinical trials either a placebo or the currently accepted treatment should be provided.\nIn experiments requiring intrusive methods to administer treatment, such as\n\ninjections\nsurgery\nrestraint\nconfinement\n\nthe control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#simultaneous-control-group-1",
    "href": "Lecture_Folder/Week7b.html#simultaneous-control-group-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "1. Simultaneous control group",
    "text": "1. Simultaneous control group\n\nThe “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.\nIn field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.\nIdeally, the same disturbance should be applied to the control plots."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#randomization",
    "href": "Lecture_Folder/Week7b.html#randomization",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2. Randomization",
    "text": "2. Randomization\n\nThe researcher should randomize assignment of treatments to units or subjects\nChance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control\nA completely randomized design is one in which treatments are assigned to all units by randomization"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#randomization-1",
    "href": "Lecture_Folder/Week7b.html#randomization-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2. Randomization",
    "text": "2. Randomization\n\nRandomization breaks the association between possible confounding variables and the explanatory variable\nRandomization doesn’t eliminate the variation contributed by confounding variables, only their correlation with treatment\nRandomization ensures that variation from confounding variables is similar between the different treatment groups."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#randomization-2",
    "href": "Lecture_Folder/Week7b.html#randomization-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2. Randomization",
    "text": "2. Randomization\n\nRandomization should be carried out using a random process:\n\nList all n subjects, one per row, in a computer spreadsheet.\nUse the computer to give each individual a random number.\nAssign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.\n\nOther ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.\n“Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#randomization-types",
    "href": "Lecture_Folder/Week7b.html#randomization-types",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2. Randomization Types",
    "text": "2. Randomization Types\n\nCompletely randomized design - all subjects are placed to treatment or control with equal probability\nRandomized block - first broken into groups (e.g. age or gender) then assigned to treatment groups at random\nMatched pair design - subjects are paired by similarity before being randomly assigned to treatment groups"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#random-sampling-approaches",
    "href": "Lecture_Folder/Week7b.html#random-sampling-approaches",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "2. Random sampling approaches",
    "text": "2. Random sampling approaches\n\nsimple random sample - every sample has equal probability of being chosen\nstratified sample - divided into groups then a simple random sample are taken from each\ncluster sample - divided into similar group, usually naturally occured, a simple random samples of clusters is then taken and very member of the cluster is included in the sample\nmultistage sampling - combines the above. First clusters are random sampled. Second random samples are take from each. Then process is repeated\nsystematic sample - members of a sample are chosen in a pre-determined ways. e.g Choose every 20th person coming into a store"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blinding",
    "href": "Lecture_Folder/Week7b.html#blinding",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "3. Blinding",
    "text": "3. Blinding\n\nBlinding is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.\nBlinding prevents subjects and researchers from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.\nFor example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding (Ernst and White 1998)."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blinding-1",
    "href": "Lecture_Folder/Week7b.html#blinding-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "3. Blinding",
    "text": "3. Blinding\n\nIn a single-blind experiment, the subjects are unaware of the treatment that they have been assigned.\nTreatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.\nBlinding can also be a concern in non-human studies where animals respond to stimuli"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blinding-2",
    "href": "Lecture_Folder/Week7b.html#blinding-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "3. Blinding",
    "text": "3. Blinding\n\nIn a double-blind experiment the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments\n\nResearchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome\nMany response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias\nResearchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blinding-3",
    "href": "Lecture_Folder/Week7b.html#blinding-3",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "3. Blinding",
    "text": "3. Blinding\n\nReviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).\nExperiments on non–human subjects are also prone to bias from lack of blinding."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blinding-4",
    "href": "Lecture_Folder/Week7b.html#blinding-4",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "3. Blinding",
    "text": "3. Blinding\n\nBebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.\nBlinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order)."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#replication",
    "href": "Lecture_Folder/Week7b.html#replication",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "4. Replication",
    "text": "4. Replication\n\nThe goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables\nOne way to reduce noise is to make the experimental conditions constant\nIn field experiments, however, highly constant experimental conditions might not be feasible nor desirable\nBy limiting the conditions of an experiment, we also limit the generality of the results\nAnother way to make treatment effects stand out is to include extreme treatments and to replicate the data."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#replication-1",
    "href": "Lecture_Folder/Week7b.html#replication-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "4. Replication",
    "text": "4. Replication\n\nReplication is the assignment of each treatment to multiple, independent experimental units.\nWithout replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.\nStudies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.\nLarger samples mean more information, and more information means better estimates and more powerful tests."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#replication-2",
    "href": "Lecture_Folder/Week7b.html#replication-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "4. Replication",
    "text": "4. Replication\n\nReplication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.\nThe figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#pseudoreplication",
    "href": "Lecture_Folder/Week7b.html#pseudoreplication",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "4. Pseudoreplication",
    "text": "4. Pseudoreplication"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#balance",
    "href": "Lecture_Folder/Week7b.html#balance",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "5. Balance",
    "text": "5. Balance\n\nA study design is balanced if all treatments have the same sample size.\nConversely, a design is unbalanced if there are unequal sample sizes between treatments.\nBalance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.\nTo appreciate this, look again at the equation for the standard error of the difference between two treatment means."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#balance-1",
    "href": "Lecture_Folder/Week7b.html#balance-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "5. Balance",
    "text": "5. Balance\n\nFor a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.\nBalance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blocking",
    "href": "Lecture_Folder/Week7b.html#blocking",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "6. Blocking",
    "text": "6. Blocking\n\nBlocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.\nBlocking essentially repeats the same, completely randomized experiment multiple times, once for each block.\nDifferences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks is discarded."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blocking-paired-designs",
    "href": "Lecture_Folder/Week7b.html#blocking-paired-designs",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "6. Blocking | Paired designs",
    "text": "6. Blocking | Paired designs\n\nFor example, consider the design choices for a two-treatment experiment to investigate the effect of clear cutting on salamander density.\nIn the completely randomized (“two-sample”) design we take a random sample of forest plots from the population and then randomly assign each plot to either the clear-cut treatment or the no clear-cut treatment.\nIn the paired design we take a random sample of forest plots and clear-cut a randomly chosen half of each plot, leaving the other half untouched."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blocking-paired-designs-1",
    "href": "Lecture_Folder/Week7b.html#blocking-paired-designs-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "6. Blocking | Paired designs",
    "text": "6. Blocking | Paired designs\n\nIn the paired design, measurements on adjacent plot-halves are not independent. This is because they are likely to be similar in soil, water, sunlight, and other conditions that affect the number of salamanders.\nAs a result, we must analyze paired data differently than when every plot is independent of all the others, as in the case of the two-sample design.\nPaired design is usually more powerful than completely randomized design because it controls for a lot of the extraneous variation between plots or sampling units that sometimes obscures the effects we are looking for."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blocking-paired-designs-2",
    "href": "Lecture_Folder/Week7b.html#blocking-paired-designs-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "6. Blocking | Paired designs",
    "text": "6. Blocking | Paired designs"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#blocking-randomized-complete-block-design",
    "href": "Lecture_Folder/Week7b.html#blocking-randomized-complete-block-design",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "6. Blocking | Randomized complete block design",
    "text": "6. Blocking | Randomized complete block design\n\nRCB design is analogous to the paired design, but may have more than two treatments. Each treatment is applied once to every block.\nAs in the paired design, treatment effects in a randomized block design are measured by differences between treatments exclusively within blocks.\nBy accounting for some sources of sampling variation blocking can make differences between treatments stand out.\nBlocking is worthwhile if units within blocks are relatively homogeneous, apart from treatment effects, and units belonging to different blocks vary because of environmental or other differences."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#what-if-you-cant-do-experiments",
    "href": "Lecture_Folder/Week7b.html#what-if-you-cant-do-experiments",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "What if you can’t do experiments?",
    "text": "What if you can’t do experiments?\n\nExperimental studies are not always feasible, in which case we must fall back upon observational studies.\nThe best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.\nRandomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.\nTwo strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates)."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#what-is-a-glmm",
    "href": "Lecture_Folder/Week7b.html#what-is-a-glmm",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "What is a GLMM?",
    "text": "What is a GLMM?\n\nGeneral Linear Mixed Model (GLMM) - a continuous response variable with a mix of continuous and categorical predictor variables, can be used to model random effects"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#how-do-we-factor-in-categorical-variables",
    "href": "Lecture_Folder/Week7b.html#how-do-we-factor-in-categorical-variables",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "How do we factor in categorical variables?",
    "text": "How do we factor in categorical variables?\n\nFor a single categorical predictor, we can include effects of each factor level:\n\n\\[ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e \\]\n\nEach factor level (ex: for Wolbachia: Yes or No) becomes it’s own “effector” that will change the value of y\nInstead of x being a continuous numerical value, for categorical data it will be either a 0 or 1"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#a-generalized-linear-model",
    "href": "Lecture_Folder/Week7b.html#a-generalized-linear-model",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "A Generalized Linear Model",
    "text": "A Generalized Linear Model\n\nCheck out the help page in RStudio for glm()\n\n\nglm(formula = y ~ x1 + x2, family = gaussian(link = \"identity\"))"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "href": "Lecture_Folder/Week7b.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nSet up a glm() to test for the effect of Wolbachia infection on Recombinant Fraction"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "href": "Lecture_Folder/Week7b.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nWhat do these components mean?\n\n\nfly &lt;- read.table(\"Mostoufi2022_Recombination_Edit.csv\", header=T, sep=',')\nmodel &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link=\"identity\"))\nsummary(model)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.348054   0.005845  59.545   &lt;2e-16 ***\nfly$WolbachiaYes 0.021664   0.008474   2.557   0.0112 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00406577)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91480  on 225  degrees of freedom\nAIC: -601.48\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#interpreting-the-glm",
    "href": "Lecture_Folder/Week7b.html#interpreting-the-glm",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nWhy is our intercept significant?\n\nRemember that the null hypothesis is a model with an intercept and slope of 0\n\nHow would you interpret the “WolbachiaYes” coefficient, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#second-steps---adding-more-variables",
    "href": "Lecture_Folder/Week7b.html#second-steps---adding-more-variables",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nNow let’s add Food to our model - how does this change our model results?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#second-steps---adding-more-variables-1",
    "href": "Lecture_Folder/Week7b.html#second-steps---adding-more-variables-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nmodel2 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = \"identity\"))\nsummary(model2)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, \n    family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.344691   0.008121  42.445   &lt;2e-16 ***\nfly$WolbachiaYes 0.021731   0.008504   2.555   0.0113 *  \nfly$FoodSucrose  0.002933   0.010481   0.280   0.7799    \nfly$FoodYeast    0.007366   0.010128   0.727   0.4678    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00409246)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91262  on 223  degrees of freedom\nAIC: -598.02\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#interpreting-the-glm-1",
    "href": "Lecture_Folder/Week7b.html#interpreting-the-glm-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nHow would you interpret the Intercept and Food coefficients, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#interaction-effects-in-glms",
    "href": "Lecture_Folder/Week7b.html#interaction-effects-in-glms",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Interaction effects in GLMs",
    "text": "Interaction effects in GLMs\n\nYou can also model interactions between two categorical variables in glms\n\nWhat if variable x and variable z interact in non-additive ways?\n\nUse the notation x*z in the formula"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#third-steps---adding-interaction-effects",
    "href": "Lecture_Folder/Week7b.html#third-steps---adding-interaction-effects",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nLet’s finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model\nRun the model - what are the results?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#third-steps---adding-interaction-effects-1",
    "href": "Lecture_Folder/Week7b.html#third-steps---adding-interaction-effects-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nHow do we interpret these findings?\n\n\nmodel3 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = \"identity\"))\nsummary(model3)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + \n    fly$Wolbachia * fly$Food, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       0.344520   0.009760  35.298   &lt;2e-16 ***\nfly$WolbachiaYes                  0.022080   0.013970   1.581    0.115    \nfly$FoodSucrose                   0.010286   0.014458   0.711    0.478    \nfly$FoodYeast                     0.001256   0.014059   0.089    0.929    \nfly$WolbachiaYes:fly$FoodSucrose -0.015873   0.021002  -0.756    0.451    \nfly$WolbachiaYes:fly$FoodYeast    0.012910   0.020282   0.637    0.525    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.004096248)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.90527  on 221  degrees of freedom\nAIC: -595.86\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#how-do-we-know-which-model-to-use",
    "href": "Lecture_Folder/Week7b.html#how-do-we-know-which-model-to-use",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "How do we know which model to use?",
    "text": "How do we know which model to use?\n\nWant to be careful not to overfit your linear model (give too many variables)\nThe Akaike information criterion (AIC) is a metric for comparing different models to find the best fit\n\nNotice the AIC score in your output?\nFor more on this, take Advanced Bio Stats! Or do some reading on the internet."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#attributes-of-mixed-effects-models",
    "href": "Lecture_Folder/Week7b.html#attributes-of-mixed-effects-models",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Attributes of mixed effects models",
    "text": "Attributes of mixed effects models\n\nLinear models that include both fixed and random effects.\nThe model is split into fixed and random parts:\n\nFixed effects influence mean of the response variable Y.\nRandom effects influence the variance of Y.\n\nThere is a different error variance for each level of grouping.\nEstimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.\nP-values for fixed effects are conservative when design unbalanced.\nImplemented in the nlme & lme4 packages in R."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#assumptions-of-mixed-effects-models",
    "href": "Lecture_Folder/Week7b.html#assumptions-of-mixed-effects-models",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Assumptions of mixed-effects models",
    "text": "Assumptions of mixed-effects models\n\nVariation within groups follows a normal distribution with equal variance among groups.\nGroups are randomly sampled from “population” of groups.\nGroup means follow a normal distribution.\nMeasurements within groups are independent."
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "href": "Lecture_Folder/Week7b.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects",
    "text": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#general-r-syntax-for-two-factor-factorial-designs",
    "href": "Lecture_Folder/Week7b.html#general-r-syntax-for-two-factor-factorial-designs",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "General R syntax for two factor factorial designs",
    "text": "General R syntax for two factor factorial designs"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "href": "Lecture_Folder/Week7b.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Variance components with 2 random factors using LME4",
    "text": "R INTERLUDE | Variance components with 2 random factors using LME4\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\nvariables excluding first 5 and last 5 observations\n\ngene &lt;- rnadata$Gene80[6:75] \nmicrobiota &lt;- rnadata$Microbiota[6:75]\ngenotype &lt;- rnadata$Genotype[6:75]\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)\n\nEstimate the variance components using Restricted Maximum Likelihood (REML)\n\nlibrary(lme4)\nlmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))\n\nBased on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#brain-body-size-neaderthals-as-compared-to-humans",
    "href": "Lecture_Folder/Week7b.html#brain-body-size-neaderthals-as-compared-to-humans",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "href": "Lecture_Folder/Week7b.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "href": "Lecture_Folder/Week7b.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova",
    "href": "Lecture_Folder/Week7b.html#ancova",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA",
    "text": "ANCOVA\n\nAnalysis of covariance - mixture of regression and ANOVA\nResponse is still a normally distributed continuous variable\nOne or more continuous predictor variables (covariates)\nSometimes the covariates are of biological interest\nMost often we want to remove unexplained variance\nIn this way they are similar to a blocking variable in ANOVA\nOperationally, ANCOVA is regular ANOVA in which the group and overall means are replaced by group and overall relationships"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-adjusting-for-the-covariate",
    "href": "Lecture_Folder/Week7b.html#ancova-adjusting-for-the-covariate",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-adjusting-for-the-covariate-1",
    "href": "Lecture_Folder/Week7b.html#ancova-adjusting-for-the-covariate-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Adjusting for the covariate",
    "text": "ANCOVA | Adjusting for the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-linear-model-with-two-covariates",
    "href": "Lecture_Folder/Week7b.html#ancova-linear-model-with-two-covariates",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Linear model with two covariates",
    "text": "ANCOVA | Linear model with two covariates"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-factor-and-covariate-hypothesis-tests",
    "href": "Lecture_Folder/Week7b.html#ancova-factor-and-covariate-hypothesis-tests",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Factor and covariate hypothesis tests",
    "text": "ANCOVA | Factor and covariate hypothesis tests"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-f-ratio-tests",
    "href": "Lecture_Folder/Week7b.html#ancova-f-ratio-tests",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | F ratio tests",
    "text": "ANCOVA | F ratio tests"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-assumptions",
    "href": "Lecture_Folder/Week7b.html#ancova-assumptions",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Assumptions",
    "text": "ANCOVA | Assumptions\n\nThe residuals are normally distributed\nThe residuals show homoscedasticity of variance\nThe residuals are independent of one another\nThe relationship between the response variable and each covariate is linear\nHomogeneity of slopes among the groups\nSimilar covariate ranges among the groups"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-heterogeneous-slopes",
    "href": "Lecture_Folder/Week7b.html#ancova-heterogeneous-slopes",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-heterogeneous-slopes-1",
    "href": "Lecture_Folder/Week7b.html#ancova-heterogeneous-slopes-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Heterogeneous slopes",
    "text": "ANCOVA | Heterogeneous slopes\n\nProblem - adjusting to a mean is difficult or impossible if the slopes are different\nIn essence, the samples for the groups come from two different populations\nA test for homogeneity of slopes can be performed\nThe assumption is tested by looking for a significant interaction term between the categorical response variables and the covariate(s)"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#ancova-non-overlapping-range-of-the-covariate",
    "href": "Lecture_Folder/Week7b.html#ancova-non-overlapping-range-of-the-covariate",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "ANCOVA | Non-overlapping range of the covariate",
    "text": "ANCOVA | Non-overlapping range of the covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-ancova",
    "href": "Lecture_Folder/Week7b.html#r-interlude-ancova",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nImpacts of sexual activity on male fruitfly longevity\nData from Partridge and Faraquhar (1981)\nLongevity of male measured in response to access to\n\nno females\none virgin\neight virgins\none mated\neight mated\n\nThe male fruit flies also varied in size\nThe males were assigned randomly to each of the treatment levels, and then measured thorax length as a covariate"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-ancova-1",
    "href": "Lecture_Folder/Week7b.html#r-interlude-ancova-1",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nlongevity_data &lt;- read.table('longevity.csv', header=T, sep=',')\nhead(longevity_data)\n\nVariables\n\nlong &lt;- longevity_data$LONGEVITY\ntreat &lt;- longevity_data$TREATMENT\nthorax &lt;- longevity_data$THORAX\n\n\ncheck to see if the covariate should be included\n\n\nboxplot(long ~ treat)\nplot(long ~ thorax)"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-ancova-2",
    "href": "Lecture_Folder/Week7b.html#r-interlude-ancova-2",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nassess assumptions of normality and homogeneity of variance\n\n\nplot(aov(long ~ thorax + treat ), which = 1)\n\n\n†ry it again with a transformed response variable\n\n\nplot(aov(log10(long) ~ thorax + treat ), which = 1)\n\n\nvisually assess linearity, homogenetiy of slopes and covariate range equality\n\n\nlibrary(lattice)\nprint(xyplot(log10(long) ~ thorax | treat, type = c(\"r\", \"p\")))"
  },
  {
    "objectID": "Lecture_Folder/Week7b.html#r-interlude-ancova-3",
    "href": "Lecture_Folder/Week7b.html#r-interlude-ancova-3",
    "title": "Week 7b - Statistics for Bioengineering",
    "section": "R INTERLUDE | ANCOVA",
    "text": "R INTERLUDE | ANCOVA\n\nformally test homogenetiy of slopes by testing the interaction term\n\n\nanova(aov(log10(long) ~ thorax*treat))\n\n\nformally test covariate range disparity by modeling the effect of the treatments on the covariate\n\n\nanova(aov(thorax ~ treat))\n\n\nFINALLY, set up contrasts, fit the additive model and visualize the results (pg. 459 and 460 of your Logan book)\nSummarize the trends in a nice plot (pg. 461 of your Logan book)"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html",
    "href": "Homework_Folder/HW3_2025.html",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use a new data set studying the effects of different types of seasonal flu on immune response in humans (flu.tsv), a small data table of cystic fibrosis patients, and a data table of the effect of different scaffolds and stem cells for bone regeneration.\nIn addition, perform at least one of these statistical analyses on the dataset that you’ve identified for your term long project depending on the nature of your data.\nDue: Submit your work via Canvas by the end of the day (midnight) on Wednesday, May 28th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#directions",
    "href": "Homework_Folder/HW3_2025.html#directions",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use a new data set studying the effects of different types of seasonal flu on immune response in humans (flu.tsv), a small data table of cystic fibrosis patients, and a data table of the effect of different scaffolds and stem cells for bone regeneration.\nIn addition, perform at least one of these statistical analyses on the dataset that you’ve identified for your term long project depending on the nature of your data.\nDue: Submit your work via Canvas by the end of the day (midnight) on Wednesday, May 28th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#problem-3.1-factorial-anova-of-flu-data-and-immune-response",
    "href": "Homework_Folder/HW3_2025.html#problem-3.1-factorial-anova-of-flu-data-and-immune-response",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "Problem 3.1 : Factorial ANOVA of Flu data and Immune Response",
    "text": "Problem 3.1 : Factorial ANOVA of Flu data and Immune Response"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#the-study",
    "href": "Homework_Folder/HW3_2025.html#the-study",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "The Study",
    "text": "The Study\nYou are working with a group studying immune response to different types of seasonal flu. From a large number of blood samples from people with the flu but otherwise healthy, the group has determined for each person the strain of flu, the strength of the immune response (in units of pg/mL of interleukin-1β), and the person’s genotype at an immune-regulating gene. The group is interested in a fine-scale classification of flu, so they have divided the flu samples up into a fairly large number of distinct strains. The main question they are interested in is whether the mean strength of immune response (measured using interleukin-1β concentration) differs by flu strains. Next they are interested in which strains (if any) tend to induce stronger, or weaker, responses. Of course, they would like to know how any differences compare to natural variation in immune response. In previous studies, mean immune response differed by genotype of the immune-regulating gene, so the analysis should take this into account. You should look at the data, then answer these questions using a multifactor ANOVA. In particular, you should examine both whether there is an effect of flu strain and whether that effect depends on person’s genotype (i.e., if there are significant interaction effects). Your report should explain, in your own words, how each analysis works what the conclusions are, and what to conclude after looking at both sets of results.\nThe dataset (flu.tsv) can be found in the data folder on Canvas. This dataset has the following variables\n\nid\nstrain of the flu virus\ngenotype of the individual\nresponse in terms of interleukin-1β\n\nThe data are available on Canvas. Note: this is fake data; for real information on flu strains see nextflu.org.\n\nYour Tasks:\n\nFit and interpret the ANOVA model.\nMake an interaction plot for this question: the x-axis should show the various flu strains; the y-axis should show immune response, and there should be one line for each genotype, connecting the mean response to each flu strain for people of that genotype. The plot should show not just the means, but also the range of variation in the data.\nCreate a combined variable of the two factor variables and perform a Tukey’s post-hoc means test, as well as one a priori test of your choice."
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#exercise-3.2-goodness-of-fit-test-for-cystic-fibrosis",
    "href": "Homework_Folder/HW3_2025.html#exercise-3.2-goodness-of-fit-test-for-cystic-fibrosis",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "Exercise 3.2: Goodness of Fit Test for Cystic Fibrosis",
    "text": "Exercise 3.2: Goodness of Fit Test for Cystic Fibrosis\n\nThe Study\nCystic fibrosis (CF) is an autosomal recessive genetic disorder. When both parents are carriers (genotype Ff), each child has the following expected probab:\n\n25% chance of being homozygous dominant (FF) — unaffected, not a carrier\n50% chance of being heterozygous (Ff) — unaffected carrier\n25% chance of being homozygous recessive (ff) — affected by cystic fibrosis\n\nA genetic counselor collects data from 200 children born to heterozygous carrier parents in a particular community and records the following distribution of genotypes:\n\n\n\nGenotype\nPhenotype Status\nObserved Count\n\n\n\n\nFF\nUnaffected (not carrier)\n69\n\n\nFf\nCarrier\n206\n\n\nff\nAffected (CF)\n102\n\n\n\nThe genetic counselor suspects that there might divergence from Hardy-Weinberg Equilibrium (HWE) in this community due to some unmeasured environmental or genetic factors.\n\n\nYour Tasks:\n\nState the null and alternative hypotheses for a Chi-square goodness of fit test to determine whether the observed genotypic distribution follows HWE expectations.\nCalculate the expected counts for each genotype under the 1:2:1 Mendelian ratio by first calculating the allele frequencies in this population.\nUse R to perform the Chi-square goodness of fit test to compare the expected genotype counts to the observed genotype counts.\nInterpret your results in the context of Mendelian genetics. Use a significance level of α = 0.05.\nWhat would you recommend that the genetic counselor conclude about whether something else might be going on?"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#the-study-1",
    "href": "Homework_Folder/HW3_2025.html#the-study-1",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "The Study",
    "text": "The Study\nCystic fibrosis (CF) is an autosomal recessive genetic disorder. When both parents are carriers (genotype Ff), each child has the following expected probab:\n\n25% chance of being homozygous dominant (FF) — unaffected, not a carrier\n50% chance of being heterozygous (Ff) — unaffected carrier\n25% chance of being homozygous recessive (ff) — affected by cystic fibrosis\n\nA genetic counselor collects data from 200 children born to heterozygous carrier parents in a particular community and records the following distribution of genotypes:\n\n\n\nGenotype\nPhenotype Status\nObserved Count\n\n\n\n\nFF\nUnaffected (not carrier)\n69\n\n\nFf\nCarrier\n206\n\n\nff\nAffected (CF)\n102\n\n\n\nThe genetic counselor suspects that there might divergence from Hardy-Weinberg Equilibrium (HWE) in this community due to some unmeasured environmental or genetic factors.\n\nYour Tasks:\n\nState the null and alternative hypotheses for a Chi-square goodness of fit test to determine whether the observed genotypic distribution follows HWE expectations.\nCalculate the expected counts for each genotype under the 1:2:1 Mendelian ratio by first calculating the allele frequencies in this population.\nUse R to perform the Chi-square goodness of fit test to compare the expected genotype counts to the observed genotype counts.\nInterpret your results in the context of Mendelian genetics. Use a significance level of α = 0.05.\nWhat would you recommend that the genetic counselor conclude about whether something else might be going on?"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#exercise-3.3-chi-squar-contigency-table-analysis-of-successful-regeneration",
    "href": "Homework_Folder/HW3_2025.html#exercise-3.3-chi-squar-contigency-table-analysis-of-successful-regeneration",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "Exercise 3.3: Chi-squar contigency table analysis of successful regeneration",
    "text": "Exercise 3.3: Chi-squar contigency table analysis of successful regeneration"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#the-study-2",
    "href": "Homework_Folder/HW3_2025.html#the-study-2",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "The Study",
    "text": "The Study\nA team of bioengineers is evaluating how scaffold material and stem cell type influence the success of tissue regeneration in a lab-grown cartilage model. They use three different scaffold materials and three types of stem cells and record whether the engineered cartilage shows successful regeneration (defined by a set of mechanical and histological markers) after 4 weeks.\nThey test the following materials\n\nScaffold Materials: \n\nCollagen\nHydrogel\nBioceramic\n\nStem Cell Types: \n\nAdipose-derived stem cells (ASC)\nBone marrow-derived stem cells (BMSC)\nInduced pluripotent stem cells (iPSC)\n\n\nThe counts below represent the number of successful regenerations in each combination of material and cell type.\n\n\n\n\nASC\nBMSC\niPSC\n\n\n\n\nCollagen\n18\n22\n15\n\n\nHydrogel\n25\n27\n30\n\n\nBioceramic\n20\n23\n21\n\n\n\n\nYour Tasks:\n\nState the null and alternative hypotheses for this test.\nUsing R, perform a Chi-square test of independence. Include the R code and output.\nCalculate the odds ratio and LOD score for just the collagen/hydrogel vs. ASC/BMSC combination.\nWhat do the results suggest? Use a significance level of α = 0.05.\nWould you conclude that scaffold type and cell type influence regeneration success independently, or do they interact?"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#problem-3.1-factorial-anova-of-flu-and-immune-response",
    "href": "Homework_Folder/HW3_2025.html#problem-3.1-factorial-anova-of-flu-and-immune-response",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "Problem 3.1 : Factorial ANOVA of Flu and Immune Response",
    "text": "Problem 3.1 : Factorial ANOVA of Flu and Immune Response\n\nThe Study\nYou are working with a group studying immune response to different types of seasonal flu. From a large number of blood samples from people with the flu but otherwise healthy, the group has determined for each person the strain of flu, the strength of the immune response (in units of pg/mL of interleukin-1β), and the person’s genotype at an immune-regulating gene. The group is interested in a fine-scale classification of flu, so they have divided the flu samples up into a fairly large number of distinct strains. The main question they are interested in is whether the mean strength of immune response (measured using interleukin-1β concentration) differs by flu strains. Next they are interested in which strains (if any) tend to induce stronger, or weaker, responses. Of course, they would like to know how any differences compare to natural variation in immune response. In previous studies, mean immune response differed by genotype of the immune-regulating gene, so the analysis should take this into account. You should look at the data, then answer these questions using a multifactor ANOVA. In particular, you should examine both whether there is an effect of flu strain and whether that effect depends on person’s genotype (i.e., if there are significant interaction effects). Your report should explain, in your own words, how each analysis works what the conclusions are, and what to conclude after looking at both sets of results.\nThe dataset (flu.tsv) can be found in the data folder on Canvas. This dataset has the following variables\n\nid\nstrain of the flu virus\ngenotype of the individual\nresponse in terms of interleukin-1β\n\nThe data are available on Canvas. Note: this is fake data; for real information on flu strains see nextflu.org.\n\n\nYour Tasks:\n\nFit and interpret the ANOVA model.\nMake an interaction plot for this question: the x-axis should show the various flu strains; the y-axis should show immune response, and there should be one line for each genotype, connecting the mean response to each flu strain for people of that genotype. The plot should show not just the means, but also the range of variation in the data.\nCreate a combined variable of the two factor variables and perform a Tukey’s post-hoc means test, as well as one a priori test of your choice."
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#exercise-3.3-chi-square-contingency-table-analysis-of-scaffold-materials-and-regeneration",
    "href": "Homework_Folder/HW3_2025.html#exercise-3.3-chi-square-contingency-table-analysis-of-scaffold-materials-and-regeneration",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "Exercise 3.3: Chi-square Contingency Table Analysis of Scaffold Materials and Regeneration",
    "text": "Exercise 3.3: Chi-square Contingency Table Analysis of Scaffold Materials and Regeneration\n\nThe Study\nA team of bioengineers is evaluating how scaffold material and stem cell type influence the success of tissue regeneration in a lab-grown cartilage model. They use three different scaffold materials and three types of stem cells and record whether the engineered cartilage shows successful regeneration (defined by a set of mechanical and histological markers) after 4 weeks.\nThey test the following materials\n\nScaffold Materials:\n\nCollagen\nHydrogel\nBioceramic\n\nStem Cell Types:\n\nAdipose-derived stem cells (ASC)\nBone marrow-derived stem cells (BMSC)\nInduced pluripotent stem cells (iPSC)\n\n\nThe counts below represent the number of successful regenerations in each combination of material and cell type.\n\n\n\n\nASC\nBMSC\niPSC\n\n\n\n\nCollagen\n48\n22\n15\n\n\nHydrogel\n25\n57\n30\n\n\nBioceramic\n20\n23\n61\n\n\n\n\n\nYour Tasks:\n\nState the null and alternative hypotheses for this test.\nUsing R, perform a Chi-square test of independence. Include the R code and output.\nCalculate the odds ratio and LOD score for just the collagen/hydrogel vs. ASC/BMSC combination.\nWhat do the results suggest? Use a significance level of α = 0.05.\nWould you conclude that scaffold type and cell type influence regeneration success independently, or do they interact?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html",
    "href": "Lecture_Folder/Week8a.html",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tibble)"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#this-week",
    "href": "Lecture_Folder/Week8a.html#this-week",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nKey principles of experimental design\nLinear Mixed Models (GLMMs)\nChi-square tests\nGeneralized Linear Models - Logistic and Poisson Regression"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#what-is-an-experimental-study",
    "href": "Lecture_Folder/Week8a.html#what-is-an-experimental-study",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "What is an experimental study?",
    "text": "What is an experimental study?\n\nIn an experimental study the researcher assigns treatments to units\nIn an observational study nature does the assigning of treatments to units\nThe crucial advantage of experiments derives from the random assignment of treatments to units\nRandomization minimizes the influence of confounding variables\nAllows us to infer cause and effect more easily (or at all)"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#mount-everest-example",
    "href": "Lecture_Folder/Week8a.html#mount-everest-example",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\nSurvival of climbers of Mount Everest is higher for individuals taking supplemental oxygen than those who don’t.\nWhy?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#mount-everest-example-1",
    "href": "Lecture_Folder/Week8a.html#mount-everest-example-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Mount Everest example",
    "text": "Mount Everest example\n\nOne possibility is that supplemental oxygen (explanatory variable) really does cause higher survival (response variable).\nThe other is that the two variables are associated because other variables affect both supplemental oxygen and survival.\nUse of supplemental oxygen might be a benign indicator of a greater overall preparedness of the climbers that use it.\nVariables (like preparedness) that distort the causal relationship between the measured variables of interest (oxygen use and survival) are called confounding variables"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#clinical-trials",
    "href": "Lecture_Folder/Week8a.html#clinical-trials",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Clinical Trials",
    "text": "Clinical Trials\n\nThe gold standard of experimental designs is the clinical trial\nExperimental design in all areas of biology have been informed by procedures used in clinical trials\nA clinical trial is an experimental study in which two or more treatments are assigned to human subjects\nThe design of clinical trials has been refined because the cost of making a mistake with human subjects is so high\nExperiments on nonhuman subjects are simply called “laboratory experiments”or “field experiments”"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#example-of-a-clinical-trial",
    "href": "Lecture_Folder/Week8a.html#example-of-a-clinical-trial",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Example of a clinical trial",
    "text": "Example of a clinical trial\n\nTransmission of the HIV-1 virus via sex workers contributes to the rapid spread of AIDS in Africa\nThe spermicide nonoxynol-9 had shown in vitro activity against HIV-1, which motivated a clinical trial by van Damme et al. (2002).\nThey tested whether a vaginal gel containing the chemical would reduce the risk of acquiring the disease by female sex workers.\nData were gathered on a volunteer sample of 765 HIV-free sex-workers in six clinics in Asia and Africa.\nTwo gel treatments were assigned randomly to women at each clinic:\n\nOne gel contained nonoxynol-9\nthe other was a placebo.\n\nNeither the subjects nor the researchers making observations at the clinics knew who received the treatment and who got the placebo."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#outcome-of-the-clinical-trial",
    "href": "Lecture_Folder/Week8a.html#outcome-of-the-clinical-trial",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Outcome of the clinical trial",
    "text": "Outcome of the clinical trial\n\n\n\n\n\n\n\n\n\n\nNote that these are count data but clinical trials could involve continuous data\nWe will use these data on Thursday for our Chi-square analyses\nAlso there is another variable - what is the nature of that variable?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#design-components-of-a-clinical-trial",
    "href": "Lecture_Folder/Week8a.html#design-components-of-a-clinical-trial",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Design components of a clinical trial",
    "text": "Design components of a clinical trial\nThe goal of experimental design is to eliminate bias and to reduce sampling error when estimating and testing effects of one variable on another.\n\nTo reduce bias, the experiment included:\n\nSimultaneous control group: study included both the treatment of interest and a control group (the women receiving the placebo).\nRandomization: treatments were randomly assigned to women at each clinic.\nBlinding: neither the subjects nor the clinicians knew which women were assigned which treatment.\n\nTo reduce the effects of sampling error, the experiment included:\n\nReplication: study was carried out on multiple independent subjects.\nBalance: number of women was nearly equal in the two groups at every clinic.\nBlocking: subjects were grouped according to the clinic they attended, yielding multiple repetitions of the same experiment in different settings (“blocks”)."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#simultaneous-control-group",
    "href": "Lecture_Folder/Week8a.html#simultaneous-control-group",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "1. Simultaneous control group",
    "text": "1. Simultaneous control group\n\nIn clinical trials either a placebo or the currently accepted treatment should be provided.\nIn experiments requiring intrusive methods to administer treatment, such as\n\ninjections\nsurgery\nrestraint\nconfinement\n\nthe control subjects should be perturbed in the same way as the other subjects, except for the treatment itself, as far as ethical considerations permit.\nThe “sham operation”, in which surgery is carried out without the experimental treatment itself, is an example.\nIn field experiments, applying a treatment of interest may physically disturb the plots receiving it and the surrounding areas, perhaps by trampling the ground by the researchers.\nIdeally, the same disturbance should be applied to the control plots."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#randomization",
    "href": "Lecture_Folder/Week8a.html#randomization",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "2. Randomization",
    "text": "2. Randomization\n\nThe researcher should randomize assignment of treatments to units or subjects\nChance rather than conscious or unconscious decision determines which units end up receiving the treatment and which the control\nRandomization breaks the association between possible confounding variables and the explanatory variable\nRandomization doesn’t eliminate the variation contributed by confounding variables, only their correlation with treatment\nRandomization ensures that variation from confounding variables is similar between the different treatment groups."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#randomization-1",
    "href": "Lecture_Folder/Week8a.html#randomization-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "2. Randomization",
    "text": "2. Randomization\n\nRandomization should be carried out using a random process:\n\nList all n subjects, one per row, in a computer spreadsheet.\nUse the computer to give each individual a random number.\nAssign treatment A to those subjects receiving the lowest numbers and treatment B to those with the highest numbers.\n\nOther ways of assigning treatments to subjects are almost always inferior because they do not eliminate the effects of confounding variables.\n“Haphazard” assignment, in which the researcher chooses a treatment while trying to make it random, has repeatedly been shown to be non-random and prone to bias."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#randomization-types",
    "href": "Lecture_Folder/Week8a.html#randomization-types",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "2. Randomization Types",
    "text": "2. Randomization Types\n\nCompletely randomized design - all subjects are placed to treatment or control with equal probability\nRandomized block - first broken into groups (e.g. age or gender) then assigned to treatment groups at random\nMatched pair design - subjects are paired by similarity before being randomly assigned to treatment groups"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#random-sampling-approaches",
    "href": "Lecture_Folder/Week8a.html#random-sampling-approaches",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "2. Random sampling approaches",
    "text": "2. Random sampling approaches\n\nSimple random sample - every sample has equal probability of being chosen\nStratified sample - subjects are randomly divided into groups then a simple random sample are taken from each\nCluster sample - subjects are divided into similar groups, usually naturally occurring, and then a simple random samples of clusters is then taken and every member of the cluster is included in the sample\nMultistage sampling - First clusters are random sampled, and then random samples are take from each cluster.\nSystematic sample - members of a sample are chosen in a pre-determined ways. e.g Choose every 20th person coming into a store"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#blinding",
    "href": "Lecture_Folder/Week8a.html#blinding",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "3. Blinding",
    "text": "3. Blinding\n\nBlinding is the process of concealing information from participants (sometimes including researchers) about which subjects receive which treatment.\nBlinding prevents subjects and researchers from changing their behavior, consciously or unconsciously, as a result of knowing which treatment they were receiving or administering.\nFor example, studies showing that acupuncture has a significant effect on back pain are limited to those without blinding.\nReviews of medical studies have revealed that studies carried out without double- blinding exaggerated treatment effects by 16% on average compared with studies carried out with double-blinding (Jüni et al. 2001).\nBebarta et al.(2003) reviewed 290 two-treatment experiments carried out on animals or on cell lines. The odds of detecting a positive effect of treatment were more than threefold higher in studies without blinding than in studies with blinding.\nBlinding can be incorporated into experiments on nonhuman subjects using coded tags that identify the subject to a “blind” observer without revealing the treatment (and who measures units from different treatments in random order)."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#blinding-1",
    "href": "Lecture_Folder/Week8a.html#blinding-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "3. Blinding",
    "text": "3. Blinding\n\nIn a single-blind experiment, the subjects are unaware of the treatment that they have been assigned.\n\nTreatments must be indistinguishable to subjects, which prevents them from responding differently according to knowledge of treatment.\nBlinding can also be a concern in non-human studies where animals respond to stimuli\n\nIn a double-blind experiment the researchers administering the treatments and measuring the response are also unaware of which subjects are receiving which treatments\n\nResearchers sometimes have pet hypotheses, and they might treat experimental subjects in different ways depending on their hopes for the outcome\nMany response variables are difficult to measure and require some subjective interpretation, which makes the results prone to a bias\nResearchers are naturally more interested in the treated subjects than the control subjects, and this increased attention can itself result in improved response"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#replication",
    "href": "Lecture_Folder/Week8a.html#replication",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "4. Replication",
    "text": "4. Replication\n\nReplication is the assignment of each treatment to multiple, independent experimental units.\nThe goal of experiments is to estimate and test treatment effects against the background of variation between individuals (“noise”) caused by other variables\nWithout replication, we would not know whether response differences were due to the treatments or just chance differences between the treatments caused by other factors.\nOne way to reduce noise is to make the experimental conditions constant\nHowever, highly constant experimental conditions might not be feasible nor desirable\nBy limiting the conditions of an experiment, we also limit the generality of the results\nAnother way to make treatment effects stand out is to include extreme treatments and to replicate the data."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#replication-1",
    "href": "Lecture_Folder/Week8a.html#replication-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "4. Replication",
    "text": "4. Replication\n\nStudies that use more units (i.e. that have larger sample sizes) will have smaller standard errors and a higher probability of getting the correct answer from a hypothesis test.\nLarger samples mean more information, and more information means better estimates and more powerful tests.\nReplication is not about the number of plants or animals used, but the number of independent units in the experiment. An “experimental unit” is the independent unit to which treatments are assigned.\nThe figure shows three experimental designs used to compare plant growth under two temperature treatments (indicated by the shading of the pots). The first two designs are un-replicated."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#pseudoreplication",
    "href": "Lecture_Folder/Week8a.html#pseudoreplication",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "4. (Pseudo)replication",
    "text": "4. (Pseudo)replication"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#balance",
    "href": "Lecture_Folder/Week8a.html#balance",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "5. Balance",
    "text": "5. Balance\n\nA study design is balanced if all treatments have the same sample size.\nConversely, a design is unbalanced if there are unequal sample sizes between treatments.\nBalance is a second way to reduce the influence of sampling error on estimation and hypothesis testing.\nTo appreciate this, look again at the equation for the standard error of the difference between two treatment means.\nFor a fixed total number of experimental units, n1 + n2, the standard error is smallest when n1 and n2 are equal.\nBalance has other benefits. For example, ANOVA is more robust to departures from the assumption of equal variances when designs are balanced or nearly so."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#blocking",
    "href": "Lecture_Folder/Week8a.html#blocking",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "6. Blocking",
    "text": "6. Blocking\n\nBlocking is the grouping of experimental units that have similar properties. Within each block, treatments are randomly assigned to experimental units.\nBlocking essentially repeats the same, completely randomized experiment multiple times, once for each block.\nDifferences between treatments are only evaluated within blocks, and in this way the component of variation arising from differences between blocks are controlled for."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#what-if-you-cant-do-experiments",
    "href": "Lecture_Folder/Week8a.html#what-if-you-cant-do-experiments",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "What if you can’t do experiments?",
    "text": "What if you can’t do experiments?\n\nExperimental studies are not always feasible, in which case we must fall back upon observational studies.\nThe best observational studies incorporate as many of the features of good experimental design as possible to minimize bias (e.g., blinding) and the impact of sampling error (e.g., replication, balance, blocking, and even extreme treatments) except for one: randomization.\nRandomization is out of the question, because in an observational study the researcher does not assign treatments to subjects.\nTwo strategies are used to limit the effects of confounding variables on a difference between treatments in a controlled observational study: matching; and adjusting for known confounding variables (covariates).\nBut beware - there could always be a co-variate that you didn’t include!"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#what-is-a-glmm",
    "href": "Lecture_Folder/Week8a.html#what-is-a-glmm",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "What is a GLMM?",
    "text": "What is a GLMM?\n\nGeneral Linear Mixed Model (GLMM)\nA continuous response variable with a mix of continuous and categorical predictor variables\nGLMM’s can be used to model random effects"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#attributes-of-mixed-effects-models",
    "href": "Lecture_Folder/Week8a.html#attributes-of-mixed-effects-models",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Attributes of mixed effects models",
    "text": "Attributes of mixed effects models\n\nLinear models that include both fixed and random effects.\nThe model is split into fixed and random parts:\n\nFixed effects influence mean of the response variable Y.\nRandom effects influence the variance of Y.\n\nThere is a different error variance for each level of grouping.\nEstimation and testing is based on restricted maximum likelihood, which can handle unequal sample size.\nP-values for fixed effects are conservative when design unbalanced.\nWe can use lm for simple models (which we’ll do today)\nMore complicated models are better performed using the nlme & lme4 packages in R."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#assumptions-of-mixed-effects-models",
    "href": "Lecture_Folder/Week8a.html#assumptions-of-mixed-effects-models",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Assumptions of mixed-effects models",
    "text": "Assumptions of mixed-effects models\n\nVariation within groups follows a normal distribution with equal variance among groups.\nGroups are randomly sampled from “population” of groups.\nGroup means follow a normal distribution.\nMeasurements within groups are independent."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "href": "Lecture_Folder/Week8a.html#hypotheses-for-model-3-anova-factorial-design-with-mixed-effects",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects",
    "text": "Hypotheses for Model 3 ANOVA Factorial Design With Mixed Effects"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#brain-body-size-neaderthals-as-compared-to-humans",
    "href": "Lecture_Folder/Week8a.html#brain-body-size-neaderthals-as-compared-to-humans",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "href": "Lecture_Folder/Week8a.html#brain-body-size-neaderthals-as-compared-to-humans-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "href": "Lecture_Folder/Week8a.html#brain-body-size-neaderthals-as-compared-to-humans-2",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Brain & body size | neaderthals as compared to humans",
    "text": "Brain & body size | neaderthals as compared to humans"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-mixed-model",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-mixed-model",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Mixed Model",
    "text": "Parallel Slopes Mixed Model\n\nMixture of regression and ANOVA\nResponse is still a normally distributed continuous variable\nOne or more continuous predictor variables (covariates)\nSometimes the covariates are of biological interest\nMost often we want to remove unexplained variance\nIn this way they are similar to a blocking variable in ANOVA\nOperationally, similar to regular ANOVA in which the group and overall means are replaced by group and overall relationships"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Model - R Interlude",
    "text": "Parallel Slopes Model - R Interlude\n\nlibrary(ggplot2)\nlibrary(tibble)\nheart_rate_df &lt;- read.csv(\"mouse_rat_heart.csv\", header = TRUE)\n\nggplot(heart_rate_df, aes(x = temp, y = heart_rate, col = species)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-1",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Model - R Interlude",
    "text": "Parallel Slopes Model - R Interlude\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-2",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-2",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Model - R Interlude",
    "text": "Parallel Slopes Model - R Interlude\n\nlibrary(ggplot2)\nlibrary(tibble)\nheart_rate_df &lt;- read.csv(\"mouse_rat_heart.csv\", header = TRUE)\n\nmodel_additive &lt;- lm(heart_rate ~ temp + species, data = heart_rate_df)\nsummary(model_additive)\n\nnew_heart_rate_df &lt;- tibble(\n  species = c(\"mouse\", \"mouse\", \"mouse\", \"rat\", \"rat\", \"rat\"),\n  temp = c(24, 26, 28, 24, 26, 28)\n)\n\npredict(model_additive, new_heart_rate_df)"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-3",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-3",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Model - R Interlude",
    "text": "Parallel Slopes Model - R Interlude\n\n\n\nCall:\nlm(formula = heart_rate ~ temp + species, data = heart_rate_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0128 -1.1296 -0.3912  0.9650  3.7800 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -7.21091    2.55094  -2.827  0.00858 ** \ntemp          3.60275    0.09729  37.032  &lt; 2e-16 ***\nspeciesrat  -10.06529    0.73526 -13.689 6.27e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.786 on 28 degrees of freedom\nMultiple R-squared:  0.9896,    Adjusted R-squared:  0.9888 \nF-statistic:  1331 on 2 and 28 DF,  p-value: &lt; 2.2e-16\n\n\n       1        2        3        4        5        6 \n79.25516 86.46067 93.66617 69.18987 76.39538 83.60088"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-mixed-model-1",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-mixed-model-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Mixed Model",
    "text": "Parallel Slopes Mixed Model\n\\[ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\epsilon \\] where\n\\[\ny = \\left\\{\n\\begin{aligned}\n    & \\beta_0 + \\beta_1x_1 + \\epsilon \\\\\n    &(\\beta_0 + \\beta_2) +\\beta_1x_1 + \\epsilon\n\\end{aligned}\n\\right.\n\\]\n\nWhere the intercepts are different from one another but the slopes are not - R gives those estimates in that exact order\n\n\\[\ny = \\left\\{\n\\begin{aligned}\n    & -7.21091 + 3.60275x_1  \\\\\n    &(-7.21091 -10.06529) +3.60275x_1\n\\end{aligned}\n\\right.\n\\]"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interaction-mixed-model-1",
    "href": "Lecture_Folder/Week8a.html#interaction-mixed-model-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interaction Mixed Model",
    "text": "Interaction Mixed Model\n\nlibrary(tidyverse)\nlibrary(modeldata)\ntheme_set(theme_minimal())\ndata(penguins)\npenguins_sm &lt;- filter(penguins, species != \"Adelie\")\n\nggplot(penguins_sm, aes(x = flipper_length_mm,\n                        y = body_mass_g,\n                        col = species)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interaction-mixed-model-2",
    "href": "Lecture_Folder/Week8a.html#interaction-mixed-model-2",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interaction Mixed Model",
    "text": "Interaction Mixed Model\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 row containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interaction-mixed-model-3",
    "href": "Lecture_Folder/Week8a.html#interaction-mixed-model-3",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interaction Mixed Model",
    "text": "Interaction Mixed Model\n\nlibrary(tidyverse)\nlibrary(modeldata)\ntheme_set(theme_minimal())\ndata(penguins)\npenguins_sm &lt;- filter(penguins, species != \"Adelie\")\n\nmodel &lt;- lm(body_mass_g ~ flipper_length_mm * species,\n            data = penguins_sm)\nsummary(model)"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interaction-mixed-model-4",
    "href": "Lecture_Folder/Week8a.html#interaction-mixed-model-4",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interaction Mixed Model",
    "text": "Interaction Mixed Model\n\n\n\nCall:\nlm(formula = body_mass_g ~ flipper_length_mm * species, data = penguins_sm)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-911.18 -215.38  -42.69  162.67 1015.71 \n\nCoefficients:\n                                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     -3037.196   1138.679  -2.667  0.00832 ** \nflipper_length_mm                  34.573      5.811   5.950  1.3e-08 ***\nspeciesGentoo                   -3750.085   1534.769  -2.443  0.01548 *  \nflipper_length_mm:speciesGentoo    20.049      7.496   2.674  0.00815 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 339.2 on 187 degrees of freedom\n  (1 observation deleted due to missingness)\nMultiple R-squared:  0.8205,    Adjusted R-squared:  0.8176 \nF-statistic: 284.9 on 3 and 187 DF,  p-value: &lt; 2.2e-16\n\n\n\nMake a dummy data set of values for Gentoo and Chinstrap Penguins\nUse the interaction model that you fit to make new predictions for those values"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interaction-mixed-model-5",
    "href": "Lecture_Folder/Week8a.html#interaction-mixed-model-5",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interaction Mixed Model",
    "text": "Interaction Mixed Model\n\\[\nx_2 = \\left\\{\n\\begin{aligned}\n    & 0 \\qquad \\text{for Chinstrap} \\\\\n    & 1 \\qquad \\text{for Gentoo}\n\\end{aligned}\n\\right.\n\\] \\[ y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_1x_2 + \\epsilon \\]\n\\[\ny = \\left\\{\n\\begin{aligned}\n    & \\beta_0 + \\beta_1x_1 + \\epsilon \\\\\n    &(\\beta_0 + \\beta_2) +(\\beta_1 +\\beta_3)x_1 + \\epsilon\n\\end{aligned}\n\\right.\n\\] - Where the intercepts are different from one another but the slopes are not - Again R gives those estimates in that exact order\n\\[\ny = \\left\\{\n\\begin{aligned}\n    & -3037.196 + 34.573x_1  \\\\\n    &(-3037.196 - 3750.085) + (34.573 + 20.049)x_1\n\\end{aligned}\n\\right.\n\\]"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#how-do-we-factor-in-categorical-variables",
    "href": "Lecture_Folder/Week8a.html#how-do-we-factor-in-categorical-variables",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "How do we factor in categorical variables?",
    "text": "How do we factor in categorical variables?\n\nFor a single categorical predictor, we can include effects of each factor level:\n\n\\[ y = B_0 + B_1(x~level1) + B_2(x~level2) +~... ~+ e \\]\n\nEach factor level (ex: for Wolbachia: Yes or No) becomes it’s own “effector” that will change the value of y\nInstead of x being a continuous numerical value, for categorical data it will be either a 0 or 1"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#a-generalized-linear-model",
    "href": "Lecture_Folder/Week8a.html#a-generalized-linear-model",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "A Generalized Linear Model",
    "text": "A Generalized Linear Model\n\nCheck out the help page in RStudio for glm()\n\n\nglm(formula = y ~ x1 + x2, family = gaussian(link = \"identity\"))"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "href": "Lecture_Folder/Week8a.html#first-steps-use-a-glm-to-test-wolbachia-infection",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nSet up a glm() to test for the effect of Wolbachia infection on Recombinant Fraction"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "href": "Lecture_Folder/Week8a.html#first-steps-use-a-glm-to-test-wolbachia-infection-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "First steps: use a glm to test Wolbachia infection",
    "text": "First steps: use a glm to test Wolbachia infection\n\nWhat do these components mean?\n\n\nfly &lt;- read.table(\"Mostoufi2022_Recombination_Edit.csv\", header=T, sep=',')\nmodel &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link=\"identity\"))\nsummary(model)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.348054   0.005845  59.545   &lt;2e-16 ***\nfly$WolbachiaYes 0.021664   0.008474   2.557   0.0112 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00406577)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91480  on 225  degrees of freedom\nAIC: -601.48\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interpreting-the-glm",
    "href": "Lecture_Folder/Week8a.html#interpreting-the-glm",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nWhy is our intercept significant?\n\nRemember that the null hypothesis is a model with an intercept and slope of 0\n\nHow would you interpret the “WolbachiaYes” coefficient, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#second-steps---adding-more-variables",
    "href": "Lecture_Folder/Week8a.html#second-steps---adding-more-variables",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nNow let’s add Food to our model - how does this change our model results?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#second-steps---adding-more-variables-1",
    "href": "Lecture_Folder/Week8a.html#second-steps---adding-more-variables-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Second steps - adding more variables",
    "text": "Second steps - adding more variables\n\nmodel2 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = \"identity\"))\nsummary(model2)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, \n    family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.344691   0.008121  42.445   &lt;2e-16 ***\nfly$WolbachiaYes 0.021731   0.008504   2.555   0.0113 *  \nfly$FoodSucrose  0.002933   0.010481   0.280   0.7799    \nfly$FoodYeast    0.007366   0.010128   0.727   0.4678    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00409246)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91262  on 223  degrees of freedom\nAIC: -598.02\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interpreting-the-glm-1",
    "href": "Lecture_Folder/Week8a.html#interpreting-the-glm-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interpreting the GLM",
    "text": "Interpreting the GLM\n\nHow would you interpret the Intercept and Food coefficients, especially the estimate and the p value?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#interaction-effects-in-glms",
    "href": "Lecture_Folder/Week8a.html#interaction-effects-in-glms",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Interaction effects in GLMs",
    "text": "Interaction effects in GLMs\n\nYou can also model interactions between two categorical variables in glms\n\nWhat if variable x and variable z interact in non-additive ways?\n\nUse the notation x*z in the formula"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#third-steps---adding-interaction-effects",
    "href": "Lecture_Folder/Week8a.html#third-steps---adding-interaction-effects",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nLet’s finally add an interaction between Wolbachia infection and Food to represent Wolbachia titer in our model\nRun the model - what are the results?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#third-steps---adding-interaction-effects-1",
    "href": "Lecture_Folder/Week8a.html#third-steps---adding-interaction-effects-1",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Third steps - adding interaction effects",
    "text": "Third steps - adding interaction effects\n\nHow do we interpret these findings?\n\n\nmodel3 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = \"identity\"))\nsummary(model3)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + \n    fly$Wolbachia * fly$Food, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       0.344520   0.009760  35.298   &lt;2e-16 ***\nfly$WolbachiaYes                  0.022080   0.013970   1.581    0.115    \nfly$FoodSucrose                   0.010286   0.014458   0.711    0.478    \nfly$FoodYeast                     0.001256   0.014059   0.089    0.929    \nfly$WolbachiaYes:fly$FoodSucrose -0.015873   0.021002  -0.756    0.451    \nfly$WolbachiaYes:fly$FoodYeast    0.012910   0.020282   0.637    0.525    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.004096248)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.90527  on 221  degrees of freedom\nAIC: -595.86\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#how-do-we-know-which-model-to-use",
    "href": "Lecture_Folder/Week8a.html#how-do-we-know-which-model-to-use",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "How do we know which model to use?",
    "text": "How do we know which model to use?\n\nWant to be careful not to overfit your linear model (give too many variables)\nThe Akaike information criterion (AIC) is a metric for comparing different models to find the best fit\n\nNotice the AIC score in your output?\nFor more on this, take Advanced Bio Stats! Or do some reading on the internet."
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "href": "Lecture_Folder/Week8a.html#r-interlude-variance-components-with-2-random-factors-using-lme4",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "R INTERLUDE | Variance components with 2 random factors using LME4",
    "text": "R INTERLUDE | Variance components with 2 random factors using LME4\n\nrnadata &lt;- read.table('RNAseq.tsv', header=T, sep='')\nhead(rnadata)\n\nvariables excluding first 5 and last 5 observations\n\ngene &lt;- rnadata$Gene80[6:75] \nmicrobiota &lt;- rnadata$Microbiota[6:75]\ngenotype &lt;- rnadata$Genotype[6:75]\nboxplot(gene ~ microbiota)\nboxplot(gene ~ genotype)\nboxplot(gene ~ microbiota*genotype)\n\nEstimate the variance components using Restricted Maximum Likelihood (REML)\n\nlibrary(lme4)\nlmer(gene ~ 1 + (1 | microbiota) + (1 | genotype) + (1 | microbiota:genotype))\n\nBased on the REML sd estimates, what are the relative contributions of the factors to total variance in gene expression?"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-4",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-4",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Model - R Interlude",
    "text": "Parallel Slopes Model - R Interlude\n\nlibrary(ggplot2)\nlibrary(tibble)\nheart_rate_df &lt;- read.csv(\"mouse_rat_heart.csv\", header = TRUE)\n\nmodel_interactive &lt;- lm(heart_rate ~ temp * species, data = heart_rate_df)\nsummary(model_interactive)\n\nnew_heart_rate_df &lt;- tibble(\n  species = c(\"mouse\", \"mouse\", \"mouse\", \"rat\", \"rat\", \"rat\"),\n  temp = c(24, 26, 28, 24, 26, 28)\n)\n\npredict(model_interactive, new_heart_rate_df)"
  },
  {
    "objectID": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-5",
    "href": "Lecture_Folder/Week8a.html#parallel-slopes-model---r-interlude-5",
    "title": "Week 8a - Statistics for Bioengineering",
    "section": "Parallel Slopes Model - R Interlude",
    "text": "Parallel Slopes Model - R Interlude\n\n\n\nCall:\nlm(formula = heart_rate ~ temp * species, data = heart_rate_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7031 -1.3417 -0.1235  0.8100  3.6330 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     -11.0408     4.1515  -2.659    0.013 *  \ntemp              3.7514     0.1601  23.429   &lt;2e-16 ***\nspeciesrat       -4.3484     4.9617  -0.876    0.389    \ntemp:speciesrat  -0.2340     0.2009  -1.165    0.254    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.775 on 27 degrees of freedom\nMultiple R-squared:  0.9901,    Adjusted R-squared:  0.989 \nF-statistic: 898.9 on 3 and 27 DF,  p-value: &lt; 2.2e-16\n\n\n       1        2        3        4        5        6 \n78.99389 86.49678 93.99967 69.02983 76.06475 83.09967"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html",
    "href": "Lecture_Folder/Week8b.html",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tibble)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#this-week",
    "href": "Lecture_Folder/Week8b.html#this-week",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nKey principles of experimental design\nLinear Mixed Models (GLMMs)\nGeneralized Linear Models - Logistic and Poisson Regression\nChi-square tests of association and goodness of fit"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#using-glm-for-more-complicated-mixed-models",
    "href": "Lecture_Folder/Week8b.html#using-glm-for-more-complicated-mixed-models",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Using glm for more complicated mixed models",
    "text": "Using glm for more complicated mixed models\n\nFor a single categorical predictor, we can include effects of each factor level:\n\n\\[ y_i = \\beta_0 + \\beta_1(x~level1) + \\beta_2(x~level2) + \\beta_3x_3~... ~+ e_1 \\]\n\nEach factor level becomes it’s own “effector” that will change the value of y\nInstead of x being a continuous numerical value, for categorical data it will be either a 0 or 1\n\\(x_3\\) is also a continuous variable so this is a mixed model"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#a-generalized-linear-model",
    "href": "Lecture_Folder/Week8b.html#a-generalized-linear-model",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "A Generalized Linear Model",
    "text": "A Generalized Linear Model\n\nCheck out the help page in RStudio for glm()\n\n\nglm(formula = y ~ x1 + x2 + x3, family = gaussian(link = \"identity\"))"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#glm-to-test-wolbachia-infection",
    "href": "Lecture_Folder/Week8b.html#glm-to-test-wolbachia-infection",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "glm to test Wolbachia infection",
    "text": "glm to test Wolbachia infection\n\nSet up a glm() to test for the effect of Wolbachia infection on Recombinant Fraction\n\n\nfly &lt;- read.table(\"Mostoufi2022_Recombination_Edit.csv\", header=T, sep=',')\nmodel &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link=\"identity\"))\nsummary(model)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.348054   0.005845  59.545   &lt;2e-16 ***\nfly$WolbachiaYes 0.021664   0.008474   2.557   0.0112 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00406577)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91480  on 225  degrees of freedom\nAIC: -601.48\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#adding-more-variables",
    "href": "Lecture_Folder/Week8b.html#adding-more-variables",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Adding more variables",
    "text": "Adding more variables\n\nmodel2 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, family = gaussian(link = \"identity\"))\nsummary(model2)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food, \n    family = gaussian(link = \"identity\"))\n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      0.344691   0.008121  42.445   &lt;2e-16 ***\nfly$WolbachiaYes 0.021731   0.008504   2.555   0.0113 *  \nfly$FoodSucrose  0.002933   0.010481   0.280   0.7799    \nfly$FoodYeast    0.007366   0.010128   0.727   0.4678    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.00409246)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.91262  on 223  degrees of freedom\nAIC: -598.02\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#adding-interaction-effects",
    "href": "Lecture_Folder/Week8b.html#adding-interaction-effects",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Adding interaction effects",
    "text": "Adding interaction effects\n\nmodel3 &lt;- glm(fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + fly$Wolbachia*fly$Food, family = gaussian(link = \"identity\"))\nsummary(model3)\n\n\nCall:\nglm(formula = fly$RecombinantFraction ~ fly$Wolbachia + fly$Food + \n    fly$Wolbachia * fly$Food, family = gaussian(link = \"identity\"))\n\nCoefficients:\n                                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                       0.344520   0.009760  35.298   &lt;2e-16 ***\nfly$WolbachiaYes                  0.022080   0.013970   1.581    0.115    \nfly$FoodSucrose                   0.010286   0.014458   0.711    0.478    \nfly$FoodYeast                     0.001256   0.014059   0.089    0.929    \nfly$WolbachiaYes:fly$FoodSucrose -0.015873   0.021002  -0.756    0.451    \nfly$WolbachiaYes:fly$FoodYeast    0.012910   0.020282   0.637    0.525    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 0.004096248)\n\n    Null deviance: 0.94137  on 226  degrees of freedom\nResidual deviance: 0.90527  on 221  degrees of freedom\nAIC: -595.86\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#how-do-we-know-which-model-to-use",
    "href": "Lecture_Folder/Week8b.html#how-do-we-know-which-model-to-use",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "How do we know which model to use?",
    "text": "How do we know which model to use?\n\nWant to be careful not to overfit your linear model (give too many variables)\nWe can use Deviance\nThe Akaike information criterion (AIC) is a metric for comparing different models to find the best fit\n\nNotice the AIC score in your output?\nThis works the same way that it did in multiple linear regression"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#what-is-deviance",
    "href": "Lecture_Folder/Week8b.html#what-is-deviance",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "What is Deviance?",
    "text": "What is Deviance?\n\nDeviance measures model fit in generalized linear models (GLMs)\nSimilar to residual sum of squares in linear regression\nCompares fitted model to a saturated model\nSaturated model: fits data perfectly (one parameter per observation)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#mathematical-definition",
    "href": "Lecture_Folder/Week8b.html#mathematical-definition",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Mathematical Definition",
    "text": "Mathematical Definition\n\\[\n\\text{Deviance} = 2 \\times (\\log L_{\\text{saturated}} - \\log L_{\\text{fitted}})\n\\]\n\nLower deviance = better fit\nUsed to compare models"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#types-of-deviance-in-glm",
    "href": "Lecture_Folder/Week8b.html#types-of-deviance-in-glm",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Types of Deviance in glm()",
    "text": "Types of Deviance in glm()\n\nNull Deviance:\n\nFrom model with only intercept\nMeasures fit using just the mean response\n\nResidual Deviance:\n\nFrom the fitted model (with predictors)\nMeasures how well your model fits relative to saturated model"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#interpreting-deviance",
    "href": "Lecture_Folder/Week8b.html#interpreting-deviance",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Interpreting Deviance",
    "text": "Interpreting Deviance\n\nLarge drop from null deviance to residual deviance → better model fit\nTest improvement with chi-square test:\n\nwith(model, pchisq(null.deviance - deviance, \n                   df.null - df.residual, \n                   lower.tail = FALSE))"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#example-output",
    "href": "Lecture_Folder/Week8b.html#example-output",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Example Output",
    "text": "Example Output\nNull deviance: 120.45  on 99  degrees of freedom\nResidual deviance:  98.23  on 97  degrees of freedom\n\nThe model explains variability beyond just the mean\nCompare deviances to assess predictor usefulness"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#what-is-a-generalized-linear-model",
    "href": "Lecture_Folder/Week8b.html#what-is-a-generalized-linear-model",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "What is a generalized linear model?",
    "text": "What is a generalized linear model?\n\nThe response variable of interest is binary - violates normality assumption because binomial distributed (Logistic)\nThe response variable is a count - violates the assumption of independent mean and variance because the data are multinomial or Poisson distributed (Poisson or Log-linear)\nProvides a convenient way to connect predictor variables with categorical response variables\nBasically an extension of general linear models that link the distribution of the response variable to the predictor variables"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#generalized-linear-models-have-three-components",
    "href": "Lecture_Folder/Week8b.html#generalized-linear-models-have-three-components",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Generalized linear models have three components",
    "text": "Generalized linear models have three components\n\nThe random component that specifies the residual distribution of the response variable in terms of a function of the mean.\nThe systematic component represents the linear combination of the predictor variables, and is equivalent to what you’ve learned previously for general linear models\nThe link function connects the random and systematic components, and depends on the nature of the random response distribution (e.g. binomial or poisson)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#assumptions",
    "href": "Lecture_Folder/Week8b.html#assumptions",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Assumptions",
    "text": "Assumptions\n\nIndependence of observations\nNo observations are overly influential\nLinearity between the response and predictors is not assumed, but the relationship between each of the predictors and the link function is assumed to be linear\nThe dispersion is not extreme (over or under), and fits the assumptions for binomial or Poisson error distributions\nWhat if the dispersion assumption is not met?\n\nCan fit ‘quasibinomial’ or ‘quasipoisson’ distributions where the dispersion parameter is derived from the data\nUse a Generalized Additive Model (GAM)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#what-is-logistic-regression",
    "href": "Lecture_Folder/Week8b.html#what-is-logistic-regression",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "What is Logistic Regression?",
    "text": "What is Logistic Regression?\n\nA classification algorithm\nUsed to predict a binary outcome (e.g., success/failure)\nOutputs a probability that is mapped to class labels"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#why-not-linear-regression",
    "href": "Lecture_Folder/Week8b.html#why-not-linear-regression",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Why Not Linear Regression?",
    "text": "Why Not Linear Regression?\n\nLinear regression is unbounded\nLogistic regression uses the logit function to map outputs between 0 and 1\n\n\\[P(y = 1 \\mid x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}\\]"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#the-logistic-function",
    "href": "Lecture_Folder/Week8b.html#the-logistic-function",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "The Logistic Function",
    "text": "The Logistic Function\n\ncurve(1 / (1 + exp(-x)), from = -10, to = 10, col = \"blue\", ylab = \"Probability\", xlab = \"Linear predictor\")\n\n\n\n\n\n\n\n\n\nS-shaped (sigmoid) curve\nConverts linear predictions into probabilities"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#odds-and-log-odds",
    "href": "Lecture_Folder/Week8b.html#odds-and-log-odds",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Odds and Log-Odds",
    "text": "Odds and Log-Odds\nLogistic regression models log-odds as a linear function\nOdds: \\[\\frac{P}{1 - P}\\]\nLog-odds (logit):\n\\[\\log\\left(\\frac{P}{1 - P}\\right)\\]"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#equivalent-model-equation",
    "href": "Lecture_Folder/Week8b.html#equivalent-model-equation",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Equivalent Model Equation",
    "text": "Equivalent Model Equation\n\\[P(y = 1 \\mid x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 x)}}\\]\n\\[\n\\log\\left(\\frac{P(y=1)}{1 - P(y=1)}\\right) = \\beta_0 + \\beta_1 x\n\\]\n\nLinear in parameters\nNon-linear in terms of prediction\nWe have linked the two sides with the logit function"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#fitting-the-model",
    "href": "Lecture_Folder/Week8b.html#fitting-the-model",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Fitting the Model",
    "text": "Fitting the Model\n\n# Example in R\ndata(mtcars)\nmtcars$am &lt;- factor(mtcars$am)\n\nmodel &lt;- glm(am ~ mpg, data = mtcars, family = binomial)\nsummary(model)\n\n\nCall:\nglm(formula = am ~ mpg, family = binomial, data = mtcars)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  -6.6035     2.3514  -2.808  0.00498 **\nmpg           0.3070     0.1148   2.673  0.00751 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43.230  on 31  degrees of freedom\nResidual deviance: 29.675  on 30  degrees of freedom\nAIC: 33.675\n\nNumber of Fisher Scoring iterations: 5\n\n\n\nUses maximum likelihood estimation\nOutput includes coefficients for log-odds"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#interpreting-coefficients",
    "href": "Lecture_Folder/Week8b.html#interpreting-coefficients",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Interpreting Coefficients",
    "text": "Interpreting Coefficients\n\nCoefficients are in log-odds\nTo interpret: exponentiate\n\n\nexp(coef(model))\n\n(Intercept)         mpg \n0.001355579 1.359379288 \n\n\n\n\\(\\exp(\\beta_1)\\): multiplicative change in odds for a 1-unit increase in predictor"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#making-predictions",
    "href": "Lecture_Folder/Week8b.html#making-predictions",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Making Predictions",
    "text": "Making Predictions\n\npredict(model, newdata = data.frame(mpg = 20), type = \"response\")\n\n        1 \n0.3862832 \n\n\n\nReturns the probability that am = 1 given mpg = 20"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#model-evaluation-metrics",
    "href": "Lecture_Folder/Week8b.html#model-evaluation-metrics",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Model Evaluation Metrics",
    "text": "Model Evaluation Metrics\nTo assess the quality of a logistic regression model, we often use:\n\nConfusion matrix\nAccuracy\nPrecision\nRecall\nAUC-ROC"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#confusion-matrix",
    "href": "Lecture_Folder/Week8b.html#confusion-matrix",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\nA 2x2 table comparing predicted vs. actual values:\n\n\n\n\nPredicted Positive\nPredicted Negative\n\n\n\n\nActual Positive\nTrue Positive (TP)\nFalse Negative (FN)\n\n\nActual Negative\nFalse Positive (FP)\nTrue Negative (TN)\n\n\n\nHelps visualize performance across all classification outcomes."
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#accuracy",
    "href": "Lecture_Folder/Week8b.html#accuracy",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Accuracy",
    "text": "Accuracy\n\nProportion of correct predictions out of all predictions:\n\n\\[\n\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n\\]\n\nSimple but may be misleading with imbalanced data."
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#precision",
    "href": "Lecture_Folder/Week8b.html#precision",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Precision",
    "text": "Precision\n\nOf all predicted positives, how many are actually positive?\n\n\\[\n\\text{Precision} = \\frac{TP}{TP + FP}\n\\]\n\nHigh precision = low false positive rate"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#recall-sensitivity",
    "href": "Lecture_Folder/Week8b.html#recall-sensitivity",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Recall (Sensitivity)",
    "text": "Recall (Sensitivity)\n\nOf all actual positives, how many were predicted correctly?\n\n\\[\n\\text{Recall} = \\frac{TP}{TP + FN}\n\\]\n\nHigh recall = low false negative rate"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#precision-vs.-recall",
    "href": "Lecture_Folder/Week8b.html#precision-vs.-recall",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Precision vs. Recall",
    "text": "Precision vs. Recall\n\nTrade-off: improving one can reduce the other\nUse F1 score to balance both:\n\n\\[\nF1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n\\]"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#auc-roc",
    "href": "Lecture_Folder/Week8b.html#auc-roc",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "AUC-ROC",
    "text": "AUC-ROC\n\nROC Curve plots TPR (Recall) vs. FPR across thresholds\nAUC (Area Under Curve) summarizes performance:\nProbability the model ranks a random positive higher than a random negative\nRanges from 0.5 (random) to 1.0 (perfect)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#r-interlude-logistic-regression",
    "href": "Lecture_Folder/Week8b.html#r-interlude-logistic-regression",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Logistic regression",
    "text": "R INTERLUDE | Logistic regression"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#dataset-variable-descriptions",
    "href": "Lecture_Folder/Week8b.html#dataset-variable-descriptions",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Dataset Variable Descriptions",
    "text": "Dataset Variable Descriptions\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\n\nbiomaterial\nCategorical\nType of biomaterial used in the scaffold (Material_A, Material_B, Material_C)\n\n\nstiffness\nNumeric\nMechanical stiffness of the scaffold (in kilopascals, kPa)\n\n\nage_days\nInteger\nAge of the scaffold at implantation (in days; range: 20–60)\n\n\nsuccess\nBinary\nOutcome of tissue integration (1 = successful, 0 = unsuccessful)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#fitting-the-model-1",
    "href": "Lecture_Folder/Week8b.html#fitting-the-model-1",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Fitting the model",
    "text": "Fitting the model\n\nbio_data &lt;- read.csv(\"BioE_logistic_data.csv\", header = TRUE)\nmodel &lt;- glm(success ~ biomaterial + stiffness + age_days, \n             data = bio_data, \n             family = binomial)\n\nsummary(model)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#fitting-the-model-2",
    "href": "Lecture_Folder/Week8b.html#fitting-the-model-2",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Fitting the model",
    "text": "Fitting the model\n\n\n\nCall:\nglm(formula = success ~ biomaterial + stiffness + age_days, family = binomial, \n    data = bio_data)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)            1.72263    1.42408   1.210  0.22641   \nbiomaterialMaterial_B  0.84062    0.54300   1.548  0.12160   \nbiomaterialMaterial_C  1.34228    0.63184   2.124  0.03364 * \nstiffness              0.23744    0.11396   2.084  0.03720 * \nage_days              -0.06895    0.02441  -2.825  0.00473 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 135.17  on 149  degrees of freedom\nResidual deviance: 114.89  on 145  degrees of freedom\nAIC: 124.89\n\nNumber of Fisher Scoring iterations: 5"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#plotting-the-model",
    "href": "Lecture_Folder/Week8b.html#plotting-the-model",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Plotting the model",
    "text": "Plotting the model\n\nggplot(bio_data, aes(x = stiffness, y = success, color = biomaterial)) +\n  geom_point(alpha = 0.4, shape = 1) +\n  geom_smooth(method = \"glm\", method.args = list(family = \"binomial\"), \n              formula = success ~ biomaterial + stiffness + age_days, se = FALSE, size = 1.2) +\n  labs(title = \"Predicted Probability of Success\",\n       x = \"Stiffness (kPa)\",\n       y = \"Predicted Probability\",\n       color = \"Biomaterial\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: Failed to fit group 1.\nCaused by error:\n! object 'success' not found\n\n\nWarning: Failed to fit group 2.\nCaused by error:\n! object 'success' not found\n\n\nWarning: Failed to fit group 3.\nCaused by error:\n! object 'success' not found"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#what-is-poisson-regression",
    "href": "Lecture_Folder/Week8b.html#what-is-poisson-regression",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "What is Poisson Regression?",
    "text": "What is Poisson Regression?\n\nA type of Generalized Linear Model (GLM)\nUsed to model count data (e.g., number of visits, accidents, events)\nThe outcome variable is assumed to follow a Poisson distribution"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#the-poisson-distribution",
    "href": "Lecture_Folder/Week8b.html#the-poisson-distribution",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "The Poisson Distribution",
    "text": "The Poisson Distribution\n\\[ P(Y = y) = \\frac{e^{-\\lambda} \\lambda^y}{y!} \\]\n\nMean = Variance = \\(\\lambda\\)\nSuitable for modeling counts of rare events"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#model-structure",
    "href": "Lecture_Folder/Week8b.html#model-structure",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Model Structure",
    "text": "Model Structure\n\\[ Y_i \\sim \\text{Poisson}(\\lambda_i) \\]\n\\[\n\\log(\\lambda_i) = \\beta_0 + \\beta_1 x_{i1} + \\ldots + \\beta_p x_{ip}\n\\]\n\nThe log link ensures ( _i &gt; 0 )\nLinear model for the log of expected counts"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#why-not-use-linear-regression",
    "href": "Lecture_Folder/Week8b.html#why-not-use-linear-regression",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Why Not Use Linear Regression?",
    "text": "Why Not Use Linear Regression?\n\nLinear regression may predict negative counts\nIt assumes constant variance, but Poisson variance = mean\nPoisson regression accounts for the distributional structure of count data"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#example",
    "href": "Lecture_Folder/Week8b.html#example",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Example",
    "text": "Example\n\nmodel &lt;- glm(y ~ x1 + x2, data = something, family = poisson)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#interpreting-coefficients-1",
    "href": "Lecture_Folder/Week8b.html#interpreting-coefficients-1",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Interpreting Coefficients",
    "text": "Interpreting Coefficients\n\nCoefficients are on the log scale\nTo interpret, exponentiate them:\n\n\nexp(coef(model))\n\n\n\\(\\exp(\\beta_j)\\): multiplicative change in expected count for a 1-unit increase in predictor \\(x_j\\)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#model-assumptions",
    "href": "Lecture_Folder/Week8b.html#model-assumptions",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Model Assumptions",
    "text": "Model Assumptions\n\nCounts are Poisson-distributed\nMean equals variance (can be relaxed in quasi-Poisson or negative binomial models)\nLog-linear relationship between predictors and the outcome"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#model-evaluation",
    "href": "Lecture_Folder/Week8b.html#model-evaluation",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Model Evaluation",
    "text": "Model Evaluation\n\nDeviance residuals\nAkaike Information Criterion (AIC)\nOverdispersion checks\nPseudo-\\(R^2\\)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#overdispersion",
    "href": "Lecture_Folder/Week8b.html#overdispersion",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Overdispersion",
    "text": "Overdispersion\n\nWhen variance &gt; mean\nCan inflate type I errors\nCheck with:\n\n\\[\n\\text{Dispersion} = \\frac{\\text{Residual deviance}}{\\text{df}}\n\\]\n\nConsider alternatives:\n\nQuasi-Poisson\nNegative Binomial Regression"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#goodness-of-fit",
    "href": "Lecture_Folder/Week8b.html#goodness-of-fit",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Goodness-of-Fit",
    "text": "Goodness-of-Fit\n\nDeviance: compares model to saturated model\nPearson residuals: detect outliers and overdispersion\nUse AIC to compare models"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#r-interlude-log-linear-poisson-regression",
    "href": "Lecture_Folder/Week8b.html#r-interlude-log-linear-poisson-regression",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "R INTERLUDE | Log-linear (Poisson) regression",
    "text": "R INTERLUDE | Log-linear (Poisson) regression"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#dataset-variable-descriptions-poisson-model",
    "href": "Lecture_Folder/Week8b.html#dataset-variable-descriptions-poisson-model",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Dataset Variable Descriptions (Poisson Model)",
    "text": "Dataset Variable Descriptions (Poisson Model)\n\n\n\n\n\n\n\n\nVariable\nType\nDescription\n\n\n\n\nbiomaterial\nCategorical\nType of biomaterial used in the scaffold\n\n\nstiffness\nNumeric\nMechanical stiffness in kilopascals (kPa)\n\n\nage_days\nInteger\nAge of scaffold at implantation (20–60 days)\n\n\nintegration_events\nCount\nNumber of successful tissue integration events (simulated)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#fit-the-model",
    "href": "Lecture_Folder/Week8b.html#fit-the-model",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Fit the model",
    "text": "Fit the model\n\n# Load data\nbio_data &lt;- read.csv(\"BioE_poisson_data.csv\")\n\n# Fit log-linear (Poisson) model\nmodel &lt;- glm(integration_events ~ biomaterial + stiffness + age_days,\n             family = poisson, data = bio_data)\n\nsummary(model)"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#fit-the-model-1",
    "href": "Lecture_Folder/Week8b.html#fit-the-model-1",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Fit the model",
    "text": "Fit the model\n\n\n\nCall:\nglm(formula = integration_events ~ biomaterial + stiffness + \n    age_days, family = poisson, data = bio_data)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            1.11533    0.16566   6.733 1.67e-11 ***\nbiomaterialMaterial_B  0.42231    0.07179   5.883 4.03e-09 ***\nbiomaterialMaterial_C  0.67282    0.06835   9.843  &lt; 2e-16 ***\nstiffness              0.14544    0.01226  11.864  &lt; 2e-16 ***\nage_days              -0.01885    0.00221  -8.533  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 465.13  on 149  degrees of freedom\nResidual deviance: 151.52  on 145  degrees of freedom\nAIC: 755.3\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "Lecture_Folder/Week8b.html#make-a-plot",
    "href": "Lecture_Folder/Week8b.html#make-a-plot",
    "title": "Week 8b - Statistics for Bioengineering",
    "section": "Make a plot",
    "text": "Make a plot\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Add predicted counts\nbio_data$predicted_counts &lt;- predict(model, type = \"response\")\n\n# Plot predicted vs actual across stiffness for each biomaterial\nggplot(bio_data, aes(x = stiffness, y = predicted_counts, color = biomaterial)) +\n  geom_point(aes(y = integration_events), alpha = 0.5, shape = 1) +\n  geom_line(size = 1.2) +\n  labs(title = \"Predicted Integration Events\",\n       x = \"Stiffness (kPa)\",\n       y = \"Predicted Count\",\n       color = \"Biomaterial\") +\n  theme_minimal()"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#problem-3.2-goodness-of-fit-test-for-cystic-fibrosis",
    "href": "Homework_Folder/HW3_2025.html#problem-3.2-goodness-of-fit-test-for-cystic-fibrosis",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "Problem 3.2: Goodness of Fit Test for Cystic Fibrosis",
    "text": "Problem 3.2: Goodness of Fit Test for Cystic Fibrosis\n\nThe Study\nCystic fibrosis (CF) is an autosomal recessive genetic disorder. When both parents are carriers (genotype Ff), each child has the following expected probab:\n\n25% chance of being homozygous dominant (FF) — unaffected, not a carrier\n50% chance of being heterozygous (Ff) — unaffected carrier\n25% chance of being homozygous recessive (ff) — affected by cystic fibrosis\n\nA genetic counselor collects data from 377 children born to heterozygous carrier parents in a particular community and records the following distribution of genotypes:\n\n\n\nGenotype\nPhenotype Status\nObserved Count\n\n\n\n\nFF\nUnaffected (not carrier)\n69\n\n\nFf\nCarrier\n206\n\n\nff\nAffected (CF)\n102\n\n\n\nThe genetic counselor suspects that there might divergence from Hardy-Weinberg Equilibrium (HWE) in this community due to some unmeasured environmental or genetic factors.\n\n\nYour Tasks:\n\nState the null and alternative hypotheses for a Chi-square goodness of fit test to determine whether the observed genotypic distribution follows HWE expectations.\nCalculate the expected counts for each genotype under the 1:2:1 Mendelian ratio by first calculating the allele frequencies in this population.\nUse R to perform the Chi-square goodness of fit test to compare the expected genotype counts to the observed genotype counts.\nInterpret your results in the context of Mendelian genetics. Use a significance level of α = 0.05.\nWhat would you recommend that the genetic counselor conclude about whether something else might be going on?"
  },
  {
    "objectID": "Homework_Folder/HW3_2025.html#problem-3.3-chi-square-contingency-table-analysis-of-scaffold-materials-and-regeneration",
    "href": "Homework_Folder/HW3_2025.html#problem-3.3-chi-square-contingency-table-analysis-of-scaffold-materials-and-regeneration",
    "title": "BioE_Stats_2025_HW3 - Multifactor ANOVA and Chi-square tests",
    "section": "Problem 3.3: Chi-square Contingency Table Analysis of Scaffold Materials and Regeneration",
    "text": "Problem 3.3: Chi-square Contingency Table Analysis of Scaffold Materials and Regeneration\n\nThe Study\nA team of bioengineers is evaluating how scaffold material and stem cell type influence the success of tissue regeneration in a lab-grown cartilage model. They use three different scaffold materials and three types of stem cells and record whether the engineered cartilage shows successful regeneration (defined by a set of mechanical and histological markers) after 4 weeks.\nThey test the following materials\n\nScaffold Materials:\n\nCollagen\nHydrogel\nBioceramic\n\nStem Cell Types:\n\nAdipose-derived stem cells (ASC)\nBone marrow-derived stem cells (BMSC)\nInduced pluripotent stem cells (iPSC)\n\n\nThe counts below represent the number of successful regenerations in each combination of material and cell type.\n\n\n\n\nASC\nBMSC\niPSC\n\n\n\n\nCollagen\n48\n22\n15\n\n\nHydrogel\n25\n57\n30\n\n\nBioceramic\n20\n23\n61\n\n\n\n\n\nYour Tasks:\n\nState the null and alternative hypotheses for this test.\nUsing R, perform a Chi-square test of independence. Include the R code and output.\nCalculate the odds ratio and LOD score for just the collagen/hydrogel vs. ASC/BMSC combination.\nWhat do the results suggest? Use a significance level of α = 0.05.\nWould you conclude that scaffold type and cell type influence regeneration success independently, or do they interact?"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html",
    "href": "Lecture_Folder/Week9a.html",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tibble)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#this-week",
    "href": "Lecture_Folder/Week9a.html#this-week",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nChi-square tests of association and goodness of fit\nConnections to confusion matrices\nBasics of statistical (classical) machine learning\nTomorrow - homework 3 due\nOn Thursday - brief presentation to the class of your dataset\nNext week - finish statistical (classical) machine learning\nSpecial session - Git/GitHub and Talapas"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-the-chi2-distribution",
    "href": "Lecture_Folder/Week9a.html#what-is-the-chi2-distribution",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What is the \\(\\chi^2\\) Distribution ?",
    "text": "What is the \\(\\chi^2\\) Distribution ?\n\nHow do we perform statistical tests on one or more categorical variables?\nThe Chi-square distribution (χ²) is a continuous probability distribution.\nIt arises when you sum the squares of independent standard normal variables.\nIt is widely used in statistical tests and in machine learning for evaluation"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-distribution-definition",
    "href": "Lecture_Folder/Week9a.html#chi2-distribution-definition",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Distribution Definition",
    "text": "\\(\\chi^2\\) Distribution Definition\n\nStart with a set of variables \\(X_1, X_2, ..., X_k\\)\nThen take the z-scores for each variable\n\nIf \\(Z_1, Z_2, ..., Z_k\\) are independent standard normal variables, then:\n\\[\n\\chi^2_k = \\sum_{i=1}^k Z_i^2\n\\]\n\n\\(\\chi^2_k\\) denotes a chi-square distribution with \\(k\\) degrees of freedom (df).\nThe shape depends on the degrees of freedom.\nAs the mean increases it approaches a normal distribution (via Central Limit Theorem)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#section",
    "href": "Lecture_Folder/Week9a.html#section",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "",
    "text": "Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nChi-square distribution for different degrees of freedom"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-distribution-properties",
    "href": "Lecture_Folder/Week9a.html#chi2-distribution-properties",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Distribution Properties",
    "text": "\\(\\chi^2\\) Distribution Properties\n\nDomain: \\(x \\in [0, \\infty)\\)\nMean: \\(k\\)\nVariance: \\(2k\\)\nRight-skewed distribution"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-distribution-probability-density-function",
    "href": "Lecture_Folder/Week9a.html#chi2-distribution-probability-density-function",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Distribution Probability Density Function",
    "text": "\\(\\chi^2\\) Distribution Probability Density Function\n\\[\nf(x; k) = \\frac{1}{2^{k/2} \\Gamma(k/2)} x^{k/2 - 1} e^{-x/2}, \\quad x &gt; 0\n\\]\n\nWhere \\(\\Gamma\\) is the gamma function.\nThis function defines the shape of the chi-square distribution.\nThe gamma function is linked to the gamma distribution"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#gamma-distribution",
    "href": "Lecture_Folder/Week9a.html#gamma-distribution",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\na continuous probability distribution\nused to model the times that elapses before \\(\\alpha\\) occurrences of a randomly occurring event\ne.g. calls to a pizza place or defects on a production line\nsuch events are said to occur via a Poisson Process"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#gamma-distribution-1",
    "href": "Lecture_Folder/Week9a.html#gamma-distribution-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\nDescribes the waiting time until the \\(r^{th}\\) event for a process that occurs randomly over time at a rate \\(\\lambda\\) :\n\n\n\\[f(x) = \\frac{e^{-\\lambda x}\\lambda x^{r-1}}{(r-1)!}\\lambda\\]\n\n\\[ Mean =  \\frac{r}{\\lambda} \\] \\[ Variance = \\frac{r}{\\lambda^2} \\]"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#gamma-distribution-2",
    "href": "Lecture_Folder/Week9a.html#gamma-distribution-2",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\\[\nf(x; \\alpha, \\lambda) =\n\\frac{\\lambda^{\\alpha}}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\lambda x}, \\quad x &gt; 0\n\\]\n\nwith shape parameter \\(\\alpha\\) &gt; 0 and rate parameter \\(\\lambda\\) &gt; 0\n\n\\[\nf(x; \\alpha, \\theta) =\n\\frac{1}{\\Gamma(\\alpha) \\theta^\\alpha} x^{\\alpha - 1} e^{-x/\\theta}, \\quad x &gt; 0\n\\]\n\nwith scale parameter \\(\\theta = \\frac{1}{\\lambda}\\)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#gamma-distribution-3",
    "href": "Lecture_Folder/Week9a.html#gamma-distribution-3",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\n\n\nExample: If, in a PCR reaction, DNA polymerase synthesizes new DNA strands at a rate of 1 per millisecond, how long until 1000 new DNA strands are produced?\n\n\n\nAssume: that DNA synthesis does not deplete the pool of primers or nucleotides in the chamber, so that each event is independent of other events in the PCR chamber."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#uses-of-the-chi-square-distribution",
    "href": "Lecture_Folder/Week9a.html#uses-of-the-chi-square-distribution",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Uses of the Chi-square distribution",
    "text": "Uses of the Chi-square distribution\n\nGoodness-of-fit tests: Does observed data match expected proportions?\nTest of independence: Are two categorical variables related?\nTest of homogeneity: Do different groups have the same distribution?"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-a-chi-square-goodness-of-fit-test",
    "href": "Lecture_Folder/Week9a.html#what-is-a-chi-square-goodness-of-fit-test",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What is a Chi-square Goodness-of-Fit Test?",
    "text": "What is a Chi-square Goodness-of-Fit Test?\n\nA Chi-square Goodness-of-Fit Test checks whether observed frequencies differ from expected frequencies.\nUsed when:\n\nYou have one categorical variable.\nYou want to test whether it fits a specified distribution."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#hypotheses",
    "href": "Lecture_Folder/Week9a.html#hypotheses",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Hypotheses",
    "text": "Hypotheses\n\nNull hypothesis (H₀): Observed data follows the expected distribution.\nAlternative hypothesis (H₁): Observed data does not follow the expected distribution."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#when-to-use-this-test",
    "href": "Lecture_Folder/Week9a.html#when-to-use-this-test",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "When to use this test",
    "text": "When to use this test\n\nMarketing: preference among product categories\nBiology: expected vs observed phenotypes\nEducation: survey responses by category"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#assumptions",
    "href": "Lecture_Folder/Week9a.html#assumptions",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Assumptions",
    "text": "Assumptions\n\nData are counts (not percentages or proportions).\nCategories are mutually exclusive.\nExpected count in each category should be ≥ 5 ."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#test-statistic",
    "href": "Lecture_Folder/Week9a.html#test-statistic",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Test Statistic",
    "text": "Test Statistic\nThe test statistic is:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\nWhere:\n\\(O_i\\) = Observed frequency\n\\(E_i\\) = Expected frequency\nDegrees of freedom:\n\\[\ndf = k - 1\n\\]\nwhere ( k ) = number of categories"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#example-scenario",
    "href": "Lecture_Folder/Week9a.html#example-scenario",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Example Scenario",
    "text": "Example Scenario\nA geneticist expects a 3:1 Mendelian ratio in offspring genotypes.\nObserved counts:\n\nDominant: 72\nRecessive: 28\n\nExpected proportions:\n\nDominant: 0.75\nRecessive: 0.25"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#goodness-of-fit-by-hand-in-r",
    "href": "Lecture_Folder/Week9a.html#goodness-of-fit-by-hand-in-r",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Goodness of Fit by hand in R",
    "text": "Goodness of Fit by hand in R\n\n# Observed data\nobserved &lt;- c(Dominant = 72, Recessive = 28)\n\n# Expected proportions\nexpected_probs &lt;- c(0.75, 0.25)\n\n# Expected counts\nexpected &lt;- sum(observed) * expected_probs\n\n# Chi-square test manually\nchisq_stat &lt;- sum((observed - expected)^2 / expected)\nchisq_stat  # Output: Chi-square statistic\n\n# Degrees of freedom\ndf &lt;- length(observed) - 1\n\n# Critical value at alpha = 0.05\ncritical_val &lt;- qchisq(0.95, df)\ncritical_val\n\n# P-value\np_val &lt;- pchisq(chisq_stat, df, lower.tail = FALSE)\np_val\n\n# Alternatively, use chisq.test()\nchisq.test(x = observed, p = expected_probs)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#goodness-of-fit-by-hand-in-r-1",
    "href": "Lecture_Folder/Week9a.html#goodness-of-fit-by-hand-in-r-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Goodness of Fit by hand in R",
    "text": "Goodness of Fit by hand in R\n\n\n[1] 0.48\n\n\n[1] 3.841459\n\n\n[1] 0.4884223\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  observed\nX-squared = 0.48, df = 1, p-value = 0.4884"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#parametric---rolling-a-six-sided-die-60-times",
    "href": "Lecture_Folder/Week9a.html#parametric---rolling-a-six-sided-die-60-times",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Parametric - rolling a six-sided die 60 times",
    "text": "Parametric - rolling a six-sided die 60 times\n\nobserved &lt;- c(8, 9, 10, 12, 11, 10)\n\nexpected_probs &lt;- rep(1/6, 6)\n\nchisq.test(x = observed, p = expected_probs)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#parametric---rolling-a-six-sided-die-60-times-1",
    "href": "Lecture_Folder/Week9a.html#parametric---rolling-a-six-sided-die-60-times-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Parametric - rolling a six-sided die 60 times",
    "text": "Parametric - rolling a six-sided die 60 times\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  observed\nX-squared = 1, df = 5, p-value = 0.9626"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#goodness-of-fit-using-resampling",
    "href": "Lecture_Folder/Week9a.html#goodness-of-fit-using-resampling",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Goodness of fit using resampling",
    "text": "Goodness of fit using resampling\n\nset.seed(123)  # For reproducibility\n\n# Observed data\nobserved &lt;- c(Dominant = 72, Recessive = 28)\nn &lt;- sum(observed)\n\n# Expected probabilities\nexpected_probs &lt;- c(0.75, 0.25)\n\n# Number of simulations\nn_sim &lt;- 10000\n\n# Simulate chi-square statistics under the null\nsim_chisq &lt;- replicate(n_sim, {\n  simulated &lt;- rmultinom(1, size = n, prob = expected_probs)\n  expected &lt;- n * expected_probs\n  sum((simulated - expected)^2 / expected)\n})\n\n# Observed chi-square statistic\nobs_chisq &lt;- sum((observed - n * expected_probs)^2 / (n * expected_probs))\n\n# Empirical p-value\np_value &lt;- mean(sim_chisq &gt;= obs_chisq)\n\n# Output results\ncat(\"Observed Chi-square:\", obs_chisq, \"\\n\")\ncat(\"Empirical P-value:\", p_value, \"\\n\")"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#goodness-of-fit-using-resampling-1",
    "href": "Lecture_Folder/Week9a.html#goodness-of-fit-using-resampling-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Goodness of fit using resampling",
    "text": "Goodness of fit using resampling\n\n\nObserved Chi-square: 0.48 \n\n\nEmpirical P-value: 0.5615"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#goodness-of-fit-null-distribution",
    "href": "Lecture_Folder/Week9a.html#goodness-of-fit-null-distribution",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Goodness of fit null distribution",
    "text": "Goodness of fit null distribution\n\nhist(sim_chisq, breaks = 50, main = \"Resampling Null Distribution\",\n     xlab = \"Chi-square statistic\", col = \"lightblue\", border = \"white\")\nabline(v = obs_chisq, col = \"red\", lwd = 2)\nlegend(\"topright\", legend = \"Observed\", col = \"red\", lwd = 2)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#on-your-own",
    "href": "Lecture_Folder/Week9a.html#on-your-own",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "On your own",
    "text": "On your own\n\nChange around the data in the examples above and see how it affects the results\nTake your term-long data set or one of the data sets we’ve examined in class\nCreate a hypothesis of expected proportions and test it\nCreate a side-by-side plot of observed and expected frequencies"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-a-chi-square-test-of-association",
    "href": "Lecture_Folder/Week9a.html#what-is-a-chi-square-test-of-association",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What is a Chi-square Test of Association?",
    "text": "What is a Chi-square Test of Association?\n\nA statistical test to determine whether two categorical variables are associated (not independent).\nNull hypothesis (H₀): The two variables are independent.\nAlternative hypothesis (H₁): There is an association between the variables."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#assumptions-1",
    "href": "Lecture_Folder/Week9a.html#assumptions-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Assumptions",
    "text": "Assumptions\n\nObservations are independent.\nExpected counts ≥ 5 in at least 80% of cells.\nNo more than 20% of cells have expected counts &lt; 5."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#example-scenario-1",
    "href": "Lecture_Folder/Week9a.html#example-scenario-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Example Scenario",
    "text": "Example Scenario\nA researcher surveys students about their study preference:\n\n\n\n\nMorning\nEvening\n\n\n\n\nUndergraduates\n30\n20\n\n\nGraduates\n10\n40\n\n\n\n\nAre study time preference and academic level associated?"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#performing-a-chi-square-test-of-association-in-r",
    "href": "Lecture_Folder/Week9a.html#performing-a-chi-square-test-of-association-in-r",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Performing a Chi-square test of association in R",
    "text": "Performing a Chi-square test of association in R\n\n# Create contingency table\nstudy_table &lt;- matrix(c(30, 20, 10, 40),\n                      nrow = 2,\n                      byrow = TRUE)\n\n# Add row and column names\nrownames(study_table) &lt;- c(\"Undergraduate\", \"Graduate\")\ncolnames(study_table) &lt;- c(\"Morning\", \"Evening\")\n\n# View the table\nstudy_table\n\n# Perform Chi-square test of independence\nchisq.test(study_table)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#performing-a-chi-square-test-of-association-in-r-1",
    "href": "Lecture_Folder/Week9a.html#performing-a-chi-square-test-of-association-in-r-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Performing a Chi-square test of association in R",
    "text": "Performing a Chi-square test of association in R\n\n\n              Morning Evening\nUndergraduate      30      20\nGraduate           10      40\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  study_table\nX-squared = 15.042, df = 1, p-value = 0.0001052"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#paired-histogram",
    "href": "Lecture_Folder/Week9a.html#paired-histogram",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Paired Histogram",
    "text": "Paired Histogram\n\nlibrary(ggplot2)\n\ndf &lt;- as.data.frame(as.table(study_table))\nggplot(df, aes(x = Var2, y = Freq, fill = Var1)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Study Time\", y = \"Number of Students\", fill = \"Student Type\") +\n  theme_minimal()"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#paired-histogram-1",
    "href": "Lecture_Folder/Week9a.html#paired-histogram-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Paired Histogram",
    "text": "Paired Histogram\n\n\n\n\n\nStudy Preferences by Student Type"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#mosaic-plot",
    "href": "Lecture_Folder/Week9a.html#mosaic-plot",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Mosaic Plot",
    "text": "Mosaic Plot\n\nmosaicplot(study_table,\n           main = \"Study Time Preference by Student Type\",\n           xlab = \"Student Type\",\n           ylab = \"Study Preference\",\n           color = TRUE)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#mosaic-plot-1",
    "href": "Lecture_Folder/Week9a.html#mosaic-plot-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Mosaic Plot",
    "text": "Mosaic Plot\n\n\n\n\n\nMosaic Plot of Study Preference by Student Type"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#calculating-the-effect-size-using-cramérs-v",
    "href": "Lecture_Folder/Week9a.html#calculating-the-effect-size-using-cramérs-v",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Calculating the effect size using Cramér’s V",
    "text": "Calculating the effect size using Cramér’s V\n\\[\nV = \\sqrt{\\frac{\\chi^2}{n(k-1)}}\n\\] where\n\n\\(\\chi^2\\) is the test statistic\nn is the total number of observations\nk is the min(number of rows, number of columns)\nranges from 0 to 1, with\n\n0.1 being a small effect\n0.3 being a medium effect\n0.5 being a large effect"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#calculating-the-effect-size-in-r",
    "href": "Lecture_Folder/Week9a.html#calculating-the-effect-size-in-r",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Calculating the effect size in R",
    "text": "Calculating the effect size in R\n\n# Example 2x2 contingency table\ntbl &lt;- matrix(c(500, 10, 20, 40), nrow = 2, byrow = TRUE)\nrownames(tbl) &lt;- c(\"Group1\", \"Group2\")\ncolnames(tbl) &lt;- c(\"Outcome1\", \"Outcome2\")\n\n# Chi-square test of independence\ntest &lt;- chisq.test(tbl)\n\n# Extract test statistic\nchisq_val &lt;- test$statistic\n\n# Total number of observations\nn &lt;- sum(tbl)\n\n# Minimum of (rows, columns) for Cramér’s V formula\nk &lt;- min(nrow(tbl), ncol(tbl))\n\n# Cramér’s V calculation\ncramers_v &lt;- sqrt(chisq_val / (n * (k - 1)))\n\n# Print result\ncramers_v"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#calculating-the-effect-size-in-r-1",
    "href": "Lecture_Folder/Week9a.html#calculating-the-effect-size-in-r-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Calculating the effect size in R",
    "text": "Calculating the effect size in R\n\n\nCramer's V: 0.4901895"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-fishers-exact-test",
    "href": "Lecture_Folder/Week9a.html#what-is-fishers-exact-test",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What is Fisher’s Exact Test?",
    "text": "What is Fisher’s Exact Test?\n\nA statistical test used to determine if there is a nonrandom association between two categorical variables.\nAppropriate when:\n\nSample sizes are small\nExpected frequencies are &lt; 5"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#when-to-use-a-fishers-exact-test",
    "href": "Lecture_Folder/Week9a.html#when-to-use-a-fishers-exact-test",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "When to use a Fisher’s Exact Test",
    "text": "When to use a Fisher’s Exact Test\n\n2x2 tables (most common)\nVery small sample sizes\nWhen Chi-square assumptions are violated\nExpected frequency &lt; 5 in &gt;20% of cells"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#caution-and-notes",
    "href": "Lecture_Folder/Week9a.html#caution-and-notes",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Caution and Notes",
    "text": "Caution and Notes\n\nNot limited to 2x2 tables (but computationally expensive for larger ones)\nMore accurate than Chi-square in small samples\nCannot directly compute effect size (but odds ratio is available)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#hypotheses-1",
    "href": "Lecture_Folder/Week9a.html#hypotheses-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Hypotheses",
    "text": "Hypotheses\n\nH₀: The row and column variables are independent.\nH₁: There is an association between the variables."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#example-scenario-2",
    "href": "Lecture_Folder/Week9a.html#example-scenario-2",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Example Scenario",
    "text": "Example Scenario\nA researcher asks 20 people whether they prefer coffee or tea.\n\n\n\n\nCoffee\nTea\n\n\n\n\nEnglish\n8\n2\n\n\nAmerican\n1\n9\n\n\n\nIs beverage preference independent of nationality?"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#creating-the-table-in-r",
    "href": "Lecture_Folder/Week9a.html#creating-the-table-in-r",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Creating the Table in R",
    "text": "Creating the Table in R\n\n# Create 2x2 contingency table\nbeverage_table &lt;- matrix(c(8, 2, 1, 9),\n                         nrow = 2,\n                         byrow = TRUE)\n\nrownames(beverage_table) &lt;- c(\"American\", \"English\")\ncolnames(beverage_table) &lt;- c(\"Coffee\", \"Tea\")\n\nbeverage_table\n\n         Coffee Tea\nAmerican      8   2\nEnglish       1   9"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#running-the-fishers-exact-test",
    "href": "Lecture_Folder/Week9a.html#running-the-fishers-exact-test",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Running the Fisher’s exact test",
    "text": "Running the Fisher’s exact test\n\n# Perform Fisher's Exact Test\nfisher.test(beverage_table)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  beverage_table\np-value = 0.005477\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n    2.057999 1740.081669\nsample estimates:\nodds ratio \n  27.32632"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#paired-histogram-2",
    "href": "Lecture_Folder/Week9a.html#paired-histogram-2",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Paired Histogram",
    "text": "Paired Histogram\n\nlibrary(ggplot2)\n\ndf &lt;- as.data.frame(as.table(beverage_table))\nggplot(df, aes(x = Var2, y = Freq, fill = Var1)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(x = \"Beverage\", y = \"Count\", fill = \"Nationality\") +\n  theme_minimal()"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#paired-histogram-3",
    "href": "Lecture_Folder/Week9a.html#paired-histogram-3",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Paired Histogram",
    "text": "Paired Histogram\n\n\n\n\n\nBeverage Preference by Nationality"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#mosaic-plot-2",
    "href": "Lecture_Folder/Week9a.html#mosaic-plot-2",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Mosaic Plot",
    "text": "Mosaic Plot\n\nmosaicplot(beverage_table,\n           main = \"Beverage preference by nationality\",\n           xlab = \"Nationality\",\n           ylab = \"Beverage\",\n           color = TRUE)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#mosaic-plot-3",
    "href": "Lecture_Folder/Week9a.html#mosaic-plot-3",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Mosaic Plot",
    "text": "Mosaic Plot\n\n\n\n\n\nBeverage Preference by Nationality"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-an-odds-ratio",
    "href": "Lecture_Folder/Week9a.html#what-is-an-odds-ratio",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What is an Odds Ratio?",
    "text": "What is an Odds Ratio?\n\nAn odds is the ratio of the probability an event occurs to the probability it does not occur.\nThe odds ratio (OR) compares the odds of an event between two groups.\nCan think of this as an analogue of the effect size from linear models."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#interpretation",
    "href": "Lecture_Folder/Week9a.html#interpretation",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Interpretation",
    "text": "Interpretation\n\nOdds (linear scale) show how much more likely men are to prefer coffee than women.\nLog(odds) scale:\n\nMakes multiplicative differences additive.\nUseful for regression and effect size comparison.\n\nA large positive log(OR) indicates strong association."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#example-coffee-preference-by-nationality",
    "href": "Lecture_Folder/Week9a.html#example-coffee-preference-by-nationality",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Example: Coffee Preference by Nationality",
    "text": "Example: Coffee Preference by Nationality\n\n\n\n\nCoffee\nTea\nTotal\n\n\n\n\nAmerican\n8\n2\n10\n\n\nEnglish\n1\n9\n10\n\n\n\n\nOdds (Americans prefer Coffee) = \\(\\frac{8}{2} = 4\\)\nOdds (English prefer Coffee) = \\(\\frac{1}{9} ≈ 0.111\\)\nOdds Ratio of preferring coffee = \\(\\frac{4}{0.111} ≈ 36\\)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#interpreting-the-odds-ratio",
    "href": "Lecture_Folder/Week9a.html#interpreting-the-odds-ratio",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Interpreting the Odds Ratio",
    "text": "Interpreting the Odds Ratio\n\nOR = 1 → No association (odds are equal)\nOR &gt; 1 → Group 1 has higher odds of the event\nOR &lt; 1 → Group 1 has lower odds of the event\n\nIn this case, Americans are 36 times more likely to prefer coffee compared to English — a strong association."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#visualizing-odds-and-log-odds-ratio",
    "href": "Lecture_Folder/Week9a.html#visualizing-odds-and-log-odds-ratio",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Visualizing Odds and Log Odds Ratio",
    "text": "Visualizing Odds and Log Odds Ratio\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Data setup\nodds_data &lt;- data.frame(\n  Nationality = c(\"American\", \"English\"),\n  Coffee = c(8, 1),\n  Tea = c(2, 9)\n)\n\n# Compute odds and log(odds)\nodds_data &lt;- odds_data |&gt;\n  mutate(\n    Odds = Coffee / Tea,\n    LogOdds = log(Odds)\n  )\n\n# Long format for bar plot\nodds_long &lt;- odds_data |&gt;\n  select(Nationality, Odds, LogOdds) |&gt;\n  tidyr::pivot_longer(cols = c(Odds, LogOdds), names_to = \"Metric\", values_to = \"Value\")\n\n# Bar plot for odds and log(odds)\nggplot(odds_long, aes(x = Nationality, y = Value, fill = Nationality)) +\n  geom_col(width = 0.6, show.legend = FALSE) +\n  facet_wrap(~Metric, scales = \"free_y\") +\n  labs(title = \"Comparison of Odds and Log(Odds)\",\n       y = \"Value\", x = \"Nationality\") +\n  theme_minimal(base_size = 14)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#visualizing-odds-and-log-odds-ratio-1",
    "href": "Lecture_Folder/Week9a.html#visualizing-odds-and-log-odds-ratio-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Visualizing Odds and Log Odds Ratio",
    "text": "Visualizing Odds and Log Odds Ratio\n\n\n\n\n\nOdds and Log(Odds Ratio) for Coffee Preference by Nationality"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-a-confusion-matrix",
    "href": "Lecture_Folder/Week9a.html#what-is-a-confusion-matrix",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What Is a Confusion Matrix?",
    "text": "What Is a Confusion Matrix?\n\nA confusion matrix summarizes the outcomes of a classification task.\nIt compares predicted labels to actual (true) labels.\nHelps identify where the model is getting things right or wrong.\nExample for binary classification:"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#confusion-matrix-layout-binary",
    "href": "Lecture_Folder/Week9a.html#confusion-matrix-layout-binary",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Confusion Matrix Layout (Binary)",
    "text": "Confusion Matrix Layout (Binary)\n\n\n\n\n\n\n\n\n\nPredicted: Positive\nPredicted: Negative\n\n\n\n\nActual: Positive\nTrue Positive (TP)\nFalse Negative (FN)\n\n\nActual: Negative\nFalse Positive (FP)\nTrue Negative (TN)\n\n\n\n\n\n\nTP: Correctly predicted positive case\nTN: Correctly predicted negative case\nFP: Incorrectly predicted positive (Type I error)\nFN: Incorrectly predicted negative (Type II error)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#confusion-matrix-contingency-table",
    "href": "Lecture_Folder/Week9a.html#confusion-matrix-contingency-table",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Confusion Matrix = Contingency Table",
    "text": "Confusion Matrix = Contingency Table\n\nA confusion matrix is a special case of a contingency table:\n\nPredicted class ↔︎ Variable 1\nTrue class ↔︎ Variable 2\n\nEntries are counts of observations in each combination of categories.\nIt is just a labeled 2×2 (or K×K) contingency table."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#key-metrics",
    "href": "Lecture_Folder/Week9a.html#key-metrics",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Key Metrics",
    "text": "Key Metrics\n\nAccuracy\n\\[ \\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN} \\]\n\n\nPrecision (Positive Predictive Value)\n\\[\n\\text{Precision} = \\frac{TP}{TP + FP}\n\\]\n\n\nRecall (Sensitivity, True Positive Rate)\n\\[\n\\text{Recall} = \\frac{TP}{TP + FN}\n\\]\n\n\nF1 Score\n\\[\n\\text{F1} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n\\]"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#an-example-confusion-matrix",
    "href": "Lecture_Folder/Week9a.html#an-example-confusion-matrix",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "An example confusion matrix",
    "text": "An example confusion matrix\n\n\n\n\nPredicted Positive\nPredicted Negative\n\n\n\n\nActual Positive\nTP = 50\nFN = 10\n\n\nActual Negative\nFP = 5\nTN = 35"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#calculating-the-confusion-matrix-metrics",
    "href": "Lecture_Folder/Week9a.html#calculating-the-confusion-matrix-metrics",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Calculating the confusion matrix metrics",
    "text": "Calculating the confusion matrix metrics\n\nTP &lt;- 50; FN &lt;- 10; FP &lt;- 5; TN &lt;- 35\n\naccuracy &lt;- (TP + TN) / (TP + TN + FP + FN)\nprecision &lt;- TP / (TP + FP)\nrecall &lt;- TP / (TP + FN)\nf1 &lt;- 2 * precision * recall / (precision + recall)\n\nc(Accuracy = accuracy, Precision = precision, Recall = recall, F1 = f1)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#calculating-the-confusion-matrix-metrics-1",
    "href": "Lecture_Folder/Week9a.html#calculating-the-confusion-matrix-metrics-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Calculating the confusion matrix metrics",
    "text": "Calculating the confusion matrix metrics\n\n\n Accuracy Precision    Recall        F1 \n0.8500000 0.9090909 0.8333333 0.8695652"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#visualizing-the-confusion-matrix-in-r",
    "href": "Lecture_Folder/Week9a.html#visualizing-the-confusion-matrix-in-r",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Visualizing the Confusion Matrix in R",
    "text": "Visualizing the Confusion Matrix in R\n\n# Create confusion matrix\nconf_mat &lt;- matrix(c(50, 10, 5, 35), nrow = 2,\n                   dimnames = list(\"Actual\" = c(\"Positive\", \"Negative\"),\n                                   \"Predicted\" = c(\"Positive\", \"Negative\")))\n\nconf_mat\n\n          Predicted\nActual     Positive Negative\n  Positive       50        5\n  Negative       10       35"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#applying-statistical-tests-to-a-confusion-matrix",
    "href": "Lecture_Folder/Week9a.html#applying-statistical-tests-to-a-confusion-matrix",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Applying Statistical Tests to a Confusion Matrix",
    "text": "Applying Statistical Tests to a Confusion Matrix\n\nYou can apply a Chi-square test of independence to a confusion matrix:\n\nTests if predicted and actual labels are statistically independent.\n\nFor small sample sizes or sparse data, use Fisher’s Exact Test.\n\n\nconf_matrix &lt;- matrix(c(50, 10, 5, 35), nrow = 2)\ndimnames(conf_matrix) &lt;- list(\n  \"Actual\" = c(\"Positive\", \"Negative\"),\n  \"Predicted\" = c(\"Positive\", \"Negative\")\n)\n\nchisq.test(conf_matrix)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  conf_matrix\nX-squared = 45.833, df = 1, p-value = 1.288e-11"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#on-your-own-1",
    "href": "Lecture_Folder/Week9a.html#on-your-own-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "On your own",
    "text": "On your own\n\ncalculate the odds ratios for this confusion matrix\ncan you see how odds ratios can be used to evaluate fit?\nParticularly in the case of training vs. test data sets?"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#analyzing-categorical-variables",
    "href": "Lecture_Folder/Week9a.html#analyzing-categorical-variables",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Analyzing categorical variables",
    "text": "Analyzing categorical variables\n\nHow do we test frequencies of a categorical variable against what we expect?\nHow do we test for correlation among two or more categorical variables?\nHow do we measure the effect size of the correlation of two or more categorical variables?\nThese each involve contingency tables and the \\(\\chi^2\\) distribution"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#uses-of-the-chi2-distribution",
    "href": "Lecture_Folder/Week9a.html#uses-of-the-chi2-distribution",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Uses of the \\(\\chi^2\\) distribution",
    "text": "Uses of the \\(\\chi^2\\) distribution\n\nGoodness-of-fit tests: Does observed data match expected proportions?\nTest of independence: Are two categorical variables related?\nTest of homogeneity: Do different groups have the same distribution?"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-a-chi2-goodness-of-fit-test",
    "href": "Lecture_Folder/Week9a.html#what-is-a-chi2-goodness-of-fit-test",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What is a \\(\\chi^2\\) Goodness-of-Fit Test?",
    "text": "What is a \\(\\chi^2\\) Goodness-of-Fit Test?\n\nA Chi-square Goodness-of-Fit Test checks whether observed frequencies differ from expected frequencies.\nUsed when:\n\nYou have one categorical variable.\nYou want to test whether it fits a specified distribution."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-test-statistic",
    "href": "Lecture_Folder/Week9a.html#chi2-test-statistic",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Test Statistic",
    "text": "\\(\\chi^2\\) Test Statistic\nThe test statistic is:\n\\[\n\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n\\]\nWhere:\n\\(O_i\\) = Observed frequency\n\\(E_i\\) = Expected frequency\nDegrees of freedom:\n\\[\ndf = k - 1\n\\]\nwhere ( k ) = number of categories"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-by-hand-in-r",
    "href": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-by-hand-in-r",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Goodness of Fit by hand in R",
    "text": "\\(\\chi^2\\) Goodness of Fit by hand in R\n\n# Observed data\nobserved &lt;- c(Dominant = 72, Recessive = 28)\n\n# Expected proportions\nexpected_probs &lt;- c(0.75, 0.25)\n\n# Expected counts\nexpected &lt;- sum(observed) * expected_probs\n\n# Chi-square test manually\nchisq_stat &lt;- sum((observed - expected)^2 / expected)\nchisq_stat  # Output: Chi-square statistic\n\n# Degrees of freedom\ndf &lt;- length(observed) - 1\n\n# Critical value at alpha = 0.05\ncritical_val &lt;- qchisq(0.95, df)\ncritical_val\n\n# P-value\np_val &lt;- pchisq(chisq_stat, df, lower.tail = FALSE)\np_val\n\n# Alternatively, use chisq.test()\nchisq.test(x = observed, p = expected_probs)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-by-hand-in-r-1",
    "href": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-by-hand-in-r-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Goodness of Fit by hand in R",
    "text": "\\(\\chi^2\\) Goodness of Fit by hand in R\n\n\n[1] 0.48\n\n\n[1] 3.841459\n\n\n[1] 0.4884223\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  observed\nX-squared = 0.48, df = 1, p-value = 0.4884"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-parametric-test",
    "href": "Lecture_Folder/Week9a.html#chi2-parametric-test",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Parametric Test",
    "text": "\\(\\chi^2\\) Parametric Test\n\nrolling a six-sided die 60 times\n\n\nobserved &lt;- c(8, 9, 10, 12, 11, 10)\n\nexpected_probs &lt;- rep(1/6, 6)\n\nchisq.test(x = observed, p = expected_probs)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-parametric-test-1",
    "href": "Lecture_Folder/Week9a.html#chi2-parametric-test-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) Parametric Test",
    "text": "\\(\\chi^2\\) Parametric Test\n\nrolling a six-sided die 60 times\n\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  observed\nX-squared = 1, df = 5, p-value = 0.9626"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-test-using-resampling",
    "href": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-test-using-resampling",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) goodness of fit test using resampling",
    "text": "\\(\\chi^2\\) goodness of fit test using resampling\n\nset.seed(123)  # For reproducibility\n\n# Observed data\nobserved &lt;- c(Dominant = 72, Recessive = 28)\nn &lt;- sum(observed)\n\n# Expected probabilities\nexpected_probs &lt;- c(0.75, 0.25)\n\n# Number of simulations\nn_sim &lt;- 10000\n\n# Simulate chi-square statistics under the null\nsim_chisq &lt;- replicate(n_sim, {\n  simulated &lt;- rmultinom(1, size = n, prob = expected_probs)\n  expected &lt;- n * expected_probs\n  sum((simulated - expected)^2 / expected)\n})\n\n# Observed chi-square statistic\nobs_chisq &lt;- sum((observed - n * expected_probs)^2 / (n * expected_probs))\n\n# Empirical p-value\np_value &lt;- mean(sim_chisq &gt;= obs_chisq)\n\n# Output results\ncat(\"Observed Chi-square:\", obs_chisq, \"\\n\")\ncat(\"Empirical P-value:\", p_value, \"\\n\")"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-test-using-resampling-1",
    "href": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-test-using-resampling-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) goodness of fit test using resampling",
    "text": "\\(\\chi^2\\) goodness of fit test using resampling\n\n\nObserved Chi-square: 0.48 \n\n\nEmpirical P-value: 0.5615"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-null-distribution",
    "href": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-null-distribution",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) goodness of fit null distribution",
    "text": "\\(\\chi^2\\) goodness of fit null distribution\n\n#|eval: false\n#|echo: true\n\nhist(sim_chisq, breaks = 50, main = \"Resampling Null Distribution\",\n     xlab = \"Chi-square statistic\", col = \"lightblue\", border = \"white\")\nabline(v = obs_chisq, col = \"red\", lwd = 2)\nlegend(\"topright\", legend = \"Observed\", col = \"red\", lwd = 2)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#what-is-a-chi2-test-of-association",
    "href": "Lecture_Folder/Week9a.html#what-is-a-chi2-test-of-association",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "What is a \\(\\chi^2\\) Test of Association?",
    "text": "What is a \\(\\chi^2\\) Test of Association?\n\nA statistical test to determine whether two categorical variables are associated (not independent).\nNull hypothesis (H₀): The two variables are independent.\nAlternative hypothesis (H₁): There is an association between the variables."
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#performing-a-chi2-test-of-association-in-r",
    "href": "Lecture_Folder/Week9a.html#performing-a-chi2-test-of-association-in-r",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Performing a \\(\\chi^2\\) test of association in R",
    "text": "Performing a \\(\\chi^2\\) test of association in R\n\n# Create contingency table\nstudy_table &lt;- matrix(c(30, 20, 10, 40),\n                      nrow = 2,\n                      byrow = TRUE)\n\n# Add row and column names\nrownames(study_table) &lt;- c(\"Undergraduate\", \"Graduate\")\ncolnames(study_table) &lt;- c(\"Morning\", \"Evening\")\n\n# View the table\nstudy_table\n\n# Perform Chi-square test of independence\nchisq.test(study_table)"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#performing-a-chi2-test-of-association-in-r-1",
    "href": "Lecture_Folder/Week9a.html#performing-a-chi2-test-of-association-in-r-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "Performing a \\(\\chi^2\\) test of association in R",
    "text": "Performing a \\(\\chi^2\\) test of association in R\n\n\n              Morning Evening\nUndergraduate      30      20\nGraduate           10      40\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  study_table\nX-squared = 15.042, df = 1, p-value = 0.0001052"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html",
    "href": "Lecture_Folder/Week9b.html",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tibble)"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#this-week",
    "href": "Lecture_Folder/Week9b.html#this-week",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nChi-square tests of association and goodness of fit\nConnections to confusion matrices\nBasics of statistical (classical) machine learning\nToday - brief presentation to the class of your dataset\nNext week - finish statistical (classical) machine learning including decision trees and random forests"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#what-is-machine-learning",
    "href": "Lecture_Folder/Week9b.html#what-is-machine-learning",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "What is Machine Learning?",
    "text": "What is Machine Learning?\n\nMachine learning is a subset of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed for every task.\nTwo main paradigms:\n\nStatistical (classical) Machine Learning\nDeep Learning"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#statistical-machine-learning",
    "href": "Lecture_Folder/Week9b.html#statistical-machine-learning",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Statistical Machine Learning",
    "text": "Statistical Machine Learning\n\nTraditional approach using statistical methods and algorithms that require manual feature engineering.\nKey characteristics:\n\nExplicit feature extraction\nRelatively simple model architectures\nInterpretable results\nWorks well with smaller datasets"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#deep-learning",
    "href": "Lecture_Folder/Week9b.html#deep-learning",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Deep Learning",
    "text": "Deep Learning\n\nModern approach using artificial neural networks with multiple layers to automatically learn hierarchical representations.\nKey characteristics:\n\nAutomatic feature learning\nComplex, multi-layered architectures\nOften requires large datasets\nHigh computational requirements"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#common-classical-ml-algorithms",
    "href": "Lecture_Folder/Week9b.html#common-classical-ml-algorithms",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Common Classical ML Algorithms",
    "text": "Common Classical ML Algorithms\n\nSupervised Learning:\n\nLinear/Logistic Regression\nDecision Trees\nRandom Forest\nSupport Vector Machines (SVM)\nNaive Bayes\nK-Nearest Neighbors (KNN)\n\nUnsupervised Learning:\n\nK-Means Clustering\nHierarchical Clustering\nPrincipal Component Analysis (PCA)"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#common-deep-learning-architectures",
    "href": "Lecture_Folder/Week9b.html#common-deep-learning-architectures",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Common Deep Learning Architectures",
    "text": "Common Deep Learning Architectures\n\nNeural Networks:\n\nFeedforward Neural Networks\nConvolutional Neural Networks (CNNs)\nRecurrent Neural Networks (RNNs)\nTransformer Networks\n\nApplications:\n\nComputer Vision\nNatural Language Processing\nSpeech Recognition\nGenerative Models"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#feature-engineering",
    "href": "Lecture_Folder/Week9b.html#feature-engineering",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Feature Engineering",
    "text": "Feature Engineering\n\n\n\nClassical ML\n\nManual feature extraction\nDomain expertise required\nTime-intensive process\nFeatures explicitly defined\n\n\n\n\nDeep Learning\n\nAutomatic feature learning\nNetworks learn features during training\nHierarchical feature representation\nNo manual feature engineering needed"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#model-complexity",
    "href": "Lecture_Folder/Week9b.html#model-complexity",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Model Complexity",
    "text": "Model Complexity\n\n\n\nClassical ML\n\nSimpler architectures\nLinear models, tree-based methods\nLogistic Regression, Random Forest, SVM\nFewer parameters (hundreds to thousands)\nEasier to understand and debug\n\n\n\n\nDeep Learning\n\nComplex architectures\nMultiple hidden layers\nCNNs, RNNs, Transformers\nMillions to billions of parameters\n“Black box” nature"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#data-requirements",
    "href": "Lecture_Folder/Week9b.html#data-requirements",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Data Requirements",
    "text": "Data Requirements\n\n\n\nClassical ML\n\nWorks with smaller datasets\nHundreds to thousands of samples\nCan handle tabular data effectively\nLess prone to overfitting with small data\nGood performance with limited data\n\n\n\n\nDeep Learning\n\nRequires large datasets\nThousands to millions of samples\nNeeds big data to avoid overfitting\nData-hungry algorithms\nPerformance improves with more data"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#when-to-use-statistical-ml",
    "href": "Lecture_Folder/Week9b.html#when-to-use-statistical-ml",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "When to Use Statistical ML",
    "text": "When to Use Statistical ML\n\nSmall to medium datasets (&lt; 10,000 samples)\nStructured/tabular data\nNeed for interpretability\nLimited computational resources\nQuick prototyping\nRegulatory requirements for explainability"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#two-general-goals-of-statistical-ml",
    "href": "Lecture_Folder/Week9b.html#two-general-goals-of-statistical-ml",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Two General Goals of Statistical ML",
    "text": "Two General Goals of Statistical ML\n\nPrediction\n\ngenerally using linear models such as regression\noutcome is a prediction of the response variable value and associated error\n\nClassification\n\nuse logistic regression, random forest, Bayes classifiers, etc…\noutcome is a statement about what category each observation belongs"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#the-learning-process",
    "href": "Lecture_Folder/Week9b.html#the-learning-process",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "The Learning Process",
    "text": "The Learning Process\n\nCollect Data: Features (X) and target (Y)\nSplit Data:\n\nTraining set\nValidation set\n\nSelect Model: Choose algorithm, e.g.\n\nlinear regression\nlogistic regression\ndecision trees\n\nTrain Model: Fit model to training data\nEvaluate: Use independent test data to assess performance\nDeploy: Use model to make future predictions"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#overfitting-vs.-underfitting",
    "href": "Lecture_Folder/Week9b.html#overfitting-vs.-underfitting",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Overfitting vs. Underfitting",
    "text": "Overfitting vs. Underfitting\n\nUnderfitting: Model too simple → high bias\nOverfitting: Model too complex → high variance\nUse cross-validation to estimate test error and tune model complexity\nUse independent test data to estimate generalizability of model"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#model-accuracy-metrics",
    "href": "Lecture_Folder/Week9b.html#model-accuracy-metrics",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Model Accuracy Metrics",
    "text": "Model Accuracy Metrics\n\nPrediction:\n\nMean Squared Error (MSE)\nR²\n\nClassification:\n\nAccuracy\nPrecision\nRecall\nAUC\n\nSplit data and thus error into:\n\nTraining error: fit to training set\nValidation error: fit to the validation set\nTest error: error generalized to new data"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#simulated-binary-data",
    "href": "Lecture_Folder/Week9b.html#simulated-binary-data",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Simulated binary data",
    "text": "Simulated binary data\n\nmetal_exposure &lt;- runif(200, -2, 2)\np &lt;- 1 / (1 + exp(-(-0.5 + 2 * metal_exposure)))\ncancer_diagnosis &lt;- rbinom(200, 1, prob = p)\nlogit_model &lt;- glm(cancer_diagnosis ~ metal_exposure, family = binomial)\nsummary(logit_model)"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#simulated-binary-data-1",
    "href": "Lecture_Folder/Week9b.html#simulated-binary-data-1",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Simulated binary data",
    "text": "Simulated binary data\n\n\n\nCall:\nglm(formula = cancer_diagnosis ~ metal_exposure, family = binomial)\n\nCoefficients:\n               Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.9842     0.2445  -4.026 5.68e-05 ***\nmetal_exposure   2.3420     0.3144   7.450 9.34e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 271.45  on 199  degrees of freedom\nResidual deviance: 142.19  on 198  degrees of freedom\nAIC: 146.19\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#plotting-the-logistic-regression-curve",
    "href": "Lecture_Folder/Week9b.html#plotting-the-logistic-regression-curve",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Plotting the Logistic Regression Curve",
    "text": "Plotting the Logistic Regression Curve\n\ncancer_df &lt;- data.frame(metal_exposure, cancer_diagnosis)\ncancer_df$prob &lt;- predict(logit_model, type = \"response\")\n\nggplot(cancer_df, aes(metal_exposure, cancer_diagnosis)) +\n  geom_point(alpha = 0.4) +\n  geom_line(aes(y = prob), color = \"red\") +\n  labs(title = \"Logistic Regression Fit\", \n       x= \"Heavy Metal Exposure\", \n       y = \"Probability of Cancer\") +\n  theme_minimal()"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#plotting-logistic-regression-curve",
    "href": "Lecture_Folder/Week9b.html#plotting-logistic-regression-curve",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Plotting Logistic Regression Curve",
    "text": "Plotting Logistic Regression Curve"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#making-predictions-using-the-iris-dataset",
    "href": "Lecture_Folder/Week9b.html#making-predictions-using-the-iris-dataset",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Making predictions using the Iris dataset",
    "text": "Making predictions using the Iris dataset\n\nwe’re using the tidymodels package for splitting the data\nHere we’re just creating binary variable for whether the plant is or isn’t a setosa\n\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n\n\n✔ broom        1.0.8     ✔ rsample      1.3.0\n✔ dials        1.4.0     ✔ tune         1.3.0\n✔ infer        1.0.8     ✔ workflows    1.2.0\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.3.1     ✔ yardstick    1.3.2\n✔ recipes      1.3.0     \n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\niris &lt;- iris %&gt;% \n  mutate(setosa = as.integer(Species == \"setosa\"))"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#split-data-into-training-and-validation-sets",
    "href": "Lecture_Folder/Week9b.html#split-data-into-training-and-validation-sets",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Split data into training and validation sets",
    "text": "Split data into training and validation sets\n\nThis function allows you to split the data into test vs. training data objects\nNote how we make the split data object which contains both groups of data\nThen we pull those out into two different data sets\n\n\nsplit &lt;- initial_split(iris, \n                       prop = .80, \n                       strata = setosa) \niris_train &lt;- training(split)\niris_test &lt;- testing(split)\n\n\nTake a look at those new data objects in R Studio. How many observations are in each, and how many observations are there in the original data set?"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#visualize-sepal-length-to-prob-of-setosa",
    "href": "Lecture_Folder/Week9b.html#visualize-sepal-length-to-prob-of-setosa",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Visualize sepal length to prob of setosa",
    "text": "Visualize sepal length to prob of setosa\n\nNote that this is another way to visualize the logit function\nDoes it look like sepal length can predict whether a plant is a setosa?\n\n\nggplot(iris_train, aes(x = Sepal.Length,\n                       y = setosa)) +\n  geom_jitter(height = .05, \n              alpha = .5) +\n  geom_smooth(method = \"glm\",\n              method.args = list(family = \"binomial\"),\n              se = TRUE) +\n  theme_minimal()"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#visualize-sepal-length-to-prob-of-setosa-1",
    "href": "Lecture_Folder/Week9b.html#visualize-sepal-length-to-prob-of-setosa-1",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Visualize sepal length to prob of setosa",
    "text": "Visualize sepal length to prob of setosa\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#build-a-model-with-training-data",
    "href": "Lecture_Folder/Week9b.html#build-a-model-with-training-data",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Build a model with training data",
    "text": "Build a model with training data\n\ntraining_model &lt;- glm(setosa ~ Sepal.Length,\n             data = iris_train,\n             family = \"binomial\")\nsummary(training_model)"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#build-a-model-with-training-data-1",
    "href": "Lecture_Folder/Week9b.html#build-a-model-with-training-data-1",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Build a model with training data",
    "text": "Build a model with training data\n\n\n\nCall:\nglm(formula = setosa ~ Sepal.Length, family = \"binomial\", data = iris_train)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    28.432      5.587   5.089 3.60e-07 ***\nSepal.Length   -5.273      1.031  -5.116 3.11e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 152.763  on 119  degrees of freedom\nResidual deviance:  54.665  on 118  degrees of freedom\nAIC: 58.665\n\nNumber of Fisher Scoring iterations: 7"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#evaluate-the-model",
    "href": "Lecture_Folder/Week9b.html#evaluate-the-model",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\nFirst we create predictions of the validation data from the training model\nNote that the output is a probability, but we just turn it into a binary classification\n\n\niris_test &lt;- iris_test %&gt;% \n  mutate(setosa_prob = predict(training_model,\n                               iris_test,\n                               type = \"response\"),\n         setosa_pred = ifelse(setosa_prob &gt; .5, 1, 0))\n\n\nTake a look at the iris_test data object\nYou should now see the setosa_pred variable"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#evaluate-the-model-1",
    "href": "Lecture_Folder/Week9b.html#evaluate-the-model-1",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\nNow let’s create a confusion matrix to see how well the trained model predicted on the validation data set\n\n\nsetosa_conf_matrix &lt;- table(iris_test$setosa,\n           iris_test$setosa_pred)\n\nas.data.frame.matrix(setosa_conf_matrix) %&gt;%\n  gt(rownames_to_stub = TRUE) %&gt;%\n  tab_header(title = \"Setosa Confusion Matrix\") %&gt;%\n  tab_stubhead(label = \"Actual\") %&gt;%\n  tab_spanner(label = \"Predicted\", columns = everything())"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#evaluate-the-model-2",
    "href": "Lecture_Folder/Week9b.html#evaluate-the-model-2",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetosa Confusion Matrix\n\n\nActual\n\nPredicted\n\n\n\n0\n1\n\n\n\n\n0\n19\n1\n\n\n1\n1\n9"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#what-is-a-confusion-matrix",
    "href": "Lecture_Folder/Week9b.html#what-is-a-confusion-matrix",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "What Is a Confusion Matrix?",
    "text": "What Is a Confusion Matrix?\n\nA confusion matrix summarizes the outcomes of a classification task.\nIt compares predicted labels to actual (true) labels.\nHelps identify where the model is getting things right or wrong.\nExample for binary classification:"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#confusion-matrix-layout-binary",
    "href": "Lecture_Folder/Week9b.html#confusion-matrix-layout-binary",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Confusion Matrix Layout (Binary)",
    "text": "Confusion Matrix Layout (Binary)\n\n\n\n\n\n\n\n\n\nPredicted: Positive\nPredicted: Negative\n\n\n\n\nActual: Positive\nTrue Positive (TP)\nFalse Negative (FN)\n\n\nActual: Negative\nFalse Positive (FP)\nTrue Negative (TN)\n\n\n\n\n\n\nTP: Correctly predicted positive case\nTN: Correctly predicted negative case\nFP: Incorrectly predicted positive (Type I error)\nFN: Incorrectly predicted negative (Type II error)"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#key-metrics-for-classification",
    "href": "Lecture_Folder/Week9b.html#key-metrics-for-classification",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Key Metrics for Classification",
    "text": "Key Metrics for Classification\n\\[\n\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n\\]\n\n\\[\n\\text{Precision} = \\frac{TP}{TP + FP}\n\\]\n\n\\[\n\\text{Sensitivity} = \\frac{TP}{TP + FN}\n\\]\n\n\\[\n\\text{Specificity} = \\frac{TN}{TN + FP}\n\\]\n\n\\[\n\\text{F1_score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n\\]"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#key-metrics-for-classification-1",
    "href": "Lecture_Folder/Week9b.html#key-metrics-for-classification-1",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Key Metrics for Classification",
    "text": "Key Metrics for Classification\n\n\n\n\n\n\nWarning\n\n\n\n\nThere is no single best evaluation metric for model fit for prediction\nHow important is it to identify true positives and what are the costs of false positives?\nHow important is it to identify true negatives, and what are the costs of false negatives?\nBoth of these need to be determined based upon the use of the classification\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDifferent types of evaluation are used for prediction (e.g. regression) models"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#evaluate-the-model-3",
    "href": "Lecture_Folder/Week9b.html#evaluate-the-model-3",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\nNow let’s calculate various metrics for the setosa analysis\n\n\ntn &lt;- setosa_conf_matrix[1,1]  # True Negative\nfp &lt;- setosa_conf_matrix[1,2]  # False Positive  \nfn &lt;- setosa_conf_matrix[2,1]  # False Negative\ntp &lt;- setosa_conf_matrix[2,2]  # True Positive\n\n# Calculate metrics\nmetrics_df &lt;- data.frame(\n  Metric = c(\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1-Score\"),\n  Value = c(\n    (tp + tn) / (tp + tn + fp + fn),           # Accuracy\n    tp / (tp + fp),                            # Precision\n    tp / (tp + fn),                            # Recall/Sensitivity\n    tn / (tn + fp),                            # Specificity\n    2 * (tp / (tp + fp)) * (tp / (tp + fn)) / \n    ((tp / (tp + fp)) + (tp / (tp + fn)))      # F1-Score\n  )\n)\n\n# Create simple gt table\nmetrics_df %&gt;%\n  gt() %&gt;%\n  tab_header(title = \"Classification Evaluation Metrics\") %&gt;%\n  fmt_number(columns = Value, decimals = 3)"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#evaluate-the-model-4",
    "href": "Lecture_Folder/Week9b.html#evaluate-the-model-4",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Evaluate the model",
    "text": "Evaluate the model\n\n\n\n\n\n\n\n\nClassification Evaluation Metrics\n\n\nMetric\nValue\n\n\n\n\nAccuracy\n0.933\n\n\nPrecision\n0.900\n\n\nRecall\n0.900\n\n\nSpecificity\n0.950\n\n\nF1-Score\n0.900"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#what-is-cross-validation",
    "href": "Lecture_Folder/Week9b.html#what-is-cross-validation",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "What is Cross-Validation?",
    "text": "What is Cross-Validation?\nCross-validation is a statistical technique for assessing how well a model generalizes to new data by repeatedly splitting your dataset into training and testing portions.\nThe Process:\n\nSplit your data into k groups (folds)\nTrain your model on k-1 folds\n\nTest on the remaining fold\nRepeat this process k times\nAverage the results to get a robust estimate of model performance"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#the-boot-library",
    "href": "Lecture_Folder/Week9b.html#the-boot-library",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "The boot Library",
    "text": "The boot Library\nThe boot library’s main function is cv.glm(), which performs cross-validation for generalized linear models.\n\nlibrary(boot)\n\n# Example with linear regression\nmodel &lt;- glm(mpg ~ wt + hp, data = mtcars)\n\n# Perform 10-fold cross-validation\ncv_result &lt;- cv.glm(mtcars, model, K = 10)\n\nWarning in cv.glm(mtcars, model, K = 10): 'K' has been set to 11.000000\n\n# Extract cross-validation error\ncv_error &lt;- cv_result$delta[1]"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#key-parameters",
    "href": "Lecture_Folder/Week9b.html#key-parameters",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Key Parameters",
    "text": "Key Parameters\nK parameter - Controls the number of folds:\n\nK = nrow(data) → Leave-one-out cross-validation (LOOCV)\nK = 10 → 10-fold CV (common choice)\nK = 5 → 5-fold CV\n\nCustom cost functions - Specify different loss functions:\n\n# Custom cost function (mean absolute error)\nmae_cost &lt;- function(y, yhat) mean(abs(y - yhat))\n\ncv_result &lt;- cv.glm(mtcars, model, K = 10, cost = mae_cost)\n\nWarning in cv.glm(mtcars, model, K = 10, cost = mae_cost): 'K' has been set to\n11.000000"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#practical-example-model-comparison",
    "href": "Lecture_Folder/Week9b.html#practical-example-model-comparison",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Practical Example: Model Comparison",
    "text": "Practical Example: Model Comparison\n\nlibrary(boot)\ndata(mtcars)\n\n# Fit different models\nmodel1 &lt;- glm(mpg ~ wt, data = mtcars)\nmodel2 &lt;- glm(mpg ~ wt + hp, data = mtcars)\nmodel3 &lt;- glm(mpg ~ wt + hp + disp, data = mtcars)\n\n# Compare models using 10-fold CV\ncv1 &lt;- cv.glm(mtcars, model1, K = 10)\n\nWarning in cv.glm(mtcars, model1, K = 10): 'K' has been set to 11.000000\n\ncv2 &lt;- cv.glm(mtcars, model2, K = 10)\n\nWarning in cv.glm(mtcars, model2, K = 10): 'K' has been set to 11.000000\n\ncv3 &lt;- cv.glm(mtcars, model3, K = 10)\n\nWarning in cv.glm(mtcars, model3, K = 10): 'K' has been set to 11.000000\n\n# Compare cross-validation errors\ncv_errors &lt;- c(cv1$delta[1], cv2$delta[1], cv3$delta[1])\nnames(cv_errors) &lt;- c(\"Model 1\", \"Model 2\", \"Model 3\")\nprint(cv_errors)\n\n  Model 1   Model 2   Model 3 \n10.458141  7.499546  8.309597"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#understanding-the-output",
    "href": "Lecture_Folder/Week9b.html#understanding-the-output",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Understanding the Output",
    "text": "Understanding the Output\nThe cv.glm() function returns:\n\ndelta[1]: Raw cross-validation estimate\ndelta[2]: Bias-corrected cross-validation estimate\n\nK: Number of folds used\n\nInterpretation: Lower cross-validation error = better expected performance on new data"
  },
  {
    "objectID": "Lecture_Folder/Week9b.html#advantages-of-the-boot-library",
    "href": "Lecture_Folder/Week9b.html#advantages-of-the-boot-library",
    "title": "Week 9b - Statistics for Bioengineering",
    "section": "Advantages of the boot Library",
    "text": "Advantages of the boot Library\n✓ Automatically handles data splitting\n✓ Ensures each observation appears in exactly one test fold per iteration\n✓ Provides both biased and bias-corrected estimates\n✓ Well-suited for GLMs\n✓ Integrates seamlessly with R’s modeling framework"
  },
  {
    "objectID": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-null-distribution-1",
    "href": "Lecture_Folder/Week9a.html#chi2-goodness-of-fit-null-distribution-1",
    "title": "Week 9a - Statistics for Bioengineering",
    "section": "\\(\\chi^2\\) goodness of fit null distribution",
    "text": "\\(\\chi^2\\) goodness of fit null distribution\n\n#|eval: true\n#|echo: false\n\nhist(sim_chisq, breaks = 50, main = \"Resampling Null Distribution\",\n     xlab = \"Chi-square statistic\", col = \"lightblue\", border = \"white\")\nabline(v = obs_chisq, col = \"red\", lwd = 2)\nlegend(\"topright\", legend = \"Observed\", col = \"red\", lwd = 2)"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html",
    "href": "Lecture_Folder/Week10a.html",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(boot)"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#this-week",
    "href": "Lecture_Folder/Week10a.html#this-week",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "This week",
    "text": "This week\n\nThe problem of overfitting\nLOESS (Locally Estimated Scatterplot Smoothing)\nCross validation using the boot package\nDecision trees and random forests\nSupport Vector Machines (if there’s time)"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#building-models-for-prediction",
    "href": "Lecture_Folder/Week10a.html#building-models-for-prediction",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Building Models for Prediction",
    "text": "Building Models for Prediction\n\nWe build a model using the sample data with the goal of applying it to new data from the population to make predictions about response variables of interest.\nStatistical and machine learning models are built to fit the data on which they’re trained as closely as possible within their particular structures."
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#optimization-examples",
    "href": "Lecture_Folder/Week10a.html#optimization-examples",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Optimization Examples",
    "text": "Optimization Examples\n\nLinear regression picks out the line that minimizes the squared residuals (RSE) in the set\nLogistic regression minimizes residual deviance\nClassification models might be optimized to identify as high a proportion of the sample correctly as possible"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#the-overfitting-problem",
    "href": "Lecture_Folder/Week10a.html#the-overfitting-problem",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "The Overfitting Problem",
    "text": "The Overfitting Problem\n\nUnfortunately, models that perform better on their training data are often worse at making predictions from new data.\nOverfitting refers to when a model goes too far out of its way to accommodate the peculiarities of the set used to build it, integrating random noise as if it were meaningful information.\nMore flexible modeling techniques are more susceptible to overfitting."
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#overfitting-vs.-underfitting",
    "href": "Lecture_Folder/Week10a.html#overfitting-vs.-underfitting",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Overfitting vs. Underfitting",
    "text": "Overfitting vs. Underfitting\n\n\n\n\n\n\n\n\nUnderfitting\n\n\n\n\nModel too simple\nHigh bias\nMisses important patterns\nPoor performance everywhere\n\n\n\n\n\n\n\n\n\n\nOverfitting\n\n\n\n\nModel too complex\nHigh variance\n\nMemorizes noise\nGreat on training, poor on testing\n\n\n\n\n\n\n\n\n\n\n\nThe Solution\n\n\n\nMeasuring model performance on training data is unreliable - we need cross-validation."
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#what-is-loess",
    "href": "Lecture_Folder/Week10a.html#what-is-loess",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "What is LOESS?",
    "text": "What is LOESS?\n\nLOESS = LOcally wEighted Scatterplot Smoothing\nAlso known as LOWESS (locally weighted regression)\nNon-parametric regression method\nIt fits local regressions to subsets of the data\nEach local fit is weighted using a kernel function\nOne popular kernel: the tricube weighting function"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#the-big-picture",
    "href": "Lecture_Folder/Week10a.html#the-big-picture",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "The Big Picture",
    "text": "The Big Picture\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear regression assumes a straight line relationship\n\n\nLOESS discovers the underlying pattern without assumptions"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#historical-context",
    "href": "Lecture_Folder/Week10a.html#historical-context",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Historical Context",
    "text": "Historical Context\n\nBuilt on earlier work:\n\nKernel regression methods\nk-nearest neighbor approaches\nLocal polynomial fitting\n\nPart of the “smooth” revolution in statistics"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#how-loess-works-the-intuition",
    "href": "Lecture_Folder/Week10a.html#how-loess-works-the-intuition",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "How LOESS Works: The Intuition",
    "text": "How LOESS Works: The Intuition\n\nFor each point where you want a prediction:\n\n\n\nFind neighbors - Identify nearby data points\nAssign weights - Closer points get higher weights\n\nFit locally - Use weighted regression on neighbors\nMake prediction - Use the local model\nRepeat - Do this for every point"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#visual-intuition",
    "href": "Lecture_Folder/Week10a.html#visual-intuition",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Visual Intuition",
    "text": "Visual Intuition"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#the-tricube-function",
    "href": "Lecture_Folder/Week10a.html#the-tricube-function",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "The Tricube Function",
    "text": "The Tricube Function\nThe tricube weight function is defined as:\n\\[\nw(x) =\n\\begin{cases}\n(1 - |x|^3)^3 & \\text{if } |x| &lt; 1 \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\n\nDefined on the interval \\([-1, 1]\\)\nSmooth and bell-shaped\nWeight goes to 0 smoothly at the boundary"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#tricube-weighting-function",
    "href": "Lecture_Folder/Week10a.html#tricube-weighting-function",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Tricube Weighting Function",
    "text": "Tricube Weighting Function"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#step-1-neighborhood-selection",
    "href": "Lecture_Folder/Week10a.html#step-1-neighborhood-selection",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Step 1: Neighborhood Selection",
    "text": "Step 1: Neighborhood Selection\n\nChoose a bandwidth or span parameter (α)\nTypically ranges from 0.2 to 0.8\nα = 0.5 means use 50% of data points for each local fit\nLarger α → smoother curve\nSmaller α → more flexible, follows data closely"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#step-2-distance-based-weighting",
    "href": "Lecture_Folder/Week10a.html#step-2-distance-based-weighting",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Step 2: Distance-Based Weighting",
    "text": "Step 2: Distance-Based Weighting\n\nPoints closer to target point get higher weights\nPoints farther away get lower weights\nWeight decreases smoothly with distance\nCreates smooth transitions between local fits"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#step-3-local-polynomial-fitting",
    "href": "Lecture_Folder/Week10a.html#step-3-local-polynomial-fitting",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Step 3: Local Polynomial Fitting",
    "text": "Step 3: Local Polynomial Fitting\n\nFit polynomial regression to weighted neighborhood\nUsually degree 1 (linear) or degree 2 (quadratic)\nLinear: good for straight-line segments\nQuadratic: better for curved regions\nHigher degrees rarely used (overfitting risk)"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#when-to-use-loess",
    "href": "Lecture_Folder/Week10a.html#when-to-use-loess",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "When to Use LOESS",
    "text": "When to Use LOESS\n\n\n\n\n\n\nLOESS is Great For:\n\n\n\n\nExploratory data analysis - Understanding relationships\nNon-linear patterns - Complex curves and trends\n\nVisualization - Smooth trend lines\nFlexible modeling - When you don’t know the functional form\n\n\n\n\n\n\n\n\n\nLOESS Limitations:\n\n\n\n\nLarge datasets - Computationally intensive\nExtrapolation - Poor predictions outside data range\nHigh dimensions - Curse of dimensionality\nInference - Limited theoretical framework"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#data-generation",
    "href": "Lecture_Folder/Week10a.html#data-generation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Data Generation",
    "text": "Data Generation\n\nset.seed(1)\nx &lt;- runif(1000, 0, 10)\ny &lt;- 6 - .5 * x + rnorm(1000, sd = 2)\ndf &lt;- data.frame(x, y)\n\nset.seed(1)\ndf_sample &lt;- df |&gt; slice_sample(n = 25)\n\n\n\n\n\n\n\nWhat We’re Creating\n\n\n\n\nPopulation: 1000 points with true relationship y = 6 - 0.5x + noise\nSample: 25 randomly selected points for model fitting"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#population-data-with-true-relationship",
    "href": "Lecture_Folder/Week10a.html#population-data-with-true-relationship",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Population Data with True Relationship",
    "text": "Population Data with True Relationship\n\nggplot(df, aes(x, y)) + \n  geom_point(color = \"lightblue\") + \n  geom_abline(slope = -.5, \n              intercept = 6,\n              color = \"blue\",\n              linewidth = 1) +\n  labs(title = \"Population Data with True Relationship\",\n       subtitle = \"Blue line shows true relationship: y = 6 - 0.5x\")"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#population-data-with-true-relationship-1",
    "href": "Lecture_Folder/Week10a.html#population-data-with-true-relationship-1",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Population Data with True Relationship",
    "text": "Population Data with True Relationship"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#sample-data-with-smooth-fit",
    "href": "Lecture_Folder/Week10a.html#sample-data-with-smooth-fit",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Sample Data with Smooth Fit",
    "text": "Sample Data with Smooth Fit\n\nggplot(df, aes(x, y)) + \n  geom_point(color = \"lightblue\") + \n  geom_abline(slope = -.5, \n              intercept = 6,\n              color = \"blue\",\n              linewidth = 1) +\n  geom_point(data = df_sample,\n             color = \"black\") +\n  geom_smooth(data = df_sample,\n              se = FALSE,\n              color = \"black\") +\n  labs(title = \"Sample Data with LOESS Smooth\",\n       subtitle = \"Black points: sample data, Black curve: LOESS fit\")"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#sample-data-with-linear-fit",
    "href": "Lecture_Folder/Week10a.html#sample-data-with-linear-fit",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Sample Data with Linear Fit",
    "text": "Sample Data with Linear Fit\n\nggplot(df, aes(x, y)) + \n  geom_point(color = \"lightblue\") + \n  geom_abline(slope = -.5, \n              intercept = 6,\n              color = \"blue\",\n              linewidth = 1) +\n  geom_point(data = df_sample,\n             color = \"black\") +\n  geom_smooth(data = df_sample,\n              se = FALSE,\n              method = \"lm\",\n              color = \"black\") +\n  labs(title = \"Sample Data with Linear Fit\",\n       subtitle = \"Black points: sample data, Black line: linear regression\")"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#section",
    "href": "Lecture_Folder/Week10a.html#section",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "",
    "text": "`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\nSample Data with LOESS Smooth\n\n\n\n\n\n\n\nSample Data with Linear Fit"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#model-building",
    "href": "Lecture_Folder/Week10a.html#model-building",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Model Building",
    "text": "Model Building\n\nmodel_linear &lt;- lm(y ~ x, data = df_sample)\nmodel_loess &lt;- loess(y ~ x, data = df_sample)"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#section-1",
    "href": "Lecture_Folder/Week10a.html#section-1",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "",
    "text": "Linear Model Summary\n\nsummary(model_linear)\n\n\nCall:\nlm(formula = y ~ x, data = df_sample)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.5098 -1.1427 -0.1999  1.1595  4.9768 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   6.3284     1.1020   5.743 7.54e-06 ***\nx            -0.5213     0.2062  -2.528   0.0188 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.494 on 23 degrees of freedom\nMultiple R-squared:  0.2175,    Adjusted R-squared:  0.1834 \nF-statistic: 6.391 on 1 and 23 DF,  p-value: 0.01879\n\n\n\nLOESS Model Summary\n\nsummary(model_loess)\n\nCall:\nloess(formula = y ~ x, data = df_sample)\n\nNumber of Observations: 25 \nEquivalent Number of Parameters: 4.78 \nResidual Standard Error: 1.956 \nTrace of smoother matrix: 5.26  (exact)\n\nControl settings:\n  span     :  0.75 \n  degree   :  2 \n  family   :  gaussian\n  surface  :  interpolate     cell = 0.2\n  normalize:  TRUE\n parametric:  FALSE\ndrop.square:  FALSE"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#model-evaluation",
    "href": "Lecture_Folder/Week10a.html#model-evaluation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Model Evaluation",
    "text": "Model Evaluation\n\n# Calculate RSS for both models\n\ndf_resid &lt;- df %&gt;% \n  mutate(linear_resid = df$y - predict(model_linear, df),\n         loess_resid = df$y - predict(model_loess, df)) %&gt;% \n  drop_na()\n\nrss_linear &lt;- sum(df_resid$linear_resid^2)\nrss_loess &lt;- sum(df_resid$loess_resid^2)\n\n\n\nLinear Model RSS: 3814.17 \n\n\nLOESS Model RSS: 6099.69 \n\n\nDifference: -2285.52\n\n\n\n\n\n\n\n\nKey Finding\n\n\n\nThe more flexible LOESS model performs worse on new data despite fitting the sample better - this is overfitting!"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#the-testing-set-approach",
    "href": "Lecture_Folder/Week10a.html#the-testing-set-approach",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "The Testing Set Approach",
    "text": "The Testing Set Approach\n\n\n\n\n\n\n\n\nSimple Solution\n\n\n\nSplit data into training and testing sets\nProcess: 1. Train model on training set 2. Evaluate on testing set 3. Report testing performance\n\n\n\n\n\n\n\n\n\n✅ Benefits\n\n\n\n\nEasy to understand and implement\nComputationally very efficient\nClear separation of training/testing\n\n\n\n\n\n\n\n\n\n\n\n❌ Major Drawbacks\n\n\n\n\nReduced training data - Less data to learn from\nSplit dependency - Results vary based on random split\nHigh variance - Unreliable performance estimates"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#cross-validation-a-better-approach",
    "href": "Lecture_Folder/Week10a.html#cross-validation-a-better-approach",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Cross-Validation: A Better Approach",
    "text": "Cross-Validation: A Better Approach\n\n\n\n\n\n\nThe Cross-Validation Process\n\n\n\n\nSplit data into K folds\nTrain on K-1 folds, test on 1 fold\n\nRepeat K times (each fold gets to be the test set)\nAverage results across all folds\n\n\n\n\n\n\n\n\n\n\n\nKey Benefits\n\n\n\n\nUses all data for both training and testing\nMore reliable performance estimates\nReduces variance in results\n\n\n\n\n\n\n\n\n\n\nCommon Choices\n\n\n\n\nK = 5: Good balance of bias/variance\nK = 10: Most popular choice\nK = n: Leave-one-out (LOOCV)"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#what-is-cross-validation",
    "href": "Lecture_Folder/Week10a.html#what-is-cross-validation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "What is Cross-Validation?",
    "text": "What is Cross-Validation?\nCross-validation is a statistical method used to:\n\nAssess model performance on unseen data\nReduce overfitting by testing generalization\nCompare different models objectively\nEstimate prediction error more reliably\n\nThe core principle: Use part of your data for training, part for testing"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#what-is-cross-validation-1",
    "href": "Lecture_Folder/Week10a.html#what-is-cross-validation-1",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "What is Cross-Validation?",
    "text": "What is Cross-Validation?\nCross-validation is a statistical technique for assessing how well a model generalizes to new data by repeatedly splitting your dataset into training and testing portions.\nThe Process:\n\nSplit your data into k groups (folds)\nTrain your model on k-1 folds\n\nTest on the remaining fold\nRepeat this process k times\nAverage the results to get a robust estimate of model performance"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#key-functions-in-boot-package",
    "href": "Lecture_Folder/Week10a.html#key-functions-in-boot-package",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Key Functions in Boot Package",
    "text": "Key Functions in Boot Package\n\n\n\nFunction\nPurpose\n\n\n\n\ncv.glm()\nCross-validation for GLMs\n\n\nboot()\nBootstrap resampling\n\n\nboot.ci()\nBootstrap confidence intervals\n\n\ncv.glm.object\nCross-validation results object"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#types-of-cross-validation",
    "href": "Lecture_Folder/Week10a.html#types-of-cross-validation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Types of Cross-Validation",
    "text": "Types of Cross-Validation\n\nLeave-One-Out (LOOCV)\nK-Fold Cross-Validation\nStratified Cross-Validation\nTime Series Cross-Validation"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#leave-one-out-cross-validation-loocv",
    "href": "Lecture_Folder/Week10a.html#leave-one-out-cross-validation-loocv",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Leave-One-Out Cross-Validation (LOOCV)",
    "text": "Leave-One-Out Cross-Validation (LOOCV)\nConcept: Use n-1 observations for training, 1 for testing, repeat n times\n\nlibrary(boot)\n# LOOCV with cv.glm\nmodel &lt;- glm(mpg ~ hp + wt, data = mtcars)\nloocv_error &lt;- cv.glm(mtcars, model)\n\n# Extract CV error\nloocv_mse &lt;- loocv_error$delta[1]\nprint(paste(\"LOOCV MSE:\", round(loocv_mse, 3)))\n\n[1] \"LOOCV MSE: 7.703\"\n\n\nAdvantages: Uses maximum data for training Disadvantages: Computationally expensive for large datasets"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#k-fold-cross-validation",
    "href": "Lecture_Folder/Week10a.html#k-fold-cross-validation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "K-Fold Cross-Validation",
    "text": "K-Fold Cross-Validation\nConcept: Divide data into K folds, use K-1 for training, 1 for testing\n\n# 10-fold cross-validation\nmodel &lt;- glm(mpg ~ hp + wt + disp, data = mtcars)\nk10_error &lt;- cv.glm(mtcars, model, K = 10)\n\nWarning in cv.glm(mtcars, model, K = 10): 'K' has been set to 11.000000\n\n# Results\ncv_mse &lt;- k10_error$delta[1]\ncv_mse_adjusted &lt;- k10_error$delta[2]  # Bias-corrected\n\nprint(paste(\"10-fold CV MSE:\", round(cv_mse, 3)))\n\n[1] \"10-fold CV MSE: 8.359\"\n\n\nCommon choices: K = 5, 10, or √n"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#practical-example-polynomial-regression",
    "href": "Lecture_Folder/Week10a.html#practical-example-polynomial-regression",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Practical Example: Polynomial Regression",
    "text": "Practical Example: Polynomial Regression\n\nlibrary(boot)\nlibrary(ggplot2)\n\n# Generate sample data\nset.seed(123)\nn &lt;- 100\nx &lt;- runif(n, 0, 2*pi)\ny &lt;- sin(x) + rnorm(n, 0, 0.3)\ndata &lt;- data.frame(x = x, y = y)\n\n# Test different polynomial degrees\ndegrees &lt;- 1:10\ncv_errors &lt;- numeric(length(degrees))\n\nfor(i in seq_along(degrees)) {\n  # Fit polynomial model\n  model &lt;- glm(y ~ poly(x, degrees[i]), data = data)\n  \n  # 10-fold cross-validation\n  cv_result &lt;- cv.glm(data, model, K = 10)\n  cv_errors[i] &lt;- cv_result$delta[1]\n}"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#visualizing-cv-results",
    "href": "Lecture_Folder/Week10a.html#visualizing-cv-results",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Visualizing CV Results",
    "text": "Visualizing CV Results\n\n# Create results data frame\nresults &lt;- data.frame(\n  degree = degrees,\n  cv_error = cv_errors\n)\n\n# Plot CV error vs polynomial degree\nggplot(results, aes(x = degree, y = cv_error)) +\n  geom_line(color = \"blue\", size = 1) +\n  geom_point(color = \"red\", size = 2) +\n  labs(title = \"Cross-Validation Error vs Polynomial Degree\",\n       x = \"Polynomial Degree\",\n       y = \"10-Fold CV Error\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n# Find optimal degree\noptimal_degree &lt;- degrees[which.min(cv_errors)]\nprint(paste(\"Optimal polynomial degree:\", optimal_degree))\n\n[1] \"Optimal polynomial degree: 6\""
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#custom-cross-validation-function",
    "href": "Lecture_Folder/Week10a.html#custom-cross-validation-function",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Custom Cross-Validation Function",
    "text": "Custom Cross-Validation Function\n\n# Custom CV function for specific needs\ncustom_cv &lt;- function(data, model_formula, K = 10) {\n  n &lt;- nrow(data)\n  folds &lt;- sample(rep(1:K, length.out = n))\n  errors &lt;- numeric(K)\n  \n  for(k in 1:K) {\n    # Split data\n    train_data &lt;- data[folds != k, ]\n    test_data &lt;- data[folds == k, ]\n    \n    # Fit model on training data\n    model &lt;- lm(model_formula, data = train_data)\n    \n    # Predict on test data\n    predictions &lt;- predict(model, test_data)\n    \n    # Calculate error\n    errors[k] &lt;- mean((test_data$y - predictions)^2)\n  }\n  \n  return(list(\n    cv_error = mean(errors),\n    fold_errors = errors,\n    se = sd(errors) / sqrt(K)\n  ))\n}"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#model-comparison-example",
    "href": "Lecture_Folder/Week10a.html#model-comparison-example",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Model Comparison Example",
    "text": "Model Comparison Example\n\n# Compare different models\nmodels &lt;- list(\n  linear = y ~ x,\n  quadratic = y ~ x + I(x^2),\n  cubic = y ~ x + I(x^2) + I(x^3),\n  sine = y ~ sin(x) + cos(x)\n)\n\n# Perform CV for each model\ncv_results &lt;- list()\nfor(name in names(models)) {\n  model &lt;- glm(models[[name]], data = data)\n  cv_results[[name]] &lt;- cv.glm(data, model, K = 10)$delta[1]\n}\n\n# Display results\ncv_comparison &lt;- data.frame(\n  Model = names(cv_results),\n  CV_Error = unlist(cv_results)\n)\nprint(cv_comparison)\n\n              Model   CV_Error\nlinear       linear 0.31539669\nquadratic quadratic 0.33241714\ncubic         cubic 0.10240748\nsine           sine 0.08786227"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#bootstrap-cross-validation",
    "href": "Lecture_Folder/Week10a.html#bootstrap-cross-validation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Bootstrap Cross-Validation",
    "text": "Bootstrap Cross-Validation\n\n# Bootstrap approach for CV\nbootstrap_cv &lt;- function(data, indices) {\n  # Sample data with replacement\n  boot_data &lt;- data[indices, ]\n  \n  # Fit model\n  model &lt;- lm(y ~ poly(x, 3), data = boot_data)\n  \n  # Predict on original data (out-of-bag prediction)\n  predictions &lt;- predict(model, data)\n  mse &lt;- mean((data$y - predictions)^2)\n  \n  return(mse)\n}\n\n# Perform bootstrap CV\nset.seed(123)\nboot_results &lt;- boot(data, bootstrap_cv, R = 1000)\n\n# Bootstrap CV estimate\nboot_cv_error &lt;- mean(boot_results$t)\nboot_cv_se &lt;- sd(boot_results$t)\n\nprint(paste(\"Bootstrap CV Error:\", round(boot_cv_error, 3), \n           \"±\", round(boot_cv_se, 3)))\n\n[1] \"Bootstrap CV Error: 0.097 ± 0.004\""
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#stratified-cross-validation",
    "href": "Lecture_Folder/Week10a.html#stratified-cross-validation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Stratified Cross-Validation",
    "text": "Stratified Cross-Validation\nFor classification problems:\n\n# Example with classification\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\ndata(iris)\n\n# Create stratified folds manually\ncreate_stratified_folds &lt;- function(y, K = 10) {\n  folds &lt;- vector(\"list\", K)\n  classes &lt;- unique(y)\n  \n  for(class in classes) {\n    class_indices &lt;- which(y == class)\n    class_folds &lt;- sample(rep(1:K, length.out = length(class_indices)))\n    \n    for(k in 1:K) {\n      folds[[k]] &lt;- c(folds[[k]], class_indices[class_folds == k])\n    }\n  }\n  return(folds)\n}\n\n# Use stratified folds\nfolds &lt;- create_stratified_folds(iris$Species, K = 5)"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#time-series-cross-validation",
    "href": "Lecture_Folder/Week10a.html#time-series-cross-validation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Time Series Cross-Validation",
    "text": "Time Series Cross-Validation\nFor temporal data:\n\n# Time series CV (forward chaining)\nts_cv &lt;- function(data, window_size, horizon = 1) {\n  n &lt;- nrow(data)\n  n_folds &lt;- n - window_size - horizon + 1\n  errors &lt;- numeric(n_folds)\n  \n  for(i in 1:n_folds) {\n    # Training window\n    train_end &lt;- window_size + i - 1\n    train_data &lt;- data[i:train_end, ]\n    \n    # Test data\n    test_start &lt;- train_end + 1\n    test_end &lt;- min(test_start + horizon - 1, n)\n    test_data &lt;- data[test_start:test_end, ]\n    \n    # Fit and predict (example with linear model)\n    model &lt;- lm(y ~ x, data = train_data)\n    pred &lt;- predict(model, test_data)\n    errors[i] &lt;- mean((test_data$y - pred)^2)\n  }\n  \n  return(mean(errors))\n}"
  },
  {
    "objectID": "Lecture_Folder/Week10a.html#advanced-nested-cross-validation",
    "href": "Lecture_Folder/Week10a.html#advanced-nested-cross-validation",
    "title": "Week 10a - Statistics for Bioengineering",
    "section": "Advanced: Nested Cross-Validation",
    "text": "Advanced: Nested Cross-Validation\nFor hyperparameter tuning:\n\n# Nested CV for model selection and evaluation\nnested_cv &lt;- function(data, param_grid, outer_K = 10, inner_K = 5) {\n  n &lt;- nrow(data)\n  outer_folds &lt;- sample(rep(1:outer_K, length.out = n))\n  outer_errors &lt;- numeric(outer_K)\n  \n  for(k in 1:outer_K) {\n    # Outer split\n    train_data &lt;- data[outer_folds != k, ]\n    test_data &lt;- data[outer_folds == k, ]\n    \n    # Inner CV for parameter selection\n    best_param &lt;- tune_parameters(train_data, param_grid, inner_K)\n    \n    # Fit final model with best parameters\n    final_model &lt;- fit_model(train_data, best_param)\n    \n    # Evaluate on outer test set\n    pred &lt;- predict(final_model, test_data)\n    outer_errors[k] &lt;- mean((test_data$y - pred)^2)\n  }\n  \n  return(list(\n    cv_error = mean(outer_errors),\n    se = sd(outer_errors) / sqrt(outer_K)\n  ))\n}"
  },
  {
    "objectID": "Homework_Folder/HW4_2025.html",
    "href": "Homework_Folder/HW4_2025.html",
    "title": "BioE_Stats_2025_HW4 - Classification using Logistic Regression and Random Forests",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use a new data set studying the predictive ability of different (knee_injury.csv) which is a synthetic data set of various measurements and whether the participant developed a knee injury.\nIn addition, perform at least one of these statistical analyses on the dataset that you’ve identified for your term long project depending on the nature of your data.\nDue: Submit your work via Canvas by the end of the day (midnight) on Wednesday, June 11th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW4_2025.html#directions",
    "href": "Homework_Folder/HW4_2025.html#directions",
    "title": "BioE_Stats_2025_HW4 - Classification using Logistic Regression and Random Forests",
    "section": "",
    "text": "Assignment: Your task is to use R and Quarto Markdown to write a short report including the following tasks. You will use a new data set studying the predictive ability of different (knee_injury.csv) which is a synthetic data set of various measurements and whether the participant developed a knee injury.\nIn addition, perform at least one of these statistical analyses on the dataset that you’ve identified for your term long project depending on the nature of your data.\nDue: Submit your work via Canvas by the end of the day (midnight) on Wednesday, June 11th. Please submit both the Quarto_md file and the resulting html or pdf file. You can work with other members of class, but I expect each of you to construct and run all of the scripts yourself."
  },
  {
    "objectID": "Homework_Folder/HW4_2025.html#problem-3.1-logistic-regression-analysis-of-injury-risk",
    "href": "Homework_Folder/HW4_2025.html#problem-3.1-logistic-regression-analysis-of-injury-risk",
    "title": "BioE_Stats_2025_HW4 - Classification using Logistic Regression and Random Forests",
    "section": "Problem 3.1 : Logistic regression analysis of injury risk",
    "text": "Problem 3.1 : Logistic regression analysis of injury risk"
  },
  {
    "objectID": "Homework_Folder/HW4_2025.html#the-study",
    "href": "Homework_Folder/HW4_2025.html#the-study",
    "title": "BioE_Stats_2025_HW4 - Classification using Logistic Regression and Random Forests",
    "section": "The Study",
    "text": "The Study\nKnee injuries are common among individuals who engage in physical activity. Understanding the risk factors contributing to such injuries is essential for developing preventative strategies. In this assignment, you will use logistic regression to model the probability of experiencing a knee injury based on physiological and lifestyle variables.\nDataset Description: You have been provided with a dataset (available on Canvas) containing 300 synthetic observations with the following variables:\n\nknee_injury: Binary response variable (1 = injury occurred, 0 = no injury)\nage: Age of the individual in years\nfitness_level: Composite fitness score (0–100 scale)\nexercise_hours_per_week: Average number of hours of physical activity per week\nmetabolic_marker: A standardized metabolic biomarker level (unitless)\nbmi: Body Mass Index\nmuscle_strength: a measurement of maximum resistance\nflexibility score: a scaled integrative measurement of various stretching tests\nprevious injury: whether the participant had a similar previous injury\nbalance score: a summary score of how well the individual balances on one leg\n\nTasks:\n\nExploratory Data Analysis\n\nSummarize the distribution of each variable.\nVisualize relationships between each predictor and the injury outcome.\n\nModel Building\n\nFit a logistic regression model to predict knee_injury using the other variables.\nInterpret the coefficients, especially in terms of odds ratios.\n\nModel Evaluation\n\nAssess model performance using appropriate metrics (e.g. confusion matrix)."
  },
  {
    "objectID": "Homework_Folder/HW4_2025.html#problem-3.2-random-forest-analysis-of-injury-risk",
    "href": "Homework_Folder/HW4_2025.html#problem-3.2-random-forest-analysis-of-injury-risk",
    "title": "BioE_Stats_2025_HW4 - Classification using Logistic Regression and Random Forests",
    "section": "Problem 3.2 : Random forest analysis of injury risk",
    "text": "Problem 3.2 : Random forest analysis of injury risk\nNow you’re going to analyze the exact same data set using a random forest classifier using the following steps.\n\nTasks\n\nData Preparation\n\nLoad the dataset in R.\nInspect the variables and perform any necessary preprocessing (e.g., scaling, handling missing values if present).\n\nModel Fitting\n\nUse the randomForest package to fit a random forest model predicting knee_injury.\n\nModel Interpretation\n\nReport model accuracy, confusion matrix, and OOB (out-of-bag) error estimate.\nPlot and interpret variable importance\nIdentify which variables were most useful in predicting injury risk.\n\nModel Evaluation\n\nUse ROC analysis (pROC or caret packages) to evaluate model performance.\nAnalyze performance using LOOCV and K-fold CV.\n\nCompare results to a logistic regression model"
  },
  {
    "objectID": "Homework_Folder/HW4_2025.html#problem-4.1-logistic-regression-analysis-of-injury-risk",
    "href": "Homework_Folder/HW4_2025.html#problem-4.1-logistic-regression-analysis-of-injury-risk",
    "title": "BioE_Stats_2025_HW4 - Classification using Logistic Regression and Random Forests",
    "section": "Problem 4.1 : Logistic regression analysis of injury risk",
    "text": "Problem 4.1 : Logistic regression analysis of injury risk"
  },
  {
    "objectID": "Homework_Folder/HW4_2025.html#problem-4.2-random-forest-analysis-of-injury-risk",
    "href": "Homework_Folder/HW4_2025.html#problem-4.2-random-forest-analysis-of-injury-risk",
    "title": "BioE_Stats_2025_HW4 - Classification using Logistic Regression and Random Forests",
    "section": "Problem 4.2 : Random forest analysis of injury risk",
    "text": "Problem 4.2 : Random forest analysis of injury risk\nNow you’re going to analyze the exact same data set using a random forest classifier using the following steps.\n\nTasks\n\nData Preparation\n\nLoad the dataset in R.\nInspect the variables and perform any necessary preprocessing (e.g., scaling, handling missing values if present).\n\nModel Fitting\n\nUse the randomForest package to fit a random forest model predicting knee_injury.\n\nModel Interpretation\n\nReport model accuracy, confusion matrix, and OOB (out-of-bag) error estimate.\nPlot and interpret variable importance\nIdentify which variables were most useful in predicting injury risk.\n\nModel Evaluation\n\nUse ROC analysis (pROC or caret packages) to evaluate model performance.\nAnalyze performance using LOOCV and K-fold CV.\n\nCompare results to a logistic regression model"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html",
    "href": "Lecture_Folder/Week10b.html",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(gt)\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(tibble)\nlibrary(randomForest)\n\nrandomForest 4.7-1.2\nType rfNews() to see new features/changes/bug fixes.\n\nAttaching package: 'randomForest'\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(caret)\n\nLoading required package: lattice\n\nAttaching package: 'caret'\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\nAttaching package: 'pROC'\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\nlibrary(ROCR)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#todays-topics",
    "href": "Lecture_Folder/Week10b.html#todays-topics",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Today’s Topics",
    "text": "Today’s Topics\n\nBias-Variance tradeoff\nDecision trees and random forests\nCross-validation strategies\nROC curves and AUC analysis\nBioengineering applications"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#bias-variance-tradeoff",
    "href": "Lecture_Folder/Week10b.html#bias-variance-tradeoff",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Bias-Variance Tradeoff",
    "text": "Bias-Variance Tradeoff\n\\[\n\\text{Expected Test Error} = \\text{Bias}^2 + \\text{Variance} + \\text{Irreducible Error}\n\\]\n\nBias: Error from overly simple models (underfitting)\nVariance: Error from overly complex models (overfitting)\nGoal: Balance model complexity with generalization"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#strategies-to-address-the-tradeoff",
    "href": "Lecture_Folder/Week10b.html#strategies-to-address-the-tradeoff",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Strategies to Address the Tradeoff",
    "text": "Strategies to Address the Tradeoff\n\nRegularization (Lasso, Ridge) to constrain model complexity\nCross-validation to choose optimal model complexity\nEnsemble methods (bagging, boosting) to reduce variance\n\nThis often used with decision tree models"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#decision-trees",
    "href": "Lecture_Folder/Week10b.html#decision-trees",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Decision Trees",
    "text": "Decision Trees\n\nA non-parametric way to build models\nKey Characteristics:\n\nTree-like structure of decision rules\nEasy to interpret and visualize\nHandle both numerical and categorical data\nNo distributional assumptions\nCapture non-linear relationships naturally\n\nAlgorithm:\n\nRecursively split data to maximize information gain until stopping criteria are met"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#decision-tree-example",
    "href": "Lecture_Folder/Week10b.html#decision-tree-example",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Decision tree example",
    "text": "Decision tree example"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#introduction-to-impurity-measures",
    "href": "Lecture_Folder/Week10b.html#introduction-to-impurity-measures",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Introduction to Impurity Measures",
    "text": "Introduction to Impurity Measures\n\nDecision trees need to decide which features to split on\nImpurity measures help quantify how “mixed” or “pure” a dataset is\nTwo main measures: Gini Index and Entropy\nBoth measure the same concept but with different mathematical approaches"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#what-is-impurity",
    "href": "Lecture_Folder/Week10b.html#what-is-impurity",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "What is “Impurity”?",
    "text": "What is “Impurity”?\n\nPure Node:\n\nAll samples belong to the same class\nEasy to make predictions\nLow impurity\n\nImpure Node:\n\nSamples belong to multiple classes\nHarder to make predictions\nHigh impurity\n\nExample: If participants at a node are “injured” → pure\nIf 50% injured, 50% not → impure"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#gini-index-definition",
    "href": "Lecture_Folder/Week10b.html#gini-index-definition",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Gini Index: Definition",
    "text": "Gini Index: Definition\nThe Gini Index measures the probability of misclassifying a randomly chosen sample.\n\\[\\text{Gini} = 1 - \\sum_{i=1}^{c} p_i^2\\]\n\nWhere:\n\n\\(c\\) = number of classes\n\\(p_i\\) = probability of class \\(i\\)\n\nRange: 0 to 0.5 (for binary classification)\n\n0 = perfectly pure\n0.5 = maximum impurity (50-50 split)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#gini-index-examples",
    "href": "Lecture_Folder/Week10b.html#gini-index-examples",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Gini Index: Examples",
    "text": "Gini Index: Examples\n\nExample 1: Pure Node\n\n100 inuries, 0 not injuries\n\\(p_{injury} = 1.0, p_{not} = 0.0\\)\n\\(\\text{Gini} = 1 - (1.0^2 + 0.0^2) = 0\\)\n\nExample 2: Mixed Node\n\n\n60 injuries, 40 not injuries\n\\(p_{injury} = 0.6, p_{not} = 0.4\\)\n\\(\\text{Gini} = 1 - (0.6^2 + 0.4^2)\\)\n\\(\\text{Gini} = 1 - (0.36 + 0.16) = 0.48\\)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#entropy-definition",
    "href": "Lecture_Folder/Week10b.html#entropy-definition",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Entropy: Definition",
    "text": "Entropy: Definition\n\nEntropy measures the amount of information or surprise in the data.\n\n\\[\\text{Entropy} = -\\sum_{i=1}^{c} p_i \\log_2(p_i)\\]\n\nWhere:\n\n\\(c\\) = number of classes\n\n\\(p_i\\) = probability of class \\(i\\)\n\nRange: 0 to \\(\\log_2(c)\\)\n\n0 = perfectly pure\n1 = maximum impurity (for binary classification)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#entropy-examples",
    "href": "Lecture_Folder/Week10b.html#entropy-examples",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Entropy: Examples",
    "text": "Entropy: Examples\n\nExample 1: Pure Node\n\n100 injuries, 0 not injufies\n\\(p_{injury} = 1.0, p_{not} = 0.0\\)\n\\(\\text{Entropy} = -1.0 \\log_2(1.0) = 0\\)\n\nExample 2: Mixed Node\n\n60 injuries, 40 not injuries\n\\(p_{injury} = 0.6, p_{not} = 0.4\\)\n\\(\\text{Entropy} = -0.6\\log_2(0.6) - 0.4\\log_2(0.4)\\)\n\\(\\text{Entropy} = 0.44 + 0.53 = 0.97\\)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#gini-vs-entropy",
    "href": "Lecture_Folder/Week10b.html#gini-vs-entropy",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Gini vs Entropy",
    "text": "Gini vs Entropy\n\n\n\n\n\n\n\n\nAspect\nGini Index\nEntropy\n\n\n\n\nComputation\nFaster\nSlower\n\n\nRange (binary)\n0 to 0.5\n0 to 1.0\n\n\nSensitivity\nLess sensitive to changes\nMore sensitive to changes\n\n\n\nIn practice: Both usually give similar results, Gini preferred for speed."
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#information-gain",
    "href": "Lecture_Folder/Week10b.html#information-gain",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Information Gain",
    "text": "Information Gain\nBoth measures are used to calculate Information Gain:\n\\[\\text{Information Gain} = \\text{Impurity}_{parent} - \\sum \\frac{n_{child}}{n_{parent}} \\times \\text{Impurity}_{child}\\]\n\nDecision trees choose splits that maximize information gain\nHigher gain = better split = more homogeneous child nodes"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#practical-example",
    "href": "Lecture_Folder/Week10b.html#practical-example",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Practical Example",
    "text": "Practical Example\n\nDataset: 100 patients (60 injured, 40 not injured)\nBefore split:\n\nGini = \\(1 - (0.6^2 + 0.4^2) = 0.48\\)\nEntropy = \\(-0.6\\log_2(0.6) - 0.4\\log_2(0.4) = 0.97\\)\n\nAfter split on “BMI”:\n\nLeft: 50 patients (45 injured, 5 not injured)\nRight: 50 patients (15 injured, 35 not injured)\n\nCalculate weighted average impurity to find information gain!\nDo this again and again on different variables (features) to see which one provides the biggest gain"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#calculations-after-split",
    "href": "Lecture_Folder/Week10b.html#calculations-after-split",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Calculations After Split",
    "text": "Calculations After Split\n\nLeft Node (50 patients: 45 injured, 5 not injured)\n\nProportions: \\(p_{injured} = 45/50 = 0.9\\), \\(p_{not\\_injured} = 5/50 = 0.1\\)\nGini Left: \\(1 - (0.9^2 + 0.1^2) = 0.18\\)\nEntropy Left: \\(-0.9\\log_2(0.9) - 0.1\\log_2(0.1) = 0.469\\)\n\nRight Node (50 patients: 15 injured, 35 not injured)\n\nProportions: \\(p_{injured} = 15/50 = 0.3\\), \\(p_{not\\_injured} = 35/50 = 0.7\\)\nGini Right: \\(1 - (0.3^2 + 0.7^2) = 0.42\\)\nEntropy Right: \\(-0.3\\log_2(0.3) - 0.7\\log_2(0.7) = 0.882\\)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#calculations-after-split-1",
    "href": "Lecture_Folder/Week10b.html#calculations-after-split-1",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Calculations After Split",
    "text": "Calculations After Split\n\nWeighted Average Impurity After Split\n\nWeighted Gini: \\(\\frac{50}{100} \\times 0.18 + \\frac{50}{100} \\times 0.42 = 0.09 + 0.21 = 0.30\\)\nWeighted Entropy: \\(\\frac{50}{100} \\times 0.469 + \\frac{50}{100} \\times 0.882 = 0.235 + 0.441 = 0.676\\)\n\nInformation Gain\n\nGini Information Gain: \\(0.48 - 0.30 = 0.18\\)\nEntropy Information Gain: \\(0.97 - 0.676 = 0.294\\)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#building-decision-trees-in-r",
    "href": "Lecture_Folder/Week10b.html#building-decision-trees-in-r",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Building Decision Trees in R",
    "text": "Building Decision Trees in R\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\ndata(iris)\nset.seed(123)\ntrain_index &lt;- createDataPartition(iris$Species, p = 0.7, list = FALSE)\ntrain_data &lt;- iris[train_index, ]\ntest_data &lt;- iris[-train_index, ]\n\n# Build and visualize tree\ntree_model &lt;- rpart(Species ~ ., data = train_data, method = \"class\")\nrpart.plot(tree_model, type = 4, extra = 102, main = \"Iris Classification Tree\")\n\n# Evaluate performance\npredictions &lt;- predict(tree_model, test_data, type = \"class\")\nconfusionMatrix(predictions, test_data$Species)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#building-decision-trees-in-r-1",
    "href": "Lecture_Folder/Week10b.html#building-decision-trees-in-r-1",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Building Decision Trees in R",
    "text": "Building Decision Trees in R"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#building-decision-trees-in-r-2",
    "href": "Lecture_Folder/Week10b.html#building-decision-trees-in-r-2",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Building Decision Trees in R",
    "text": "Building Decision Trees in R\n\n\nConfusion Matrix and Statistics\n\n            Reference\nPrediction   setosa versicolor virginica\n  setosa         15          0         0\n  versicolor      0         14         2\n  virginica       0          1        13\n\nOverall Statistics\n                                         \n               Accuracy : 0.9333         \n                 95% CI : (0.8173, 0.986)\n    No Information Rate : 0.3333         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.9            \n                                         \n Mcnemar's Test P-Value : NA             \n\nStatistics by Class:\n\n                     Class: setosa Class: versicolor Class: virginica\nSensitivity                 1.0000            0.9333           0.8667\nSpecificity                 1.0000            0.9333           0.9667\nPos Pred Value              1.0000            0.8750           0.9286\nNeg Pred Value              1.0000            0.9655           0.9355\nPrevalence                  0.3333            0.3333           0.3333\nDetection Rate              0.3333            0.3111           0.2889\nDetection Prevalence        0.3333            0.3556           0.3111\nBalanced Accuracy           1.0000            0.9333           0.9167"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#decision-trees-pros-and-cons",
    "href": "Lecture_Folder/Week10b.html#decision-trees-pros-and-cons",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Decision Trees: Pros and Cons",
    "text": "Decision Trees: Pros and Cons\n\nAdvantages:\n\nHighly interpretable\nNo preprocessing required\nAutomatic feature selection\nHandles interactions naturally\n\nLimitations:\n\nProne to overfitting\nHigh variance (unstable)\nBias toward features with more levels\nLimited expressiveness for linear relationships\n\nSolution: Use ensemble methods like Random Forests!"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#random-forests---embrace-the-ensemble",
    "href": "Lecture_Folder/Week10b.html#random-forests---embrace-the-ensemble",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Random Forests - Embrace the Ensemble",
    "text": "Random Forests - Embrace the Ensemble\nKey Innovation: Combine multiple decision trees through:\n\nBootstrap sampling (bagging) for training data\nRandom feature selection at each split\nAggregate predictions (voting/averaging)\nOut-of-bag validation for built-in cross-validation\n\nResult: Reduced overfitting, improved accuracy, maintained interpretability through variable importance"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#random-forest-implementation",
    "href": "Lecture_Folder/Week10b.html#random-forest-implementation",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Random Forest Implementation",
    "text": "Random Forest Implementation\n\n# Classification\nrf_model &lt;- randomForest(\n  Species ~ ., \n  data = train_data,\n  ntree = 500,           # Number of trees\n  mtry = 2,              # Features per split (√p for classification)\n  importance = TRUE      # Calculate variable importance\n)\n\nprint(rf_model)\nplot(rf_model, main = \"Random Forest Error Rates\")\n\n# Variable importance\nvarImpPlot(rf_model, main = \"Variable Importance\")\nimportance(rf_model)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#random-forest-implementation-1",
    "href": "Lecture_Folder/Week10b.html#random-forest-implementation-1",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Random Forest Implementation",
    "text": "Random Forest Implementation\n\n\n\nCall:\n randomForest(formula = Species ~ ., data = train_data, ntree = 500,      mtry = 2, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n        OOB estimate of  error rate: 4.76%\nConfusion matrix:\n           setosa versicolor virginica class.error\nsetosa         35          0         0  0.00000000\nversicolor      0         33         2  0.05714286\nvirginica       0          3        32  0.08571429\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                setosa versicolor virginica MeanDecreaseAccuracy\nSepal.Length  7.147216   9.184321  8.580944            11.835818\nSepal.Width   4.447419   2.125054  5.530193             6.303784\nPetal.Length 21.678714  28.332242 26.876953            32.361134\nPetal.Width  22.023943  28.785681 31.409603            32.888441\n             MeanDecreaseGini\nSepal.Length         8.202889\nSepal.Width          1.463770\nPetal.Length        28.830718\nPetal.Width         30.736584"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#hyperparameter-tuning-with-cross-validation",
    "href": "Lecture_Folder/Week10b.html#hyperparameter-tuning-with-cross-validation",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Hyperparameter Tuning with Cross-Validation",
    "text": "Hyperparameter Tuning with Cross-Validation\n\n# Define parameter grid\nrf_grid &lt;- expand.grid(mtry = c(1, 2, 3, 4))\n\n# Cross-validation setup\nctrl &lt;- trainControl(\n  method = \"repeatedcv\",\n  number = 5,\n  repeats = 3,\n  savePredictions = TRUE,\n  classProbs = TRUE\n)\n\n# Train with tuning\nrf_tuned &lt;- train(\n  Species ~ .,\n  data = train_data,\n  method = \"rf\",\n  tuneGrid = rf_grid,\n  trControl = ctrl,\n  ntree = 300\n)\n\nplot(rf_tuned)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#hyperparameter-tuning-with-cross-validation-1",
    "href": "Lecture_Folder/Week10b.html#hyperparameter-tuning-with-cross-validation-1",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Hyperparameter Tuning with Cross-Validation",
    "text": "Hyperparameter Tuning with Cross-Validation"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#cross-validation-beyond-built-in-oob",
    "href": "Lecture_Folder/Week10b.html#cross-validation-beyond-built-in-oob",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Cross-Validation: Beyond Built-in OOB",
    "text": "Cross-Validation: Beyond Built-in OOB\n\nWhy Cross-Validation for Random Forests?\n\nMore reliable performance estimates\nFair comparison with other algorithms\nHyperparameter optimization\nNested CV for unbiased evaluation\n\nMethods:\n\nK-fold CV: Split into k folds, train on k-1, test on 1\nStratified CV: Maintains class proportions\nRepeated CV: Multiple rounds for stability"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#biomedical-case-study-knee-injury-prediction",
    "href": "Lecture_Folder/Week10b.html#biomedical-case-study-knee-injury-prediction",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Biomedical Case Study: Knee Injury Prediction",
    "text": "Biomedical Case Study: Knee Injury Prediction\nContext: Early identification of injury risk factors\n\n# Load and prepare data\ndata &lt;- read.csv(\"data/knee_injury.csv\")\ndata$knee_injury &lt;- as.factor(data$knee_injury)\n\n# Train Random Forest with CV\nset.seed(123)\ntrain_control &lt;- trainControl(\n  method = \"cv\",\n  number = 10,\n  classProbs = FALSE,  # Set to FALSE\n  summaryFunction = defaultSummary  # Use default instead of twoClassSummary\n)\n\nrf_knee &lt;- train(\n  knee_injury ~ .,\n  data = data,\n  method = \"rf\",\n  trControl = train_control,\n  metric = \"Accuracy\",  # Change metric since no ROC without probabilities\n  importance = TRUE\n)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#clinical-interpretation-variable-importance",
    "href": "Lecture_Folder/Week10b.html#clinical-interpretation-variable-importance",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Clinical Interpretation: Variable Importance",
    "text": "Clinical Interpretation: Variable Importance\n\n# Extract and visualize importance\nimportance_scores &lt;- varImp(rf_knee)\nplot(importance_scores, main = \"Risk Factors for Knee Injury\")"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#clinical-interpretation-variable-importance-1",
    "href": "Lecture_Folder/Week10b.html#clinical-interpretation-variable-importance-1",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Clinical Interpretation: Variable Importance",
    "text": "Clinical Interpretation: Variable Importance"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#model-evaluation-roc-curves-and-auc",
    "href": "Lecture_Folder/Week10b.html#model-evaluation-roc-curves-and-auc",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Model Evaluation: ROC Curves and AUC",
    "text": "Model Evaluation: ROC Curves and AUC\n\nROC Curve: Plots True Positive Rate vs False Positive Rate across all classification thresholds\nKey Metrics:\n\nSensitivity (TPR): \\(\\frac{TP}{TP + FN}\\) - How well we catch positive cases\nSpecificity (TNR): \\(\\frac{TN}{TN + FP}\\) - How well we avoid false alarms\nAUC: Area under ROC curve - Overall discriminative ability\nAUC Range: 0 to 1 (higher is better)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#mathematical-foundation",
    "href": "Lecture_Folder/Week10b.html#mathematical-foundation",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Mathematical Foundation",
    "text": "Mathematical Foundation\nFor discrete points \\((x_i, y_i)\\) on the ROC curve:\n\\[AUC = \\sum_{i=1}^{n-1} \\frac{1}{2}(x_{i+1} - x_i)(y_i + y_{i+1})\\]\n\nWhere:\n\n\\(x_i\\) = FPR at threshold \\(i\\)\n\\(y_i\\) = TPR at threshold \\(i\\)\nPoints are sorted by increasing FPR"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#auc-interpretation",
    "href": "Lecture_Folder/Week10b.html#auc-interpretation",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "AUC interpretation",
    "text": "AUC interpretation\n\nAUC = 0.5: Random guessing\nAUC = 0.7-0.8: Acceptable\nAUC = 0.8-0.9: Excellent\nAUC &gt; 0.9: Outstanding (check for overfitting)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#calculation-in-r",
    "href": "Lecture_Folder/Week10b.html#calculation-in-r",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Calculation in R",
    "text": "Calculation in R\n\n# Load required libraries\nlibrary(ROCR)\nlibrary(pROC)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Set seed for reproducibility\nset.seed(42)\n\n# Generate sample data\nn &lt;- 1000\nx1 &lt;- rnorm(n)\nx2 &lt;- rnorm(n)\n# Create binary outcome with some relationship to predictors\ny &lt;- rbinom(n, 1, plogis(0.5 * x1 + 0.3 * x2 + rnorm(n, 0, 0.5)))\n\n# Split data\ntrain_idx &lt;- sample(1:n, 0.7 * n)\ntrain_data &lt;- data.frame(x1 = x1[train_idx], x2 = x2[train_idx], y = y[train_idx])\ntest_data &lt;- data.frame(x1 = x1[-train_idx], x2 = x2[-train_idx], y = y[-train_idx])\n\n# Fit logistic regression\nmodel &lt;- glm(y ~ x1 + x2, data = train_data, family = binomial)\n\n# Get predicted probabilities\npred_probs &lt;- predict(model, test_data, type = \"response\")\nactual &lt;- test_data$y"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#calculate-roc-curve-points",
    "href": "Lecture_Folder/Week10b.html#calculate-roc-curve-points",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Calculate ROC Curve Points",
    "text": "Calculate ROC Curve Points\n\n# Using ROCR package\npred_obj &lt;- prediction(pred_probs, actual)\nperf_obj &lt;- performance(pred_obj, \"tpr\", \"fpr\")\n\n# Extract TPR and FPR\nfpr &lt;- perf_obj@x.values[[1]]\ntpr &lt;- perf_obj@y.values[[1]]\nthresholds &lt;- perf_obj@alpha.values[[1]]\n\n# Calculate AUC using ROCR\nauc_rocr &lt;- performance(pred_obj, \"auc\")@y.values[[1]]\n\n# Alternative using pROC package\nroc_obj &lt;- roc(actual, pred_probs, quiet = TRUE)\nauc_proc &lt;- auc(roc_obj)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#visualization",
    "href": "Lecture_Folder/Week10b.html#visualization",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "Visualization",
    "text": "Visualization\n\n# Create comprehensive visualization\nlibrary(gridExtra)\n\n\nAttaching package: 'gridExtra'\n\n\nThe following object is masked from 'package:randomForest':\n\n    combine\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n# ROC Curve plot\nroc_data &lt;- data.frame(FPR = fpr, TPR = tpr)\n\np1 &lt;- ggplot(roc_data, aes(x = FPR, y = TPR)) +\n  geom_ribbon(aes(ymin = 0, ymax = TPR), alpha = 0.3, fill = \"blue\") +\n  geom_line(color = \"darkorange\", size = 1.2) +\n  geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = \"gray\") +\n  labs(title = paste(\"ROC Curve (AUC =\", round(auc_rocr, 4), \")\"),\n       x = \"False Positive Rate\", y = \"True Positive Rate\") +\n  theme_minimal() +\n  coord_fixed()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# Distribution of predicted probabilities\nprob_data &lt;- data.frame(\n  Probability = pred_probs,\n  Actual = factor(actual, labels = c(\"Negative\", \"Positive\"))\n)\n\np2 &lt;- ggplot(prob_data, aes(x = Probability, fill = Actual)) +\n  geom_histogram(alpha = 0.7, bins = 30, position = \"identity\") +\n  labs(title = \"Distribution of Predicted Probabilities\",\n       x = \"Predicted Probability\", y = \"Count\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"red\", \"blue\"))\n\ngrid.arrange(p1, p2, ncol = 2)"
  },
  {
    "objectID": "Lecture_Folder/Week10b.html#when-to-use-each-method",
    "href": "Lecture_Folder/Week10b.html#when-to-use-each-method",
    "title": "Week 10b - Statistics for Bioengineering",
    "section": "When to Use Each Method",
    "text": "When to Use Each Method\n\n\n\n\n\n\n\n\nMethod\nBest For\nLimitations\n\n\n\n\nLogistic Regression\nLinear relationships, inference needs, regulatory requirements\nAssumes linearity, manual interaction terms\n\n\nDecision Trees\nHigh interpretability needs, small datasets, understanding interactions\nOverfitting, instability\n\n\nRandom Forest\nPrediction accuracy, complex patterns, robust performance\nLess interpretable, computational cost"
  },
  {
    "objectID": "Homework_Folder/Term_Project.html",
    "href": "Homework_Folder/Term_Project.html",
    "title": "Term Long Project - Pulling it All Together",
    "section": "",
    "text": "Assignment:\nPull together all of the activities that you performed on your own data that you’ve chosen to analyze throughout the term in association with each homework set and put it into one complete Markdown document that can be rendered.\nIn addition to packaging these previous analyses together, you can also perform any additional visualizations and analyses that make sense. Lastly, add some interpretive writing that explains the nature of your data, the types of analyses you performed at each step, your outcomes or findings from each, and the conclusions that you might draw from each finding.\nThe overall goal is to create something like a report to share with a collaborator or your PI, or should your work be far enough along the skeleton of a manuscript that can submitted for subsequent publication.\nDue: Submit your work via Canvas by the end of the day (midnight) on Friday, June 13th. Please submit both the Quarto_md file and the resulting html or pdf file."
  },
  {
    "objectID": "Homework_Folder/Term_Project.html#directions",
    "href": "Homework_Folder/Term_Project.html#directions",
    "title": "Term Long Project - Pulling it All Together",
    "section": "",
    "text": "Assignment:\nPull together all of the activities that you performed on your own data that you’ve chosen to analyze throughout the term in association with each homework set and put it into one complete Markdown document that can be rendered.\nIn addition to packaging these previous analyses together, you can also perform any additional visualizations and analyses that make sense. Lastly, add some interpretive writing that explains the nature of your data, the types of analyses you performed at each step, your outcomes or findings from each, and the conclusions that you might draw from each finding.\nThe overall goal is to create something like a report to share with a collaborator or your PI, or should your work be far enough along the skeleton of a manuscript that can submitted for subsequent publication.\nDue: Submit your work via Canvas by the end of the day (midnight) on Friday, June 13th. Please submit both the Quarto_md file and the resulting html or pdf file."
  }
]